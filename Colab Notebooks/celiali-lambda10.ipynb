{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"celiali-lambda10.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPVfs9gIJONMeyS8kyV2tLo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"JBOXEZmB2wG1","executionInfo":{"status":"ok","timestamp":1650685921624,"user_tz":300,"elapsed":129789,"user":{"displayName":"CM Y","userId":"12660552299343911788"}},"outputId":"d23131ef-60e4-4b36-f0fd-212e4252af01"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/celiali\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 2)) (1.0.0)\n","Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 3)) (1.9)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 4)) (0.29.28)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 5)) (1.21.6)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 7)) (4.64.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 8)) (1.4.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 9)) (7.1.2)\n","Collecting torch==1.8.0\n","  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n","\u001b[K     |████████████████████████████████| 735.5 MB 15 kB/s \n","\u001b[?25hCollecting torchvision==0.9.0\n","  Downloading torchvision-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n","\u001b[K     |████████████████████████████████| 17.3 MB 31.4 MB/s \n","\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 12)) (0.10.0+cu111)\n","Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 13)) (0.11.0)\n","Collecting omegaconf\n","  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\n","\u001b[K     |████████████████████████████████| 74 kB 4.1 MB/s \n","\u001b[?25hCollecting hydra\n","  Downloading Hydra-2.5.tar.gz (82 kB)\n","\u001b[K     |████████████████████████████████| 82 kB 313 kB/s \n","\u001b[?25hCollecting hydra-core\n","  Downloading hydra_core-1.1.2-py3-none-any.whl (147 kB)\n","\u001b[K     |████████████████████████████████| 147 kB 72.0 MB/s \n","\u001b[?25hCollecting ignite\n","  Downloading ignite-1.1.0-py2.py3-none-any.whl (4.5 kB)\n","Collecting pytorch-ignite\n","  Downloading pytorch_ignite-0.4.8-py3-none-any.whl (251 kB)\n","\u001b[K     |████████████████████████████████| 251 kB 70.1 MB/s \n","\u001b[?25hCollecting tensorboardX\n","  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 71.5 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 20)) (1.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 21)) (3.2.2)\n","Collecting abel-pytorch\n","  Downloading abel_pytorch-0.0.1-py3-none-any.whl (4.2 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r google_requirements.txt (line 10)) (4.1.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->-r google_requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.44.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (13.0.0)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 69.9 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (57.4.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.1.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.1.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.17.3)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.6.3)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.14.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.24.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.3.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.1.2)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.2.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.5.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->-r google_requirements.txt (line 6)) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->-r google_requirements.txt (line 6)) (1.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.3.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.35.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.0.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.2.0)\n","Collecting torchaudio\n","  Downloading torchaudio-0.11.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 47.6 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 55.3 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 55.1 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 61.8 MB/s \n","\u001b[?25h  Downloading torchaudio-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 62.4 MB/s \n","\u001b[?25h  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 41.4 MB/s \n","\u001b[?25h  Downloading torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 53.9 MB/s \n","\u001b[?25h  Downloading torchaudio-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 53.2 MB/s \n","\u001b[?25hCollecting torchtext\n","  Downloading torchtext-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n","\u001b[K     |████████████████████████████████| 10.4 MB 53.3 MB/s \n","\u001b[?25h  Downloading torchtext-0.11.2-cp37-cp37m-manylinux1_x86_64.whl (8.0 MB)\n","\u001b[K     |████████████████████████████████| 8.0 MB 58.6 MB/s \n","\u001b[?25h  Downloading torchtext-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (8.0 MB)\n","\u001b[K     |████████████████████████████████| 8.0 MB 56.7 MB/s \n","\u001b[?25h  Downloading torchtext-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 59.7 MB/s \n","\u001b[?25h  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 62.4 MB/s \n","\u001b[?25h  Downloading torchtext-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 26.4 MB/s \n","\u001b[?25h  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 36.4 MB/s \n","\u001b[?25hCollecting PyYAML>=5.1.0\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 67.7 MB/s \n","\u001b[?25hCollecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 73.3 MB/s \n","\u001b[?25hCollecting importlib-resources<5.3\n","  Downloading importlib_resources-5.2.3-py3-none-any.whl (27 kB)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r google_requirements.txt (line 20)) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r google_requirements.txt (line 20)) (1.1.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (3.0.8)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (1.4.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (0.11.0)\n","Building wheels for collected packages: antlr4-python3-runtime, hydra\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=4582ba4d71e54f817c0db05a6773b40f4a1e92f5e791f35bffce2fb06ad3b5cd\n","  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n","  Building wheel for hydra (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hydra: filename=Hydra-2.5-cp37-cp37m-linux_x86_64.whl size=220761 sha256=6a98ea1931517db2ca839377ec9dc11c694952e68498708d221243c551336029\n","  Stored in directory: /root/.cache/pip/wheels/46/28/7d/3b38a41d900da90c4e17576f442bac9344eb1f5a4e78ee9f83\n","Successfully built antlr4-python3-runtime hydra\n","Installing collected packages: PyYAML, antlr4-python3-runtime, torch, tf-estimator-nightly, omegaconf, importlib-resources, torchvision, torchtext, torchaudio, tensorboardX, pytorch-ignite, ignite, hydra-core, hydra, abel-pytorch\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","  Attempting uninstall: importlib-resources\n","    Found existing installation: importlib-resources 5.7.0\n","    Uninstalling importlib-resources-5.7.0:\n","      Successfully uninstalled importlib-resources-5.7.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.11.1+cu111\n","    Uninstalling torchvision-0.11.1+cu111:\n","      Successfully uninstalled torchvision-0.11.1+cu111\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.11.0\n","    Uninstalling torchtext-0.11.0:\n","      Successfully uninstalled torchtext-0.11.0\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.10.0+cu111\n","    Uninstalling torchaudio-0.10.0+cu111:\n","      Successfully uninstalled torchaudio-0.10.0+cu111\n","Successfully installed PyYAML-6.0 abel-pytorch-0.0.1 antlr4-python3-runtime-4.8 hydra-2.5 hydra-core-1.1.2 ignite-1.1.0 importlib-resources-5.2.3 omegaconf-2.1.2 pytorch-ignite-0.4.8 tensorboardX-2.5 tf-estimator-nightly-2.8.0.dev2021122109 torch-1.8.0 torchaudio-0.8.0 torchtext-0.9.0 torchvision-0.9.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{}}],"source":["# Mount into drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","# Change directory to the package folder\n","%cd '/content/drive/MyDrive/celiali'\n","%pip install -r google_requirements.txt"]},{"cell_type":"code","source":["!python run.py DATASET.label_num=4000 DATASET.strongaugment='RA' EXPERIMENT.epoch_n=120 EXPERIMENT.batch_size=64 MODEL.name='WideResNet_Lk' MODEL.depth=28 MODEL.widen_factor=2 MODEL.num_classes=10 EXPERIMENT.out_model='./checkpoints/checkpoints_celiali-lambda_unlabled_10/' EXPERIMENT.log_path='./outputs/outputs_lambda_unlabled_10/' EXPERIMENT.save_cfmatrix=False EXPERIMENT.decay_type='cosine' DATASET.cut_type='cutout' EXPERIMENT.lambda_unlabeled=10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vADjNjAA256Y","outputId":"7b378cde-b075-471d-9ea3-ecd5a3792650"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==> CONFIG is: \n"," DATASET:\n","  project_dir: ./\n","  data_dir: data\n","  loading_data: LOAD_LABEL_UNLABEL\n","  dataset: CIFAR10\n","  strongaugment: RA\n","  cut_type: cutout\n","  label_num: 4000\n","  num_expand_x: 65536\n","  mu: 7\n","  barely: false\n","  add_noisy_label: false\n","  both_strong: false\n","MODEL:\n","  name: WideResNet_Lk\n","  depth: 28\n","  widen_factor: 2\n","  num_classes: 10\n","  dropout: 0.0\n","  cardinality: 4\n","  width: 4\n","  base_width: 4\n","EXPERIMENT:\n","  name: FMExperiment\n","  out_model: ./checkpoints/checkpoints_celiali-lambda_unlabled_10/\n","  log_path: ./outputs/outputs_lambda_unlabled_10/\n","  used_gpu: true\n","  decay_type: cosine\n","  abel_decay: 0.1\n","  optim_lr: 0.03\n","  optim_momentum: 0.9\n","  used_nesterov: true\n","  warmup: 0\n","  wdecay: 0.0005\n","  clip: 1\n","  ema_used: true\n","  ema_decay: 0.999\n","  threshold: 0.95\n","  lambda_unlabeled: 10\n","  batch_size: 64\n","  num_workers: 4\n","  n_imgs_per_epoch: 65536\n","  epoch_n: 120\n","  save_every: 2\n","  save_matrix_every: 20\n","  resume: false\n","  resume_checkpoints: ./checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar\n","  save_cfmatrix: false\n","  batch_balanced: false\n","  neg_penalty: false\n","  equal_freq: false\n","  eta_negpenalty: 0.05\n","  eta_dynamic: false\n","  use_nlloss: false\n","  q: 0.0001\n","Logging:\n","  name: FM\n","  seed: 1265\n"," \n","\n","2022-04-22 20:03:14,729 - INFO - Train -   {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'cut_type': 'cutout', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-lambda_unlabled_10/', 'log_path': './outputs/outputs_lambda_unlabled_10/', 'used_gpu': True, 'decay_type': 'cosine', 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 10, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': False, 'resume_checkpoints': './checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","[2022-04-22 20:03:14,729][Train][INFO] - {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'cut_type': 'cutout', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-lambda_unlabled_10/', 'log_path': './outputs/outputs_lambda_unlabled_10/', 'used_gpu': True, 'decay_type': 'cosine', 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 10, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': False, 'resume_checkpoints': './checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","2022-04-22 20:03:15,120 - INFO - Train -   [Model] Building model WideResNet_Lk\n","[2022-04-22 20:03:15,120][Train][INFO] - [Model] Building model WideResNet_Lk\n","2022-04-22 20:03:17,782 - INFO - Train -   Total params: 1.47M\n","[2022-04-22 20:03:17,782][Train][INFO] - Total params: 1.47M\n","[2022-04-22 20:03:17,784][experiments.experiment][INFO] - I'm using cosine decay!\n","[2022-04-22 20:03:17,789][experiments.experiment][INFO] - [EMA] initial \n","[2022-04-22 20:03:23,836][datasets.datasets1][INFO] - Dataset: CIFAR10\n","[2022-04-22 20:03:23,890][datasets.datasets1][INFO] - Labeled examples: 65536 Unlabeled examples: 458752Validation examples: 5000\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-22 20:03:23,891][experiments.experiment][INFO] - Loading Labelled Loader\n","[2022-04-22 20:03:23,892][experiments.experiment][INFO] - Loading Unlabelled Loader\n","[2022-04-22 20:03:23,892][experiments.experiment][INFO] - Loading Validation Loader\n","[2022-04-22 20:03:23,903][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 20:13:45,082][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 0: use 621.2804529666901 seconds\n","--- Optimizer learning rate changed from inf to 3.00e-02 ---\n","[2022-04-22 20:13:45,183][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:13:47,464][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 20:13:47,465][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:13:49,835][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 20:13:49,915][experiments.experiment][INFO] - [EMA] Epoch 0.[Train] time:621.2804529666901 seconds, lr:0.0300, train_loss: 1.6375, unlabeled_losses_real_strong:2.2823,corrrect_unlabeled_num:25327.0,pro_above_threshold_num:27437.0,unlabelled_weak_top1_acc:49.78267070185393,unlabelled_weak_top5_acc:92.43926885351539  \n","[2022-04-22 20:13:49,916][experiments.experiment][INFO] - [EMA] Epoch 0. [Validation] raw_testing_loss: 1.7257, raw test Top1 acc:42.8, raw test Top5 acc: 89.3, ema_testing_loss: 1.5830, ema test Top1 acc:44.64, ema test Top5 acc: 91.14\n","[2022-04-22 20:13:50,057][experiments.experiment][INFO] - [Checkpoints] Epoch 0, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-22 20:13:50,059][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 20:24:14,729][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 1: use 624.7736458778381 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-22 20:24:14,833][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:24:17,317][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 20:24:17,317][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:24:19,666][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 20:24:19,667][experiments.experiment][INFO] - [EMA] Epoch 1.[Train] time:624.7736458778381 seconds, lr:0.0300, train_loss: 2.1568, unlabeled_losses_real_strong:2.0431,corrrect_unlabeled_num:106765.0,pro_above_threshold_num:113279.0,unlabelled_weak_top1_acc:63.46261080354452,unlabelled_weak_top5_acc:96.33418378978968  \n","[2022-04-22 20:24:19,669][experiments.experiment][INFO] - [EMA] Epoch 1. [Validation] raw_testing_loss: 2.0259, raw test Top1 acc:34.8, raw test Top5 acc: 82.8, ema_testing_loss: 1.1160, ema test Top1 acc:60.26, ema test Top5 acc: 95.74\n","[2022-04-22 20:24:19,865][experiments.experiment][INFO] - [Checkpoints] Epoch 1, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-22 20:24:19,866][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 20:34:49,085][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 2: use 629.3361659049988 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-22 20:34:49,202][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:34:51,687][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 20:34:51,687][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:34:54,064][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 20:34:54,065][experiments.experiment][INFO] - [EMA] Epoch 2.[Train] time:629.3361659049988 seconds, lr:0.0300, train_loss: 2.2997, unlabeled_losses_real_strong:1.7013,corrrect_unlabeled_num:151011.0,pro_above_threshold_num:159015.0,unlabelled_weak_top1_acc:68.77986248582602,unlabelled_weak_top5_acc:97.2819725126028  \n","[2022-04-22 20:34:54,068][experiments.experiment][INFO] - [EMA] Epoch 2. [Validation] raw_testing_loss: 2.3973, raw test Top1 acc:31.34, raw test Top5 acc: 80.96, ema_testing_loss: 0.9110, ema test Top1 acc:67.98, ema test Top5 acc: 97.24\n","[2022-04-22 20:34:54,069][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 20:45:17,989][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 3: use 624.0206577777863 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-22 20:45:18,089][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:45:20,572][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 20:45:20,573][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:45:22,842][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 20:45:22,843][experiments.experiment][INFO] - [EMA] Epoch 3.[Train] time:624.0206577777863 seconds, lr:0.0300, train_loss: 2.4871, unlabeled_losses_real_strong:1.4256,corrrect_unlabeled_num:189553.0,pro_above_threshold_num:199014.0,unlabelled_weak_top1_acc:73.21472052484751,unlabelled_weak_top5_acc:98.00589329004288  \n","[2022-04-22 20:45:22,846][experiments.experiment][INFO] - [EMA] Epoch 3. [Validation] raw_testing_loss: 2.6991, raw test Top1 acc:33.08, raw test Top5 acc: 88.68, ema_testing_loss: 0.7805, ema test Top1 acc:73.18, ema test Top5 acc: 98.06\n","[2022-04-22 20:45:22,997][experiments.experiment][INFO] - [Checkpoints] Epoch 3, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-22 20:45:23,005][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 20:56:00,967][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 4: use 638.0577189922333 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-22 20:56:01,063][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:56:03,501][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 20:56:03,502][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:56:05,793][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 20:56:05,794][experiments.experiment][INFO] - [EMA] Epoch 4.[Train] time:638.0577189922333 seconds, lr:0.0300, train_loss: 2.5940, unlabeled_losses_real_strong:1.2302,corrrect_unlabeled_num:221199.0,pro_above_threshold_num:231128.0,unlabelled_weak_top1_acc:76.71465066075325,unlabelled_weak_top5_acc:98.45253974199295  \n","[2022-04-22 20:56:05,796][experiments.experiment][INFO] - [EMA] Epoch 4. [Validation] raw_testing_loss: 2.0682, raw test Top1 acc:41.18, raw test Top5 acc: 92.2, ema_testing_loss: 0.6897, ema test Top1 acc:77.1, ema test Top5 acc: 98.72\n","[2022-04-22 20:56:05,796][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 21:06:34,495][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 5: use 628.7962012290955 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 2.99e-02 ---\n","[2022-04-22 21:06:34,592][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:06:37,049][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 21:06:37,050][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:06:39,389][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 21:06:39,390][experiments.experiment][INFO] - [EMA] Epoch 5.[Train] time:628.7962012290955 seconds, lr:0.0299, train_loss: 2.6115, unlabeled_losses_real_strong:1.1291,corrrect_unlabeled_num:244342.0,pro_above_threshold_num:254613.0,unlabelled_weak_top1_acc:79.07387761026621,unlabelled_weak_top5_acc:98.72000419348478  \n","[2022-04-22 21:06:39,392][experiments.experiment][INFO] - [EMA] Epoch 5. [Validation] raw_testing_loss: 1.3393, raw test Top1 acc:60.44, raw test Top5 acc: 93.9, ema_testing_loss: 0.6194, ema test Top1 acc:80.16, ema test Top5 acc: 98.96\n","[2022-04-22 21:06:39,539][experiments.experiment][INFO] - [Checkpoints] Epoch 5, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-22 21:06:39,540][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 21:17:03,569][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 6: use 624.1301786899567 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.99e-02 ---\n","[2022-04-22 21:17:03,671][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:17:06,123][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 21:17:06,123][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:17:08,717][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 21:17:08,719][experiments.experiment][INFO] - [EMA] Epoch 6.[Train] time:624.1301786899567 seconds, lr:0.0299, train_loss: 2.6092, unlabeled_losses_real_strong:1.0629,corrrect_unlabeled_num:259464.0,pro_above_threshold_num:269589.0,unlabelled_weak_top1_acc:80.80204442888498,unlabelled_weak_top5_acc:98.87019427865744  \n","[2022-04-22 21:17:08,720][experiments.experiment][INFO] - [EMA] Epoch 6. [Validation] raw_testing_loss: 1.6088, raw test Top1 acc:57.94, raw test Top5 acc: 93.32, ema_testing_loss: 0.5757, ema test Top1 acc:81.68, ema test Top5 acc: 99.04\n","[2022-04-22 21:17:08,722][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 21:27:31,919][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 7: use 623.300817489624 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.99e-02 ---\n","[2022-04-22 21:27:32,023][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:27:34,526][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 21:27:34,526][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:27:36,820][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 21:27:36,821][experiments.experiment][INFO] - [EMA] Epoch 7.[Train] time:623.300817489624 seconds, lr:0.0299, train_loss: 2.6189, unlabeled_losses_real_strong:1.0084,corrrect_unlabeled_num:272008.0,pro_above_threshold_num:282132.0,unlabelled_weak_top1_acc:82.13348285853863,unlabelled_weak_top5_acc:98.99030262231827  \n","[2022-04-22 21:27:36,824][experiments.experiment][INFO] - [EMA] Epoch 7. [Validation] raw_testing_loss: 0.8086, raw test Top1 acc:74.38, raw test Top5 acc: 97.96, ema_testing_loss: 0.5268, ema test Top1 acc:83.14, ema test Top5 acc: 99.3\n","[2022-04-22 21:27:36,970][experiments.experiment][INFO] - [Checkpoints] Epoch 7, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-22 21:27:36,972][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 21:38:05,860][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 8: use 628.9920868873596 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.98e-02 ---\n","[2022-04-22 21:38:05,964][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:38:08,240][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 21:38:08,240][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:38:10,695][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 21:38:10,696][experiments.experiment][INFO] - [EMA] Epoch 8.[Train] time:628.9920868873596 seconds, lr:0.0298, train_loss: 2.6109, unlabeled_losses_real_strong:0.9600,corrrect_unlabeled_num:282123.0,pro_above_threshold_num:292007.0,unlabelled_weak_top1_acc:83.1896089464426,unlabelled_weak_top5_acc:99.09253656864166  \n","[2022-04-22 21:38:10,698][experiments.experiment][INFO] - [EMA] Epoch 8. [Validation] raw_testing_loss: 1.3024, raw test Top1 acc:63.66, raw test Top5 acc: 95.74, ema_testing_loss: 0.4891, ema test Top1 acc:84.62, ema test Top5 acc: 99.4\n","[2022-04-22 21:38:10,699][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 21:48:43,723][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 9: use 633.1222853660583 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.98e-02 ---\n","[2022-04-22 21:48:43,822][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:48:46,249][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 21:48:46,249][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:48:48,745][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 21:48:48,746][experiments.experiment][INFO] - [EMA] Epoch 9.[Train] time:633.1222853660583 seconds, lr:0.0298, train_loss: 2.6410, unlabeled_losses_real_strong:0.9227,corrrect_unlabeled_num:291470.0,pro_above_threshold_num:301334.0,unlabelled_weak_top1_acc:84.03211204707623,unlabelled_weak_top5_acc:99.14528844505548  \n","[2022-04-22 21:48:48,747][experiments.experiment][INFO] - [EMA] Epoch 9. [Validation] raw_testing_loss: 0.6086, raw test Top1 acc:80.76, raw test Top5 acc: 98.88, ema_testing_loss: 0.4642, ema test Top1 acc:85.42, ema test Top5 acc: 99.32\n","[2022-04-22 21:48:48,892][experiments.experiment][INFO] - [Checkpoints] Epoch 9, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-22 21:48:48,898][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 21:59:20,359][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 10: use 631.5630927085876 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.98e-02 ---\n","[2022-04-22 21:59:20,461][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:59:22,792][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 21:59:22,793][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:59:25,295][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 21:59:25,296][experiments.experiment][INFO] - [EMA] Epoch 10.[Train] time:631.5630927085876 seconds, lr:0.0298, train_loss: 2.6554, unlabeled_losses_real_strong:0.8847,corrrect_unlabeled_num:299421.0,pro_above_threshold_num:309227.0,unlabelled_weak_top1_acc:84.828184902668,unlabelled_weak_top5_acc:99.20065595209599  \n","[2022-04-22 21:59:25,299][experiments.experiment][INFO] - [EMA] Epoch 10. [Validation] raw_testing_loss: 0.6979, raw test Top1 acc:77.74, raw test Top5 acc: 98.5, ema_testing_loss: 0.4359, ema test Top1 acc:86.58, ema test Top5 acc: 99.48\n","[2022-04-22 21:59:25,299][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 22:10:06,918][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 11: use 641.7236840724945 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.97e-02 ---\n","[2022-04-22 22:10:07,023][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:10:09,487][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 22:10:09,488][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:10:11,738][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 22:10:11,740][experiments.experiment][INFO] - [EMA] Epoch 11.[Train] time:641.7236840724945 seconds, lr:0.0297, train_loss: 2.6518, unlabeled_losses_real_strong:0.8582,corrrect_unlabeled_num:306706.0,pro_above_threshold_num:316357.0,unlabelled_weak_top1_acc:85.58632884174585,unlabelled_weak_top5_acc:99.24861244112253  \n","[2022-04-22 22:10:11,742][experiments.experiment][INFO] - [EMA] Epoch 11. [Validation] raw_testing_loss: 0.7558, raw test Top1 acc:77.86, raw test Top5 acc: 98.56, ema_testing_loss: 0.4115, ema test Top1 acc:87.44, ema test Top5 acc: 99.54\n","[2022-04-22 22:10:11,894][experiments.experiment][INFO] - [Checkpoints] Epoch 11, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-22 22:10:11,897][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 22:20:51,978][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 12: use 640.2013471126556 seconds\n","--- Optimizer learning rate changed from 2.97e-02 to 2.97e-02 ---\n","[2022-04-22 22:20:52,098][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:20:54,803][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 22:20:54,803][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:20:57,423][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 22:20:57,425][experiments.experiment][INFO] - [EMA] Epoch 12.[Train] time:640.2013471126556 seconds, lr:0.0297, train_loss: 2.6501, unlabeled_losses_real_strong:0.8358,corrrect_unlabeled_num:312826.0,pro_above_threshold_num:322539.0,unlabelled_weak_top1_acc:86.21826067566872,unlabelled_weak_top5_acc:99.30267208814621  \n","[2022-04-22 22:20:57,426][experiments.experiment][INFO] - [EMA] Epoch 12. [Validation] raw_testing_loss: 0.6242, raw test Top1 acc:80.02, raw test Top5 acc: 98.78, ema_testing_loss: 0.3959, ema test Top1 acc:87.88, ema test Top5 acc: 99.6\n","[2022-04-22 22:20:57,428][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 22:31:38,337][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 13: use 641.0100531578064 seconds\n","--- Optimizer learning rate changed from 2.97e-02 to 2.96e-02 ---\n","[2022-04-22 22:31:38,438][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:31:40,701][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 22:31:40,701][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:31:42,994][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 22:31:42,996][experiments.experiment][INFO] - [EMA] Epoch 13.[Train] time:641.0100531578064 seconds, lr:0.0296, train_loss: 2.6521, unlabeled_losses_real_strong:0.8109,corrrect_unlabeled_num:317935.0,pro_above_threshold_num:327345.0,unlabelled_weak_top1_acc:86.65705971419811,unlabelled_weak_top5_acc:99.33231783658266  \n","[2022-04-22 22:31:42,998][experiments.experiment][INFO] - [EMA] Epoch 13. [Validation] raw_testing_loss: 0.9440, raw test Top1 acc:73.76, raw test Top5 acc: 98.34, ema_testing_loss: 0.3854, ema test Top1 acc:88.14, ema test Top5 acc: 99.66\n","[2022-04-22 22:31:43,179][experiments.experiment][INFO] - [Checkpoints] Epoch 13, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-22 22:31:43,186][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 22:42:27,358][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 14: use 644.2833826541901 seconds\n","--- Optimizer learning rate changed from 2.96e-02 to 2.96e-02 ---\n","[2022-04-22 22:42:27,469][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:42:29,758][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 22:42:29,759][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:42:32,234][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 22:42:32,236][experiments.experiment][INFO] - [EMA] Epoch 14.[Train] time:644.2833826541901 seconds, lr:0.0296, train_loss: 2.6470, unlabeled_losses_real_strong:0.7910,corrrect_unlabeled_num:323481.0,pro_above_threshold_num:333177.0,unlabelled_weak_top1_acc:87.13291607797146,unlabelled_weak_top5_acc:99.34692274779081  \n","[2022-04-22 22:42:32,238][experiments.experiment][INFO] - [EMA] Epoch 14. [Validation] raw_testing_loss: 0.5306, raw test Top1 acc:82.4, raw test Top5 acc: 99.14, ema_testing_loss: 0.3669, ema test Top1 acc:88.4, ema test Top5 acc: 99.66\n","[2022-04-22 22:42:32,239][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 22:53:13,527][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 15: use 641.3871273994446 seconds\n","--- Optimizer learning rate changed from 2.96e-02 to 2.95e-02 ---\n","[2022-04-22 22:53:13,627][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:53:16,184][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 22:53:16,185][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:53:18,574][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 22:53:18,576][experiments.experiment][INFO] - [EMA] Epoch 15.[Train] time:641.3871273994446 seconds, lr:0.0295, train_loss: 2.6564, unlabeled_losses_real_strong:0.7733,corrrect_unlabeled_num:328081.0,pro_above_threshold_num:337717.0,unlabelled_weak_top1_acc:87.59852713346481,unlabelled_weak_top5_acc:99.38877564668655  \n","[2022-04-22 22:53:18,577][experiments.experiment][INFO] - [EMA] Epoch 15. [Validation] raw_testing_loss: 0.5690, raw test Top1 acc:82.44, raw test Top5 acc: 98.92, ema_testing_loss: 0.3596, ema test Top1 acc:89.06, ema test Top5 acc: 99.66\n","[2022-04-22 22:53:18,719][experiments.experiment][INFO] - [Checkpoints] Epoch 15, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-22 22:53:18,720][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 23:03:52,602][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 16: use 633.9818568229675 seconds\n","--- Optimizer learning rate changed from 2.95e-02 to 2.94e-02 ---\n","[2022-04-22 23:03:52,702][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:03:55,090][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 23:03:55,090][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:03:57,597][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 23:03:57,599][experiments.experiment][INFO] - [EMA] Epoch 16.[Train] time:633.9818568229675 seconds, lr:0.0294, train_loss: 2.6452, unlabeled_losses_real_strong:0.7586,corrrect_unlabeled_num:331146.0,pro_above_threshold_num:340647.0,unlabelled_weak_top1_acc:87.86403012275696,unlabelled_weak_top5_acc:99.41667742282152  \n","[2022-04-22 23:03:57,600][experiments.experiment][INFO] - [EMA] Epoch 16. [Validation] raw_testing_loss: 0.5001, raw test Top1 acc:84.6, raw test Top5 acc: 99.12, ema_testing_loss: 0.3455, ema test Top1 acc:89.6, ema test Top5 acc: 99.78\n","[2022-04-22 23:03:57,601][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 23:14:26,628][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 17: use 629.1338014602661 seconds\n","--- Optimizer learning rate changed from 2.94e-02 to 2.94e-02 ---\n","[2022-04-22 23:14:26,734][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:14:29,088][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 23:14:29,089][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:14:31,524][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 23:14:31,526][experiments.experiment][INFO] - [EMA] Epoch 17.[Train] time:629.1338014602661 seconds, lr:0.0294, train_loss: 2.6384, unlabeled_losses_real_strong:0.7506,corrrect_unlabeled_num:334030.0,pro_above_threshold_num:343507.0,unlabelled_weak_top1_acc:88.19579972326756,unlabelled_weak_top5_acc:99.41689544916153  \n","[2022-04-22 23:14:31,528][experiments.experiment][INFO] - [EMA] Epoch 17. [Validation] raw_testing_loss: 0.8107, raw test Top1 acc:79.1, raw test Top5 acc: 98.56, ema_testing_loss: 0.3343, ema test Top1 acc:89.9, ema test Top5 acc: 99.68\n","[2022-04-22 23:14:31,672][experiments.experiment][INFO] - [Checkpoints] Epoch 17, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-22 23:14:31,680][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 23:25:09,799][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 18: use 638.2176969051361 seconds\n","--- Optimizer learning rate changed from 2.94e-02 to 2.93e-02 ---\n","[2022-04-22 23:25:09,898][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:25:12,360][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 23:25:12,360][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:25:14,749][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 23:25:14,751][experiments.experiment][INFO] - [EMA] Epoch 18.[Train] time:638.2176969051361 seconds, lr:0.0293, train_loss: 2.6411, unlabeled_losses_real_strong:0.7365,corrrect_unlabeled_num:337467.0,pro_above_threshold_num:346998.0,unlabelled_weak_top1_acc:88.4392863214016,unlabelled_weak_top5_acc:99.4565684646368  \n","[2022-04-22 23:25:14,753][experiments.experiment][INFO] - [EMA] Epoch 18. [Validation] raw_testing_loss: 0.6105, raw test Top1 acc:81.62, raw test Top5 acc: 99.1, ema_testing_loss: 0.3311, ema test Top1 acc:90.2, ema test Top5 acc: 99.7\n","[2022-04-22 23:25:14,754][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 23:35:51,603][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 19: use 636.9576072692871 seconds\n","--- Optimizer learning rate changed from 2.93e-02 to 2.92e-02 ---\n","[2022-04-22 23:35:51,712][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:35:54,257][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 23:35:54,257][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:35:56,618][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 23:35:56,620][experiments.experiment][INFO] - [EMA] Epoch 19.[Train] time:636.9576072692871 seconds, lr:0.0292, train_loss: 2.6164, unlabeled_losses_real_strong:0.7268,corrrect_unlabeled_num:338967.0,pro_above_threshold_num:348425.0,unlabelled_weak_top1_acc:88.70217345654964,unlabelled_weak_top5_acc:99.47487914562225  \n","[2022-04-22 23:35:56,621][experiments.experiment][INFO] - [EMA] Epoch 19. [Validation] raw_testing_loss: 0.5472, raw test Top1 acc:84.04, raw test Top5 acc: 98.94, ema_testing_loss: 0.3254, ema test Top1 acc:90.24, ema test Top5 acc: 99.84\n","[2022-04-22 23:35:56,827][experiments.experiment][INFO] - [Checkpoints] Epoch 19, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-22 23:35:56,830][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 23:46:36,539][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 20: use 639.8192675113678 seconds\n","--- Optimizer learning rate changed from 2.92e-02 to 2.91e-02 ---\n","[2022-04-22 23:46:36,649][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:46:38,911][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 23:46:38,911][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:46:41,013][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 23:46:41,015][experiments.experiment][INFO] - [EMA] Epoch 20.[Train] time:639.8192675113678 seconds, lr:0.0291, train_loss: 2.6043, unlabeled_losses_real_strong:0.7154,corrrect_unlabeled_num:341595.0,pro_above_threshold_num:350790.0,unlabelled_weak_top1_acc:88.93846673518419,unlabelled_weak_top5_acc:99.48468821495771  \n","[2022-04-22 23:46:41,017][experiments.experiment][INFO] - [EMA] Epoch 20. [Validation] raw_testing_loss: 0.4684, raw test Top1 acc:85.12, raw test Top5 acc: 98.82, ema_testing_loss: 0.3205, ema test Top1 acc:90.38, ema test Top5 acc: 99.84\n","[2022-04-22 23:46:41,018][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 23:57:21,547][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 21: use 640.6313409805298 seconds\n","--- Optimizer learning rate changed from 2.91e-02 to 2.91e-02 ---\n","[2022-04-22 23:57:21,649][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:57:23,810][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 23:57:23,811][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:57:26,349][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 23:57:26,350][experiments.experiment][INFO] - [EMA] Epoch 21.[Train] time:640.6313409805298 seconds, lr:0.0291, train_loss: 2.6020, unlabeled_losses_real_strong:0.7008,corrrect_unlabeled_num:344735.0,pro_above_threshold_num:353916.0,unlabelled_weak_top1_acc:89.18260740488768,unlabelled_weak_top5_acc:99.50670465826988  \n","[2022-04-22 23:57:26,352][experiments.experiment][INFO] - [EMA] Epoch 21. [Validation] raw_testing_loss: 0.4679, raw test Top1 acc:86.44, raw test Top5 acc: 99.18, ema_testing_loss: 0.3124, ema test Top1 acc:90.82, ema test Top5 acc: 99.84\n","[2022-04-22 23:57:26,497][experiments.experiment][INFO] - [Checkpoints] Epoch 21, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-22 23:57:26,506][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 00:08:04,746][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 22: use 638.3445196151733 seconds\n","--- Optimizer learning rate changed from 2.91e-02 to 2.90e-02 ---\n","[2022-04-23 00:08:04,850][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:08:07,293][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 00:08:07,293][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:08:09,628][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 00:08:09,631][experiments.experiment][INFO] - [EMA] Epoch 22.[Train] time:638.3445196151733 seconds, lr:0.0290, train_loss: 2.5908, unlabeled_losses_real_strong:0.6962,corrrect_unlabeled_num:346209.0,pro_above_threshold_num:355333.0,unlabelled_weak_top1_acc:89.35394182801247,unlabelled_weak_top5_acc:99.5282850265503  \n","[2022-04-23 00:08:09,633][experiments.experiment][INFO] - [EMA] Epoch 22. [Validation] raw_testing_loss: 0.6206, raw test Top1 acc:83.18, raw test Top5 acc: 99.04, ema_testing_loss: 0.3082, ema test Top1 acc:90.76, ema test Top5 acc: 99.86\n","[2022-04-23 00:08:09,634][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 00:18:45,638][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 23: use 636.122481584549 seconds\n","--- Optimizer learning rate changed from 2.90e-02 to 2.89e-02 ---\n","[2022-04-23 00:18:45,756][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:18:48,302][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 00:18:48,302][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:18:50,846][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 00:18:50,849][experiments.experiment][INFO] - [EMA] Epoch 23.[Train] time:636.122481584549 seconds, lr:0.0289, train_loss: 2.5929, unlabeled_losses_real_strong:0.6865,corrrect_unlabeled_num:348524.0,pro_above_threshold_num:357551.0,unlabelled_weak_top1_acc:89.5198266506195,unlabelled_weak_top5_acc:99.5319907143712  \n","[2022-04-23 00:18:50,852][experiments.experiment][INFO] - [EMA] Epoch 23. [Validation] raw_testing_loss: 0.5557, raw test Top1 acc:84.4, raw test Top5 acc: 99.0, ema_testing_loss: 0.3002, ema test Top1 acc:91.06, ema test Top5 acc: 99.86\n","[2022-04-23 00:18:50,991][experiments.experiment][INFO] - [Checkpoints] Epoch 23, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 00:18:51,000][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 00:29:29,934][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 24: use 639.0389049053192 seconds\n","--- Optimizer learning rate changed from 2.89e-02 to 2.88e-02 ---\n","[2022-04-23 00:29:30,039][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:29:32,420][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 00:29:32,431][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:29:34,781][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 00:29:34,783][experiments.experiment][INFO] - [EMA] Epoch 24.[Train] time:639.0389049053192 seconds, lr:0.0288, train_loss: 2.5777, unlabeled_losses_real_strong:0.6789,corrrect_unlabeled_num:350485.0,pro_above_threshold_num:359476.0,unlabelled_weak_top1_acc:89.73366756737232,unlabelled_weak_top5_acc:99.55967473238707  \n","[2022-04-23 00:29:34,785][experiments.experiment][INFO] - [EMA] Epoch 24. [Validation] raw_testing_loss: 0.4864, raw test Top1 acc:85.98, raw test Top5 acc: 99.4, ema_testing_loss: 0.2960, ema test Top1 acc:91.4, ema test Top5 acc: 99.74\n","[2022-04-23 00:29:34,786][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 00:40:14,218][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 25: use 639.5330903530121 seconds\n","--- Optimizer learning rate changed from 2.88e-02 to 2.87e-02 ---\n","[2022-04-23 00:40:14,319][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:40:16,556][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 00:40:16,556][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:40:18,983][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 00:40:18,985][experiments.experiment][INFO] - [EMA] Epoch 25.[Train] time:639.5330903530121 seconds, lr:0.0287, train_loss: 2.5796, unlabeled_losses_real_strong:0.6717,corrrect_unlabeled_num:352129.0,pro_above_threshold_num:361098.0,unlabelled_weak_top1_acc:89.85617379844189,unlabelled_weak_top5_acc:99.53111881017685  \n","[2022-04-23 00:40:18,986][experiments.experiment][INFO] - [EMA] Epoch 25. [Validation] raw_testing_loss: 0.4847, raw test Top1 acc:86.14, raw test Top5 acc: 99.38, ema_testing_loss: 0.2936, ema test Top1 acc:91.08, ema test Top5 acc: 99.7\n","[2022-04-23 00:40:19,158][experiments.experiment][INFO] - [Checkpoints] Epoch 25, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 00:40:19,160][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 00:50:49,854][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 26: use 630.7974970340729 seconds\n","--- Optimizer learning rate changed from 2.87e-02 to 2.86e-02 ---\n","[2022-04-23 00:50:49,957][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:50:52,292][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 00:50:52,293][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:50:54,698][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 00:50:54,700][experiments.experiment][INFO] - [EMA] Epoch 26.[Train] time:630.7974970340729 seconds, lr:0.0286, train_loss: 2.5832, unlabeled_losses_real_strong:0.6647,corrrect_unlabeled_num:353552.0,pro_above_threshold_num:362261.0,unlabelled_weak_top1_acc:90.09333904087543,unlabelled_weak_top5_acc:99.5760234221816  \n","[2022-04-23 00:50:54,702][experiments.experiment][INFO] - [EMA] Epoch 26. [Validation] raw_testing_loss: 0.5259, raw test Top1 acc:84.86, raw test Top5 acc: 99.48, ema_testing_loss: 0.2906, ema test Top1 acc:91.34, ema test Top5 acc: 99.78\n","[2022-04-23 00:50:54,703][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 01:01:27,310][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 27: use 632.7099306583405 seconds\n","--- Optimizer learning rate changed from 2.86e-02 to 2.85e-02 ---\n","[2022-04-23 01:01:27,413][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 01:01:29,446][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 01:01:29,446][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 01:01:32,068][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 01:01:32,070][experiments.experiment][INFO] - [EMA] Epoch 27.[Train] time:632.7099306583405 seconds, lr:0.0285, train_loss: 2.5686, unlabeled_losses_real_strong:0.6585,corrrect_unlabeled_num:355383.0,pro_above_threshold_num:364132.0,unlabelled_weak_top1_acc:90.18968731164932,unlabelled_weak_top5_acc:99.57318971306086  \n","[2022-04-23 01:01:32,071][experiments.experiment][INFO] - [EMA] Epoch 27. [Validation] raw_testing_loss: 0.5535, raw test Top1 acc:85.56, raw test Top5 acc: 99.04, ema_testing_loss: 0.2829, ema test Top1 acc:91.72, ema test Top5 acc: 99.76\n","[2022-04-23 01:01:32,226][experiments.experiment][INFO] - [Checkpoints] Epoch 27, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 01:01:32,228][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 01:11:59,629][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 28: use 627.4977610111237 seconds\n","--- Optimizer learning rate changed from 2.85e-02 to 2.84e-02 ---\n","[2022-04-23 01:11:59,726][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 01:12:02,054][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 01:12:02,060][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 01:12:04,498][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 01:12:04,500][experiments.experiment][INFO] - [EMA] Epoch 28.[Train] time:627.4977610111237 seconds, lr:0.0284, train_loss: 2.5350, unlabeled_losses_real_strong:0.6498,corrrect_unlabeled_num:357018.0,pro_above_threshold_num:365724.0,unlabelled_weak_top1_acc:90.40091282874346,unlabelled_weak_top5_acc:99.59956561774015  \n","[2022-04-23 01:12:04,501][experiments.experiment][INFO] - [EMA] Epoch 28. [Validation] raw_testing_loss: 0.6008, raw test Top1 acc:84.64, raw test Top5 acc: 99.0, ema_testing_loss: 0.2811, ema test Top1 acc:91.72, ema test Top5 acc: 99.8\n","[2022-04-23 01:12:04,502][experiments.experiment][INFO] - ***** Running training *****\n"]}]},{"cell_type":"code","source":["!python run.py DATASET.label_num=4000 DATASET.strongaugment='RA' EXPERIMENT.epoch_n=120 EXPERIMENT.batch_size=64 MODEL.name='WideResNet_Lk' MODEL.depth=28 MODEL.widen_factor=2 MODEL.num_classes=10 EXPERIMENT.out_model='./checkpoints/checkpoints_celiali-lambda_unlabled_10/' EXPERIMENT.log_path='./outputs/outputs_lambda_unlabled_10/' EXPERIMENT.save_cfmatrix=False EXPERIMENT.decay_type='cosine' DATASET.cut_type='cutout' EXPERIMENT.lambda_unlabeled=10 EXPERIMENT.resume=True EXPERIMENT.resume_checkpoints='./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KGr2zKiKipOZ","executionInfo":{"status":"ok","timestamp":1650727735387,"user_tz":300,"elapsed":10484755,"user":{"displayName":"CM Y","userId":"12660552299343911788"}},"outputId":"4588f07f-e168-46c3-b5fa-472374b82241"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["==> CONFIG is: \n"," DATASET:\n","  project_dir: ./\n","  data_dir: data\n","  loading_data: LOAD_LABEL_UNLABEL\n","  dataset: CIFAR10\n","  strongaugment: RA\n","  cut_type: cutout\n","  label_num: 4000\n","  num_expand_x: 65536\n","  mu: 7\n","  barely: false\n","  add_noisy_label: false\n","  both_strong: false\n","MODEL:\n","  name: WideResNet_Lk\n","  depth: 28\n","  widen_factor: 2\n","  num_classes: 10\n","  dropout: 0.0\n","  cardinality: 4\n","  width: 4\n","  base_width: 4\n","EXPERIMENT:\n","  name: FMExperiment\n","  out_model: ./checkpoints/checkpoints_celiali-lambda_unlabled_10/\n","  log_path: ./outputs/outputs_lambda_unlabled_10/\n","  used_gpu: true\n","  decay_type: cosine\n","  abel_decay: 0.1\n","  optim_lr: 0.03\n","  optim_momentum: 0.9\n","  used_nesterov: true\n","  warmup: 0\n","  wdecay: 0.0005\n","  clip: 1\n","  ema_used: true\n","  ema_decay: 0.999\n","  threshold: 0.95\n","  lambda_unlabeled: 10\n","  batch_size: 64\n","  num_workers: 4\n","  n_imgs_per_epoch: 65536\n","  epoch_n: 120\n","  save_every: 2\n","  save_matrix_every: 20\n","  resume: true\n","  resume_checkpoints: ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","  save_cfmatrix: false\n","  batch_balanced: false\n","  neg_penalty: false\n","  equal_freq: false\n","  eta_negpenalty: 0.05\n","  eta_dynamic: false\n","  use_nlloss: false\n","  q: 0.0001\n","Logging:\n","  name: FM\n","  seed: 1265\n"," \n","\n","2022-04-23 03:52:20,857 - INFO - Train -   {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'cut_type': 'cutout', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-lambda_unlabled_10/', 'log_path': './outputs/outputs_lambda_unlabled_10/', 'used_gpu': True, 'decay_type': 'cosine', 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 10, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': True, 'resume_checkpoints': './checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","[2022-04-23 03:52:20,857][Train][INFO] - {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'cut_type': 'cutout', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-lambda_unlabled_10/', 'log_path': './outputs/outputs_lambda_unlabled_10/', 'used_gpu': True, 'decay_type': 'cosine', 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 10, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': True, 'resume_checkpoints': './checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","2022-04-23 03:52:21,439 - INFO - Train -   [Model] Building model WideResNet_Lk\n","[2022-04-23 03:52:21,439][Train][INFO] - [Model] Building model WideResNet_Lk\n","2022-04-23 03:52:23,844 - INFO - Train -   Total params: 1.47M\n","[2022-04-23 03:52:23,844][Train][INFO] - Total params: 1.47M\n","[2022-04-23 03:52:23,845][experiments.experiment][INFO] - I'm using cosine decay!\n","[2022-04-23 03:52:23,848][experiments.experiment][INFO] - [EMA] initial \n","[2022-04-23 03:52:33,569][datasets.datasets1][INFO] - Dataset: CIFAR10\n","[2022-04-23 03:52:33,620][datasets.datasets1][INFO] - Labeled examples: 65536 Unlabeled examples: 458752Validation examples: 5000\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-23 03:52:33,621][experiments.experiment][INFO] - Loading Labelled Loader\n","[2022-04-23 03:52:33,622][experiments.experiment][INFO] - Loading Unlabelled Loader\n","[2022-04-23 03:52:33,622][experiments.experiment][INFO] - Loading Validation Loader\n","=> loading checkpoint './checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar'\n","[2022-04-23 03:52:34,604][experiments.experiment][INFO] - ==> Resuming from checkpoint..\n","=> loaded checkpoint './checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar' (epoch 27)\n","[2022-04-23 03:52:35,504][experiments.experiment][INFO] - => loaded checkpoint './checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar' (epoch 27)\n","[2022-04-23 03:52:35,505][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 03:59:59,588][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 27: use 444.17597675323486 seconds\n","--- Optimizer learning rate changed from inf to 2.84e-02 ---\n","[2022-04-23 03:59:59,681][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:00:00,992][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:00:00,992][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:00:02,314][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:00:08,744][experiments.experiment][INFO] - [EMA] Epoch 27.[Train] time:444.17597675323486 seconds, lr:0.0284, train_loss: 2.5530, unlabeled_losses_real_strong:0.6518,corrrect_unlabeled_num:355730.0,pro_above_threshold_num:364478.0,unlabelled_weak_top1_acc:90.29475516825914,unlabelled_weak_top5_acc:99.57842126488686  \n","[2022-04-23 04:00:08,745][experiments.experiment][INFO] - [EMA] Epoch 27. [Validation] raw_testing_loss: 0.5486, raw test Top1 acc:84.34, raw test Top5 acc: 98.98, ema_testing_loss: 0.2781, ema test Top1 acc:91.62, ema test Top5 acc: 99.8\n","[2022-04-23 04:00:08,847][experiments.experiment][INFO] - [Checkpoints] Epoch 27, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 04:00:08,856][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:07:31,630][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 28: use 442.8694272041321 seconds\n","--- Optimizer learning rate changed from 2.84e-02 to 2.82e-02 ---\n","[2022-04-23 04:07:31,725][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:07:33,033][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:07:33,034][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:07:34,356][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:07:34,358][experiments.experiment][INFO] - [EMA] Epoch 28.[Train] time:442.8694272041321 seconds, lr:0.0282, train_loss: 2.5224, unlabeled_losses_real_strong:0.6428,corrrect_unlabeled_num:357477.0,pro_above_threshold_num:366031.0,unlabelled_weak_top1_acc:90.44995872676373,unlabelled_weak_top5_acc:99.5960780903697  \n","[2022-04-23 04:07:34,360][experiments.experiment][INFO] - [EMA] Epoch 28. [Validation] raw_testing_loss: 0.3524, raw test Top1 acc:88.62, raw test Top5 acc: 99.52, ema_testing_loss: 0.2727, ema test Top1 acc:92.0, ema test Top5 acc: 99.82\n","[2022-04-23 04:07:34,361][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:14:57,928][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 29: use 443.66268944740295 seconds\n","--- Optimizer learning rate changed from 2.82e-02 to 2.81e-02 ---\n","[2022-04-23 04:14:58,024][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:14:59,504][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:14:59,504][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:15:00,830][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:15:00,831][experiments.experiment][INFO] - [EMA] Epoch 29.[Train] time:443.66268944740295 seconds, lr:0.0281, train_loss: 2.5338, unlabeled_losses_real_strong:0.6359,corrrect_unlabeled_num:359626.0,pro_above_threshold_num:368327.0,unlabelled_weak_top1_acc:90.63676981627941,unlabelled_weak_top5_acc:99.60959295928478  \n","[2022-04-23 04:15:00,834][experiments.experiment][INFO] - [EMA] Epoch 29. [Validation] raw_testing_loss: 0.4343, raw test Top1 acc:87.12, raw test Top5 acc: 99.38, ema_testing_loss: 0.2710, ema test Top1 acc:92.0, ema test Top5 acc: 99.82\n","[2022-04-23 04:15:00,933][experiments.experiment][INFO] - [Checkpoints] Epoch 29, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 04:15:00,937][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:22:23,700][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 30: use 442.8598129749298 seconds\n","--- Optimizer learning rate changed from 2.81e-02 to 2.80e-02 ---\n","[2022-04-23 04:22:23,796][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:22:25,203][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:22:25,204][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:22:26,554][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:22:26,556][experiments.experiment][INFO] - [EMA] Epoch 30.[Train] time:442.8598129749298 seconds, lr:0.0280, train_loss: 2.5371, unlabeled_losses_real_strong:0.6327,corrrect_unlabeled_num:360252.0,pro_above_threshold_num:368926.0,unlabelled_weak_top1_acc:90.66314590722322,unlabelled_weak_top5_acc:99.6189662143588  \n","[2022-04-23 04:22:26,559][experiments.experiment][INFO] - [EMA] Epoch 30. [Validation] raw_testing_loss: 0.5269, raw test Top1 acc:85.12, raw test Top5 acc: 99.04, ema_testing_loss: 0.2690, ema test Top1 acc:91.98, ema test Top5 acc: 99.8\n","[2022-04-23 04:22:26,560][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:29:50,502][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 31: use 444.04177260398865 seconds\n","--- Optimizer learning rate changed from 2.80e-02 to 2.79e-02 ---\n","[2022-04-23 04:29:50,601][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:29:51,950][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:29:51,951][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:29:53,285][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:29:53,287][experiments.experiment][INFO] - [EMA] Epoch 31.[Train] time:444.04177260398865 seconds, lr:0.0279, train_loss: 2.5290, unlabeled_losses_real_strong:0.6273,corrrect_unlabeled_num:361594.0,pro_above_threshold_num:370224.0,unlabelled_weak_top1_acc:90.8233632221818,unlabelled_weak_top5_acc:99.61460653692484  \n","[2022-04-23 04:29:53,288][experiments.experiment][INFO] - [EMA] Epoch 31. [Validation] raw_testing_loss: 0.4140, raw test Top1 acc:87.94, raw test Top5 acc: 99.42, ema_testing_loss: 0.2672, ema test Top1 acc:91.96, ema test Top5 acc: 99.84\n","[2022-04-23 04:29:53,397][experiments.experiment][INFO] - [Checkpoints] Epoch 31, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 04:29:53,399][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:37:18,638][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 32: use 445.3402600288391 seconds\n","--- Optimizer learning rate changed from 2.79e-02 to 2.78e-02 ---\n","[2022-04-23 04:37:18,739][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:37:20,036][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:37:20,036][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:37:21,384][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:37:21,386][experiments.experiment][INFO] - [EMA] Epoch 32.[Train] time:445.3402600288391 seconds, lr:0.0278, train_loss: 2.5127, unlabeled_losses_real_strong:0.6219,corrrect_unlabeled_num:362641.0,pro_above_threshold_num:371353.0,unlabelled_weak_top1_acc:90.9090304672718,unlabelled_weak_top5_acc:99.63051927834749  \n","[2022-04-23 04:37:21,387][experiments.experiment][INFO] - [EMA] Epoch 32. [Validation] raw_testing_loss: 0.4717, raw test Top1 acc:87.8, raw test Top5 acc: 99.46, ema_testing_loss: 0.2623, ema test Top1 acc:92.16, ema test Top5 acc: 99.76\n","[2022-04-23 04:37:21,388][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:44:46,721][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 33: use 445.43115282058716 seconds\n","--- Optimizer learning rate changed from 2.78e-02 to 2.76e-02 ---\n","[2022-04-23 04:44:46,820][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:44:48,123][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:44:48,123][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:44:49,484][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:44:49,486][experiments.experiment][INFO] - [EMA] Epoch 33.[Train] time:445.43115282058716 seconds, lr:0.0276, train_loss: 2.5115, unlabeled_losses_real_strong:0.6158,corrrect_unlabeled_num:364285.0,pro_above_threshold_num:372646.0,unlabelled_weak_top1_acc:91.09060999006033,unlabelled_weak_top5_acc:99.62354393303394  \n","[2022-04-23 04:44:49,487][experiments.experiment][INFO] - [EMA] Epoch 33. [Validation] raw_testing_loss: 0.4152, raw test Top1 acc:87.46, raw test Top5 acc: 99.52, ema_testing_loss: 0.2560, ema test Top1 acc:92.48, ema test Top5 acc: 99.86\n","[2022-04-23 04:44:49,581][experiments.experiment][INFO] - [Checkpoints] Epoch 33, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 04:44:49,593][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:52:15,767][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 34: use 446.2672779560089 seconds\n","--- Optimizer learning rate changed from 2.76e-02 to 2.75e-02 ---\n","[2022-04-23 04:52:15,860][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:52:17,190][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:52:17,191][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:52:18,543][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:52:18,544][experiments.experiment][INFO] - [EMA] Epoch 34.[Train] time:446.2672779560089 seconds, lr:0.0275, train_loss: 2.5147, unlabeled_losses_real_strong:0.6139,corrrect_unlabeled_num:365010.0,pro_above_threshold_num:373451.0,unlabelled_weak_top1_acc:91.17387930303812,unlabelled_weak_top5_acc:99.6475221067667  \n","[2022-04-23 04:52:18,546][experiments.experiment][INFO] - [EMA] Epoch 34. [Validation] raw_testing_loss: 0.4479, raw test Top1 acc:86.54, raw test Top5 acc: 99.0, ema_testing_loss: 0.2564, ema test Top1 acc:92.6, ema test Top5 acc: 99.86\n","[2022-04-23 04:52:18,547][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:59:45,485][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 35: use 447.03248286247253 seconds\n","--- Optimizer learning rate changed from 2.75e-02 to 2.73e-02 ---\n","[2022-04-23 04:59:45,580][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:59:46,886][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:59:46,886][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:59:48,195][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:59:48,197][experiments.experiment][INFO] - [EMA] Epoch 35.[Train] time:447.03248286247253 seconds, lr:0.0273, train_loss: 2.4949, unlabeled_losses_real_strong:0.6084,corrrect_unlabeled_num:365797.0,pro_above_threshold_num:374114.0,unlabelled_weak_top1_acc:91.2684837281704,unlabelled_weak_top5_acc:99.63771284371614  \n","[2022-04-23 04:59:48,198][experiments.experiment][INFO] - [EMA] Epoch 35. [Validation] raw_testing_loss: 0.4239, raw test Top1 acc:87.88, raw test Top5 acc: 99.46, ema_testing_loss: 0.2552, ema test Top1 acc:92.72, ema test Top5 acc: 99.86\n","[2022-04-23 04:59:48,291][experiments.experiment][INFO] - [Checkpoints] Epoch 35, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 04:59:48,301][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:07:14,494][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 36: use 446.2963876724243 seconds\n","--- Optimizer learning rate changed from 2.73e-02 to 2.72e-02 ---\n","[2022-04-23 05:07:14,597][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:07:15,955][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:07:15,955][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:07:17,383][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:07:17,384][experiments.experiment][INFO] - [EMA] Epoch 36.[Train] time:446.2963876724243 seconds, lr:0.0272, train_loss: 2.5077, unlabeled_losses_real_strong:0.6046,corrrect_unlabeled_num:366337.0,pro_above_threshold_num:374803.0,unlabelled_weak_top1_acc:91.27960097789764,unlabelled_weak_top5_acc:99.6494839116931  \n","[2022-04-23 05:07:17,386][experiments.experiment][INFO] - [EMA] Epoch 36. [Validation] raw_testing_loss: 0.4286, raw test Top1 acc:88.18, raw test Top5 acc: 99.48, ema_testing_loss: 0.2575, ema test Top1 acc:92.46, ema test Top5 acc: 99.84\n","[2022-04-23 05:07:17,387][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:14:43,651][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 37: use 446.3563492298126 seconds\n","--- Optimizer learning rate changed from 2.72e-02 to 2.71e-02 ---\n","[2022-04-23 05:14:43,744][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:14:45,115][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:14:45,115][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:14:46,430][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:14:46,431][experiments.experiment][INFO] - [EMA] Epoch 37.[Train] time:446.3563492298126 seconds, lr:0.0271, train_loss: 2.4834, unlabeled_losses_real_strong:0.6003,corrrect_unlabeled_num:367456.0,pro_above_threshold_num:375869.0,unlabelled_weak_top1_acc:91.3452137708664,unlabelled_weak_top5_acc:99.64468827843666  \n","[2022-04-23 05:14:46,432][experiments.experiment][INFO] - [EMA] Epoch 37. [Validation] raw_testing_loss: 0.4118, raw test Top1 acc:88.34, raw test Top5 acc: 99.62, ema_testing_loss: 0.2583, ema test Top1 acc:92.6, ema test Top5 acc: 99.8\n","[2022-04-23 05:14:46,524][experiments.experiment][INFO] - [Checkpoints] Epoch 37, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 05:14:46,526][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:22:11,375][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 38: use 444.9444406032562 seconds\n","--- Optimizer learning rate changed from 2.71e-02 to 2.69e-02 ---\n","[2022-04-23 05:22:11,471][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:22:12,794][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:22:12,794][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:22:14,168][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:22:14,170][experiments.experiment][INFO] - [EMA] Epoch 38.[Train] time:444.9444406032562 seconds, lr:0.0269, train_loss: 2.4883, unlabeled_losses_real_strong:0.5943,corrrect_unlabeled_num:368732.0,pro_above_threshold_num:376915.0,unlabelled_weak_top1_acc:91.53333285450935,unlabelled_weak_top5_acc:99.66561474651098  \n","[2022-04-23 05:22:14,171][experiments.experiment][INFO] - [EMA] Epoch 38. [Validation] raw_testing_loss: 0.3492, raw test Top1 acc:89.2, raw test Top5 acc: 99.44, ema_testing_loss: 0.2548, ema test Top1 acc:92.82, ema test Top5 acc: 99.82\n","[2022-04-23 05:22:14,172][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:29:41,714][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 39: use 447.6364977359772 seconds\n","--- Optimizer learning rate changed from 2.69e-02 to 2.68e-02 ---\n","[2022-04-23 05:29:41,809][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:29:43,205][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:29:43,205][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:29:44,537][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:29:44,539][experiments.experiment][INFO] - [EMA] Epoch 39.[Train] time:447.6364977359772 seconds, lr:0.0268, train_loss: 2.4801, unlabeled_losses_real_strong:0.5910,corrrect_unlabeled_num:370295.0,pro_above_threshold_num:378574.0,unlabelled_weak_top1_acc:91.60701093822718,unlabelled_weak_top5_acc:99.66801256686449  \n","[2022-04-23 05:29:44,542][experiments.experiment][INFO] - [EMA] Epoch 39. [Validation] raw_testing_loss: 0.4671, raw test Top1 acc:86.64, raw test Top5 acc: 99.66, ema_testing_loss: 0.2519, ema test Top1 acc:92.78, ema test Top5 acc: 99.84\n","[2022-04-23 05:29:44,645][experiments.experiment][INFO] - [Checkpoints] Epoch 39, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 05:29:44,654][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:37:12,120][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 40: use 447.5698959827423 seconds\n","--- Optimizer learning rate changed from 2.68e-02 to 2.66e-02 ---\n","[2022-04-23 05:37:12,224][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:37:13,577][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:37:13,577][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:37:14,884][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:37:14,885][experiments.experiment][INFO] - [EMA] Epoch 40.[Train] time:447.5698959827423 seconds, lr:0.0266, train_loss: 2.4841, unlabeled_losses_real_strong:0.5840,corrrect_unlabeled_num:371171.0,pro_above_threshold_num:379410.0,unlabelled_weak_top1_acc:91.72973526269197,unlabelled_weak_top5_acc:99.67542405426502  \n","[2022-04-23 05:37:14,886][experiments.experiment][INFO] - [EMA] Epoch 40. [Validation] raw_testing_loss: 0.4068, raw test Top1 acc:88.12, raw test Top5 acc: 99.64, ema_testing_loss: 0.2471, ema test Top1 acc:92.84, ema test Top5 acc: 99.84\n","[2022-04-23 05:37:14,887][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:44:44,509][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 41: use 449.71286845207214 seconds\n","--- Optimizer learning rate changed from 2.66e-02 to 2.64e-02 ---\n","[2022-04-23 05:44:44,600][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:44:45,946][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:44:45,946][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:44:47,313][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:44:47,315][experiments.experiment][INFO] - [EMA] Epoch 41.[Train] time:449.71286845207214 seconds, lr:0.0264, train_loss: 2.4799, unlabeled_losses_real_strong:0.5832,corrrect_unlabeled_num:371679.0,pro_above_threshold_num:380046.0,unlabelled_weak_top1_acc:91.76112468540668,unlabelled_weak_top5_acc:99.6760779991746  \n","[2022-04-23 05:44:47,316][experiments.experiment][INFO] - [EMA] Epoch 41. [Validation] raw_testing_loss: 0.3584, raw test Top1 acc:89.34, raw test Top5 acc: 99.56, ema_testing_loss: 0.2453, ema test Top1 acc:92.88, ema test Top5 acc: 99.84\n","[2022-04-23 05:44:47,411][experiments.experiment][INFO] - [Checkpoints] Epoch 41, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 05:44:47,412][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:52:17,991][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 42: use 450.682480096817 seconds\n","--- Optimizer learning rate changed from 2.64e-02 to 2.63e-02 ---\n","[2022-04-23 05:52:18,094][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:52:19,429][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:52:19,429][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:52:20,748][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:52:20,749][experiments.experiment][INFO] - [EMA] Epoch 42.[Train] time:450.682480096817 seconds, lr:0.0263, train_loss: 2.4614, unlabeled_losses_real_strong:0.5787,corrrect_unlabeled_num:372093.0,pro_above_threshold_num:380310.0,unlabelled_weak_top1_acc:91.8718598857522,unlabelled_weak_top5_acc:99.69046483188868  \n","[2022-04-23 05:52:20,750][experiments.experiment][INFO] - [EMA] Epoch 42. [Validation] raw_testing_loss: 0.4215, raw test Top1 acc:87.26, raw test Top5 acc: 99.58, ema_testing_loss: 0.2422, ema test Top1 acc:93.16, ema test Top5 acc: 99.88\n","[2022-04-23 05:52:20,751][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:59:49,158][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 43: use 448.5179970264435 seconds\n","--- Optimizer learning rate changed from 2.63e-02 to 2.61e-02 ---\n","[2022-04-23 05:59:49,269][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:59:50,607][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:59:50,608][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:59:51,996][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:59:51,997][experiments.experiment][INFO] - [EMA] Epoch 43.[Train] time:448.5179970264435 seconds, lr:0.0261, train_loss: 2.4495, unlabeled_losses_real_strong:0.5733,corrrect_unlabeled_num:373736.0,pro_above_threshold_num:382006.0,unlabelled_weak_top1_acc:91.91741827130318,unlabelled_weak_top5_acc:99.69024693965912  \n","[2022-04-23 05:59:51,999][experiments.experiment][INFO] - [EMA] Epoch 43. [Validation] raw_testing_loss: 0.4834, raw test Top1 acc:86.42, raw test Top5 acc: 99.16, ema_testing_loss: 0.2425, ema test Top1 acc:93.16, ema test Top5 acc: 99.84\n","[2022-04-23 05:59:52,095][experiments.experiment][INFO] - [Checkpoints] Epoch 43, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 05:59:52,100][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:07:18,806][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 44: use 446.81373500823975 seconds\n","--- Optimizer learning rate changed from 2.61e-02 to 2.59e-02 ---\n","[2022-04-23 06:07:18,913][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:07:20,268][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:07:20,269][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:07:21,721][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:07:21,722][experiments.experiment][INFO] - [EMA] Epoch 44.[Train] time:446.81373500823975 seconds, lr:0.0259, train_loss: 2.4635, unlabeled_losses_real_strong:0.5721,corrrect_unlabeled_num:373125.0,pro_above_threshold_num:381406.0,unlabelled_weak_top1_acc:91.89431212097406,unlabelled_weak_top5_acc:99.68697711080313  \n","[2022-04-23 06:07:21,724][experiments.experiment][INFO] - [EMA] Epoch 44. [Validation] raw_testing_loss: 0.4499, raw test Top1 acc:87.08, raw test Top5 acc: 99.4, ema_testing_loss: 0.2395, ema test Top1 acc:93.38, ema test Top5 acc: 99.86\n","[2022-04-23 06:07:21,725][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:14:48,486][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 45: use 446.8573477268219 seconds\n","--- Optimizer learning rate changed from 2.59e-02 to 2.58e-02 ---\n","[2022-04-23 06:14:48,582][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:14:49,957][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:14:49,957][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:14:51,313][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:14:51,315][experiments.experiment][INFO] - [EMA] Epoch 45.[Train] time:446.8573477268219 seconds, lr:0.0258, train_loss: 2.4557, unlabeled_losses_real_strong:0.5718,corrrect_unlabeled_num:374603.0,pro_above_threshold_num:382721.0,unlabelled_weak_top1_acc:92.0161645039916,unlabelled_weak_top5_acc:99.6943885833025  \n","[2022-04-23 06:14:51,318][experiments.experiment][INFO] - [EMA] Epoch 45. [Validation] raw_testing_loss: 0.4045, raw test Top1 acc:88.94, raw test Top5 acc: 99.6, ema_testing_loss: 0.2369, ema test Top1 acc:93.28, ema test Top5 acc: 99.86\n","[2022-04-23 06:14:51,418][experiments.experiment][INFO] - [Checkpoints] Epoch 45, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 06:14:51,420][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:22:17,305][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 46: use 445.9800114631653 seconds\n","--- Optimizer learning rate changed from 2.58e-02 to 2.56e-02 ---\n","[2022-04-23 06:22:17,400][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:22:18,719][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:22:18,719][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:22:20,085][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:22:20,086][experiments.experiment][INFO] - [EMA] Epoch 46.[Train] time:445.9800114631653 seconds, lr:0.0256, train_loss: 2.4354, unlabeled_losses_real_strong:0.5654,corrrect_unlabeled_num:375126.0,pro_above_threshold_num:383108.0,unlabelled_weak_top1_acc:92.1096790805459,unlabelled_weak_top5_acc:99.71051934361458  \n","[2022-04-23 06:22:20,088][experiments.experiment][INFO] - [EMA] Epoch 46. [Validation] raw_testing_loss: 0.3963, raw test Top1 acc:88.56, raw test Top5 acc: 99.62, ema_testing_loss: 0.2365, ema test Top1 acc:93.26, ema test Top5 acc: 99.88\n","[2022-04-23 06:22:20,090][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:29:46,954][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 47: use 446.9687144756317 seconds\n","--- Optimizer learning rate changed from 2.56e-02 to 2.54e-02 ---\n","[2022-04-23 06:29:47,058][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:29:48,372][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:29:48,373][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:29:49,705][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:29:49,706][experiments.experiment][INFO] - [EMA] Epoch 47.[Train] time:446.9687144756317 seconds, lr:0.0254, train_loss: 2.4264, unlabeled_losses_real_strong:0.5650,corrrect_unlabeled_num:375451.0,pro_above_threshold_num:383404.0,unlabelled_weak_top1_acc:92.1186163276434,unlabelled_weak_top5_acc:99.7004919424653  \n","[2022-04-23 06:29:49,708][experiments.experiment][INFO] - [EMA] Epoch 47. [Validation] raw_testing_loss: 0.3758, raw test Top1 acc:89.02, raw test Top5 acc: 99.44, ema_testing_loss: 0.2350, ema test Top1 acc:93.26, ema test Top5 acc: 99.82\n","[2022-04-23 06:29:49,826][experiments.experiment][INFO] - [Checkpoints] Epoch 47, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 06:29:49,832][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:37:17,386][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 48: use 447.64999890327454 seconds\n","--- Optimizer learning rate changed from 2.54e-02 to 2.52e-02 ---\n","[2022-04-23 06:37:17,482][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:37:18,850][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:37:18,851][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:37:20,184][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:37:20,186][experiments.experiment][INFO] - [EMA] Epoch 48.[Train] time:447.64999890327454 seconds, lr:0.0252, train_loss: 2.4463, unlabeled_losses_real_strong:0.5603,corrrect_unlabeled_num:376680.0,pro_above_threshold_num:384835.0,unlabelled_weak_top1_acc:92.18880688399076,unlabelled_weak_top5_acc:99.69177269935608  \n","[2022-04-23 06:37:20,187][experiments.experiment][INFO] - [EMA] Epoch 48. [Validation] raw_testing_loss: 0.3533, raw test Top1 acc:89.04, raw test Top5 acc: 99.6, ema_testing_loss: 0.2341, ema test Top1 acc:93.2, ema test Top5 acc: 99.86\n","[2022-04-23 06:37:20,188][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:44:49,247][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 49: use 449.1549005508423 seconds\n","--- Optimizer learning rate changed from 2.52e-02 to 2.50e-02 ---\n","[2022-04-23 06:44:49,343][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:44:50,663][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:44:50,663][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:44:51,995][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:44:51,996][experiments.experiment][INFO] - [EMA] Epoch 49.[Train] time:449.1549005508423 seconds, lr:0.0250, train_loss: 2.4205, unlabeled_losses_real_strong:0.5602,corrrect_unlabeled_num:376989.0,pro_above_threshold_num:385201.0,unlabelled_weak_top1_acc:92.1977441906929,unlabelled_weak_top5_acc:99.70376188308  \n","[2022-04-23 06:44:51,997][experiments.experiment][INFO] - [EMA] Epoch 49. [Validation] raw_testing_loss: 0.3762, raw test Top1 acc:88.82, raw test Top5 acc: 99.64, ema_testing_loss: 0.2333, ema test Top1 acc:93.38, ema test Top5 acc: 99.86\n","[2022-04-23 06:44:52,104][experiments.experiment][INFO] - [Checkpoints] Epoch 49, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 06:44:52,107][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:52:18,927][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 50: use 446.9205975532532 seconds\n","--- Optimizer learning rate changed from 2.50e-02 to 2.48e-02 ---\n","[2022-04-23 06:52:19,028][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:52:20,357][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:52:20,357][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:52:21,731][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:52:21,732][experiments.experiment][INFO] - [EMA] Epoch 50.[Train] time:446.9205975532532 seconds, lr:0.0248, train_loss: 2.4187, unlabeled_losses_real_strong:0.5520,corrrect_unlabeled_num:377824.0,pro_above_threshold_num:385833.0,unlabelled_weak_top1_acc:92.3594872802496,unlabelled_weak_top5_acc:99.7137891203165  \n","[2022-04-23 06:52:21,734][experiments.experiment][INFO] - [EMA] Epoch 50. [Validation] raw_testing_loss: 0.3905, raw test Top1 acc:89.02, raw test Top5 acc: 99.5, ema_testing_loss: 0.2343, ema test Top1 acc:93.06, ema test Top5 acc: 99.88\n","[2022-04-23 06:52:21,735][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:59:48,554][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 51: use 446.9159858226776 seconds\n","--- Optimizer learning rate changed from 2.48e-02 to 2.46e-02 ---\n","[2022-04-23 06:59:48,651][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:59:49,978][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:59:49,978][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:59:51,431][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:59:51,432][experiments.experiment][INFO] - [EMA] Epoch 51.[Train] time:446.9159858226776 seconds, lr:0.0246, train_loss: 2.4158, unlabeled_losses_real_strong:0.5497,corrrect_unlabeled_num:378414.0,pro_above_threshold_num:386370.0,unlabelled_weak_top1_acc:92.39916006475687,unlabelled_weak_top5_acc:99.70833943039179  \n","[2022-04-23 06:59:51,434][experiments.experiment][INFO] - [EMA] Epoch 51. [Validation] raw_testing_loss: 0.3383, raw test Top1 acc:90.6, raw test Top5 acc: 99.66, ema_testing_loss: 0.2344, ema test Top1 acc:93.22, ema test Top5 acc: 99.84\n","[2022-04-23 06:59:51,529][experiments.experiment][INFO] - [Checkpoints] Epoch 51, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 06:59:51,532][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:07:14,961][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 52: use 443.5308802127838 seconds\n","--- Optimizer learning rate changed from 2.46e-02 to 2.44e-02 ---\n","[2022-04-23 07:07:15,063][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:07:16,369][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:07:16,369][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:07:17,675][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:07:17,677][experiments.experiment][INFO] - [EMA] Epoch 52.[Train] time:443.5308802127838 seconds, lr:0.0244, train_loss: 2.3987, unlabeled_losses_real_strong:0.5476,corrrect_unlabeled_num:379065.0,pro_above_threshold_num:387002.0,unlabelled_weak_top1_acc:92.4431925714016,unlabelled_weak_top5_acc:99.69853018969297  \n","[2022-04-23 07:07:17,679][experiments.experiment][INFO] - [EMA] Epoch 52. [Validation] raw_testing_loss: 0.3321, raw test Top1 acc:90.16, raw test Top5 acc: 99.62, ema_testing_loss: 0.2319, ema test Top1 acc:93.18, ema test Top5 acc: 99.84\n","[2022-04-23 07:07:17,680][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:14:41,944][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 53: use 444.35915517807007 seconds\n","--- Optimizer learning rate changed from 2.44e-02 to 2.42e-02 ---\n","[2022-04-23 07:14:42,039][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:14:43,368][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:14:43,368][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:14:44,700][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:14:44,702][experiments.experiment][INFO] - [EMA] Epoch 53.[Train] time:444.35915517807007 seconds, lr:0.0242, train_loss: 2.4228, unlabeled_losses_real_strong:0.5455,corrrect_unlabeled_num:379981.0,pro_above_threshold_num:387876.0,unlabelled_weak_top1_acc:92.55370990931988,unlabelled_weak_top5_acc:99.70572366565466  \n","[2022-04-23 07:14:44,703][experiments.experiment][INFO] - [EMA] Epoch 53. [Validation] raw_testing_loss: 0.2928, raw test Top1 acc:91.52, raw test Top5 acc: 99.68, ema_testing_loss: 0.2260, ema test Top1 acc:93.42, ema test Top5 acc: 99.84\n","[2022-04-23 07:14:44,797][experiments.experiment][INFO] - [Checkpoints] Epoch 53, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 07:14:44,799][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:22:07,806][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 54: use 443.1131908893585 seconds\n","--- Optimizer learning rate changed from 2.42e-02 to 2.40e-02 ---\n","[2022-04-23 07:22:07,912][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:22:09,296][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:22:09,296][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:22:10,635][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:22:10,636][experiments.experiment][INFO] - [EMA] Epoch 54.[Train] time:443.1131908893585 seconds, lr:0.0240, train_loss: 2.3998, unlabeled_losses_real_strong:0.5407,corrrect_unlabeled_num:380447.0,pro_above_threshold_num:388287.0,unlabelled_weak_top1_acc:92.58139366656542,unlabelled_weak_top5_acc:99.72664999216795  \n","[2022-04-23 07:22:10,639][experiments.experiment][INFO] - [EMA] Epoch 54. [Validation] raw_testing_loss: 0.3529, raw test Top1 acc:89.48, raw test Top5 acc: 99.26, ema_testing_loss: 0.2236, ema test Top1 acc:93.58, ema test Top5 acc: 99.86\n","[2022-04-23 07:22:10,640][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:29:32,428][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 55: use 441.8911967277527 seconds\n","--- Optimizer learning rate changed from 2.40e-02 to 2.38e-02 ---\n","[2022-04-23 07:29:32,531][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:29:33,904][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:29:33,904][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:29:35,234][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:29:35,239][experiments.experiment][INFO] - [EMA] Epoch 55.[Train] time:441.8911967277527 seconds, lr:0.0238, train_loss: 2.3828, unlabeled_losses_real_strong:0.5393,corrrect_unlabeled_num:380116.0,pro_above_threshold_num:387908.0,unlabelled_weak_top1_acc:92.58400945365429,unlabelled_weak_top5_acc:99.72032853960991  \n","[2022-04-23 07:29:35,240][experiments.experiment][INFO] - [EMA] Epoch 55. [Validation] raw_testing_loss: 0.3812, raw test Top1 acc:88.98, raw test Top5 acc: 99.58, ema_testing_loss: 0.2247, ema test Top1 acc:93.54, ema test Top5 acc: 99.88\n","[2022-04-23 07:29:35,334][experiments.experiment][INFO] - [Checkpoints] Epoch 55, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 07:29:35,342][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:37:00,417][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 56: use 445.1801242828369 seconds\n","--- Optimizer learning rate changed from 2.38e-02 to 2.36e-02 ---\n","[2022-04-23 07:37:00,522][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:37:01,900][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:37:01,901][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:37:03,225][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:37:03,227][experiments.experiment][INFO] - [EMA] Epoch 56.[Train] time:445.1801242828369 seconds, lr:0.0236, train_loss: 2.4104, unlabeled_losses_real_strong:0.5395,corrrect_unlabeled_num:381699.0,pro_above_threshold_num:389501.0,unlabelled_weak_top1_acc:92.67207451164722,unlabelled_weak_top5_acc:99.7242522239685  \n","[2022-04-23 07:37:03,228][experiments.experiment][INFO] - [EMA] Epoch 56. [Validation] raw_testing_loss: 0.4044, raw test Top1 acc:88.44, raw test Top5 acc: 99.66, ema_testing_loss: 0.2205, ema test Top1 acc:93.58, ema test Top5 acc: 99.86\n","[2022-04-23 07:37:03,229][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:44:31,721][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 57: use 448.58674240112305 seconds\n","--- Optimizer learning rate changed from 2.36e-02 to 2.34e-02 ---\n","[2022-04-23 07:44:31,816][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:44:33,117][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:44:33,117][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:44:34,417][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:44:34,418][experiments.experiment][INFO] - [EMA] Epoch 57.[Train] time:448.58674240112305 seconds, lr:0.0234, train_loss: 2.3834, unlabeled_losses_real_strong:0.5351,corrrect_unlabeled_num:381447.0,pro_above_threshold_num:389214.0,unlabelled_weak_top1_acc:92.72722418606281,unlabelled_weak_top5_acc:99.72490622103214  \n","[2022-04-23 07:44:34,419][experiments.experiment][INFO] - [EMA] Epoch 57. [Validation] raw_testing_loss: 0.3048, raw test Top1 acc:90.6, raw test Top5 acc: 99.7, ema_testing_loss: 0.2174, ema test Top1 acc:93.68, ema test Top5 acc: 99.86\n","[2022-04-23 07:44:34,514][experiments.experiment][INFO] - [Checkpoints] Epoch 57, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 07:44:34,515][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:52:01,220][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 58: use 446.7989785671234 seconds\n","--- Optimizer learning rate changed from 2.34e-02 to 2.32e-02 ---\n","[2022-04-23 07:52:01,314][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:52:02,624][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:52:02,625][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:52:03,943][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:52:03,944][experiments.experiment][INFO] - [EMA] Epoch 58.[Train] time:446.7989785671234 seconds, lr:0.0232, train_loss: 2.3965, unlabeled_losses_real_strong:0.5314,corrrect_unlabeled_num:382412.0,pro_above_threshold_num:390227.0,unlabelled_weak_top1_acc:92.75992141664028,unlabelled_weak_top5_acc:99.7307916879654  \n","[2022-04-23 07:52:03,947][experiments.experiment][INFO] - [EMA] Epoch 58. [Validation] raw_testing_loss: 0.3479, raw test Top1 acc:90.26, raw test Top5 acc: 99.44, ema_testing_loss: 0.2214, ema test Top1 acc:93.66, ema test Top5 acc: 99.9\n","[2022-04-23 07:52:03,948][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:59:28,905][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 59: use 445.052934885025 seconds\n","--- Optimizer learning rate changed from 2.32e-02 to 2.30e-02 ---\n","[2022-04-23 07:59:29,001][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:59:30,318][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:59:30,319][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:59:31,632][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:59:31,633][experiments.experiment][INFO] - [EMA] Epoch 59.[Train] time:445.052934885025 seconds, lr:0.0230, train_loss: 2.3737, unlabeled_losses_real_strong:0.5270,corrrect_unlabeled_num:382725.0,pro_above_threshold_num:390363.0,unlabelled_weak_top1_acc:92.84253697097301,unlabelled_weak_top5_acc:99.73100979626179  \n","[2022-04-23 07:59:31,636][experiments.experiment][INFO] - [EMA] Epoch 59. [Validation] raw_testing_loss: 0.3808, raw test Top1 acc:89.02, raw test Top5 acc: 99.82, ema_testing_loss: 0.2160, ema test Top1 acc:93.62, ema test Top5 acc: 99.86\n","[2022-04-23 07:59:31,729][experiments.experiment][INFO] - [Checkpoints] Epoch 59, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 07:59:31,730][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:06:54,285][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 60: use 442.6494801044464 seconds\n","--- Optimizer learning rate changed from 2.30e-02 to 2.27e-02 ---\n","[2022-04-23 08:06:54,380][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:06:55,682][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:06:55,682][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:06:56,997][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:06:56,998][experiments.experiment][INFO] - [EMA] Epoch 60.[Train] time:442.6494801044464 seconds, lr:0.0227, train_loss: 2.3780, unlabeled_losses_real_strong:0.5273,corrrect_unlabeled_num:382821.0,pro_above_threshold_num:390530.0,unlabelled_weak_top1_acc:92.85278216004372,unlabelled_weak_top5_acc:99.7246881723404  \n","[2022-04-23 08:06:57,001][experiments.experiment][INFO] - [EMA] Epoch 60. [Validation] raw_testing_loss: 0.3116, raw test Top1 acc:90.8, raw test Top5 acc: 99.84, ema_testing_loss: 0.2148, ema test Top1 acc:93.72, ema test Top5 acc: 99.86\n","[2022-04-23 08:06:57,002][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:14:22,469][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 61: use 445.5639433860779 seconds\n","--- Optimizer learning rate changed from 2.27e-02 to 2.25e-02 ---\n","[2022-04-23 08:14:22,566][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:14:23,892][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:14:23,893][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:14:25,260][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:14:25,261][experiments.experiment][INFO] - [EMA] Epoch 61.[Train] time:445.5639433860779 seconds, lr:0.0225, train_loss: 2.3574, unlabeled_losses_real_strong:0.5220,corrrect_unlabeled_num:383877.0,pro_above_threshold_num:391566.0,unlabelled_weak_top1_acc:92.89114712178707,unlabelled_weak_top5_acc:99.73994700610638  \n","[2022-04-23 08:14:25,263][experiments.experiment][INFO] - [EMA] Epoch 61. [Validation] raw_testing_loss: 0.3238, raw test Top1 acc:90.96, raw test Top5 acc: 99.76, ema_testing_loss: 0.2116, ema test Top1 acc:93.86, ema test Top5 acc: 99.88\n","[2022-04-23 08:14:25,356][experiments.experiment][INFO] - [Checkpoints] Epoch 61, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 08:14:25,359][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:21:49,696][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 62: use 444.4325113296509 seconds\n","--- Optimizer learning rate changed from 2.25e-02 to 2.23e-02 ---\n","[2022-04-23 08:21:49,791][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:21:51,211][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:21:51,211][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:21:52,527][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:21:52,529][experiments.experiment][INFO] - [EMA] Epoch 62.[Train] time:444.4325113296509 seconds, lr:0.0223, train_loss: 2.3593, unlabeled_losses_real_strong:0.5186,corrrect_unlabeled_num:384410.0,pro_above_threshold_num:392027.0,unlabelled_weak_top1_acc:93.04264501482248,unlabelled_weak_top5_acc:99.73863914608955  \n","[2022-04-23 08:21:52,530][experiments.experiment][INFO] - [EMA] Epoch 62. [Validation] raw_testing_loss: 0.3436, raw test Top1 acc:89.64, raw test Top5 acc: 99.68, ema_testing_loss: 0.2125, ema test Top1 acc:93.72, ema test Top5 acc: 99.88\n","[2022-04-23 08:21:52,531][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:29:16,093][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 63: use 443.6630642414093 seconds\n","--- Optimizer learning rate changed from 2.23e-02 to 2.21e-02 ---\n","[2022-04-23 08:29:16,194][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:29:17,544][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:29:17,544][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:29:18,991][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:29:18,993][experiments.experiment][INFO] - [EMA] Epoch 63.[Train] time:443.6630642414093 seconds, lr:0.0221, train_loss: 2.3353, unlabeled_losses_real_strong:0.5187,corrrect_unlabeled_num:384729.0,pro_above_threshold_num:392229.0,unlabelled_weak_top1_acc:93.0108195617795,unlabelled_weak_top5_acc:99.73406147956848  \n","[2022-04-23 08:29:18,994][experiments.experiment][INFO] - [EMA] Epoch 63. [Validation] raw_testing_loss: 0.3855, raw test Top1 acc:88.94, raw test Top5 acc: 99.58, ema_testing_loss: 0.2121, ema test Top1 acc:93.82, ema test Top5 acc: 99.88\n","[2022-04-23 08:29:19,095][experiments.experiment][INFO] - [Checkpoints] Epoch 63, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 08:29:19,096][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:36:45,268][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 64: use 446.275004863739 seconds\n","--- Optimizer learning rate changed from 2.21e-02 to 2.18e-02 ---\n","[2022-04-23 08:36:45,371][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:36:46,676][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:36:46,676][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:36:47,999][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:36:48,001][experiments.experiment][INFO] - [EMA] Epoch 64.[Train] time:446.275004863739 seconds, lr:0.0218, train_loss: 2.3434, unlabeled_losses_real_strong:0.5136,corrrect_unlabeled_num:385366.0,pro_above_threshold_num:392747.0,unlabelled_weak_top1_acc:93.10803989320993,unlabelled_weak_top5_acc:99.74844834208488  \n","[2022-04-23 08:36:48,003][experiments.experiment][INFO] - [EMA] Epoch 64. [Validation] raw_testing_loss: 0.3314, raw test Top1 acc:90.62, raw test Top5 acc: 99.72, ema_testing_loss: 0.2105, ema test Top1 acc:93.62, ema test Top5 acc: 99.86\n","[2022-04-23 08:36:48,004][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:44:12,405][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 65: use 444.49913597106934 seconds\n","--- Optimizer learning rate changed from 2.18e-02 to 2.16e-02 ---\n","[2022-04-23 08:44:12,503][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:44:13,838][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:44:13,839][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:44:15,163][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:44:15,165][experiments.experiment][INFO] - [EMA] Epoch 65.[Train] time:444.49913597106934 seconds, lr:0.0216, train_loss: 2.3465, unlabeled_losses_real_strong:0.5129,corrrect_unlabeled_num:385541.0,pro_above_threshold_num:392981.0,unlabelled_weak_top1_acc:93.17583242058754,unlabelled_weak_top5_acc:99.74365273118019  \n","[2022-04-23 08:44:15,168][experiments.experiment][INFO] - [EMA] Epoch 65. [Validation] raw_testing_loss: 0.3360, raw test Top1 acc:90.66, raw test Top5 acc: 99.7, ema_testing_loss: 0.2130, ema test Top1 acc:93.46, ema test Top5 acc: 99.88\n","[2022-04-23 08:44:15,264][experiments.experiment][INFO] - [Checkpoints] Epoch 65, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 08:44:15,270][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:51:43,168][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 66: use 447.99563479423523 seconds\n","--- Optimizer learning rate changed from 2.16e-02 to 2.14e-02 ---\n","[2022-04-23 08:51:43,266][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:51:44,581][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:51:44,582][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:51:45,869][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:51:45,871][experiments.experiment][INFO] - [EMA] Epoch 66.[Train] time:447.99563479423523 seconds, lr:0.0214, train_loss: 2.3289, unlabeled_losses_real_strong:0.5094,corrrect_unlabeled_num:386636.0,pro_above_threshold_num:394334.0,unlabelled_weak_top1_acc:93.17081891000271,unlabelled_weak_top5_acc:99.75738572329283  \n","[2022-04-23 08:51:45,872][experiments.experiment][INFO] - [EMA] Epoch 66. [Validation] raw_testing_loss: 0.3064, raw test Top1 acc:90.7, raw test Top5 acc: 99.5, ema_testing_loss: 0.2113, ema test Top1 acc:93.78, ema test Top5 acc: 99.9\n","[2022-04-23 08:51:45,874][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:59:12,396][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 67: use 446.62847113609314 seconds\n","--- Optimizer learning rate changed from 2.14e-02 to 2.11e-02 ---\n","[2022-04-23 08:59:12,502][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:59:13,876][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:59:13,877][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:59:15,210][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:59:15,212][experiments.experiment][INFO] - [EMA] Epoch 67.[Train] time:446.62847113609314 seconds, lr:0.0211, train_loss: 2.3113, unlabeled_losses_real_strong:0.5078,corrrect_unlabeled_num:386772.0,pro_above_threshold_num:394572.0,unlabelled_weak_top1_acc:93.1756144464016,unlabelled_weak_top5_acc:99.75367996096611  \n","[2022-04-23 08:59:15,213][experiments.experiment][INFO] - [EMA] Epoch 67. [Validation] raw_testing_loss: 0.3459, raw test Top1 acc:90.02, raw test Top5 acc: 99.48, ema_testing_loss: 0.2123, ema test Top1 acc:93.76, ema test Top5 acc: 99.9\n","[2022-04-23 08:59:15,308][experiments.experiment][INFO] - [Checkpoints] Epoch 67, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 08:59:15,316][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:06:37,349][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 68: use 442.13267707824707 seconds\n","--- Optimizer learning rate changed from 2.11e-02 to 2.09e-02 ---\n","[2022-04-23 09:06:37,449][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:06:38,786][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:06:38,787][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:06:40,138][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:06:40,139][experiments.experiment][INFO] - [EMA] Epoch 68.[Train] time:442.13267707824707 seconds, lr:0.0209, train_loss: 2.3267, unlabeled_losses_real_strong:0.5069,corrrect_unlabeled_num:387503.0,pro_above_threshold_num:395193.0,unlabelled_weak_top1_acc:93.20199047029018,unlabelled_weak_top5_acc:99.74714048206806  \n","[2022-04-23 09:06:40,141][experiments.experiment][INFO] - [EMA] Epoch 68. [Validation] raw_testing_loss: 0.3459, raw test Top1 acc:90.24, raw test Top5 acc: 99.78, ema_testing_loss: 0.2057, ema test Top1 acc:93.9, ema test Top5 acc: 99.88\n","[2022-04-23 09:06:40,142][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:14:00,085][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 69: use 440.04811453819275 seconds\n","--- Optimizer learning rate changed from 2.09e-02 to 2.06e-02 ---\n","[2022-04-23 09:14:00,190][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:14:01,516][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:14:01,517][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:14:02,823][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:14:02,824][experiments.experiment][INFO] - [EMA] Epoch 69.[Train] time:440.04811453819275 seconds, lr:0.0206, train_loss: 2.3143, unlabeled_losses_real_strong:0.5013,corrrect_unlabeled_num:387985.0,pro_above_threshold_num:395628.0,unlabelled_weak_top1_acc:93.29092741012573,unlabelled_weak_top5_acc:99.74953827261925  \n","[2022-04-23 09:14:02,826][experiments.experiment][INFO] - [EMA] Epoch 69. [Validation] raw_testing_loss: 0.3000, raw test Top1 acc:91.22, raw test Top5 acc: 99.72, ema_testing_loss: 0.2060, ema test Top1 acc:93.86, ema test Top5 acc: 99.88\n","[2022-04-23 09:14:02,919][experiments.experiment][INFO] - [Checkpoints] Epoch 69, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 09:14:02,924][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:21:22,805][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 70: use 439.9762828350067 seconds\n","--- Optimizer learning rate changed from 2.06e-02 to 2.04e-02 ---\n","[2022-04-23 09:21:22,900][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:21:24,217][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:21:24,218][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:21:25,531][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:21:25,533][experiments.experiment][INFO] - [EMA] Epoch 70.[Train] time:439.9762828350067 seconds, lr:0.0204, train_loss: 2.3093, unlabeled_losses_real_strong:0.5025,corrrect_unlabeled_num:388359.0,pro_above_threshold_num:395979.0,unlabelled_weak_top1_acc:93.34738487750292,unlabelled_weak_top5_acc:99.75324399769306  \n","[2022-04-23 09:21:25,534][experiments.experiment][INFO] - [EMA] Epoch 70. [Validation] raw_testing_loss: 0.2793, raw test Top1 acc:91.46, raw test Top5 acc: 99.86, ema_testing_loss: 0.2072, ema test Top1 acc:94.06, ema test Top5 acc: 99.88\n","[2022-04-23 09:21:25,535][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:28:47,105][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 71: use 441.67331314086914 seconds\n","--- Optimizer learning rate changed from 2.04e-02 to 2.01e-02 ---\n","[2022-04-23 09:28:47,209][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:28:48,527][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:28:48,528][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:28:49,862][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:28:49,864][experiments.experiment][INFO] - [EMA] Epoch 71.[Train] time:441.67331314086914 seconds, lr:0.0201, train_loss: 2.3081, unlabeled_losses_real_strong:0.4992,corrrect_unlabeled_num:389240.0,pro_above_threshold_num:396869.0,unlabelled_weak_top1_acc:93.40209848433733,unlabelled_weak_top5_acc:99.76000149548054  \n","[2022-04-23 09:28:49,867][experiments.experiment][INFO] - [EMA] Epoch 71. [Validation] raw_testing_loss: 0.3945, raw test Top1 acc:88.08, raw test Top5 acc: 99.52, ema_testing_loss: 0.2016, ema test Top1 acc:94.32, ema test Top5 acc: 99.88\n","[2022-04-23 09:28:49,973][experiments.experiment][INFO] - [Checkpoints] Epoch 71, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 09:28:49,979][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:36:14,298][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 72: use 444.4155042171478 seconds\n","--- Optimizer learning rate changed from 2.01e-02 to 1.99e-02 ---\n","[2022-04-23 09:36:14,394][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:36:15,746][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:36:15,746][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:36:17,064][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:36:17,065][experiments.experiment][INFO] - [EMA] Epoch 72.[Train] time:444.4155042171478 seconds, lr:0.0199, train_loss: 2.2973, unlabeled_losses_real_strong:0.4954,corrrect_unlabeled_num:389672.0,pro_above_threshold_num:397351.0,unlabelled_weak_top1_acc:93.38640382140875,unlabelled_weak_top5_acc:99.7619633153081  \n","[2022-04-23 09:36:17,068][experiments.experiment][INFO] - [EMA] Epoch 72. [Validation] raw_testing_loss: 0.3949, raw test Top1 acc:88.84, raw test Top5 acc: 99.62, ema_testing_loss: 0.2053, ema test Top1 acc:94.16, ema test Top5 acc: 99.86\n","[2022-04-23 09:36:17,069][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:43:37,891][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 73: use 440.92955231666565 seconds\n","--- Optimizer learning rate changed from 1.99e-02 to 1.96e-02 ---\n","[2022-04-23 09:43:37,998][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:43:39,318][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:43:39,319][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:43:40,617][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:43:40,619][experiments.experiment][INFO] - [EMA] Epoch 73.[Train] time:440.92955231666565 seconds, lr:0.0196, train_loss: 2.2944, unlabeled_losses_real_strong:0.4939,corrrect_unlabeled_num:389927.0,pro_above_threshold_num:397626.0,unlabelled_weak_top1_acc:93.43784772604704,unlabelled_weak_top5_acc:99.75520585477352  \n","[2022-04-23 09:43:40,620][experiments.experiment][INFO] - [EMA] Epoch 73. [Validation] raw_testing_loss: 0.3763, raw test Top1 acc:88.8, raw test Top5 acc: 99.6, ema_testing_loss: 0.2037, ema test Top1 acc:94.04, ema test Top5 acc: 99.88\n","[2022-04-23 09:43:40,717][experiments.experiment][INFO] - [Checkpoints] Epoch 73, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 09:43:40,719][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:50:59,946][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 74: use 439.3319294452667 seconds\n","--- Optimizer learning rate changed from 1.96e-02 to 1.93e-02 ---\n","[2022-04-23 09:51:00,051][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:51:01,358][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:51:01,358][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:51:02,668][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:51:02,669][experiments.experiment][INFO] - [EMA] Epoch 74.[Train] time:439.3319294452667 seconds, lr:0.0193, train_loss: 2.2787, unlabeled_losses_real_strong:0.4923,corrrect_unlabeled_num:390623.0,pro_above_threshold_num:398156.0,unlabelled_weak_top1_acc:93.52264297753572,unlabelled_weak_top5_acc:99.76523308455944  \n","[2022-04-23 09:51:02,671][experiments.experiment][INFO] - [EMA] Epoch 74. [Validation] raw_testing_loss: 0.3661, raw test Top1 acc:89.98, raw test Top5 acc: 99.56, ema_testing_loss: 0.2003, ema test Top1 acc:94.34, ema test Top5 acc: 99.88\n","[2022-04-23 09:51:02,672][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:58:25,971][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 75: use 443.40373730659485 seconds\n","--- Optimizer learning rate changed from 1.93e-02 to 1.91e-02 ---\n","[2022-04-23 09:58:26,076][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:58:27,452][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:58:27,452][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:58:28,773][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:58:28,774][experiments.experiment][INFO] - [EMA] Epoch 75.[Train] time:443.40373730659485 seconds, lr:0.0191, train_loss: 2.2732, unlabeled_losses_real_strong:0.4845,corrrect_unlabeled_num:391360.0,pro_above_threshold_num:398844.0,unlabelled_weak_top1_acc:93.60656622797251,unlabelled_weak_top5_acc:99.760437451303  \n","[2022-04-23 09:58:28,776][experiments.experiment][INFO] - [EMA] Epoch 75. [Validation] raw_testing_loss: 0.3522, raw test Top1 acc:90.26, raw test Top5 acc: 99.58, ema_testing_loss: 0.2018, ema test Top1 acc:94.16, ema test Top5 acc: 99.88\n","[2022-04-23 09:58:28,872][experiments.experiment][INFO] - [Checkpoints] Epoch 75, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 09:58:28,880][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:05:54,054][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 76: use 445.2667078971863 seconds\n","--- Optimizer learning rate changed from 1.91e-02 to 1.88e-02 ---\n","[2022-04-23 10:05:54,147][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:05:55,506][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:05:55,507][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:05:56,798][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:05:56,800][experiments.experiment][INFO] - [EMA] Epoch 76.[Train] time:445.2667078971863 seconds, lr:0.0188, train_loss: 2.2825, unlabeled_losses_real_strong:0.4847,corrrect_unlabeled_num:391875.0,pro_above_threshold_num:399267.0,unlabelled_weak_top1_acc:93.60416839271784,unlabelled_weak_top5_acc:99.77787601947784  \n","[2022-04-23 10:05:56,803][experiments.experiment][INFO] - [EMA] Epoch 76. [Validation] raw_testing_loss: 0.3199, raw test Top1 acc:90.8, raw test Top5 acc: 99.72, ema_testing_loss: 0.2017, ema test Top1 acc:94.22, ema test Top5 acc: 99.9\n","[2022-04-23 10:05:56,803][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:13:26,630][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 77: use 449.923907995224 seconds\n","--- Optimizer learning rate changed from 1.88e-02 to 1.85e-02 ---\n","[2022-04-23 10:13:26,728][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:13:28,068][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:13:28,068][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:13:29,415][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:13:29,417][experiments.experiment][INFO] - [EMA] Epoch 77.[Train] time:449.923907995224 seconds, lr:0.0185, train_loss: 2.2589, unlabeled_losses_real_strong:0.4826,corrrect_unlabeled_num:391831.0,pro_above_threshold_num:399446.0,unlabelled_weak_top1_acc:93.617465429008,unlabelled_weak_top5_acc:99.76392517983913  \n","[2022-04-23 10:13:29,418][experiments.experiment][INFO] - [EMA] Epoch 77. [Validation] raw_testing_loss: 0.3134, raw test Top1 acc:91.06, raw test Top5 acc: 99.88, ema_testing_loss: 0.2024, ema test Top1 acc:94.22, ema test Top5 acc: 99.9\n","[2022-04-23 10:13:29,512][experiments.experiment][INFO] - [Checkpoints] Epoch 77, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 10:13:29,521][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:21:01,370][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 78: use 451.94987082481384 seconds\n","--- Optimizer learning rate changed from 1.85e-02 to 1.83e-02 ---\n","[2022-04-23 10:21:01,471][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:21:02,856][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:21:02,857][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:21:04,228][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:21:04,230][experiments.experiment][INFO] - [EMA] Epoch 78.[Train] time:451.94987082481384 seconds, lr:0.0183, train_loss: 2.2619, unlabeled_losses_real_strong:0.4814,corrrect_unlabeled_num:392963.0,pro_above_threshold_num:400495.0,unlabelled_weak_top1_acc:93.714903652668,unlabelled_weak_top5_acc:99.77220849692822  \n","[2022-04-23 10:21:04,233][experiments.experiment][INFO] - [EMA] Epoch 78. [Validation] raw_testing_loss: 0.3184, raw test Top1 acc:90.5, raw test Top5 acc: 99.78, ema_testing_loss: 0.2050, ema test Top1 acc:94.18, ema test Top5 acc: 99.9\n","[2022-04-23 10:21:04,234][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:28:37,015][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 79: use 452.8785786628723 seconds\n","--- Optimizer learning rate changed from 1.83e-02 to 1.80e-02 ---\n","[2022-04-23 10:28:37,113][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:28:38,482][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:28:38,482][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:28:39,842][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:28:39,844][experiments.experiment][INFO] - [EMA] Epoch 79.[Train] time:452.8785786628723 seconds, lr:0.0180, train_loss: 2.2629, unlabeled_losses_real_strong:0.4758,corrrect_unlabeled_num:393573.0,pro_above_threshold_num:401204.0,unlabelled_weak_top1_acc:93.75305078923702,unlabelled_weak_top5_acc:99.76741288602352  \n","[2022-04-23 10:28:39,845][experiments.experiment][INFO] - [EMA] Epoch 79. [Validation] raw_testing_loss: 0.3100, raw test Top1 acc:91.24, raw test Top5 acc: 99.7, ema_testing_loss: 0.2047, ema test Top1 acc:94.08, ema test Top5 acc: 99.86\n","[2022-04-23 10:28:39,943][experiments.experiment][INFO] - [Checkpoints] Epoch 79, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 10:28:39,945][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:36:11,433][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 80: use 451.58209228515625 seconds\n","--- Optimizer learning rate changed from 1.80e-02 to 1.77e-02 ---\n","[2022-04-23 10:36:11,527][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:36:12,904][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:36:12,905][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:36:14,311][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:36:14,313][experiments.experiment][INFO] - [EMA] Epoch 80.[Train] time:451.58209228515625 seconds, lr:0.0177, train_loss: 2.2476, unlabeled_losses_real_strong:0.4723,corrrect_unlabeled_num:393530.0,pro_above_threshold_num:401161.0,unlabelled_weak_top1_acc:93.74934501945972,unlabelled_weak_top5_acc:99.7639251947403  \n","[2022-04-23 10:36:14,316][experiments.experiment][INFO] - [EMA] Epoch 80. [Validation] raw_testing_loss: 0.2939, raw test Top1 acc:91.66, raw test Top5 acc: 99.74, ema_testing_loss: 0.2032, ema test Top1 acc:94.22, ema test Top5 acc: 99.9\n","[2022-04-23 10:36:14,316][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:43:45,850][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 81: use 451.6342787742615 seconds\n","--- Optimizer learning rate changed from 1.77e-02 to 1.74e-02 ---\n","[2022-04-23 10:43:45,950][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:43:47,343][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:43:47,344][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:43:48,668][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:43:48,670][experiments.experiment][INFO] - [EMA] Epoch 81.[Train] time:451.6342787742615 seconds, lr:0.0174, train_loss: 2.2375, unlabeled_losses_real_strong:0.4746,corrrect_unlabeled_num:393759.0,pro_above_threshold_num:401233.0,unlabelled_weak_top1_acc:93.8208432868123,unlabelled_weak_top5_acc:99.77395233511925  \n","[2022-04-23 10:43:48,672][experiments.experiment][INFO] - [EMA] Epoch 81. [Validation] raw_testing_loss: 0.2875, raw test Top1 acc:91.4, raw test Top5 acc: 99.8, ema_testing_loss: 0.1987, ema test Top1 acc:94.18, ema test Top5 acc: 99.88\n","[2022-04-23 10:43:48,766][experiments.experiment][INFO] - [Checkpoints] Epoch 81, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 10:43:48,777][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:51:21,348][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 82: use 452.6672718524933 seconds\n","--- Optimizer learning rate changed from 1.74e-02 to 1.72e-02 ---\n","[2022-04-23 10:51:21,444][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:51:22,783][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:51:22,783][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:51:24,164][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:51:24,165][experiments.experiment][INFO] - [EMA] Epoch 82.[Train] time:452.6672718524933 seconds, lr:0.0172, train_loss: 2.2259, unlabeled_losses_real_strong:0.4706,corrrect_unlabeled_num:394482.0,pro_above_threshold_num:401954.0,unlabelled_weak_top1_acc:93.84111576527357,unlabelled_weak_top5_acc:99.77438842505217  \n","[2022-04-23 10:51:24,166][experiments.experiment][INFO] - [EMA] Epoch 82. [Validation] raw_testing_loss: 0.2881, raw test Top1 acc:91.24, raw test Top5 acc: 99.66, ema_testing_loss: 0.1975, ema test Top1 acc:94.2, ema test Top5 acc: 99.86\n","[2022-04-23 10:51:24,168][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:58:58,022][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 83: use 453.9550108909607 seconds\n","--- Optimizer learning rate changed from 1.72e-02 to 1.69e-02 ---\n","[2022-04-23 10:58:58,123][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:58:59,530][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:58:59,530][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:59:00,936][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:59:00,937][experiments.experiment][INFO] - [EMA] Epoch 83.[Train] time:453.9550108909607 seconds, lr:0.0169, train_loss: 2.2140, unlabeled_losses_real_strong:0.4699,corrrect_unlabeled_num:394593.0,pro_above_threshold_num:402207.0,unlabelled_weak_top1_acc:93.86226001381874,unlabelled_weak_top5_acc:99.77199057489634  \n","[2022-04-23 10:59:00,939][experiments.experiment][INFO] - [EMA] Epoch 83. [Validation] raw_testing_loss: 0.3046, raw test Top1 acc:90.82, raw test Top5 acc: 99.68, ema_testing_loss: 0.1980, ema test Top1 acc:94.28, ema test Top5 acc: 99.9\n","[2022-04-23 10:59:01,039][experiments.experiment][INFO] - [Checkpoints] Epoch 83, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 10:59:01,040][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:06:33,446][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 84: use 452.50655937194824 seconds\n","--- Optimizer learning rate changed from 1.69e-02 to 1.66e-02 ---\n","[2022-04-23 11:06:33,547][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:06:34,927][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:06:34,927][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:06:36,261][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:06:36,262][experiments.experiment][INFO] - [EMA] Epoch 84.[Train] time:452.50655937194824 seconds, lr:0.0166, train_loss: 2.2127, unlabeled_losses_real_strong:0.4646,corrrect_unlabeled_num:395232.0,pro_above_threshold_num:402860.0,unlabelled_weak_top1_acc:93.88885393738747,unlabelled_weak_top5_acc:99.7791840210557  \n","[2022-04-23 11:06:36,264][experiments.experiment][INFO] - [EMA] Epoch 84. [Validation] raw_testing_loss: 0.2692, raw test Top1 acc:92.68, raw test Top5 acc: 99.76, ema_testing_loss: 0.1987, ema test Top1 acc:94.26, ema test Top5 acc: 99.9\n","[2022-04-23 11:06:36,266][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:13:59,072][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 85: use 442.90577149391174 seconds\n","--- Optimizer learning rate changed from 1.66e-02 to 1.63e-02 ---\n","[2022-04-23 11:13:59,172][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:14:00,491][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:14:00,491][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:14:01,833][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:14:01,834][experiments.experiment][INFO] - [EMA] Epoch 85.[Train] time:442.90577149391174 seconds, lr:0.0163, train_loss: 2.1985, unlabeled_losses_real_strong:0.4643,corrrect_unlabeled_num:395546.0,pro_above_threshold_num:402986.0,unlabelled_weak_top1_acc:93.95097906142473,unlabelled_weak_top5_acc:99.78179979324341  \n","[2022-04-23 11:14:01,835][experiments.experiment][INFO] - [EMA] Epoch 85. [Validation] raw_testing_loss: 0.3756, raw test Top1 acc:89.8, raw test Top5 acc: 99.66, ema_testing_loss: 0.1954, ema test Top1 acc:94.5, ema test Top5 acc: 99.9\n","[2022-04-23 11:14:01,934][experiments.experiment][INFO] - [Checkpoints] Epoch 85, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 11:14:01,937][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:21:24,470][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 86: use 442.63293194770813 seconds\n","--- Optimizer learning rate changed from 1.63e-02 to 1.60e-02 ---\n","[2022-04-23 11:21:24,570][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:21:25,919][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:21:25,919][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:21:27,270][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:21:27,272][experiments.experiment][INFO] - [EMA] Epoch 86.[Train] time:442.63293194770813 seconds, lr:0.0160, train_loss: 2.1598, unlabeled_losses_real_strong:0.4600,corrrect_unlabeled_num:395713.0,pro_above_threshold_num:403103.0,unlabelled_weak_top1_acc:93.99501132965088,unlabelled_weak_top5_acc:99.77373439073563  \n","[2022-04-23 11:21:27,274][experiments.experiment][INFO] - [EMA] Epoch 86. [Validation] raw_testing_loss: 0.3132, raw test Top1 acc:90.7, raw test Top5 acc: 99.72, ema_testing_loss: 0.1972, ema test Top1 acc:94.38, ema test Top5 acc: 99.92\n","[2022-04-23 11:21:27,275][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:28:52,499][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 87: use 445.32518458366394 seconds\n","--- Optimizer learning rate changed from 1.60e-02 to 1.57e-02 ---\n","[2022-04-23 11:28:52,600][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:28:53,938][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:28:53,938][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:28:55,275][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:28:55,277][experiments.experiment][INFO] - [EMA] Epoch 87.[Train] time:445.32518458366394 seconds, lr:0.0157, train_loss: 2.1874, unlabeled_losses_real_strong:0.4580,corrrect_unlabeled_num:396645.0,pro_above_threshold_num:403948.0,unlabelled_weak_top1_acc:94.05735447257757,unlabelled_weak_top5_acc:99.79814847558737  \n","[2022-04-23 11:28:55,279][experiments.experiment][INFO] - [EMA] Epoch 87. [Validation] raw_testing_loss: 0.3399, raw test Top1 acc:90.84, raw test Top5 acc: 99.76, ema_testing_loss: 0.1975, ema test Top1 acc:94.12, ema test Top5 acc: 99.9\n","[2022-04-23 11:28:55,372][experiments.experiment][INFO] - [Checkpoints] Epoch 87, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 11:28:55,376][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:36:25,333][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 88: use 450.05847358703613 seconds\n","--- Optimizer learning rate changed from 1.57e-02 to 1.54e-02 ---\n","[2022-04-23 11:36:25,435][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:36:26,781][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:36:26,782][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:36:28,097][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:36:28,099][experiments.experiment][INFO] - [EMA] Epoch 88.[Train] time:450.05847358703613 seconds, lr:0.0154, train_loss: 2.1587, unlabeled_losses_real_strong:0.4559,corrrect_unlabeled_num:396467.0,pro_above_threshold_num:403954.0,unlabelled_weak_top1_acc:94.04100576043129,unlabelled_weak_top5_acc:99.77700421959162  \n","[2022-04-23 11:36:28,100][experiments.experiment][INFO] - [EMA] Epoch 88. [Validation] raw_testing_loss: 0.2604, raw test Top1 acc:92.6, raw test Top5 acc: 99.74, ema_testing_loss: 0.1960, ema test Top1 acc:94.44, ema test Top5 acc: 99.92\n","[2022-04-23 11:36:28,102][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:43:51,281][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 89: use 443.2779381275177 seconds\n","--- Optimizer learning rate changed from 1.54e-02 to 1.51e-02 ---\n","[2022-04-23 11:43:51,380][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:43:52,697][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:43:52,698][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:43:54,061][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:43:54,063][experiments.experiment][INFO] - [EMA] Epoch 89.[Train] time:443.2779381275177 seconds, lr:0.0151, train_loss: 2.1636, unlabeled_losses_real_strong:0.4540,corrrect_unlabeled_num:397131.0,pro_above_threshold_num:404553.0,unlabelled_weak_top1_acc:94.0915777310729,unlabelled_weak_top5_acc:99.78877527266741  \n","[2022-04-23 11:43:54,065][experiments.experiment][INFO] - [EMA] Epoch 89. [Validation] raw_testing_loss: 0.2763, raw test Top1 acc:91.82, raw test Top5 acc: 99.8, ema_testing_loss: 0.1898, ema test Top1 acc:94.62, ema test Top5 acc: 99.92\n","[2022-04-23 11:43:54,174][experiments.experiment][INFO] - [Checkpoints] Epoch 89, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 11:43:54,177][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:51:19,321][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 90: use 445.24541091918945 seconds\n","--- Optimizer learning rate changed from 1.51e-02 to 1.48e-02 ---\n","[2022-04-23 11:51:19,422][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:51:20,768][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:51:20,769][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:51:22,088][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:51:22,090][experiments.experiment][INFO] - [EMA] Epoch 90.[Train] time:445.24541091918945 seconds, lr:0.0148, train_loss: 2.1200, unlabeled_losses_real_strong:0.4472,corrrect_unlabeled_num:397494.0,pro_above_threshold_num:404679.0,unlabelled_weak_top1_acc:94.17114144563675,unlabelled_weak_top5_acc:99.79487881064415  \n","[2022-04-23 11:51:22,091][experiments.experiment][INFO] - [EMA] Epoch 90. [Validation] raw_testing_loss: 0.2750, raw test Top1 acc:92.16, raw test Top5 acc: 99.8, ema_testing_loss: 0.1865, ema test Top1 acc:94.88, ema test Top5 acc: 99.9\n","[2022-04-23 11:51:22,092][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:58:45,176][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 91: use 443.1811218261719 seconds\n","--- Optimizer learning rate changed from 1.48e-02 to 1.45e-02 ---\n","[2022-04-23 11:58:45,273][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:58:46,631][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:58:46,632][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:58:47,990][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:58:47,992][experiments.experiment][INFO] - [EMA] Epoch 91.[Train] time:443.1811218261719 seconds, lr:0.0145, train_loss: 2.1267, unlabeled_losses_real_strong:0.4481,corrrect_unlabeled_num:397603.0,pro_above_threshold_num:405068.0,unlabelled_weak_top1_acc:94.16198622435331,unlabelled_weak_top5_acc:99.78899321705103  \n","[2022-04-23 11:58:47,993][experiments.experiment][INFO] - [EMA] Epoch 91. [Validation] raw_testing_loss: 0.3639, raw test Top1 acc:90.18, raw test Top5 acc: 99.52, ema_testing_loss: 0.1877, ema test Top1 acc:94.58, ema test Top5 acc: 99.9\n","[2022-04-23 11:58:48,096][experiments.experiment][INFO] - [Checkpoints] Epoch 91, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 11:58:48,098][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:06:11,762][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 92: use 443.7620906829834 seconds\n","--- Optimizer learning rate changed from 1.45e-02 to 1.42e-02 ---\n","[2022-04-23 12:06:11,860][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:06:13,186][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:06:13,187][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:06:14,503][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:06:14,505][experiments.experiment][INFO] - [EMA] Epoch 92.[Train] time:443.7620906829834 seconds, lr:0.0142, train_loss: 2.1148, unlabeled_losses_real_strong:0.4446,corrrect_unlabeled_num:398187.0,pro_above_threshold_num:405479.0,unlabelled_weak_top1_acc:94.21669983118773,unlabelled_weak_top5_acc:99.79160905629396  \n","[2022-04-23 12:06:14,507][experiments.experiment][INFO] - [EMA] Epoch 92. [Validation] raw_testing_loss: 0.3293, raw test Top1 acc:90.68, raw test Top5 acc: 99.66, ema_testing_loss: 0.1893, ema test Top1 acc:94.42, ema test Top5 acc: 99.88\n","[2022-04-23 12:06:14,508][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:13:37,238][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 93: use 442.83266615867615 seconds\n","--- Optimizer learning rate changed from 1.42e-02 to 1.39e-02 ---\n","[2022-04-23 12:13:37,341][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:13:38,694][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:13:38,694][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:13:40,042][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:13:40,043][experiments.experiment][INFO] - [EMA] Epoch 93.[Train] time:442.83266615867615 seconds, lr:0.0139, train_loss: 2.1037, unlabeled_losses_real_strong:0.4420,corrrect_unlabeled_num:398480.0,pro_above_threshold_num:405752.0,unlabelled_weak_top1_acc:94.25768058001995,unlabelled_weak_top5_acc:99.79248096048832  \n","[2022-04-23 12:13:40,045][experiments.experiment][INFO] - [EMA] Epoch 93. [Validation] raw_testing_loss: 0.2768, raw test Top1 acc:92.12, raw test Top5 acc: 99.7, ema_testing_loss: 0.1899, ema test Top1 acc:94.44, ema test Top5 acc: 99.86\n","[2022-04-23 12:13:40,139][experiments.experiment][INFO] - [Checkpoints] Epoch 93, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 12:13:40,141][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:21:02,329][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 94: use 442.28807854652405 seconds\n","--- Optimizer learning rate changed from 1.39e-02 to 1.36e-02 ---\n","[2022-04-23 12:21:02,429][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:21:03,784][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:21:03,784][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:21:05,112][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:21:05,114][experiments.experiment][INFO] - [EMA] Epoch 94.[Train] time:442.28807854652405 seconds, lr:0.0136, train_loss: 2.1019, unlabeled_losses_real_strong:0.4400,corrrect_unlabeled_num:399098.0,pro_above_threshold_num:406444.0,unlabelled_weak_top1_acc:94.2812228128314,unlabelled_weak_top5_acc:99.79902046173811  \n","[2022-04-23 12:21:05,117][experiments.experiment][INFO] - [EMA] Epoch 94. [Validation] raw_testing_loss: 0.3121, raw test Top1 acc:90.98, raw test Top5 acc: 99.8, ema_testing_loss: 0.1881, ema test Top1 acc:94.64, ema test Top5 acc: 99.88\n","[2022-04-23 12:21:05,118][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:28:28,137][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 95: use 443.12046670913696 seconds\n","--- Optimizer learning rate changed from 1.36e-02 to 1.33e-02 ---\n","[2022-04-23 12:28:28,238][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:28:29,658][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:28:29,658][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:28:31,007][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:28:31,009][experiments.experiment][INFO] - [EMA] Epoch 95.[Train] time:443.12046670913696 seconds, lr:0.0133, train_loss: 2.0866, unlabeled_losses_real_strong:0.4403,corrrect_unlabeled_num:399326.0,pro_above_threshold_num:406660.0,unlabelled_weak_top1_acc:94.34051404893398,unlabelled_weak_top5_acc:99.79749463498592  \n","[2022-04-23 12:28:31,010][experiments.experiment][INFO] - [EMA] Epoch 95. [Validation] raw_testing_loss: 0.2733, raw test Top1 acc:92.56, raw test Top5 acc: 99.8, ema_testing_loss: 0.1883, ema test Top1 acc:94.56, ema test Top5 acc: 99.9\n","[2022-04-23 12:28:31,106][experiments.experiment][INFO] - [Checkpoints] Epoch 95, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 12:28:31,108][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:35:53,957][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 96: use 442.961492061615 seconds\n","--- Optimizer learning rate changed from 1.33e-02 to 1.30e-02 ---\n","[2022-04-23 12:35:54,070][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:35:55,429][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:35:55,430][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:35:56,795][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:35:56,797][experiments.experiment][INFO] - [EMA] Epoch 96.[Train] time:442.961492061615 seconds, lr:0.0130, train_loss: 2.0874, unlabeled_losses_real_strong:0.4336,corrrect_unlabeled_num:400361.0,pro_above_threshold_num:407741.0,unlabelled_weak_top1_acc:94.40285713970661,unlabelled_weak_top5_acc:99.80534193664789  \n","[2022-04-23 12:35:56,798][experiments.experiment][INFO] - [EMA] Epoch 96. [Validation] raw_testing_loss: 0.2534, raw test Top1 acc:92.86, raw test Top5 acc: 99.8, ema_testing_loss: 0.1875, ema test Top1 acc:94.62, ema test Top5 acc: 99.9\n","[2022-04-23 12:35:56,800][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:43:19,107][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 97: use 442.4038851261139 seconds\n","--- Optimizer learning rate changed from 1.30e-02 to 1.27e-02 ---\n","[2022-04-23 12:43:19,204][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:43:20,529][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:43:20,530][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:43:21,868][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:43:21,869][experiments.experiment][INFO] - [EMA] Epoch 97.[Train] time:442.4038851261139 seconds, lr:0.0127, train_loss: 2.0540, unlabeled_losses_real_strong:0.4292,corrrect_unlabeled_num:400545.0,pro_above_threshold_num:407922.0,unlabelled_weak_top1_acc:94.44231195002794,unlabelled_weak_top5_acc:99.80054631084204  \n","[2022-04-23 12:43:21,872][experiments.experiment][INFO] - [EMA] Epoch 97. [Validation] raw_testing_loss: 0.2827, raw test Top1 acc:92.24, raw test Top5 acc: 99.8, ema_testing_loss: 0.1900, ema test Top1 acc:94.64, ema test Top5 acc: 99.88\n","[2022-04-23 12:43:21,972][experiments.experiment][INFO] - [Checkpoints] Epoch 97, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 12:43:21,973][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:50:44,325][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 98: use 442.44673466682434 seconds\n","--- Optimizer learning rate changed from 1.27e-02 to 1.24e-02 ---\n","[2022-04-23 12:50:44,420][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:50:45,724][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:50:45,725][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:50:47,049][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:50:47,050][experiments.experiment][INFO] - [EMA] Epoch 98.[Train] time:442.44673466682434 seconds, lr:0.0124, train_loss: 2.0415, unlabeled_losses_real_strong:0.4255,corrrect_unlabeled_num:401621.0,pro_above_threshold_num:408856.0,unlabelled_weak_top1_acc:94.50203926116228,unlabelled_weak_top5_acc:99.79727650433779  \n","[2022-04-23 12:50:47,053][experiments.experiment][INFO] - [EMA] Epoch 98. [Validation] raw_testing_loss: 0.2551, raw test Top1 acc:92.14, raw test Top5 acc: 99.84, ema_testing_loss: 0.1900, ema test Top1 acc:94.58, ema test Top5 acc: 99.9\n","[2022-04-23 12:50:47,053][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:58:11,119][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 99: use 444.17027521133423 seconds\n","--- Optimizer learning rate changed from 1.24e-02 to 1.21e-02 ---\n","[2022-04-23 12:58:11,224][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:58:12,560][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:58:12,561][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:58:13,900][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:58:13,901][experiments.experiment][INFO] - [EMA] Epoch 99.[Train] time:444.17027521133423 seconds, lr:0.0121, train_loss: 2.0449, unlabeled_losses_real_strong:0.4260,corrrect_unlabeled_num:400878.0,pro_above_threshold_num:408189.0,unlabelled_weak_top1_acc:94.49419176578522,unlabelled_weak_top5_acc:99.79836650937796  \n","[2022-04-23 12:58:13,902][experiments.experiment][INFO] - [EMA] Epoch 99. [Validation] raw_testing_loss: 0.2615, raw test Top1 acc:92.1, raw test Top5 acc: 99.7, ema_testing_loss: 0.1876, ema test Top1 acc:94.82, ema test Top5 acc: 99.88\n","[2022-04-23 12:58:14,010][experiments.experiment][INFO] - [Checkpoints] Epoch 99, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 12:58:14,020][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:05:39,879][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 100: use 445.9701781272888 seconds\n","--- Optimizer learning rate changed from 1.21e-02 to 1.18e-02 ---\n","[2022-04-23 13:05:39,990][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:05:41,354][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:05:41,355][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:05:42,700][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:05:42,701][experiments.experiment][INFO] - [EMA] Epoch 100.[Train] time:445.9701781272888 seconds, lr:0.0118, train_loss: 2.0442, unlabeled_losses_real_strong:0.4250,corrrect_unlabeled_num:401379.0,pro_above_threshold_num:408637.0,unlabelled_weak_top1_acc:94.5486875474453,unlabelled_weak_top5_acc:99.80926558375359  \n","[2022-04-23 13:05:42,703][experiments.experiment][INFO] - [EMA] Epoch 100. [Validation] raw_testing_loss: 0.2721, raw test Top1 acc:91.92, raw test Top5 acc: 99.78, ema_testing_loss: 0.1869, ema test Top1 acc:94.64, ema test Top5 acc: 99.88\n","[2022-04-23 13:05:42,705][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:13:08,290][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 101: use 445.68667244911194 seconds\n","--- Optimizer learning rate changed from 1.18e-02 to 1.14e-02 ---\n","[2022-04-23 13:13:08,392][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:13:09,708][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:13:09,709][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:13:11,060][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:13:11,061][experiments.experiment][INFO] - [EMA] Epoch 101.[Train] time:445.68667244911194 seconds, lr:0.0114, train_loss: 2.0148, unlabeled_losses_real_strong:0.4193,corrrect_unlabeled_num:402125.0,pro_above_threshold_num:409275.0,unlabelled_weak_top1_acc:94.5744095519185,unlabelled_weak_top5_acc:99.80599594116211  \n","[2022-04-23 13:13:11,064][experiments.experiment][INFO] - [EMA] Epoch 101. [Validation] raw_testing_loss: 0.2448, raw test Top1 acc:92.68, raw test Top5 acc: 99.84, ema_testing_loss: 0.1838, ema test Top1 acc:94.72, ema test Top5 acc: 99.9\n","[2022-04-23 13:13:11,159][experiments.experiment][INFO] - [Checkpoints] Epoch 101, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 13:13:11,169][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:20:36,263][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 102: use 445.19778418540955 seconds\n","--- Optimizer learning rate changed from 1.14e-02 to 1.11e-02 ---\n","[2022-04-23 13:20:36,367][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:20:37,713][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:20:37,713][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:20:39,059][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:20:39,061][experiments.experiment][INFO] - [EMA] Epoch 102.[Train] time:445.19778418540955 seconds, lr:0.0111, train_loss: 1.9980, unlabeled_losses_real_strong:0.4158,corrrect_unlabeled_num:402752.0,pro_above_threshold_num:409970.0,unlabelled_weak_top1_acc:94.67271974682808,unlabelled_weak_top5_acc:99.81384326517582  \n","[2022-04-23 13:20:39,062][experiments.experiment][INFO] - [EMA] Epoch 102. [Validation] raw_testing_loss: 0.2392, raw test Top1 acc:92.92, raw test Top5 acc: 99.84, ema_testing_loss: 0.1840, ema test Top1 acc:94.68, ema test Top5 acc: 99.9\n","[2022-04-23 13:20:39,063][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:28:06,488][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 103: use 447.52486395835876 seconds\n","--- Optimizer learning rate changed from 1.11e-02 to 1.08e-02 ---\n","[2022-04-23 13:28:06,588][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:28:07,937][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:28:07,937][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:28:09,308][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:28:09,310][experiments.experiment][INFO] - [EMA] Epoch 103.[Train] time:447.52486395835876 seconds, lr:0.0108, train_loss: 1.9907, unlabeled_losses_real_strong:0.4145,corrrect_unlabeled_num:403635.0,pro_above_threshold_num:410718.0,unlabelled_weak_top1_acc:94.71217446774244,unlabelled_weak_top5_acc:99.81362529098988  \n","[2022-04-23 13:28:09,313][experiments.experiment][INFO] - [EMA] Epoch 103. [Validation] raw_testing_loss: 0.2435, raw test Top1 acc:92.96, raw test Top5 acc: 99.78, ema_testing_loss: 0.1816, ema test Top1 acc:94.74, ema test Top5 acc: 99.84\n","[2022-04-23 13:28:09,408][experiments.experiment][INFO] - [Checkpoints] Epoch 103, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 13:28:09,410][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:35:39,488][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 104: use 450.1859242916107 seconds\n","--- Optimizer learning rate changed from 1.08e-02 to 1.05e-02 ---\n","[2022-04-23 13:35:39,596][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:35:40,956][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:35:40,956][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:35:42,295][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:35:42,297][experiments.experiment][INFO] - [EMA] Epoch 104.[Train] time:450.1859242916107 seconds, lr:0.0105, train_loss: 1.9704, unlabeled_losses_real_strong:0.4092,corrrect_unlabeled_num:403947.0,pro_above_threshold_num:411174.0,unlabelled_weak_top1_acc:94.70607097446918,unlabelled_weak_top5_acc:99.81493318080902  \n","[2022-04-23 13:35:42,299][experiments.experiment][INFO] - [EMA] Epoch 104. [Validation] raw_testing_loss: 0.2842, raw test Top1 acc:92.3, raw test Top5 acc: 99.8, ema_testing_loss: 0.1824, ema test Top1 acc:94.94, ema test Top5 acc: 99.84\n","[2022-04-23 13:35:42,300][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:43:12,136][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 105: use 449.9347417354584 seconds\n","--- Optimizer learning rate changed from 1.05e-02 to 1.02e-02 ---\n","[2022-04-23 13:43:12,235][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:43:13,665][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:43:13,665][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:43:15,064][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:43:15,066][experiments.experiment][INFO] - [EMA] Epoch 105.[Train] time:449.9347417354584 seconds, lr:0.0102, train_loss: 1.9440, unlabeled_losses_real_strong:0.4077,corrrect_unlabeled_num:404710.0,pro_above_threshold_num:411818.0,unlabelled_weak_top1_acc:94.79522594064474,unlabelled_weak_top5_acc:99.80316212773323  \n","[2022-04-23 13:43:15,068][experiments.experiment][INFO] - [EMA] Epoch 105. [Validation] raw_testing_loss: 0.3341, raw test Top1 acc:91.22, raw test Top5 acc: 99.76, ema_testing_loss: 0.1831, ema test Top1 acc:94.82, ema test Top5 acc: 99.88\n","[2022-04-23 13:43:15,171][experiments.experiment][INFO] - [Checkpoints] Epoch 105, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 13:43:15,174][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:50:45,694][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 106: use 450.6228048801422 seconds\n","--- Optimizer learning rate changed from 1.02e-02 to 9.83e-03 ---\n","[2022-04-23 13:50:45,797][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:50:47,144][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:50:47,145][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:50:48,527][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:50:48,529][experiments.experiment][INFO] - [EMA] Epoch 106.[Train] time:450.6228048801422 seconds, lr:0.0098, train_loss: 1.9591, unlabeled_losses_real_strong:0.4027,corrrect_unlabeled_num:405608.0,pro_above_threshold_num:412747.0,unlabelled_weak_top1_acc:94.86999399214983,unlabelled_weak_top5_acc:99.82212663441896  \n","[2022-04-23 13:50:48,531][experiments.experiment][INFO] - [EMA] Epoch 106. [Validation] raw_testing_loss: 0.2294, raw test Top1 acc:92.98, raw test Top5 acc: 99.76, ema_testing_loss: 0.1796, ema test Top1 acc:94.7, ema test Top5 acc: 99.88\n","[2022-04-23 13:50:48,532][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:58:22,200][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 107: use 453.7719302177429 seconds\n","--- Optimizer learning rate changed from 9.83e-03 to 9.50e-03 ---\n","[2022-04-23 13:58:22,304][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:58:23,648][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:58:23,648][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:58:24,968][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:58:24,969][experiments.experiment][INFO] - [EMA] Epoch 107.[Train] time:453.7719302177429 seconds, lr:0.0095, train_loss: 1.9235, unlabeled_losses_real_strong:0.4011,corrrect_unlabeled_num:405064.0,pro_above_threshold_num:412365.0,unlabelled_weak_top1_acc:94.82443565875292,unlabelled_weak_top5_acc:99.81340730935335  \n","[2022-04-23 13:58:24,971][experiments.experiment][INFO] - [EMA] Epoch 107. [Validation] raw_testing_loss: 0.2356, raw test Top1 acc:93.14, raw test Top5 acc: 99.9, ema_testing_loss: 0.1799, ema test Top1 acc:94.84, ema test Top5 acc: 99.9\n","[2022-04-23 13:58:25,066][experiments.experiment][INFO] - [Checkpoints] Epoch 107, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 13:58:25,068][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 14:05:55,673][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 108: use 450.71982049942017 seconds\n","--- Optimizer learning rate changed from 9.50e-03 to 9.18e-03 ---\n","[2022-04-23 14:05:55,788][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:05:57,114][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 14:05:57,115][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:05:58,438][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 14:05:58,439][experiments.experiment][INFO] - [EMA] Epoch 108.[Train] time:450.71982049942017 seconds, lr:0.0092, train_loss: 1.9058, unlabeled_losses_real_strong:0.3965,corrrect_unlabeled_num:406124.0,pro_above_threshold_num:413448.0,unlabelled_weak_top1_acc:94.88241905719042,unlabelled_weak_top5_acc:99.80817573517561  \n","[2022-04-23 14:05:58,441][experiments.experiment][INFO] - [EMA] Epoch 108. [Validation] raw_testing_loss: 0.2549, raw test Top1 acc:92.32, raw test Top5 acc: 99.78, ema_testing_loss: 0.1782, ema test Top1 acc:94.8, ema test Top5 acc: 99.9\n","[2022-04-23 14:05:58,443][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 14:13:29,298][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 109: use 450.96139216423035 seconds\n","--- Optimizer learning rate changed from 9.18e-03 to 8.85e-03 ---\n","[2022-04-23 14:13:29,404][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:13:30,767][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 14:13:30,767][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:13:32,144][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 14:13:32,146][experiments.experiment][INFO] - [EMA] Epoch 109.[Train] time:450.96139216423035 seconds, lr:0.0088, train_loss: 1.8949, unlabeled_losses_real_strong:0.3947,corrrect_unlabeled_num:406505.0,pro_above_threshold_num:413933.0,unlabelled_weak_top1_acc:94.91402646899223,unlabelled_weak_top5_acc:99.82147269695997  \n","[2022-04-23 14:13:32,148][experiments.experiment][INFO] - [EMA] Epoch 109. [Validation] raw_testing_loss: 0.2283, raw test Top1 acc:93.44, raw test Top5 acc: 99.88, ema_testing_loss: 0.1787, ema test Top1 acc:94.78, ema test Top5 acc: 99.92\n","[2022-04-23 14:13:32,241][experiments.experiment][INFO] - [Checkpoints] Epoch 109, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 14:13:32,251][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 14:21:00,642][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 110: use 448.4922833442688 seconds\n","--- Optimizer learning rate changed from 8.85e-03 to 8.52e-03 ---\n","[2022-04-23 14:21:00,744][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:21:02,093][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 14:21:02,093][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:21:03,468][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 14:21:03,469][experiments.experiment][INFO] - [EMA] Epoch 110.[Train] time:448.4922833442688 seconds, lr:0.0085, train_loss: 1.8892, unlabeled_losses_real_strong:0.3924,corrrect_unlabeled_num:407556.0,pro_above_threshold_num:415025.0,unlabelled_weak_top1_acc:94.94977574050426,unlabelled_weak_top5_acc:99.82539638131857  \n","[2022-04-23 14:21:03,471][experiments.experiment][INFO] - [EMA] Epoch 110. [Validation] raw_testing_loss: 0.2087, raw test Top1 acc:93.8, raw test Top5 acc: 99.88, ema_testing_loss: 0.1751, ema test Top1 acc:94.88, ema test Top5 acc: 99.92\n","[2022-04-23 14:21:03,472][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 14:28:34,039][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 111: use 450.670214176178 seconds\n","--- Optimizer learning rate changed from 8.52e-03 to 8.19e-03 ---\n","[2022-04-23 14:28:34,143][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:28:35,554][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 14:28:35,554][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:28:36,888][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 14:28:36,890][experiments.experiment][INFO] - [EMA] Epoch 111.[Train] time:450.670214176178 seconds, lr:0.0082, train_loss: 1.8760, unlabeled_losses_real_strong:0.3894,corrrect_unlabeled_num:407572.0,pro_above_threshold_num:415150.0,unlabelled_weak_top1_acc:94.97004810720682,unlabelled_weak_top5_acc:99.81842090189457  \n","[2022-04-23 14:28:36,892][experiments.experiment][INFO] - [EMA] Epoch 111. [Validation] raw_testing_loss: 0.2444, raw test Top1 acc:92.94, raw test Top5 acc: 99.82, ema_testing_loss: 0.1749, ema test Top1 acc:94.92, ema test Top5 acc: 99.92\n","[2022-04-23 14:28:36,988][experiments.experiment][INFO] - [Checkpoints] Epoch 111, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 14:28:36,990][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 14:36:05,417][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 112: use 448.52502846717834 seconds\n","--- Optimizer learning rate changed from 8.19e-03 to 7.86e-03 ---\n","[2022-04-23 14:36:05,515][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:36:06,863][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 14:36:06,864][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:36:08,222][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 14:36:08,224][experiments.experiment][INFO] - [EMA] Epoch 112.[Train] time:448.52502846717834 seconds, lr:0.0079, train_loss: 1.8349, unlabeled_losses_real_strong:0.3839,corrrect_unlabeled_num:407838.0,pro_above_threshold_num:415240.0,unlabelled_weak_top1_acc:94.99664196372032,unlabelled_weak_top5_acc:99.83084597438574  \n","[2022-04-23 14:36:08,226][experiments.experiment][INFO] - [EMA] Epoch 112. [Validation] raw_testing_loss: 0.2441, raw test Top1 acc:93.06, raw test Top5 acc: 99.8, ema_testing_loss: 0.1758, ema test Top1 acc:94.84, ema test Top5 acc: 99.88\n","[2022-04-23 14:36:08,227][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 14:43:38,209][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 113: use 450.0819945335388 seconds\n","--- Optimizer learning rate changed from 7.86e-03 to 7.53e-03 ---\n","[2022-04-23 14:43:38,309][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:43:39,685][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 14:43:39,685][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:43:41,025][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 14:43:41,027][experiments.experiment][INFO] - [EMA] Epoch 113.[Train] time:450.0819945335388 seconds, lr:0.0075, train_loss: 1.8227, unlabeled_losses_real_strong:0.3821,corrrect_unlabeled_num:408438.0,pro_above_threshold_num:415764.0,unlabelled_weak_top1_acc:95.08884858340025,unlabelled_weak_top5_acc:99.82823011279106  \n","[2022-04-23 14:43:41,028][experiments.experiment][INFO] - [EMA] Epoch 113. [Validation] raw_testing_loss: 0.2302, raw test Top1 acc:93.06, raw test Top5 acc: 99.8, ema_testing_loss: 0.1734, ema test Top1 acc:95.04, ema test Top5 acc: 99.88\n","[2022-04-23 14:43:41,123][experiments.experiment][INFO] - [Checkpoints] Epoch 113, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 14:43:41,125][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 14:51:10,843][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 114: use 449.81463146209717 seconds\n","--- Optimizer learning rate changed from 7.53e-03 to 7.19e-03 ---\n","[2022-04-23 14:51:10,940][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:51:12,273][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 14:51:12,273][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:51:13,663][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 14:51:13,664][experiments.experiment][INFO] - [EMA] Epoch 114.[Train] time:449.81463146209717 seconds, lr:0.0072, train_loss: 1.7982, unlabeled_losses_real_strong:0.3770,corrrect_unlabeled_num:409052.0,pro_above_threshold_num:416644.0,unlabelled_weak_top1_acc:95.07991137355566,unlabelled_weak_top5_acc:99.8251784145832  \n","[2022-04-23 14:51:13,667][experiments.experiment][INFO] - [EMA] Epoch 114. [Validation] raw_testing_loss: 0.2264, raw test Top1 acc:93.64, raw test Top5 acc: 99.84, ema_testing_loss: 0.1688, ema test Top1 acc:95.0, ema test Top5 acc: 99.86\n","[2022-04-23 14:51:13,668][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 14:58:43,467][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 115: use 449.90925693511963 seconds\n","--- Optimizer learning rate changed from 7.19e-03 to 6.86e-03 ---\n","[2022-04-23 14:58:43,577][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:58:44,974][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 14:58:44,975][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:58:46,311][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 14:58:46,313][experiments.experiment][INFO] - [EMA] Epoch 115.[Train] time:449.90925693511963 seconds, lr:0.0069, train_loss: 1.7749, unlabeled_losses_real_strong:0.3767,corrrect_unlabeled_num:409350.0,pro_above_threshold_num:416836.0,unlabelled_weak_top1_acc:95.16230881214142,unlabelled_weak_top5_acc:99.81515115499496  \n","[2022-04-23 14:58:46,315][experiments.experiment][INFO] - [EMA] Epoch 115. [Validation] raw_testing_loss: 0.2518, raw test Top1 acc:92.42, raw test Top5 acc: 99.92, ema_testing_loss: 0.1680, ema test Top1 acc:95.4, ema test Top5 acc: 99.84\n","[2022-04-23 14:58:46,418][experiments.experiment][INFO] - [Checkpoints] Epoch 115, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 14:58:46,427][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 15:06:15,465][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 116: use 449.14140272140503 seconds\n","--- Optimizer learning rate changed from 6.86e-03 to 6.53e-03 ---\n","[2022-04-23 15:06:15,569][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 15:06:17,010][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 15:06:17,010][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 15:06:18,391][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 15:06:18,392][experiments.experiment][INFO] - [EMA] Epoch 116.[Train] time:449.14140272140503 seconds, lr:0.0065, train_loss: 1.7535, unlabeled_losses_real_strong:0.3715,corrrect_unlabeled_num:409684.0,pro_above_threshold_num:417082.0,unlabelled_weak_top1_acc:95.20655933022499,unlabelled_weak_top5_acc:99.81863894313574  \n","[2022-04-23 15:06:18,394][experiments.experiment][INFO] - [EMA] Epoch 116. [Validation] raw_testing_loss: 0.1902, raw test Top1 acc:94.42, raw test Top5 acc: 99.8, ema_testing_loss: 0.1668, ema test Top1 acc:95.14, ema test Top5 acc: 99.86\n","[2022-04-23 15:06:18,395][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 15:13:47,001][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 117: use 448.70597648620605 seconds\n","--- Optimizer learning rate changed from 6.53e-03 to 6.19e-03 ---\n","[2022-04-23 15:13:47,101][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 15:13:48,463][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 15:13:48,464][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 15:13:49,809][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 15:13:49,811][experiments.experiment][INFO] - [EMA] Epoch 117.[Train] time:448.70597648620605 seconds, lr:0.0062, train_loss: 1.7484, unlabeled_losses_real_strong:0.3666,corrrect_unlabeled_num:410530.0,pro_above_threshold_num:417924.0,unlabelled_weak_top1_acc:95.23773098737001,unlabelled_weak_top5_acc:99.82387049496174  \n","[2022-04-23 15:13:49,812][experiments.experiment][INFO] - [EMA] Epoch 117. [Validation] raw_testing_loss: 0.2017, raw test Top1 acc:93.62, raw test Top5 acc: 99.86, ema_testing_loss: 0.1661, ema test Top1 acc:95.12, ema test Top5 acc: 99.88\n","[2022-04-23 15:13:49,909][experiments.experiment][INFO] - [Checkpoints] Epoch 117, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","[2022-04-23 15:13:49,912][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 15:21:16,976][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 118: use 447.1654510498047 seconds\n","--- Optimizer learning rate changed from 6.19e-03 to 5.85e-03 ---\n","[2022-04-23 15:21:17,077][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 15:21:18,438][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 15:21:18,438][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 15:21:19,841][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 15:21:19,842][experiments.experiment][INFO] - [EMA] Epoch 118.[Train] time:447.1654510498047 seconds, lr:0.0059, train_loss: 1.7085, unlabeled_losses_real_strong:0.3614,corrrect_unlabeled_num:410394.0,pro_above_threshold_num:417852.0,unlabelled_weak_top1_acc:95.24950183928013,unlabelled_weak_top5_acc:99.82670422643423  \n","[2022-04-23 15:21:19,845][experiments.experiment][INFO] - [EMA] Epoch 118. [Validation] raw_testing_loss: 0.2213, raw test Top1 acc:93.76, raw test Top5 acc: 99.92, ema_testing_loss: 0.1670, ema test Top1 acc:95.1, ema test Top5 acc: 99.88\n","[2022-04-23 15:21:19,846][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 15:28:48,761][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 119: use 449.02145528793335 seconds\n","--- Optimizer learning rate changed from 5.85e-03 to 5.52e-03 ---\n","[2022-04-23 15:28:48,867][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 15:28:50,249][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 15:28:50,250][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 15:28:51,619][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 15:28:51,621][experiments.experiment][INFO] - [EMA] Epoch 119.[Train] time:449.02145528793335 seconds, lr:0.0055, train_loss: 1.6830, unlabeled_losses_real_strong:0.3595,corrrect_unlabeled_num:411392.0,pro_above_threshold_num:419069.0,unlabelled_weak_top1_acc:95.25996522605419,unlabelled_weak_top5_acc:99.82408849149942  \n","[2022-04-23 15:28:51,622][experiments.experiment][INFO] - [EMA] Epoch 119. [Validation] raw_testing_loss: 0.2036, raw test Top1 acc:93.82, raw test Top5 acc: 99.88, ema_testing_loss: 0.1668, ema test Top1 acc:95.04, ema test Top5 acc: 99.88\n","[2022-04-23 15:28:51,728][experiments.experiment][INFO] - [Checkpoints] Epoch 119, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_10/FMExperiment.pth.tar\n","======= Training done =======\n","2022-04-23 15:28:51,760 - INFO - Train -   ======= Training done =======\n","[2022-04-23 15:28:51,760][Train][INFO] - ======= Training done =======\n","[2022-04-23 15:28:51,761][experiments.experiment][INFO] - Loading Testing Loader\n","[2022-04-23 15:28:51,771][experiments.experiment][INFO] - [Testing with EMA] apply shadow\n","[2022-04-23 15:28:51,772][experiments.experiment][INFO] - ***** Running testing *****\n","[2022-04-23 15:28:54,267][experiments.experiment][INFO] - [Testing(EMA)] testing_loss: 0.1723, test Top1 acc:94.83, test Top5 acc: 99.85\n","[2022-04-23 15:28:54,277][experiments.experiment][INFO] - [EMA] restore \n","======= Testing done =======\n","2022-04-23 15:28:54,277 - INFO - Train -   ======= Testing done =======\n","[2022-04-23 15:28:54,277][Train][INFO] - ======= Testing done =======\n"]}]}]}