{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"celiali-lambda2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNtOSXs/5Y0mHI6LanYkthl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"OHvTZdrY1b55","executionInfo":{"status":"ok","timestamp":1650338676974,"user_tz":300,"elapsed":142644,"user":{"displayName":"CM Y","userId":"12660552299343911788"}},"outputId":"959dad6c-d84d-4216-cfef-ee27afc486c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/celiali\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 2)) (1.0.0)\n","Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 3)) (1.9)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 4)) (0.29.28)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 5)) (1.21.5)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 7)) (4.64.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 8)) (1.4.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 9)) (7.1.2)\n","Collecting torch==1.8.0\n","  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n","\u001b[K     |████████████████████████████████| 735.5 MB 15 kB/s \n","\u001b[?25hCollecting torchvision==0.9.0\n","  Downloading torchvision-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n","\u001b[K     |████████████████████████████████| 17.3 MB 121 kB/s \n","\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 12)) (0.10.0+cu111)\n","Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 13)) (0.11.0)\n","Collecting omegaconf\n","  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\n","\u001b[K     |████████████████████████████████| 74 kB 2.9 MB/s \n","\u001b[?25hCollecting hydra\n","  Downloading Hydra-2.5.tar.gz (82 kB)\n","\u001b[K     |████████████████████████████████| 82 kB 223 kB/s \n","\u001b[?25hCollecting hydra-core\n","  Downloading hydra_core-1.1.2-py3-none-any.whl (147 kB)\n","\u001b[K     |████████████████████████████████| 147 kB 49.2 MB/s \n","\u001b[?25hCollecting ignite\n","  Downloading ignite-1.1.0-py2.py3-none-any.whl (4.5 kB)\n","Collecting pytorch-ignite\n","  Downloading pytorch_ignite-0.4.8-py3-none-any.whl (251 kB)\n","\u001b[K     |████████████████████████████████| 251 kB 51.5 MB/s \n","\u001b[?25hCollecting tensorboardX\n","  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 29.5 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 20)) (1.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 21)) (3.2.2)\n","Collecting abel-pytorch\n","  Downloading abel_pytorch-0.0.1-py3-none-any.whl (4.2 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r google_requirements.txt (line 10)) (4.1.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->-r google_requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.5.3)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.3.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.24.0)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 50.2 MB/s \n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.2.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.14.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (13.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (57.4.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.1.2)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.6.3)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.17.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.1.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.1.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.44.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->-r google_requirements.txt (line 6)) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->-r google_requirements.txt (line 6)) (1.5.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2.23.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.0.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.35.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.6.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.2.0)\n","Collecting torchaudio\n","  Downloading torchaudio-0.11.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 33.0 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 36.3 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 47.6 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 34.5 MB/s \n","\u001b[?25h  Downloading torchaudio-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 32.4 MB/s \n","\u001b[?25h  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 36.3 MB/s \n","\u001b[?25h  Downloading torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 24.7 MB/s \n","\u001b[?25h  Downloading torchaudio-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 20.9 MB/s \n","\u001b[?25hCollecting torchtext\n","  Downloading torchtext-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n","\u001b[K     |████████████████████████████████| 10.4 MB 22.1 MB/s \n","\u001b[?25h  Downloading torchtext-0.11.2-cp37-cp37m-manylinux1_x86_64.whl (8.0 MB)\n","\u001b[K     |████████████████████████████████| 8.0 MB 39.7 MB/s \n","\u001b[?25h  Downloading torchtext-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (8.0 MB)\n","\u001b[K     |████████████████████████████████| 8.0 MB 35.0 MB/s \n","\u001b[?25h  Downloading torchtext-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 37.2 MB/s \n","\u001b[?25h  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 22.5 MB/s \n","\u001b[?25h  Downloading torchtext-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 15.0 MB/s \n","\u001b[?25h  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 27.2 MB/s \n","\u001b[?25hCollecting PyYAML>=5.1.0\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 46.5 MB/s \n","\u001b[?25hCollecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 49.1 MB/s \n","\u001b[?25hCollecting importlib-resources<5.3\n","  Downloading importlib_resources-5.2.3-py3-none-any.whl (27 kB)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r google_requirements.txt (line 20)) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r google_requirements.txt (line 20)) (3.1.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (3.0.8)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (1.4.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (2.8.2)\n","Building wheels for collected packages: antlr4-python3-runtime, hydra\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=0fa1f10644cdb87ed43cd83d966ee1171250d93dc5cbffe169bc95b1089ef046\n","  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n","  Building wheel for hydra (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hydra: filename=Hydra-2.5-cp37-cp37m-linux_x86_64.whl size=220763 sha256=9889e2895fa947f08afaf83f20b2ce7a84424230a770104f67b1a9755d30b54e\n","  Stored in directory: /root/.cache/pip/wheels/46/28/7d/3b38a41d900da90c4e17576f442bac9344eb1f5a4e78ee9f83\n","Successfully built antlr4-python3-runtime hydra\n","Installing collected packages: PyYAML, antlr4-python3-runtime, torch, tf-estimator-nightly, omegaconf, importlib-resources, torchvision, torchtext, torchaudio, tensorboardX, pytorch-ignite, ignite, hydra-core, hydra, abel-pytorch\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","  Attempting uninstall: importlib-resources\n","    Found existing installation: importlib-resources 5.6.0\n","    Uninstalling importlib-resources-5.6.0:\n","      Successfully uninstalled importlib-resources-5.6.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.11.1+cu111\n","    Uninstalling torchvision-0.11.1+cu111:\n","      Successfully uninstalled torchvision-0.11.1+cu111\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.11.0\n","    Uninstalling torchtext-0.11.0:\n","      Successfully uninstalled torchtext-0.11.0\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.10.0+cu111\n","    Uninstalling torchaudio-0.10.0+cu111:\n","      Successfully uninstalled torchaudio-0.10.0+cu111\n","Successfully installed PyYAML-6.0 abel-pytorch-0.0.1 antlr4-python3-runtime-4.8 hydra-2.5 hydra-core-1.1.2 ignite-1.1.0 importlib-resources-5.2.3 omegaconf-2.1.2 pytorch-ignite-0.4.8 tensorboardX-2.5 tf-estimator-nightly-2.8.0.dev2021122109 torch-1.8.0 torchaudio-0.8.0 torchtext-0.9.0 torchvision-0.9.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{}}],"source":["# Mount into drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","# Change directory to the package folder\n","%cd '/content/drive/MyDrive/celiali'\n","%pip install -r google_requirements.txt"]},{"cell_type":"code","source":["!python run.py DATASET.label_num=4000 DATASET.strongaugment='RA' EXPERIMENT.epoch_n=120 EXPERIMENT.batch_size=64 MODEL.name='WideResNet_Lk' MODEL.depth=28 MODEL.widen_factor=2 MODEL.num_classes=10 EXPERIMENT.out_model='./checkpoints/checkpoints_celiali-lambda_unlabled_2/' EXPERIMENT.log_path='./outputs/outputs_lambda_unlabled_2/' EXPERIMENT.save_cfmatrix=False EXPERIMENT.decay_type='cosine' DATASET.cut_type='cutout' EXPERIMENT.lambda_unlabeled=2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JteofEcR1d0s","executionInfo":{"status":"ok","timestamp":1650411670582,"user_tz":300,"elapsed":14832111,"user":{"displayName":"CM Y","userId":"12660552299343911788"}},"outputId":"5ee1431f-287d-4033-d105-f345744b89c0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["==> CONFIG is: \n"," DATASET:\n","  project_dir: ./\n","  data_dir: data\n","  loading_data: LOAD_LABEL_UNLABEL\n","  dataset: CIFAR10\n","  strongaugment: RA\n","  cut_type: cutout\n","  label_num: 4000\n","  num_expand_x: 65536\n","  mu: 7\n","  barely: false\n","  add_noisy_label: false\n","  both_strong: false\n","MODEL:\n","  name: WideResNet_Lk\n","  depth: 28\n","  widen_factor: 2\n","  num_classes: 10\n","  dropout: 0.0\n","  cardinality: 4\n","  width: 4\n","  base_width: 4\n","EXPERIMENT:\n","  name: FMExperiment\n","  out_model: ./checkpoints/checkpoints_celiali-lambda_unlabled_2/\n","  log_path: ./outputs/outputs_lambda_unlabled_2/\n","  used_gpu: true\n","  decay_type: cosine\n","  abel_decay: 0.1\n","  optim_lr: 0.03\n","  optim_momentum: 0.9\n","  used_nesterov: true\n","  warmup: 0\n","  wdecay: 0.0005\n","  clip: 1\n","  ema_used: true\n","  ema_decay: 0.999\n","  threshold: 0.95\n","  lambda_unlabeled: 2\n","  batch_size: 64\n","  num_workers: 4\n","  n_imgs_per_epoch: 65536\n","  epoch_n: 120\n","  save_every: 2\n","  save_matrix_every: 20\n","  resume: false\n","  resume_checkpoints: ./checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar\n","  save_cfmatrix: false\n","  batch_balanced: false\n","  neg_penalty: false\n","  equal_freq: false\n","  eta_negpenalty: 0.05\n","  eta_dynamic: false\n","  use_nlloss: false\n","  q: 0.0001\n","Logging:\n","  name: FM\n","  seed: 1265\n"," \n","\n","2022-04-19 03:24:59,999 - INFO - Train -   {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'cut_type': 'cutout', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-lambda_unlabled_2/', 'log_path': './outputs/outputs_lambda_unlabled_2/', 'used_gpu': True, 'decay_type': 'cosine', 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 2, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': False, 'resume_checkpoints': './checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","[2022-04-19 03:24:59,999][Train][INFO] - {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'cut_type': 'cutout', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-lambda_unlabled_2/', 'log_path': './outputs/outputs_lambda_unlabled_2/', 'used_gpu': True, 'decay_type': 'cosine', 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 2, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': False, 'resume_checkpoints': './checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","2022-04-19 03:25:00,682 - INFO - Train -   [Model] Building model WideResNet_Lk\n","[2022-04-19 03:25:00,682][Train][INFO] - [Model] Building model WideResNet_Lk\n","2022-04-19 03:25:03,496 - INFO - Train -   Total params: 1.47M\n","[2022-04-19 03:25:03,496][Train][INFO] - Total params: 1.47M\n","[2022-04-19 03:25:03,498][experiments.experiment][INFO] - I'm using cosine decay!\n","[2022-04-19 03:25:03,503][experiments.experiment][INFO] - [EMA] initial \n","[2022-04-19 03:25:11,963][datasets.datasets1][INFO] - Dataset: CIFAR10\n","[2022-04-19 03:25:12,020][datasets.datasets1][INFO] - Labeled examples: 65536 Unlabeled examples: 458752Validation examples: 5000\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-19 03:25:12,022][experiments.experiment][INFO] - Loading Labelled Loader\n","[2022-04-19 03:25:12,022][experiments.experiment][INFO] - Loading Unlabelled Loader\n","[2022-04-19 03:25:12,023][experiments.experiment][INFO] - Loading Validation Loader\n","[2022-04-19 03:25:12,034][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 03:35:27,866][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 0: use 615.947331905365 seconds\n","--- Optimizer learning rate changed from inf to 3.00e-02 ---\n","[2022-04-19 03:35:27,981][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 03:35:29,877][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 03:35:29,878][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 03:35:31,746][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 03:35:31,836][experiments.experiment][INFO] - [EMA] Epoch 0.[Train] time:615.947331905365 seconds, lr:0.0300, train_loss: 1.3013, unlabeled_losses_real_strong:2.0270,corrrect_unlabeled_num:24241.0,pro_above_threshold_num:25665.0,unlabelled_weak_top1_acc:51.149858239106834,unlabelled_weak_top5_acc:92.80024824663997  \n","[2022-04-19 03:35:31,837][experiments.experiment][INFO] - [EMA] Epoch 0. [Validation] raw_testing_loss: 1.6564, raw test Top1 acc:44.94, raw test Top5 acc: 90.48, ema_testing_loss: 1.5834, ema test Top1 acc:46.6, ema test Top5 acc: 91.96\n","[2022-04-19 03:35:31,957][experiments.experiment][INFO] - [Checkpoints] Epoch 0, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 03:35:31,958][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 03:45:56,544][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 1: use 624.6987681388855 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-19 03:45:56,657][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 03:45:58,573][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 03:45:58,576][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 03:46:00,455][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 03:46:00,457][experiments.experiment][INFO] - [EMA] Epoch 1.[Train] time:624.6987681388855 seconds, lr:0.0300, train_loss: 1.0341, unlabeled_losses_real_strong:1.8104,corrrect_unlabeled_num:114186.0,pro_above_threshold_num:121130.0,unlabelled_weak_top1_acc:65.1105597987771,unlabelled_weak_top5_acc:96.65069466084242  \n","[2022-04-19 03:46:00,460][experiments.experiment][INFO] - [EMA] Epoch 1. [Validation] raw_testing_loss: 2.2496, raw test Top1 acc:32.04, raw test Top5 acc: 87.4, ema_testing_loss: 1.0522, ema test Top1 acc:63.04, ema test Top5 acc: 96.42\n","[2022-04-19 03:46:00,586][experiments.experiment][INFO] - [Checkpoints] Epoch 1, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 03:46:00,588][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 03:56:25,209][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 2: use 624.734983921051 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-19 03:56:25,323][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 03:56:27,224][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 03:56:27,224][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 03:56:29,124][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 03:56:29,126][experiments.experiment][INFO] - [EMA] Epoch 2.[Train] time:624.734983921051 seconds, lr:0.0300, train_loss: 0.9741, unlabeled_losses_real_strong:1.5260,corrrect_unlabeled_num:179811.0,pro_above_threshold_num:192405.0,unlabelled_weak_top1_acc:70.9073737449944,unlabelled_weak_top5_acc:97.62791112810373  \n","[2022-04-19 03:56:29,129][experiments.experiment][INFO] - [EMA] Epoch 2. [Validation] raw_testing_loss: 2.8931, raw test Top1 acc:31.98, raw test Top5 acc: 81.58, ema_testing_loss: 0.8772, ema test Top1 acc:70.12, ema test Top5 acc: 97.64\n","[2022-04-19 03:56:29,130][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 04:06:51,816][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 3: use 622.7928335666656 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-19 04:06:51,923][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 04:06:53,777][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 04:06:53,778][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 04:06:55,612][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 04:06:55,614][experiments.experiment][INFO] - [EMA] Epoch 3.[Train] time:622.7928335666656 seconds, lr:0.0300, train_loss: 0.9380, unlabeled_losses_real_strong:1.3448,corrrect_unlabeled_num:224111.0,pro_above_threshold_num:240057.0,unlabelled_weak_top1_acc:75.06735556572676,unlabelled_weak_top5_acc:98.18115133792162  \n","[2022-04-19 04:06:55,615][experiments.experiment][INFO] - [EMA] Epoch 3. [Validation] raw_testing_loss: 2.9102, raw test Top1 acc:29.36, raw test Top5 acc: 87.22, ema_testing_loss: 0.7856, ema test Top1 acc:74.7, ema test Top5 acc: 98.48\n","[2022-04-19 04:06:55,734][experiments.experiment][INFO] - [Checkpoints] Epoch 3, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 04:06:55,743][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 04:17:13,813][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 4: use 618.1797845363617 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-19 04:17:13,923][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 04:17:15,764][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 04:17:15,764][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 04:17:17,640][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 04:17:17,643][experiments.experiment][INFO] - [EMA] Epoch 4.[Train] time:618.1797845363617 seconds, lr:0.0300, train_loss: 0.9064, unlabeled_losses_real_strong:1.2269,corrrect_unlabeled_num:254024.0,pro_above_threshold_num:270712.0,unlabelled_weak_top1_acc:78.10494446754456,unlabelled_weak_top5_acc:98.53406530618668  \n","[2022-04-19 04:17:17,645][experiments.experiment][INFO] - [EMA] Epoch 4. [Validation] raw_testing_loss: 1.7859, raw test Top1 acc:51.0, raw test Top5 acc: 91.64, ema_testing_loss: 0.7002, ema test Top1 acc:78.4, ema test Top5 acc: 98.78\n","[2022-04-19 04:17:17,646][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 04:27:35,772][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 5: use 618.2348210811615 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 2.99e-02 ---\n","[2022-04-19 04:27:35,881][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 04:27:37,721][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 04:27:37,722][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 04:27:39,564][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 04:27:39,566][experiments.experiment][INFO] - [EMA] Epoch 5.[Train] time:618.2348210811615 seconds, lr:0.0299, train_loss: 0.8625, unlabeled_losses_real_strong:1.1293,corrrect_unlabeled_num:274399.0,pro_above_threshold_num:291263.0,unlabelled_weak_top1_acc:80.20716970413923,unlabelled_weak_top5_acc:98.76556270569563  \n","[2022-04-19 04:27:39,567][experiments.experiment][INFO] - [EMA] Epoch 5. [Validation] raw_testing_loss: 1.4011, raw test Top1 acc:58.62, raw test Top5 acc: 95.8, ema_testing_loss: 0.6403, ema test Top1 acc:81.3, ema test Top5 acc: 99.02\n","[2022-04-19 04:27:39,687][experiments.experiment][INFO] - [Checkpoints] Epoch 5, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 04:27:39,688][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 04:37:57,658][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 6: use 618.078709602356 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.99e-02 ---\n","[2022-04-19 04:37:57,767][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 04:37:59,601][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 04:37:59,602][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 04:38:01,464][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 04:38:01,466][experiments.experiment][INFO] - [EMA] Epoch 6.[Train] time:618.078709602356 seconds, lr:0.0299, train_loss: 0.8275, unlabeled_losses_real_strong:1.0579,corrrect_unlabeled_num:289467.0,pro_above_threshold_num:305775.0,unlabelled_weak_top1_acc:81.88214871287346,unlabelled_weak_top5_acc:98.94757806509733  \n","[2022-04-19 04:38:01,468][experiments.experiment][INFO] - [EMA] Epoch 6. [Validation] raw_testing_loss: 1.1383, raw test Top1 acc:70.66, raw test Top5 acc: 96.28, ema_testing_loss: 0.6015, ema test Top1 acc:83.54, ema test Top5 acc: 99.3\n","[2022-04-19 04:38:01,470][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 04:48:23,566][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 7: use 622.2141752243042 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.99e-02 ---\n","[2022-04-19 04:48:23,684][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 04:48:25,625][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 04:48:25,626][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 04:48:27,499][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 04:48:27,501][experiments.experiment][INFO] - [EMA] Epoch 7.[Train] time:622.2141752243042 seconds, lr:0.0299, train_loss: 0.8012, unlabeled_losses_real_strong:1.0043,corrrect_unlabeled_num:300908.0,pro_above_threshold_num:316907.0,unlabelled_weak_top1_acc:83.15909142047167,unlabelled_weak_top5_acc:99.02932149171829  \n","[2022-04-19 04:48:27,506][experiments.experiment][INFO] - [EMA] Epoch 7. [Validation] raw_testing_loss: 1.7889, raw test Top1 acc:60.86, raw test Top5 acc: 93.52, ema_testing_loss: 0.5709, ema test Top1 acc:84.82, ema test Top5 acc: 99.32\n","[2022-04-19 04:48:27,630][experiments.experiment][INFO] - [Checkpoints] Epoch 7, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 04:48:27,634][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 04:58:47,475][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 8: use 619.9443070888519 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.98e-02 ---\n","[2022-04-19 04:58:47,578][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 04:58:49,395][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 04:58:49,395][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 04:58:51,190][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 04:58:51,192][experiments.experiment][INFO] - [EMA] Epoch 8.[Train] time:619.9443070888519 seconds, lr:0.0298, train_loss: 0.7801, unlabeled_losses_real_strong:0.9588,corrrect_unlabeled_num:309320.0,pro_above_threshold_num:324887.0,unlabelled_weak_top1_acc:84.04366518557072,unlabelled_weak_top5_acc:99.10801336169243  \n","[2022-04-19 04:58:51,193][experiments.experiment][INFO] - [EMA] Epoch 8. [Validation] raw_testing_loss: 0.8153, raw test Top1 acc:75.28, raw test Top5 acc: 98.48, ema_testing_loss: 0.5309, ema test Top1 acc:85.82, ema test Top5 acc: 99.4\n","[2022-04-19 04:58:51,196][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 05:09:07,847][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 9: use 616.7649073600769 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.98e-02 ---\n","[2022-04-19 05:09:07,961][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 05:09:09,798][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 05:09:09,798][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 05:09:11,652][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 05:09:11,654][experiments.experiment][INFO] - [EMA] Epoch 9.[Train] time:616.7649073600769 seconds, lr:0.0298, train_loss: 0.7569, unlabeled_losses_real_strong:0.9196,corrrect_unlabeled_num:317028.0,pro_above_threshold_num:332011.0,unlabelled_weak_top1_acc:84.9103644490242,unlabelled_weak_top5_acc:99.1886670961976  \n","[2022-04-19 05:09:11,656][experiments.experiment][INFO] - [EMA] Epoch 9. [Validation] raw_testing_loss: 0.9041, raw test Top1 acc:76.46, raw test Top5 acc: 98.88, ema_testing_loss: 0.5028, ema test Top1 acc:86.5, ema test Top5 acc: 99.48\n","[2022-04-19 05:09:11,783][experiments.experiment][INFO] - [Checkpoints] Epoch 9, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 05:09:11,793][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 05:19:31,284][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 10: use 619.6049633026123 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.98e-02 ---\n","[2022-04-19 05:19:31,398][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 05:19:33,264][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 05:19:33,264][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 05:19:35,103][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 05:19:35,105][experiments.experiment][INFO] - [EMA] Epoch 10.[Train] time:619.6049633026123 seconds, lr:0.0298, train_loss: 0.7404, unlabeled_losses_real_strong:0.8836,corrrect_unlabeled_num:323927.0,pro_above_threshold_num:338158.0,unlabelled_weak_top1_acc:85.72779960930347,unlabelled_weak_top5_acc:99.25122807919979  \n","[2022-04-19 05:19:35,106][experiments.experiment][INFO] - [EMA] Epoch 10. [Validation] raw_testing_loss: 0.7339, raw test Top1 acc:79.34, raw test Top5 acc: 98.72, ema_testing_loss: 0.4718, ema test Top1 acc:87.58, ema test Top5 acc: 99.54\n","[2022-04-19 05:19:35,109][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 05:29:53,028][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 11: use 618.0342950820923 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.97e-02 ---\n","[2022-04-19 05:29:53,143][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 05:29:55,007][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 05:29:55,008][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 05:29:56,853][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 05:29:56,855][experiments.experiment][INFO] - [EMA] Epoch 11.[Train] time:618.0342950820923 seconds, lr:0.0297, train_loss: 0.7251, unlabeled_losses_real_strong:0.8591,corrrect_unlabeled_num:329772.0,pro_above_threshold_num:343819.0,unlabelled_weak_top1_acc:86.33379139006138,unlabelled_weak_top5_acc:99.29940235614777  \n","[2022-04-19 05:29:56,857][experiments.experiment][INFO] - [EMA] Epoch 11. [Validation] raw_testing_loss: 0.6796, raw test Top1 acc:80.32, raw test Top5 acc: 98.52, ema_testing_loss: 0.4421, ema test Top1 acc:88.14, ema test Top5 acc: 99.58\n","[2022-04-19 05:29:56,986][experiments.experiment][INFO] - [Checkpoints] Epoch 11, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 05:29:56,988][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 05:40:13,473][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 12: use 616.5958936214447 seconds\n","--- Optimizer learning rate changed from 2.97e-02 to 2.97e-02 ---\n","[2022-04-19 05:40:13,584][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 05:40:15,450][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 05:40:15,450][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 05:40:17,337][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 05:40:17,339][experiments.experiment][INFO] - [EMA] Epoch 12.[Train] time:616.5958936214447 seconds, lr:0.0297, train_loss: 0.7030, unlabeled_losses_real_strong:0.8337,corrrect_unlabeled_num:332984.0,pro_above_threshold_num:346351.0,unlabelled_weak_top1_acc:86.86152763664722,unlabelled_weak_top5_acc:99.35564197599888  \n","[2022-04-19 05:40:17,341][experiments.experiment][INFO] - [EMA] Epoch 12. [Validation] raw_testing_loss: 1.0720, raw test Top1 acc:73.06, raw test Top5 acc: 96.8, ema_testing_loss: 0.4225, ema test Top1 acc:88.52, ema test Top5 acc: 99.68\n","[2022-04-19 05:40:17,342][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 05:50:36,321][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 13: use 619.1069025993347 seconds\n","--- Optimizer learning rate changed from 2.97e-02 to 2.96e-02 ---\n","[2022-04-19 05:50:36,450][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 05:50:38,345][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 05:50:38,346][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 05:50:40,252][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 05:50:40,254][experiments.experiment][INFO] - [EMA] Epoch 13.[Train] time:619.1069025993347 seconds, lr:0.0296, train_loss: 0.6943, unlabeled_losses_real_strong:0.8080,corrrect_unlabeled_num:338760.0,pro_above_threshold_num:351692.0,unlabelled_weak_top1_acc:87.41149804741144,unlabelled_weak_top5_acc:99.3739527091384  \n","[2022-04-19 05:50:40,258][experiments.experiment][INFO] - [EMA] Epoch 13. [Validation] raw_testing_loss: 0.6806, raw test Top1 acc:80.86, raw test Top5 acc: 98.9, ema_testing_loss: 0.4045, ema test Top1 acc:88.78, ema test Top5 acc: 99.7\n","[2022-04-19 05:50:40,382][experiments.experiment][INFO] - [Checkpoints] Epoch 13, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 05:50:40,384][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 06:00:59,981][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 14: use 619.7103052139282 seconds\n","--- Optimizer learning rate changed from 2.96e-02 to 2.96e-02 ---\n","[2022-04-19 06:01:00,094][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 06:01:01,925][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 06:01:01,925][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 06:01:03,753][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 06:01:03,755][experiments.experiment][INFO] - [EMA] Epoch 14.[Train] time:619.7103052139282 seconds, lr:0.0296, train_loss: 0.6821, unlabeled_losses_real_strong:0.7921,corrrect_unlabeled_num:342079.0,pro_above_threshold_num:354992.0,unlabelled_weak_top1_acc:87.73629216104746,unlabelled_weak_top5_acc:99.37765833735466  \n","[2022-04-19 06:01:03,758][experiments.experiment][INFO] - [EMA] Epoch 14. [Validation] raw_testing_loss: 0.5909, raw test Top1 acc:82.96, raw test Top5 acc: 99.34, ema_testing_loss: 0.3909, ema test Top1 acc:88.86, ema test Top5 acc: 99.74\n","[2022-04-19 06:01:03,759][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 06:11:19,566][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 15: use 615.9109780788422 seconds\n","--- Optimizer learning rate changed from 2.96e-02 to 2.95e-02 ---\n","[2022-04-19 06:11:19,671][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 06:11:21,496][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 06:11:21,496][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 06:11:23,379][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 06:11:23,381][experiments.experiment][INFO] - [EMA] Epoch 15.[Train] time:615.9109780788422 seconds, lr:0.0295, train_loss: 0.6767, unlabeled_losses_real_strong:0.7733,corrrect_unlabeled_num:345639.0,pro_above_threshold_num:358202.0,unlabelled_weak_top1_acc:88.1221214234829,unlabelled_weak_top5_acc:99.42343496531248  \n","[2022-04-19 06:11:23,383][experiments.experiment][INFO] - [EMA] Epoch 15. [Validation] raw_testing_loss: 0.7273, raw test Top1 acc:80.7, raw test Top5 acc: 99.08, ema_testing_loss: 0.3771, ema test Top1 acc:89.3, ema test Top5 acc: 99.8\n","[2022-04-19 06:11:23,506][experiments.experiment][INFO] - [Checkpoints] Epoch 15, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 06:11:23,516][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 06:21:34,083][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 16: use 610.6832778453827 seconds\n","--- Optimizer learning rate changed from 2.95e-02 to 2.94e-02 ---\n","[2022-04-19 06:21:34,199][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 06:21:36,018][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 06:21:36,018][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 06:21:37,830][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 06:21:37,833][experiments.experiment][INFO] - [EMA] Epoch 16.[Train] time:610.6832778453827 seconds, lr:0.0294, train_loss: 0.6705, unlabeled_losses_real_strong:0.7580,corrrect_unlabeled_num:348713.0,pro_above_threshold_num:361140.0,unlabelled_weak_top1_acc:88.49814160913229,unlabelled_weak_top5_acc:99.44741304963827  \n","[2022-04-19 06:21:37,836][experiments.experiment][INFO] - [EMA] Epoch 16. [Validation] raw_testing_loss: 0.6985, raw test Top1 acc:82.58, raw test Top5 acc: 98.88, ema_testing_loss: 0.3663, ema test Top1 acc:89.74, ema test Top5 acc: 99.84\n","[2022-04-19 06:21:37,837][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 06:31:47,449][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 17: use 609.7195062637329 seconds\n","--- Optimizer learning rate changed from 2.94e-02 to 2.94e-02 ---\n","[2022-04-19 06:31:47,557][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 06:31:49,404][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 06:31:49,404][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 06:31:51,229][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 06:31:51,231][experiments.experiment][INFO] - [EMA] Epoch 17.[Train] time:609.7195062637329 seconds, lr:0.0294, train_loss: 0.6600, unlabeled_losses_real_strong:0.7464,corrrect_unlabeled_num:350490.0,pro_above_threshold_num:362618.0,unlabelled_weak_top1_acc:88.7078410461545,unlabelled_weak_top5_acc:99.48556026816368  \n","[2022-04-19 06:31:51,232][experiments.experiment][INFO] - [EMA] Epoch 17. [Validation] raw_testing_loss: 0.5333, raw test Top1 acc:84.74, raw test Top5 acc: 99.36, ema_testing_loss: 0.3544, ema test Top1 acc:89.94, ema test Top5 acc: 99.86\n","[2022-04-19 06:31:51,357][experiments.experiment][INFO] - [Checkpoints] Epoch 17, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 06:31:51,367][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 06:42:15,692][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 18: use 624.4661974906921 seconds\n","--- Optimizer learning rate changed from 2.94e-02 to 2.93e-02 ---\n","[2022-04-19 06:42:15,834][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 06:42:17,775][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 06:42:17,776][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 06:42:19,686][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 06:42:19,689][experiments.experiment][INFO] - [EMA] Epoch 18.[Train] time:624.4661974906921 seconds, lr:0.0293, train_loss: 0.6570, unlabeled_losses_real_strong:0.7343,corrrect_unlabeled_num:353957.0,pro_above_threshold_num:366055.0,unlabelled_weak_top1_acc:89.10086387395859,unlabelled_weak_top5_acc:99.49100978672504  \n","[2022-04-19 06:42:19,689][experiments.experiment][INFO] - [EMA] Epoch 18. [Validation] raw_testing_loss: 0.4950, raw test Top1 acc:86.0, raw test Top5 acc: 99.32, ema_testing_loss: 0.3444, ema test Top1 acc:90.22, ema test Top5 acc: 99.78\n","[2022-04-19 06:42:19,692][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 06:52:56,557][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 19: use 636.9799160957336 seconds\n","--- Optimizer learning rate changed from 2.93e-02 to 2.92e-02 ---\n","[2022-04-19 06:52:56,672][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 06:52:58,629][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 06:52:58,630][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 06:53:00,581][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 06:53:00,584][experiments.experiment][INFO] - [EMA] Epoch 19.[Train] time:636.9799160957336 seconds, lr:0.0292, train_loss: 0.6494, unlabeled_losses_real_strong:0.7220,corrrect_unlabeled_num:355617.0,pro_above_threshold_num:367500.0,unlabelled_weak_top1_acc:89.29377853870392,unlabelled_weak_top5_acc:99.48665010929108  \n","[2022-04-19 06:53:00,585][experiments.experiment][INFO] - [EMA] Epoch 19. [Validation] raw_testing_loss: 0.6413, raw test Top1 acc:83.76, raw test Top5 acc: 99.18, ema_testing_loss: 0.3441, ema test Top1 acc:90.18, ema test Top5 acc: 99.76\n","[2022-04-19 06:53:00,715][experiments.experiment][INFO] - [Checkpoints] Epoch 19, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 06:53:00,725][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 07:03:44,160][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 20: use 643.5557582378387 seconds\n","--- Optimizer learning rate changed from 2.92e-02 to 2.91e-02 ---\n","[2022-04-19 07:03:44,281][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 07:03:46,269][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 07:03:46,269][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 07:03:48,199][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 07:03:48,201][experiments.experiment][INFO] - [EMA] Epoch 20.[Train] time:643.5557582378387 seconds, lr:0.0291, train_loss: 0.6429, unlabeled_losses_real_strong:0.7161,corrrect_unlabeled_num:357298.0,pro_above_threshold_num:369244.0,unlabelled_weak_top1_acc:89.33563128113747,unlabelled_weak_top5_acc:99.51542400568724  \n","[2022-04-19 07:03:48,205][experiments.experiment][INFO] - [EMA] Epoch 20. [Validation] raw_testing_loss: 0.6652, raw test Top1 acc:82.54, raw test Top5 acc: 98.94, ema_testing_loss: 0.3372, ema test Top1 acc:90.58, ema test Top5 acc: 99.78\n","[2022-04-19 07:03:48,205][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 07:14:31,224][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 21: use 643.130401134491 seconds\n","--- Optimizer learning rate changed from 2.91e-02 to 2.91e-02 ---\n","[2022-04-19 07:14:31,336][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 07:14:33,364][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 07:14:33,365][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 07:14:35,302][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 07:14:35,304][experiments.experiment][INFO] - [EMA] Epoch 21.[Train] time:643.130401134491 seconds, lr:0.0291, train_loss: 0.6422, unlabeled_losses_real_strong:0.7014,corrrect_unlabeled_num:360576.0,pro_above_threshold_num:372396.0,unlabelled_weak_top1_acc:89.7092536687851,unlabelled_weak_top5_acc:99.50735855102539  \n","[2022-04-19 07:14:35,305][experiments.experiment][INFO] - [EMA] Epoch 21. [Validation] raw_testing_loss: 1.0589, raw test Top1 acc:77.8, raw test Top5 acc: 99.08, ema_testing_loss: 0.3328, ema test Top1 acc:90.76, ema test Top5 acc: 99.8\n","[2022-04-19 07:14:35,438][experiments.experiment][INFO] - [Checkpoints] Epoch 21, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 07:14:35,439][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 07:25:19,733][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 22: use 644.4073362350464 seconds\n","--- Optimizer learning rate changed from 2.91e-02 to 2.90e-02 ---\n","[2022-04-19 07:25:19,846][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 07:25:21,835][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 07:25:21,835][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 07:25:23,833][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 07:25:23,835][experiments.experiment][INFO] - [EMA] Epoch 22.[Train] time:644.4073362350464 seconds, lr:0.0290, train_loss: 0.6354, unlabeled_losses_real_strong:0.6916,corrrect_unlabeled_num:361854.0,pro_above_threshold_num:373172.0,unlabelled_weak_top1_acc:89.90500207990408,unlabelled_weak_top5_acc:99.53874824941158  \n","[2022-04-19 07:25:23,837][experiments.experiment][INFO] - [EMA] Epoch 22. [Validation] raw_testing_loss: 0.5702, raw test Top1 acc:84.98, raw test Top5 acc: 99.44, ema_testing_loss: 0.3261, ema test Top1 acc:91.12, ema test Top5 acc: 99.78\n","[2022-04-19 07:25:23,839][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 07:36:14,599][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 23: use 650.8869211673737 seconds\n","--- Optimizer learning rate changed from 2.90e-02 to 2.89e-02 ---\n","[2022-04-19 07:36:14,727][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 07:36:16,690][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 07:36:16,690][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 07:36:18,685][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 07:36:18,688][experiments.experiment][INFO] - [EMA] Epoch 23.[Train] time:650.8869211673737 seconds, lr:0.0289, train_loss: 0.6284, unlabeled_losses_real_strong:0.6845,corrrect_unlabeled_num:363390.0,pro_above_threshold_num:374866.0,unlabelled_weak_top1_acc:89.98827144503593,unlabelled_weak_top5_acc:99.55139131844044  \n","[2022-04-19 07:36:18,691][experiments.experiment][INFO] - [EMA] Epoch 23. [Validation] raw_testing_loss: 0.4162, raw test Top1 acc:87.38, raw test Top5 acc: 99.38, ema_testing_loss: 0.3184, ema test Top1 acc:91.28, ema test Top5 acc: 99.84\n","[2022-04-19 07:36:18,823][experiments.experiment][INFO] - [Checkpoints] Epoch 23, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 07:36:18,828][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 07:47:07,624][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 24: use 648.9264895915985 seconds\n","--- Optimizer learning rate changed from 2.89e-02 to 2.88e-02 ---\n","[2022-04-19 07:47:07,755][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 07:47:09,751][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 07:47:09,752][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 07:47:11,700][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 07:47:11,703][experiments.experiment][INFO] - [EMA] Epoch 24.[Train] time:648.9264895915985 seconds, lr:0.0288, train_loss: 0.6282, unlabeled_losses_real_strong:0.6759,corrrect_unlabeled_num:365683.0,pro_above_threshold_num:376867.0,unlabelled_weak_top1_acc:90.23372003436089,unlabelled_weak_top5_acc:99.56839399784803  \n","[2022-04-19 07:47:11,704][experiments.experiment][INFO] - [EMA] Epoch 24. [Validation] raw_testing_loss: 0.4808, raw test Top1 acc:86.66, raw test Top5 acc: 99.68, ema_testing_loss: 0.3117, ema test Top1 acc:91.32, ema test Top5 acc: 99.82\n","[2022-04-19 07:47:11,706][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 07:57:57,492][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 25: use 645.907196521759 seconds\n","--- Optimizer learning rate changed from 2.88e-02 to 2.87e-02 ---\n","[2022-04-19 07:57:57,613][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 07:57:59,622][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 07:57:59,623][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 07:58:01,588][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 07:58:01,590][experiments.experiment][INFO] - [EMA] Epoch 25.[Train] time:645.907196521759 seconds, lr:0.0287, train_loss: 0.6205, unlabeled_losses_real_strong:0.6681,corrrect_unlabeled_num:366020.0,pro_above_threshold_num:377024.0,unlabelled_weak_top1_acc:90.31829731911421,unlabelled_weak_top5_acc:99.55858470499516  \n","[2022-04-19 07:58:01,594][experiments.experiment][INFO] - [EMA] Epoch 25. [Validation] raw_testing_loss: 0.5071, raw test Top1 acc:86.18, raw test Top5 acc: 99.56, ema_testing_loss: 0.3051, ema test Top1 acc:91.76, ema test Top5 acc: 99.8\n","[2022-04-19 07:58:01,724][experiments.experiment][INFO] - [Checkpoints] Epoch 25, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 07:58:01,729][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 08:08:48,405][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 26: use 646.8023145198822 seconds\n","--- Optimizer learning rate changed from 2.87e-02 to 2.86e-02 ---\n","[2022-04-19 08:08:48,532][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 08:08:50,485][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 08:08:50,486][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 08:08:52,413][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 08:08:52,416][experiments.experiment][INFO] - [EMA] Epoch 26.[Train] time:646.8023145198822 seconds, lr:0.0286, train_loss: 0.6197, unlabeled_losses_real_strong:0.6627,corrrect_unlabeled_num:368267.0,pro_above_threshold_num:379098.0,unlabelled_weak_top1_acc:90.54717908799648,unlabelled_weak_top5_acc:99.59477004408836  \n","[2022-04-19 08:08:52,418][experiments.experiment][INFO] - [EMA] Epoch 26. [Validation] raw_testing_loss: 0.5246, raw test Top1 acc:86.12, raw test Top5 acc: 99.38, ema_testing_loss: 0.3029, ema test Top1 acc:92.02, ema test Top5 acc: 99.82\n","[2022-04-19 08:08:52,420][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 08:19:22,255][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 27: use 629.9494128227234 seconds\n","--- Optimizer learning rate changed from 2.86e-02 to 2.85e-02 ---\n","[2022-04-19 08:19:22,369][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 08:19:24,195][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 08:19:24,196][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 08:19:26,070][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 08:19:26,072][experiments.experiment][INFO] - [EMA] Epoch 27.[Train] time:629.9494128227234 seconds, lr:0.0285, train_loss: 0.6137, unlabeled_losses_real_strong:0.6563,corrrect_unlabeled_num:369000.0,pro_above_threshold_num:379887.0,unlabelled_weak_top1_acc:90.62608888745308,unlabelled_weak_top5_acc:99.5851788520813  \n","[2022-04-19 08:19:26,075][experiments.experiment][INFO] - [EMA] Epoch 27. [Validation] raw_testing_loss: 0.5883, raw test Top1 acc:84.7, raw test Top5 acc: 99.34, ema_testing_loss: 0.2980, ema test Top1 acc:92.04, ema test Top5 acc: 99.82\n","[2022-04-19 08:19:26,197][experiments.experiment][INFO] - [Checkpoints] Epoch 27, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 08:19:26,207][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 08:29:48,520][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 28: use 622.4289169311523 seconds\n","--- Optimizer learning rate changed from 2.85e-02 to 2.84e-02 ---\n","[2022-04-19 08:29:48,636][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 08:29:50,562][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 08:29:50,563][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 08:29:52,470][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 08:29:52,473][experiments.experiment][INFO] - [EMA] Epoch 28.[Train] time:622.4289169311523 seconds, lr:0.0284, train_loss: 0.6082, unlabeled_losses_real_strong:0.6505,corrrect_unlabeled_num:370353.0,pro_above_threshold_num:381203.0,unlabelled_weak_top1_acc:90.74881306290627,unlabelled_weak_top5_acc:99.60218159109354  \n","[2022-04-19 08:29:52,475][experiments.experiment][INFO] - [EMA] Epoch 28. [Validation] raw_testing_loss: 0.4361, raw test Top1 acc:87.22, raw test Top5 acc: 99.48, ema_testing_loss: 0.2963, ema test Top1 acc:92.12, ema test Top5 acc: 99.78\n","[2022-04-19 08:29:52,479][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 08:40:14,575][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 29: use 622.2082748413086 seconds\n","--- Optimizer learning rate changed from 2.84e-02 to 2.82e-02 ---\n","[2022-04-19 08:40:14,687][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 08:40:16,653][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 08:40:16,654][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 08:40:18,563][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 08:40:18,565][experiments.experiment][INFO] - [EMA] Epoch 29.[Train] time:622.2082748413086 seconds, lr:0.0282, train_loss: 0.6112, unlabeled_losses_real_strong:0.6472,corrrect_unlabeled_num:371061.0,pro_above_threshold_num:381863.0,unlabelled_weak_top1_acc:90.85824041813612,unlabelled_weak_top5_acc:99.60414328426123  \n","[2022-04-19 08:40:18,567][experiments.experiment][INFO] - [EMA] Epoch 29. [Validation] raw_testing_loss: 0.4262, raw test Top1 acc:88.48, raw test Top5 acc: 99.52, ema_testing_loss: 0.2880, ema test Top1 acc:92.28, ema test Top5 acc: 99.82\n","[2022-04-19 08:40:18,691][experiments.experiment][INFO] - [Checkpoints] Epoch 29, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 08:40:18,693][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 08:50:33,955][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 30: use 615.3809087276459 seconds\n","--- Optimizer learning rate changed from 2.82e-02 to 2.81e-02 ---\n","[2022-04-19 08:50:34,074][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 08:50:35,832][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 08:50:35,833][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 08:50:37,620][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 08:50:37,622][experiments.experiment][INFO] - [EMA] Epoch 30.[Train] time:615.3809087276459 seconds, lr:0.0281, train_loss: 0.6038, unlabeled_losses_real_strong:0.6386,corrrect_unlabeled_num:372068.0,pro_above_threshold_num:382713.0,unlabelled_weak_top1_acc:90.9938256368041,unlabelled_weak_top5_acc:99.59150023758411  \n","[2022-04-19 08:50:37,624][experiments.experiment][INFO] - [EMA] Epoch 30. [Validation] raw_testing_loss: 0.4622, raw test Top1 acc:88.0, raw test Top5 acc: 99.6, ema_testing_loss: 0.2854, ema test Top1 acc:92.28, ema test Top5 acc: 99.86\n","[2022-04-19 08:50:37,626][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 09:00:38,300][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 31: use 600.7825393676758 seconds\n","--- Optimizer learning rate changed from 2.81e-02 to 2.80e-02 ---\n","[2022-04-19 09:00:38,408][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 09:00:40,162][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 09:00:40,163][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 09:00:41,938][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 09:00:41,940][experiments.experiment][INFO] - [EMA] Epoch 31.[Train] time:600.7825393676758 seconds, lr:0.0280, train_loss: 0.6037, unlabeled_losses_real_strong:0.6329,corrrect_unlabeled_num:374042.0,pro_above_threshold_num:384680.0,unlabelled_weak_top1_acc:91.14684957265854,unlabelled_weak_top5_acc:99.60959282517433  \n","[2022-04-19 09:00:41,942][experiments.experiment][INFO] - [EMA] Epoch 31. [Validation] raw_testing_loss: 0.4666, raw test Top1 acc:88.26, raw test Top5 acc: 99.34, ema_testing_loss: 0.2780, ema test Top1 acc:92.4, ema test Top5 acc: 99.86\n","[2022-04-19 09:00:42,069][experiments.experiment][INFO] - [Checkpoints] Epoch 31, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 09:00:42,074][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 09:10:31,959][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 32: use 589.9858753681183 seconds\n","--- Optimizer learning rate changed from 2.80e-02 to 2.79e-02 ---\n","[2022-04-19 09:10:32,060][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 09:10:33,794][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 09:10:33,795][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 09:10:35,537][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 09:10:35,541][experiments.experiment][INFO] - [EMA] Epoch 32.[Train] time:589.9858753681183 seconds, lr:0.0279, train_loss: 0.5980, unlabeled_losses_real_strong:0.6238,corrrect_unlabeled_num:375361.0,pro_above_threshold_num:385743.0,unlabelled_weak_top1_acc:91.35000932216644,unlabelled_weak_top5_acc:99.64294446259737  \n","[2022-04-19 09:10:35,543][experiments.experiment][INFO] - [EMA] Epoch 32. [Validation] raw_testing_loss: 0.5026, raw test Top1 acc:86.6, raw test Top5 acc: 99.48, ema_testing_loss: 0.2766, ema test Top1 acc:92.48, ema test Top5 acc: 99.82\n","[2022-04-19 09:10:35,546][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 09:20:23,097][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 33: use 587.6558876037598 seconds\n","--- Optimizer learning rate changed from 2.79e-02 to 2.78e-02 ---\n","[2022-04-19 09:20:23,202][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 09:20:24,946][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 09:20:24,946][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 09:20:26,748][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 09:20:26,750][experiments.experiment][INFO] - [EMA] Epoch 33.[Train] time:587.6558876037598 seconds, lr:0.0278, train_loss: 0.5965, unlabeled_losses_real_strong:0.6207,corrrect_unlabeled_num:375695.0,pro_above_threshold_num:386077.0,unlabelled_weak_top1_acc:91.37333355844021,unlabelled_weak_top5_acc:99.64185451716185  \n","[2022-04-19 09:20:26,752][experiments.experiment][INFO] - [EMA] Epoch 33. [Validation] raw_testing_loss: 0.4396, raw test Top1 acc:87.2, raw test Top5 acc: 99.62, ema_testing_loss: 0.2777, ema test Top1 acc:92.74, ema test Top5 acc: 99.78\n","[2022-04-19 09:20:26,874][experiments.experiment][INFO] - [Checkpoints] Epoch 33, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 09:20:26,877][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 09:30:20,491][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 34: use 593.7139875888824 seconds\n","--- Optimizer learning rate changed from 2.78e-02 to 2.76e-02 ---\n","[2022-04-19 09:30:20,591][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 09:30:22,349][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 09:30:22,349][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 09:30:24,125][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 09:30:24,128][experiments.experiment][INFO] - [EMA] Epoch 34.[Train] time:593.7139875888824 seconds, lr:0.0276, train_loss: 0.5952, unlabeled_losses_real_strong:0.6156,corrrect_unlabeled_num:376816.0,pro_above_threshold_num:387201.0,unlabelled_weak_top1_acc:91.40886460989714,unlabelled_weak_top5_acc:99.64272652566433  \n","[2022-04-19 09:30:24,129][experiments.experiment][INFO] - [EMA] Epoch 34. [Validation] raw_testing_loss: 0.4685, raw test Top1 acc:87.18, raw test Top5 acc: 99.48, ema_testing_loss: 0.2763, ema test Top1 acc:92.92, ema test Top5 acc: 99.8\n","[2022-04-19 09:30:24,132][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 09:40:15,082][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 35: use 591.0528168678284 seconds\n","--- Optimizer learning rate changed from 2.76e-02 to 2.75e-02 ---\n","[2022-04-19 09:40:15,185][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 09:40:16,991][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 09:40:16,992][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 09:40:18,786][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 09:40:18,788][experiments.experiment][INFO] - [EMA] Epoch 35.[Train] time:591.0528168678284 seconds, lr:0.0275, train_loss: 0.5924, unlabeled_losses_real_strong:0.6124,corrrect_unlabeled_num:377549.0,pro_above_threshold_num:387825.0,unlabelled_weak_top1_acc:91.55992660671473,unlabelled_weak_top5_acc:99.64098256826401  \n","[2022-04-19 09:40:18,789][experiments.experiment][INFO] - [EMA] Epoch 35. [Validation] raw_testing_loss: 0.4185, raw test Top1 acc:88.28, raw test Top5 acc: 99.54, ema_testing_loss: 0.2756, ema test Top1 acc:92.78, ema test Top5 acc: 99.8\n","[2022-04-19 09:40:18,910][experiments.experiment][INFO] - [Checkpoints] Epoch 35, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 09:40:18,912][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 09:50:06,972][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 36: use 588.1709561347961 seconds\n","--- Optimizer learning rate changed from 2.75e-02 to 2.73e-02 ---\n","[2022-04-19 09:50:07,083][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 09:50:08,821][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 09:50:08,821][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 09:50:10,666][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 09:50:10,668][experiments.experiment][INFO] - [EMA] Epoch 36.[Train] time:588.1709561347961 seconds, lr:0.0273, train_loss: 0.5868, unlabeled_losses_real_strong:0.6068,corrrect_unlabeled_num:378472.0,pro_above_threshold_num:388640.0,unlabelled_weak_top1_acc:91.5686460211873,unlabelled_weak_top5_acc:99.64229040592909  \n","[2022-04-19 09:50:10,671][experiments.experiment][INFO] - [EMA] Epoch 36. [Validation] raw_testing_loss: 0.4134, raw test Top1 acc:88.14, raw test Top5 acc: 99.46, ema_testing_loss: 0.2703, ema test Top1 acc:92.8, ema test Top5 acc: 99.8\n","[2022-04-19 09:50:10,672][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 10:00:06,167][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 37: use 595.6019432544708 seconds\n","--- Optimizer learning rate changed from 2.73e-02 to 2.72e-02 ---\n","[2022-04-19 10:00:06,274][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 10:00:08,049][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 10:00:08,049][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 10:00:09,832][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 10:00:09,834][experiments.experiment][INFO] - [EMA] Epoch 37.[Train] time:595.6019432544708 seconds, lr:0.0272, train_loss: 0.5822, unlabeled_losses_real_strong:0.6019,corrrect_unlabeled_num:378834.0,pro_above_threshold_num:388938.0,unlabelled_weak_top1_acc:91.69006248563528,unlabelled_weak_top5_acc:99.65057390928268  \n","[2022-04-19 10:00:09,835][experiments.experiment][INFO] - [EMA] Epoch 37. [Validation] raw_testing_loss: 0.4800, raw test Top1 acc:86.84, raw test Top5 acc: 99.18, ema_testing_loss: 0.2711, ema test Top1 acc:92.96, ema test Top5 acc: 99.84\n","[2022-04-19 10:00:09,954][experiments.experiment][INFO] - [Checkpoints] Epoch 37, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 10:00:09,964][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 10:10:09,095][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 38: use 599.2386703491211 seconds\n","--- Optimizer learning rate changed from 2.72e-02 to 2.71e-02 ---\n","[2022-04-19 10:10:09,203][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 10:10:11,011][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 10:10:11,011][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 10:10:12,837][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 10:10:12,839][experiments.experiment][INFO] - [EMA] Epoch 38.[Train] time:599.2386703491211 seconds, lr:0.0271, train_loss: 0.5849, unlabeled_losses_real_strong:0.5992,corrrect_unlabeled_num:379519.0,pro_above_threshold_num:389436.0,unlabelled_weak_top1_acc:91.7434681430459,unlabelled_weak_top5_acc:99.66125503182411  \n","[2022-04-19 10:10:12,842][experiments.experiment][INFO] - [EMA] Epoch 38. [Validation] raw_testing_loss: 0.3569, raw test Top1 acc:90.18, raw test Top5 acc: 99.74, ema_testing_loss: 0.2694, ema test Top1 acc:93.06, ema test Top5 acc: 99.82\n","[2022-04-19 10:10:12,843][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 10:20:12,867][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 39: use 600.1291015148163 seconds\n","--- Optimizer learning rate changed from 2.71e-02 to 2.69e-02 ---\n","[2022-04-19 10:20:12,972][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 10:20:14,735][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 10:20:14,736][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 10:20:16,512][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 10:20:16,514][experiments.experiment][INFO] - [EMA] Epoch 39.[Train] time:600.1291015148163 seconds, lr:0.0269, train_loss: 0.5813, unlabeled_losses_real_strong:0.5943,corrrect_unlabeled_num:381073.0,pro_above_threshold_num:391086.0,unlabelled_weak_top1_acc:91.84940785169601,unlabelled_weak_top5_acc:99.65994718670845  \n","[2022-04-19 10:20:16,517][experiments.experiment][INFO] - [EMA] Epoch 39. [Validation] raw_testing_loss: 0.4136, raw test Top1 acc:88.26, raw test Top5 acc: 99.46, ema_testing_loss: 0.2693, ema test Top1 acc:93.02, ema test Top5 acc: 99.8\n","[2022-04-19 10:20:16,644][experiments.experiment][INFO] - [Checkpoints] Epoch 39, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 10:20:16,646][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 10:30:09,457][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 40: use 592.9142508506775 seconds\n","--- Optimizer learning rate changed from 2.69e-02 to 2.68e-02 ---\n","[2022-04-19 10:30:09,560][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 10:30:11,351][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 10:30:11,351][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 10:30:13,117][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 10:30:13,119][experiments.experiment][INFO] - [EMA] Epoch 40.[Train] time:592.9142508506775 seconds, lr:0.0268, train_loss: 0.5798, unlabeled_losses_real_strong:0.5902,corrrect_unlabeled_num:381772.0,pro_above_threshold_num:391888.0,unlabelled_weak_top1_acc:91.89169634878635,unlabelled_weak_top5_acc:99.67738585174084  \n","[2022-04-19 10:30:13,122][experiments.experiment][INFO] - [EMA] Epoch 40. [Validation] raw_testing_loss: 0.3830, raw test Top1 acc:89.58, raw test Top5 acc: 99.56, ema_testing_loss: 0.2658, ema test Top1 acc:93.32, ema test Top5 acc: 99.78\n","[2022-04-19 10:30:13,123][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 10:40:03,661][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 41: use 590.6396296024323 seconds\n","--- Optimizer learning rate changed from 2.68e-02 to 2.66e-02 ---\n","[2022-04-19 10:40:03,763][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 10:40:05,516][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 10:40:05,517][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 10:40:07,329][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 10:40:07,332][experiments.experiment][INFO] - [EMA] Epoch 41.[Train] time:590.6396296024323 seconds, lr:0.0266, train_loss: 0.5799, unlabeled_losses_real_strong:0.5885,corrrect_unlabeled_num:381903.0,pro_above_threshold_num:391928.0,unlabelled_weak_top1_acc:91.93790878355503,unlabelled_weak_top5_acc:99.66757661104202  \n","[2022-04-19 10:40:07,335][experiments.experiment][INFO] - [EMA] Epoch 41. [Validation] raw_testing_loss: 0.6297, raw test Top1 acc:85.1, raw test Top5 acc: 99.22, ema_testing_loss: 0.2669, ema test Top1 acc:93.1, ema test Top5 acc: 99.82\n","[2022-04-19 10:40:07,455][experiments.experiment][INFO] - [Checkpoints] Epoch 41, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 10:40:07,460][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 10:49:57,709][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 42: use 590.3510472774506 seconds\n","--- Optimizer learning rate changed from 2.66e-02 to 2.64e-02 ---\n","[2022-04-19 10:49:57,811][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 10:49:59,617][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 10:49:59,617][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 10:50:01,438][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 10:50:01,440][experiments.experiment][INFO] - [EMA] Epoch 42.[Train] time:590.3510472774506 seconds, lr:0.0264, train_loss: 0.5726, unlabeled_losses_real_strong:0.5808,corrrect_unlabeled_num:382994.0,pro_above_threshold_num:393178.0,unlabelled_weak_top1_acc:91.98346719145775,unlabelled_weak_top5_acc:99.67542403936386  \n","[2022-04-19 10:50:01,442][experiments.experiment][INFO] - [EMA] Epoch 42. [Validation] raw_testing_loss: 0.5333, raw test Top1 acc:87.12, raw test Top5 acc: 99.52, ema_testing_loss: 0.2678, ema test Top1 acc:92.98, ema test Top5 acc: 99.82\n","[2022-04-19 10:50:01,443][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 10:59:52,707][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 43: use 591.3750500679016 seconds\n","--- Optimizer learning rate changed from 2.64e-02 to 2.63e-02 ---\n","[2022-04-19 10:59:52,818][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 10:59:54,626][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 10:59:54,626][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 10:59:56,421][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 10:59:56,423][experiments.experiment][INFO] - [EMA] Epoch 43.[Train] time:591.3750500679016 seconds, lr:0.0263, train_loss: 0.5727, unlabeled_losses_real_strong:0.5794,corrrect_unlabeled_num:383231.0,pro_above_threshold_num:393078.0,unlabelled_weak_top1_acc:92.1179623901844,unlabelled_weak_top5_acc:99.68087360262871  \n","[2022-04-19 10:59:56,425][experiments.experiment][INFO] - [EMA] Epoch 43. [Validation] raw_testing_loss: 0.3616, raw test Top1 acc:89.48, raw test Top5 acc: 99.7, ema_testing_loss: 0.2582, ema test Top1 acc:93.24, ema test Top5 acc: 99.86\n","[2022-04-19 10:59:56,551][experiments.experiment][INFO] - [Checkpoints] Epoch 43, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 10:59:56,555][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 11:09:50,419][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 44: use 593.968683719635 seconds\n","--- Optimizer learning rate changed from 2.63e-02 to 2.61e-02 ---\n","[2022-04-19 11:09:50,524][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 11:09:52,306][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 11:09:52,306][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 11:09:54,072][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 11:09:54,074][experiments.experiment][INFO] - [EMA] Epoch 44.[Train] time:593.968683719635 seconds, lr:0.0261, train_loss: 0.5702, unlabeled_losses_real_strong:0.5769,corrrect_unlabeled_num:384310.0,pro_above_threshold_num:394248.0,unlabelled_weak_top1_acc:92.16657253354788,unlabelled_weak_top5_acc:99.69024685025215  \n","[2022-04-19 11:09:54,077][experiments.experiment][INFO] - [EMA] Epoch 44. [Validation] raw_testing_loss: 0.5362, raw test Top1 acc:86.24, raw test Top5 acc: 99.44, ema_testing_loss: 0.2556, ema test Top1 acc:93.16, ema test Top5 acc: 99.86\n","[2022-04-19 11:09:54,078][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 11:19:46,448][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 45: use 592.4741823673248 seconds\n","--- Optimizer learning rate changed from 2.61e-02 to 2.59e-02 ---\n","[2022-04-19 11:19:46,552][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 11:19:48,320][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 11:19:48,321][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 11:19:50,081][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 11:19:50,083][experiments.experiment][INFO] - [EMA] Epoch 45.[Train] time:592.4741823673248 seconds, lr:0.0259, train_loss: 0.5713, unlabeled_losses_real_strong:0.5710,corrrect_unlabeled_num:385501.0,pro_above_threshold_num:395550.0,unlabelled_weak_top1_acc:92.21452857553959,unlabelled_weak_top5_acc:99.6765139400959  \n","[2022-04-19 11:19:50,086][experiments.experiment][INFO] - [EMA] Epoch 45. [Validation] raw_testing_loss: 0.3297, raw test Top1 acc:89.72, raw test Top5 acc: 99.7, ema_testing_loss: 0.2584, ema test Top1 acc:93.4, ema test Top5 acc: 99.84\n","[2022-04-19 11:19:50,206][experiments.experiment][INFO] - [Checkpoints] Epoch 45, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 11:19:50,208][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 11:29:41,415][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 46: use 591.3133869171143 seconds\n","--- Optimizer learning rate changed from 2.59e-02 to 2.58e-02 ---\n","[2022-04-19 11:29:41,522][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 11:29:43,279][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 11:29:43,279][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 11:29:45,031][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 11:29:45,033][experiments.experiment][INFO] - [EMA] Epoch 46.[Train] time:591.3133869171143 seconds, lr:0.0258, train_loss: 0.5664, unlabeled_losses_real_strong:0.5687,corrrect_unlabeled_num:385642.0,pro_above_threshold_num:395481.0,unlabelled_weak_top1_acc:92.3270078226924,unlabelled_weak_top5_acc:99.698312304914  \n","[2022-04-19 11:29:45,035][experiments.experiment][INFO] - [EMA] Epoch 46. [Validation] raw_testing_loss: 0.4420, raw test Top1 acc:88.46, raw test Top5 acc: 99.34, ema_testing_loss: 0.2590, ema test Top1 acc:93.4, ema test Top5 acc: 99.84\n","[2022-04-19 11:29:45,037][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 11:39:36,396][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 47: use 591.4664330482483 seconds\n","--- Optimizer learning rate changed from 2.58e-02 to 2.56e-02 ---\n","[2022-04-19 11:39:36,504][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 11:39:38,245][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 11:39:38,246][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 11:39:39,976][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 11:39:39,978][experiments.experiment][INFO] - [EMA] Epoch 47.[Train] time:591.4664330482483 seconds, lr:0.0256, train_loss: 0.5642, unlabeled_losses_real_strong:0.5647,corrrect_unlabeled_num:386984.0,pro_above_threshold_num:396658.0,unlabelled_weak_top1_acc:92.44471853226423,unlabelled_weak_top5_acc:99.70180004090071  \n","[2022-04-19 11:39:39,981][experiments.experiment][INFO] - [EMA] Epoch 47. [Validation] raw_testing_loss: 0.4392, raw test Top1 acc:88.64, raw test Top5 acc: 99.5, ema_testing_loss: 0.2564, ema test Top1 acc:93.56, ema test Top5 acc: 99.84\n","[2022-04-19 11:39:40,099][experiments.experiment][INFO] - [Checkpoints] Epoch 47, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 11:39:40,106][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 11:49:30,324][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 48: use 590.3290302753448 seconds\n","--- Optimizer learning rate changed from 2.56e-02 to 2.54e-02 ---\n","[2022-04-19 11:49:30,435][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 11:49:32,241][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 11:49:32,242][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 11:49:33,978][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 11:49:33,980][experiments.experiment][INFO] - [EMA] Epoch 48.[Train] time:590.3290302753448 seconds, lr:0.0254, train_loss: 0.5605, unlabeled_losses_real_strong:0.5608,corrrect_unlabeled_num:387187.0,pro_above_threshold_num:396944.0,unlabelled_weak_top1_acc:92.51447300612926,unlabelled_weak_top5_acc:99.69308067113161  \n","[2022-04-19 11:49:33,983][experiments.experiment][INFO] - [EMA] Epoch 48. [Validation] raw_testing_loss: 0.3504, raw test Top1 acc:89.74, raw test Top5 acc: 99.78, ema_testing_loss: 0.2530, ema test Top1 acc:93.54, ema test Top5 acc: 99.8\n","[2022-04-19 11:49:33,984][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 11:59:44,483][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 49: use 610.6098453998566 seconds\n","--- Optimizer learning rate changed from 2.54e-02 to 2.52e-02 ---\n","[2022-04-19 11:59:44,594][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 11:59:46,440][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 11:59:46,440][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 11:59:48,306][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 11:59:48,309][experiments.experiment][INFO] - [EMA] Epoch 49.[Train] time:610.6098453998566 seconds, lr:0.0252, train_loss: 0.5601, unlabeled_losses_real_strong:0.5607,corrrect_unlabeled_num:387376.0,pro_above_threshold_num:397048.0,unlabelled_weak_top1_acc:92.50030405074358,unlabelled_weak_top5_acc:99.69874832034111  \n","[2022-04-19 11:59:48,311][experiments.experiment][INFO] - [EMA] Epoch 49. [Validation] raw_testing_loss: 0.5061, raw test Top1 acc:87.68, raw test Top5 acc: 99.62, ema_testing_loss: 0.2519, ema test Top1 acc:93.66, ema test Top5 acc: 99.84\n","[2022-04-19 11:59:48,431][experiments.experiment][INFO] - [Checkpoints] Epoch 49, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 11:59:48,433][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 12:09:55,235][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 50: use 606.9085037708282 seconds\n","--- Optimizer learning rate changed from 2.52e-02 to 2.50e-02 ---\n","[2022-04-19 12:09:55,342][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 12:09:57,165][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 12:09:57,166][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 12:09:59,029][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 12:09:59,031][experiments.experiment][INFO] - [EMA] Epoch 50.[Train] time:606.9085037708282 seconds, lr:0.0250, train_loss: 0.5573, unlabeled_losses_real_strong:0.5547,corrrect_unlabeled_num:388219.0,pro_above_threshold_num:397764.0,unlabelled_weak_top1_acc:92.55763354897499,unlabelled_weak_top5_acc:99.694824449718  \n","[2022-04-19 12:09:59,033][experiments.experiment][INFO] - [EMA] Epoch 50. [Validation] raw_testing_loss: 0.3344, raw test Top1 acc:91.24, raw test Top5 acc: 99.74, ema_testing_loss: 0.2455, ema test Top1 acc:93.7, ema test Top5 acc: 99.86\n","[2022-04-19 12:09:59,035][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 12:20:08,776][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 51: use 609.8525166511536 seconds\n","--- Optimizer learning rate changed from 2.50e-02 to 2.48e-02 ---\n","[2022-04-19 12:20:08,887][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 12:20:10,706][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 12:20:10,706][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 12:20:12,547][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 12:20:12,549][experiments.experiment][INFO] - [EMA] Epoch 51.[Train] time:609.8525166511536 seconds, lr:0.0248, train_loss: 0.5565, unlabeled_losses_real_strong:0.5524,corrrect_unlabeled_num:388730.0,pro_above_threshold_num:398500.0,unlabelled_weak_top1_acc:92.63763318955898,unlabelled_weak_top5_acc:99.70703160762787  \n","[2022-04-19 12:20:12,552][experiments.experiment][INFO] - [EMA] Epoch 51. [Validation] raw_testing_loss: 0.3534, raw test Top1 acc:90.7, raw test Top5 acc: 99.6, ema_testing_loss: 0.2490, ema test Top1 acc:93.66, ema test Top5 acc: 99.82\n","[2022-04-19 12:20:12,672][experiments.experiment][INFO] - [Checkpoints] Epoch 51, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 12:20:12,674][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 12:30:09,207][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 52: use 596.6405475139618 seconds\n","--- Optimizer learning rate changed from 2.48e-02 to 2.46e-02 ---\n","[2022-04-19 12:30:09,315][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 12:30:11,084][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 12:30:11,084][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 12:30:12,843][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 12:30:12,845][experiments.experiment][INFO] - [EMA] Epoch 52.[Train] time:596.6405475139618 seconds, lr:0.0246, train_loss: 0.5525, unlabeled_losses_real_strong:0.5489,corrrect_unlabeled_num:389109.0,pro_above_threshold_num:398629.0,unlabelled_weak_top1_acc:92.64875036478043,unlabelled_weak_top5_acc:99.70071000605822  \n","[2022-04-19 12:30:12,846][experiments.experiment][INFO] - [EMA] Epoch 52. [Validation] raw_testing_loss: 0.4072, raw test Top1 acc:89.78, raw test Top5 acc: 99.66, ema_testing_loss: 0.2499, ema test Top1 acc:93.54, ema test Top5 acc: 99.82\n","[2022-04-19 12:30:12,848][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 12:40:04,837][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 53: use 592.097692489624 seconds\n","--- Optimizer learning rate changed from 2.46e-02 to 2.44e-02 ---\n","[2022-04-19 12:40:04,946][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 12:40:06,767][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 12:40:06,767][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 12:40:08,562][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 12:40:08,564][experiments.experiment][INFO] - [EMA] Epoch 53.[Train] time:592.097692489624 seconds, lr:0.0244, train_loss: 0.5554, unlabeled_losses_real_strong:0.5462,corrrect_unlabeled_num:390082.0,pro_above_threshold_num:399678.0,unlabelled_weak_top1_acc:92.7167608588934,unlabelled_weak_top5_acc:99.70899341255426  \n","[2022-04-19 12:40:08,568][experiments.experiment][INFO] - [EMA] Epoch 53. [Validation] raw_testing_loss: 0.3801, raw test Top1 acc:89.6, raw test Top5 acc: 99.68, ema_testing_loss: 0.2479, ema test Top1 acc:93.58, ema test Top5 acc: 99.84\n","[2022-04-19 12:40:08,683][experiments.experiment][INFO] - [Checkpoints] Epoch 53, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 12:40:08,688][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 12:49:59,580][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 54: use 590.9987006187439 seconds\n","--- Optimizer learning rate changed from 2.44e-02 to 2.42e-02 ---\n","[2022-04-19 12:49:59,687][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 12:50:01,520][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 12:50:01,521][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 12:50:03,342][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 12:50:03,344][experiments.experiment][INFO] - [EMA] Epoch 54.[Train] time:590.9987006187439 seconds, lr:0.0242, train_loss: 0.5502, unlabeled_losses_real_strong:0.5421,corrrect_unlabeled_num:390958.0,pro_above_threshold_num:400585.0,unlabelled_weak_top1_acc:92.79959423094988,unlabelled_weak_top5_acc:99.7253421023488  \n","[2022-04-19 12:50:03,347][experiments.experiment][INFO] - [EMA] Epoch 54. [Validation] raw_testing_loss: 0.3549, raw test Top1 acc:90.26, raw test Top5 acc: 99.7, ema_testing_loss: 0.2439, ema test Top1 acc:93.8, ema test Top5 acc: 99.86\n","[2022-04-19 12:50:03,348][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 13:00:03,564][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 55: use 600.3287880420685 seconds\n","--- Optimizer learning rate changed from 2.42e-02 to 2.40e-02 ---\n","[2022-04-19 13:00:03,677][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 13:00:05,392][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 13:00:05,393][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 13:00:07,156][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 13:00:07,158][experiments.experiment][INFO] - [EMA] Epoch 55.[Train] time:600.3287880420685 seconds, lr:0.0240, train_loss: 0.5516, unlabeled_losses_real_strong:0.5396,corrrect_unlabeled_num:391455.0,pro_above_threshold_num:400907.0,unlabelled_weak_top1_acc:92.85932151973248,unlabelled_weak_top5_acc:99.71269924938679  \n","[2022-04-19 13:00:07,161][experiments.experiment][INFO] - [EMA] Epoch 55. [Validation] raw_testing_loss: 0.3797, raw test Top1 acc:90.1, raw test Top5 acc: 99.5, ema_testing_loss: 0.2480, ema test Top1 acc:93.9, ema test Top5 acc: 99.84\n","[2022-04-19 13:00:07,279][experiments.experiment][INFO] - [Checkpoints] Epoch 55, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 13:00:07,289][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 13:09:54,124][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 56: use 586.9408271312714 seconds\n","--- Optimizer learning rate changed from 2.40e-02 to 2.38e-02 ---\n","[2022-04-19 13:09:54,230][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 13:09:55,941][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 13:09:55,942][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 13:09:57,680][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 13:09:57,682][experiments.experiment][INFO] - [EMA] Epoch 56.[Train] time:586.9408271312714 seconds, lr:0.0238, train_loss: 0.5464, unlabeled_losses_real_strong:0.5361,corrrect_unlabeled_num:391997.0,pro_above_threshold_num:401396.0,unlabelled_weak_top1_acc:92.92776820063591,unlabelled_weak_top5_acc:99.72054650634527  \n","[2022-04-19 13:09:57,685][experiments.experiment][INFO] - [EMA] Epoch 56. [Validation] raw_testing_loss: 0.4921, raw test Top1 acc:88.12, raw test Top5 acc: 99.52, ema_testing_loss: 0.2466, ema test Top1 acc:93.7, ema test Top5 acc: 99.86\n","[2022-04-19 13:09:57,686][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 13:19:44,294][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 57: use 586.7143337726593 seconds\n","--- Optimizer learning rate changed from 2.38e-02 to 2.36e-02 ---\n","[2022-04-19 13:19:44,401][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 13:19:46,105][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 13:19:46,105][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 13:19:47,810][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 13:19:47,812][experiments.experiment][INFO] - [EMA] Epoch 57.[Train] time:586.7143337726593 seconds, lr:0.0236, train_loss: 0.5470, unlabeled_losses_real_strong:0.5328,corrrect_unlabeled_num:392399.0,pro_above_threshold_num:401879.0,unlabelled_weak_top1_acc:92.9691848307848,unlabelled_weak_top5_acc:99.72076451033354  \n","[2022-04-19 13:19:47,813][experiments.experiment][INFO] - [EMA] Epoch 57. [Validation] raw_testing_loss: 0.4324, raw test Top1 acc:88.66, raw test Top5 acc: 99.42, ema_testing_loss: 0.2452, ema test Top1 acc:93.84, ema test Top5 acc: 99.84\n","[2022-04-19 13:19:47,934][experiments.experiment][INFO] - [Checkpoints] Epoch 57, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 13:19:47,936][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 13:29:34,674][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 58: use 586.8431839942932 seconds\n","--- Optimizer learning rate changed from 2.36e-02 to 2.34e-02 ---\n","[2022-04-19 13:29:34,779][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 13:29:36,525][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 13:29:36,525][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 13:29:38,259][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 13:29:38,261][experiments.experiment][INFO] - [EMA] Epoch 58.[Train] time:586.8431839942932 seconds, lr:0.0234, train_loss: 0.5422, unlabeled_losses_real_strong:0.5302,corrrect_unlabeled_num:393007.0,pro_above_threshold_num:402418.0,unlabelled_weak_top1_acc:93.0476586818695,unlabelled_weak_top5_acc:99.72229049354792  \n","[2022-04-19 13:29:38,262][experiments.experiment][INFO] - [EMA] Epoch 58. [Validation] raw_testing_loss: 0.3321, raw test Top1 acc:91.22, raw test Top5 acc: 99.82, ema_testing_loss: 0.2415, ema test Top1 acc:93.96, ema test Top5 acc: 99.86\n","[2022-04-19 13:29:38,265][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 13:39:25,687][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 59: use 587.5220911502838 seconds\n","--- Optimizer learning rate changed from 2.34e-02 to 2.32e-02 ---\n","[2022-04-19 13:39:25,787][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 13:39:27,438][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 13:39:27,439][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 13:39:29,187][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 13:39:29,189][experiments.experiment][INFO] - [EMA] Epoch 59.[Train] time:587.5220911502838 seconds, lr:0.0232, train_loss: 0.5437, unlabeled_losses_real_strong:0.5262,corrrect_unlabeled_num:393897.0,pro_above_threshold_num:403335.0,unlabelled_weak_top1_acc:93.07316261529922,unlabelled_weak_top5_acc:99.72665005922318  \n","[2022-04-19 13:39:29,192][experiments.experiment][INFO] - [EMA] Epoch 59. [Validation] raw_testing_loss: 0.4185, raw test Top1 acc:89.3, raw test Top5 acc: 99.46, ema_testing_loss: 0.2371, ema test Top1 acc:94.0, ema test Top5 acc: 99.88\n","[2022-04-19 13:39:29,308][experiments.experiment][INFO] - [Checkpoints] Epoch 59, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 13:39:29,311][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 13:49:15,312][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 60: use 586.1056807041168 seconds\n","--- Optimizer learning rate changed from 2.32e-02 to 2.30e-02 ---\n","[2022-04-19 13:49:15,416][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 13:49:17,150][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 13:49:17,150][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 13:49:18,928][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 13:49:18,930][experiments.experiment][INFO] - [EMA] Epoch 60.[Train] time:586.1056807041168 seconds, lr:0.0230, train_loss: 0.5414, unlabeled_losses_real_strong:0.5230,corrrect_unlabeled_num:394232.0,pro_above_threshold_num:403510.0,unlabelled_weak_top1_acc:93.14836668223143,unlabelled_weak_top5_acc:99.73536937683821  \n","[2022-04-19 13:49:18,933][experiments.experiment][INFO] - [EMA] Epoch 60. [Validation] raw_testing_loss: 0.4430, raw test Top1 acc:89.22, raw test Top5 acc: 99.68, ema_testing_loss: 0.2383, ema test Top1 acc:93.88, ema test Top5 acc: 99.86\n","[2022-04-19 13:49:18,935][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 13:59:02,130][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 61: use 583.2964498996735 seconds\n","--- Optimizer learning rate changed from 2.30e-02 to 2.27e-02 ---\n","[2022-04-19 13:59:02,231][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 13:59:03,934][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 13:59:03,934][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 13:59:05,662][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 13:59:05,664][experiments.experiment][INFO] - [EMA] Epoch 61.[Train] time:583.2964498996735 seconds, lr:0.0227, train_loss: 0.5372, unlabeled_losses_real_strong:0.5246,corrrect_unlabeled_num:394209.0,pro_above_threshold_num:403548.0,unlabelled_weak_top1_acc:93.17234466224909,unlabelled_weak_top5_acc:99.72577818483114  \n","[2022-04-19 13:59:05,666][experiments.experiment][INFO] - [EMA] Epoch 61. [Validation] raw_testing_loss: 0.3293, raw test Top1 acc:90.74, raw test Top5 acc: 99.66, ema_testing_loss: 0.2434, ema test Top1 acc:93.6, ema test Top5 acc: 99.84\n","[2022-04-19 13:59:05,787][experiments.experiment][INFO] - [Checkpoints] Epoch 61, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 13:59:05,798][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 14:08:54,321][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 62: use 588.6289751529694 seconds\n","--- Optimizer learning rate changed from 2.27e-02 to 2.25e-02 ---\n","[2022-04-19 14:08:54,428][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 14:08:56,227][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 14:08:56,228][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 14:08:58,029][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 14:08:58,031][experiments.experiment][INFO] - [EMA] Epoch 62.[Train] time:588.6289751529694 seconds, lr:0.0225, train_loss: 0.5350, unlabeled_losses_real_strong:0.5212,corrrect_unlabeled_num:394271.0,pro_above_threshold_num:403707.0,unlabelled_weak_top1_acc:93.18258989602327,unlabelled_weak_top5_acc:99.73318950086832  \n","[2022-04-19 14:08:58,033][experiments.experiment][INFO] - [EMA] Epoch 62. [Validation] raw_testing_loss: 0.2989, raw test Top1 acc:91.4, raw test Top5 acc: 99.76, ema_testing_loss: 0.2411, ema test Top1 acc:93.7, ema test Top5 acc: 99.8\n","[2022-04-19 14:08:58,035][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 14:18:46,677][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 63: use 588.7486929893494 seconds\n","--- Optimizer learning rate changed from 2.25e-02 to 2.23e-02 ---\n","[2022-04-19 14:18:46,784][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 14:18:48,605][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 14:18:48,605][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 14:18:50,404][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 14:18:50,407][experiments.experiment][INFO] - [EMA] Epoch 63.[Train] time:588.7486929893494 seconds, lr:0.0223, train_loss: 0.5310, unlabeled_losses_real_strong:0.5167,corrrect_unlabeled_num:394949.0,pro_above_threshold_num:404155.0,unlabelled_weak_top1_acc:93.24144529551268,unlabelled_weak_top5_acc:99.73253571242094  \n","[2022-04-19 14:18:50,409][experiments.experiment][INFO] - [EMA] Epoch 63. [Validation] raw_testing_loss: 0.3464, raw test Top1 acc:90.42, raw test Top5 acc: 99.62, ema_testing_loss: 0.2377, ema test Top1 acc:93.8, ema test Top5 acc: 99.8\n","[2022-04-19 14:18:50,533][experiments.experiment][INFO] - [Checkpoints] Epoch 63, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 14:18:50,540][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 14:28:35,747][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 64: use 585.3162565231323 seconds\n","--- Optimizer learning rate changed from 2.23e-02 to 2.21e-02 ---\n","[2022-04-19 14:28:35,857][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 14:28:37,573][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 14:28:37,574][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 14:28:39,345][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 14:28:39,347][experiments.experiment][INFO] - [EMA] Epoch 64.[Train] time:585.3162565231323 seconds, lr:0.0221, train_loss: 0.5344, unlabeled_losses_real_strong:0.5159,corrrect_unlabeled_num:395361.0,pro_above_threshold_num:404562.0,unlabelled_weak_top1_acc:93.30793007463217,unlabelled_weak_top5_acc:99.74408871680498  \n","[2022-04-19 14:28:39,348][experiments.experiment][INFO] - [EMA] Epoch 64. [Validation] raw_testing_loss: 0.3237, raw test Top1 acc:90.66, raw test Top5 acc: 99.68, ema_testing_loss: 0.2381, ema test Top1 acc:93.96, ema test Top5 acc: 99.82\n","[2022-04-19 14:28:39,351][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 14:38:30,350][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 65: use 591.1147708892822 seconds\n","--- Optimizer learning rate changed from 2.21e-02 to 2.18e-02 ---\n","[2022-04-19 14:38:30,466][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 14:38:32,240][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 14:38:32,240][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 14:38:33,990][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 14:38:33,992][experiments.experiment][INFO] - [EMA] Epoch 65.[Train] time:591.1147708892822 seconds, lr:0.0218, train_loss: 0.5306, unlabeled_losses_real_strong:0.5110,corrrect_unlabeled_num:396455.0,pro_above_threshold_num:405487.0,unlabelled_weak_top1_acc:93.42062709480524,unlabelled_weak_top5_acc:99.74169088900089  \n","[2022-04-19 14:38:33,995][experiments.experiment][INFO] - [EMA] Epoch 65. [Validation] raw_testing_loss: 0.3718, raw test Top1 acc:90.2, raw test Top5 acc: 99.72, ema_testing_loss: 0.2340, ema test Top1 acc:94.08, ema test Top5 acc: 99.82\n","[2022-04-19 14:38:34,111][experiments.experiment][INFO] - [Checkpoints] Epoch 65, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 14:38:34,114][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 14:48:34,393][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 66: use 600.3861212730408 seconds\n","--- Optimizer learning rate changed from 2.18e-02 to 2.16e-02 ---\n","[2022-04-19 14:48:34,500][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 14:48:36,292][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 14:48:36,293][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 14:48:38,043][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 14:48:38,046][experiments.experiment][INFO] - [EMA] Epoch 66.[Train] time:600.3861212730408 seconds, lr:0.0216, train_loss: 0.5262, unlabeled_losses_real_strong:0.5079,corrrect_unlabeled_num:396606.0,pro_above_threshold_num:405774.0,unlabelled_weak_top1_acc:93.36918318271637,unlabelled_weak_top5_acc:99.75520583987236  \n","[2022-04-19 14:48:38,047][experiments.experiment][INFO] - [EMA] Epoch 66. [Validation] raw_testing_loss: 0.3089, raw test Top1 acc:90.92, raw test Top5 acc: 99.62, ema_testing_loss: 0.2344, ema test Top1 acc:94.12, ema test Top5 acc: 99.8\n","[2022-04-19 14:48:38,049][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 14:58:44,114][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 67: use 606.1712470054626 seconds\n","--- Optimizer learning rate changed from 2.16e-02 to 2.14e-02 ---\n","[2022-04-19 14:58:44,221][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 14:58:46,022][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 14:58:46,023][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 14:58:47,831][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 14:58:47,833][experiments.experiment][INFO] - [EMA] Epoch 67.[Train] time:606.1712470054626 seconds, lr:0.0214, train_loss: 0.5281, unlabeled_losses_real_strong:0.5063,corrrect_unlabeled_num:397146.0,pro_above_threshold_num:406218.0,unlabelled_weak_top1_acc:93.49561312049627,unlabelled_weak_top5_acc:99.75106412917376  \n","[2022-04-19 14:58:47,835][experiments.experiment][INFO] - [EMA] Epoch 67. [Validation] raw_testing_loss: 0.3277, raw test Top1 acc:90.76, raw test Top5 acc: 99.64, ema_testing_loss: 0.2269, ema test Top1 acc:94.02, ema test Top5 acc: 99.82\n","[2022-04-19 14:58:47,965][experiments.experiment][INFO] - [Checkpoints] Epoch 67, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 14:58:47,975][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 15:09:01,076][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 68: use 613.2046804428101 seconds\n","--- Optimizer learning rate changed from 2.14e-02 to 2.11e-02 ---\n","[2022-04-19 15:09:01,180][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 15:09:03,001][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 15:09:03,001][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 15:09:04,856][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 15:09:04,859][experiments.experiment][INFO] - [EMA] Epoch 68.[Train] time:613.2046804428101 seconds, lr:0.0211, train_loss: 0.5240, unlabeled_losses_real_strong:0.5081,corrrect_unlabeled_num:397057.0,pro_above_threshold_num:406204.0,unlabelled_weak_top1_acc:93.43021821975708,unlabelled_weak_top5_acc:99.75520581752062  \n","[2022-04-19 15:09:04,862][experiments.experiment][INFO] - [EMA] Epoch 68. [Validation] raw_testing_loss: 0.3314, raw test Top1 acc:91.12, raw test Top5 acc: 99.7, ema_testing_loss: 0.2243, ema test Top1 acc:94.24, ema test Top5 acc: 99.86\n","[2022-04-19 15:09:04,863][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 15:19:11,687][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 69: use 606.9383234977722 seconds\n","--- Optimizer learning rate changed from 2.11e-02 to 2.09e-02 ---\n","[2022-04-19 15:19:11,801][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 15:19:13,527][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 15:19:13,528][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 15:19:15,272][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 15:19:15,275][experiments.experiment][INFO] - [EMA] Epoch 69.[Train] time:606.9383234977722 seconds, lr:0.0209, train_loss: 0.5212, unlabeled_losses_real_strong:0.5017,corrrect_unlabeled_num:397582.0,pro_above_threshold_num:406649.0,unlabelled_weak_top1_acc:93.48645781725645,unlabelled_weak_top5_acc:99.75956561416388  \n","[2022-04-19 15:19:15,276][experiments.experiment][INFO] - [EMA] Epoch 69. [Validation] raw_testing_loss: 0.2935, raw test Top1 acc:91.32, raw test Top5 acc: 99.64, ema_testing_loss: 0.2253, ema test Top1 acc:94.24, ema test Top5 acc: 99.84\n","[2022-04-19 15:19:15,400][experiments.experiment][INFO] - [Checkpoints] Epoch 69, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 15:19:15,405][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 15:29:16,562][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 70: use 601.2707371711731 seconds\n","--- Optimizer learning rate changed from 2.09e-02 to 2.06e-02 ---\n","[2022-04-19 15:29:16,676][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 15:29:18,511][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 15:29:18,511][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 15:29:20,336][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 15:29:20,338][experiments.experiment][INFO] - [EMA] Epoch 70.[Train] time:601.2707371711731 seconds, lr:0.0206, train_loss: 0.5220, unlabeled_losses_real_strong:0.5005,corrrect_unlabeled_num:398357.0,pro_above_threshold_num:407606.0,unlabelled_weak_top1_acc:93.55839213728905,unlabelled_weak_top5_acc:99.75411596894264  \n","[2022-04-19 15:29:20,339][experiments.experiment][INFO] - [EMA] Epoch 70. [Validation] raw_testing_loss: 0.2951, raw test Top1 acc:91.74, raw test Top5 acc: 99.72, ema_testing_loss: 0.2258, ema test Top1 acc:94.2, ema test Top5 acc: 99.9\n","[2022-04-19 15:29:20,342][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 15:39:30,113][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 71: use 609.8805551528931 seconds\n","--- Optimizer learning rate changed from 2.06e-02 to 2.04e-02 ---\n","[2022-04-19 15:39:30,223][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 15:39:32,021][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 15:39:32,021][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 15:39:33,804][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 15:39:33,808][experiments.experiment][INFO] - [EMA] Epoch 71.[Train] time:609.8805551528931 seconds, lr:0.0204, train_loss: 0.5182, unlabeled_losses_real_strong:0.4955,corrrect_unlabeled_num:398787.0,pro_above_threshold_num:407840.0,unlabelled_weak_top1_acc:93.61572157591581,unlabelled_weak_top5_acc:99.7569497525692  \n","[2022-04-19 15:39:33,816][experiments.experiment][INFO] - [EMA] Epoch 71. [Validation] raw_testing_loss: 0.3128, raw test Top1 acc:91.44, raw test Top5 acc: 99.8, ema_testing_loss: 0.2262, ema test Top1 acc:94.06, ema test Top5 acc: 99.88\n","[2022-04-19 15:39:33,938][experiments.experiment][INFO] - [Checkpoints] Epoch 71, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 15:39:33,946][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 15:49:38,218][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 72: use 604.382622718811 seconds\n","--- Optimizer learning rate changed from 2.04e-02 to 2.01e-02 ---\n","[2022-04-19 15:49:38,329][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 15:49:40,122][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 15:49:40,122][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 15:49:41,888][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 15:49:41,890][experiments.experiment][INFO] - [EMA] Epoch 72.[Train] time:604.382622718811 seconds, lr:0.0201, train_loss: 0.5160, unlabeled_losses_real_strong:0.4938,corrrect_unlabeled_num:398753.0,pro_above_threshold_num:407625.0,unlabelled_weak_top1_acc:93.62160722911358,unlabelled_weak_top5_acc:99.77286254614592  \n","[2022-04-19 15:49:41,892][experiments.experiment][INFO] - [EMA] Epoch 72. [Validation] raw_testing_loss: 0.3384, raw test Top1 acc:90.42, raw test Top5 acc: 99.72, ema_testing_loss: 0.2228, ema test Top1 acc:94.2, ema test Top5 acc: 99.9\n","[2022-04-19 15:49:41,893][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 15:59:46,322][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 73: use 604.5394008159637 seconds\n","--- Optimizer learning rate changed from 2.01e-02 to 1.99e-02 ---\n","[2022-04-19 15:59:46,433][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 15:59:48,234][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 15:59:48,235][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 15:59:50,036][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 15:59:50,039][experiments.experiment][INFO] - [EMA] Epoch 73.[Train] time:604.5394008159637 seconds, lr:0.0199, train_loss: 0.5188, unlabeled_losses_real_strong:0.4938,corrrect_unlabeled_num:399436.0,pro_above_threshold_num:408379.0,unlabelled_weak_top1_acc:93.67457687109709,unlabelled_weak_top5_acc:99.761091388762  \n","[2022-04-19 15:59:50,042][experiments.experiment][INFO] - [EMA] Epoch 73. [Validation] raw_testing_loss: 0.3109, raw test Top1 acc:91.16, raw test Top5 acc: 99.74, ema_testing_loss: 0.2207, ema test Top1 acc:94.14, ema test Top5 acc: 99.88\n","[2022-04-19 15:59:50,166][experiments.experiment][INFO] - [Checkpoints] Epoch 73, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 15:59:50,174][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 16:09:51,647][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 74: use 601.5775182247162 seconds\n","--- Optimizer learning rate changed from 1.99e-02 to 1.96e-02 ---\n","[2022-04-19 16:09:51,752][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 16:09:53,512][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 16:09:53,512][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 16:09:55,257][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 16:09:55,259][experiments.experiment][INFO] - [EMA] Epoch 74.[Train] time:601.5775182247162 seconds, lr:0.0196, train_loss: 0.5139, unlabeled_losses_real_strong:0.4877,corrrect_unlabeled_num:399715.0,pro_above_threshold_num:408593.0,unlabelled_weak_top1_acc:93.7323423102498,unlabelled_weak_top5_acc:99.77482438832521  \n","[2022-04-19 16:09:55,261][experiments.experiment][INFO] - [EMA] Epoch 74. [Validation] raw_testing_loss: 0.3235, raw test Top1 acc:90.76, raw test Top5 acc: 99.74, ema_testing_loss: 0.2166, ema test Top1 acc:94.16, ema test Top5 acc: 99.9\n","[2022-04-19 16:09:55,263][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 16:19:59,831][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 75: use 604.6777632236481 seconds\n","--- Optimizer learning rate changed from 1.96e-02 to 1.93e-02 ---\n","[2022-04-19 16:19:59,941][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 16:20:01,760][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 16:20:01,760][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 16:20:03,559][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 16:20:03,561][experiments.experiment][INFO] - [EMA] Epoch 75.[Train] time:604.6777632236481 seconds, lr:0.0193, train_loss: 0.5130, unlabeled_losses_real_strong:0.4865,corrrect_unlabeled_num:400673.0,pro_above_threshold_num:409775.0,unlabelled_weak_top1_acc:93.7635139003396,unlabelled_weak_top5_acc:99.78070984780788  \n","[2022-04-19 16:20:03,564][experiments.experiment][INFO] - [EMA] Epoch 75. [Validation] raw_testing_loss: 0.3155, raw test Top1 acc:91.46, raw test Top5 acc: 99.82, ema_testing_loss: 0.2139, ema test Top1 acc:94.32, ema test Top5 acc: 99.88\n","[2022-04-19 16:20:03,683][experiments.experiment][INFO] - [Checkpoints] Epoch 75, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 16:20:03,685][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 16:30:07,184][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 76: use 603.6062428951263 seconds\n","--- Optimizer learning rate changed from 1.93e-02 to 1.91e-02 ---\n","[2022-04-19 16:30:07,291][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 16:30:09,116][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 16:30:09,116][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 16:30:10,925][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 16:30:10,927][experiments.experiment][INFO] - [EMA] Epoch 76.[Train] time:603.6062428951263 seconds, lr:0.0191, train_loss: 0.5102, unlabeled_losses_real_strong:0.4856,corrrect_unlabeled_num:401028.0,pro_above_threshold_num:409939.0,unlabelled_weak_top1_acc:93.8010067269206,unlabelled_weak_top5_acc:99.77831217646599  \n","[2022-04-19 16:30:10,930][experiments.experiment][INFO] - [EMA] Epoch 76. [Validation] raw_testing_loss: 0.3104, raw test Top1 acc:91.16, raw test Top5 acc: 99.76, ema_testing_loss: 0.2123, ema test Top1 acc:94.28, ema test Top5 acc: 99.84\n","[2022-04-19 16:30:10,931][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 16:40:12,917][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 77: use 602.0939474105835 seconds\n","--- Optimizer learning rate changed from 1.91e-02 to 1.88e-02 ---\n","[2022-04-19 16:40:13,025][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 16:40:14,817][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 16:40:14,818][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 16:40:16,603][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 16:40:16,605][experiments.experiment][INFO] - [EMA] Epoch 77.[Train] time:602.0939474105835 seconds, lr:0.0188, train_loss: 0.5056, unlabeled_losses_real_strong:0.4812,corrrect_unlabeled_num:401607.0,pro_above_threshold_num:410528.0,unlabelled_weak_top1_acc:93.83740989118814,unlabelled_weak_top5_acc:99.77351647615433  \n","[2022-04-19 16:40:16,607][experiments.experiment][INFO] - [EMA] Epoch 77. [Validation] raw_testing_loss: 0.2953, raw test Top1 acc:91.96, raw test Top5 acc: 99.84, ema_testing_loss: 0.2142, ema test Top1 acc:94.4, ema test Top5 acc: 99.9\n","[2022-04-19 16:40:16,723][experiments.experiment][INFO] - [Checkpoints] Epoch 77, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 16:40:16,725][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 16:50:16,937][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 78: use 600.3179218769073 seconds\n","--- Optimizer learning rate changed from 1.88e-02 to 1.85e-02 ---\n","[2022-04-19 16:50:17,043][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 16:50:18,818][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 16:50:18,818][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 16:50:20,593][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 16:50:20,595][experiments.experiment][INFO] - [EMA] Epoch 78.[Train] time:600.3179218769073 seconds, lr:0.0185, train_loss: 0.5044, unlabeled_losses_real_strong:0.4791,corrrect_unlabeled_num:401844.0,pro_above_threshold_num:410726.0,unlabelled_weak_top1_acc:93.89168766885996,unlabelled_weak_top5_acc:99.77765808999538  \n","[2022-04-19 16:50:20,599][experiments.experiment][INFO] - [EMA] Epoch 78. [Validation] raw_testing_loss: 0.2945, raw test Top1 acc:91.96, raw test Top5 acc: 99.76, ema_testing_loss: 0.2162, ema test Top1 acc:94.22, ema test Top5 acc: 99.88\n","[2022-04-19 16:50:20,600][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 17:00:21,657][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 79: use 601.167475938797 seconds\n","--- Optimizer learning rate changed from 1.85e-02 to 1.83e-02 ---\n","[2022-04-19 17:00:21,768][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 17:00:23,593][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 17:00:23,594][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 17:00:25,381][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 17:00:25,383][experiments.experiment][INFO] - [EMA] Epoch 79.[Train] time:601.167475938797 seconds, lr:0.0183, train_loss: 0.5065, unlabeled_losses_real_strong:0.4764,corrrect_unlabeled_num:402343.0,pro_above_threshold_num:411288.0,unlabelled_weak_top1_acc:93.96471201628447,unlabelled_weak_top5_acc:99.77656825631857  \n","[2022-04-19 17:00:25,385][experiments.experiment][INFO] - [EMA] Epoch 79. [Validation] raw_testing_loss: 0.3103, raw test Top1 acc:91.62, raw test Top5 acc: 99.8, ema_testing_loss: 0.2171, ema test Top1 acc:94.2, ema test Top5 acc: 99.88\n","[2022-04-19 17:00:25,511][experiments.experiment][INFO] - [Checkpoints] Epoch 79, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 17:00:25,514][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 17:10:25,131][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 80: use 599.7245967388153 seconds\n","--- Optimizer learning rate changed from 1.83e-02 to 1.80e-02 ---\n","[2022-04-19 17:10:25,238][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 17:10:27,024][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 17:10:27,024][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 17:10:28,820][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 17:10:28,822][experiments.experiment][INFO] - [EMA] Epoch 80.[Train] time:599.7245967388153 seconds, lr:0.0180, train_loss: 0.5013, unlabeled_losses_real_strong:0.4736,corrrect_unlabeled_num:402639.0,pro_above_threshold_num:411455.0,unlabelled_weak_top1_acc:93.97561081498861,unlabelled_weak_top5_acc:99.7955327630043  \n","[2022-04-19 17:10:28,823][experiments.experiment][INFO] - [EMA] Epoch 80. [Validation] raw_testing_loss: 0.3180, raw test Top1 acc:90.9, raw test Top5 acc: 99.76, ema_testing_loss: 0.2141, ema test Top1 acc:94.28, ema test Top5 acc: 99.88\n","[2022-04-19 17:10:28,825][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 17:20:29,777][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 81: use 601.0595903396606 seconds\n","--- Optimizer learning rate changed from 1.80e-02 to 1.77e-02 ---\n","[2022-04-19 17:20:29,885][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 17:20:31,660][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 17:20:31,660][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 17:20:33,473][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 17:20:33,475][experiments.experiment][INFO] - [EMA] Epoch 81.[Train] time:601.0595903396606 seconds, lr:0.0177, train_loss: 0.4996, unlabeled_losses_real_strong:0.4715,corrrect_unlabeled_num:403070.0,pro_above_threshold_num:411986.0,unlabelled_weak_top1_acc:93.98367626219988,unlabelled_weak_top5_acc:99.79684063792229  \n","[2022-04-19 17:20:33,479][experiments.experiment][INFO] - [EMA] Epoch 81. [Validation] raw_testing_loss: 0.3260, raw test Top1 acc:91.64, raw test Top5 acc: 99.76, ema_testing_loss: 0.2172, ema test Top1 acc:94.26, ema test Top5 acc: 99.88\n","[2022-04-19 17:20:33,600][experiments.experiment][INFO] - [Checkpoints] Epoch 81, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 17:20:33,610][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 17:30:30,879][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 82: use 597.3730189800262 seconds\n","--- Optimizer learning rate changed from 1.77e-02 to 1.74e-02 ---\n","[2022-04-19 17:30:30,983][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 17:30:32,744][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 17:30:32,744][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 17:30:34,519][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 17:30:34,522][experiments.experiment][INFO] - [EMA] Epoch 82.[Train] time:597.3730189800262 seconds, lr:0.0174, train_loss: 0.4972, unlabeled_losses_real_strong:0.4694,corrrect_unlabeled_num:404064.0,pro_above_threshold_num:412947.0,unlabelled_weak_top1_acc:94.0761011466384,unlabelled_weak_top5_acc:99.79335291683674  \n","[2022-04-19 17:30:34,525][experiments.experiment][INFO] - [EMA] Epoch 82. [Validation] raw_testing_loss: 0.2913, raw test Top1 acc:91.72, raw test Top5 acc: 99.8, ema_testing_loss: 0.2168, ema test Top1 acc:94.3, ema test Top5 acc: 99.88\n","[2022-04-19 17:30:34,526][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 17:40:26,025][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 83: use 591.6024827957153 seconds\n","--- Optimizer learning rate changed from 1.74e-02 to 1.72e-02 ---\n","[2022-04-19 17:40:26,129][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 17:40:27,926][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 17:40:27,926][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 17:40:29,626][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 17:40:29,628][experiments.experiment][INFO] - [EMA] Epoch 83.[Train] time:591.6024827957153 seconds, lr:0.0172, train_loss: 0.4948, unlabeled_losses_real_strong:0.4667,corrrect_unlabeled_num:403980.0,pro_above_threshold_num:412634.0,unlabelled_weak_top1_acc:94.12078754603863,unlabelled_weak_top5_acc:99.79378880560398  \n","[2022-04-19 17:40:29,631][experiments.experiment][INFO] - [EMA] Epoch 83. [Validation] raw_testing_loss: 0.3178, raw test Top1 acc:91.3, raw test Top5 acc: 99.8, ema_testing_loss: 0.2109, ema test Top1 acc:94.6, ema test Top5 acc: 99.88\n","[2022-04-19 17:40:29,748][experiments.experiment][INFO] - [Checkpoints] Epoch 83, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 17:40:29,757][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 17:50:24,242][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 84: use 594.5891788005829 seconds\n","--- Optimizer learning rate changed from 1.72e-02 to 1.69e-02 ---\n","[2022-04-19 17:50:24,347][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 17:50:26,090][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 17:50:26,090][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 17:50:27,898][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 17:50:27,900][experiments.experiment][INFO] - [EMA] Epoch 84.[Train] time:594.5891788005829 seconds, lr:0.0169, train_loss: 0.4925, unlabeled_losses_real_strong:0.4635,corrrect_unlabeled_num:404333.0,pro_above_threshold_num:412956.0,unlabelled_weak_top1_acc:94.11926157772541,unlabelled_weak_top5_acc:99.79248098284006  \n","[2022-04-19 17:50:27,901][experiments.experiment][INFO] - [EMA] Epoch 84. [Validation] raw_testing_loss: 0.2936, raw test Top1 acc:92.0, raw test Top5 acc: 99.76, ema_testing_loss: 0.2079, ema test Top1 acc:94.62, ema test Top5 acc: 99.88\n","[2022-04-19 17:50:27,905][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 18:00:21,884][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 85: use 594.0939493179321 seconds\n","--- Optimizer learning rate changed from 1.69e-02 to 1.66e-02 ---\n","[2022-04-19 18:00:21,999][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 18:00:23,754][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 18:00:23,755][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 18:00:25,522][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 18:00:25,525][experiments.experiment][INFO] - [EMA] Epoch 85.[Train] time:594.0939493179321 seconds, lr:0.0166, train_loss: 0.4905, unlabeled_losses_real_strong:0.4610,corrrect_unlabeled_num:404912.0,pro_above_threshold_num:413800.0,unlabelled_weak_top1_acc:94.13234055042267,unlabelled_weak_top5_acc:99.78899322450161  \n","[2022-04-19 18:00:25,528][experiments.experiment][INFO] - [EMA] Epoch 85. [Validation] raw_testing_loss: 0.3232, raw test Top1 acc:91.68, raw test Top5 acc: 99.66, ema_testing_loss: 0.2093, ema test Top1 acc:94.4, ema test Top5 acc: 99.88\n","[2022-04-19 18:00:25,648][experiments.experiment][INFO] - [Checkpoints] Epoch 85, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 18:00:25,658][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 18:10:15,193][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 86: use 589.6433708667755 seconds\n","--- Optimizer learning rate changed from 1.66e-02 to 1.63e-02 ---\n","[2022-04-19 18:10:15,301][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 18:10:17,077][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 18:10:17,077][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 18:10:18,840][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 18:10:18,842][experiments.experiment][INFO] - [EMA] Epoch 86.[Train] time:589.6433708667755 seconds, lr:0.0163, train_loss: 0.4908, unlabeled_losses_real_strong:0.4601,corrrect_unlabeled_num:405045.0,pro_above_threshold_num:413727.0,unlabelled_weak_top1_acc:94.21713580936193,unlabelled_weak_top5_acc:99.77809405326843  \n","[2022-04-19 18:10:18,844][experiments.experiment][INFO] - [EMA] Epoch 86. [Validation] raw_testing_loss: 0.3360, raw test Top1 acc:90.88, raw test Top5 acc: 99.66, ema_testing_loss: 0.2099, ema test Top1 acc:94.44, ema test Top5 acc: 99.88\n","[2022-04-19 18:10:18,846][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 18:20:06,396][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 87: use 587.6607482433319 seconds\n","--- Optimizer learning rate changed from 1.63e-02 to 1.60e-02 ---\n","[2022-04-19 18:20:06,507][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 18:20:08,318][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 18:20:08,318][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 18:20:10,097][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 18:20:10,099][experiments.experiment][INFO] - [EMA] Epoch 87.[Train] time:587.6607482433319 seconds, lr:0.0160, train_loss: 0.4854, unlabeled_losses_real_strong:0.4527,corrrect_unlabeled_num:406112.0,pro_above_threshold_num:414693.0,unlabelled_weak_top1_acc:94.34116803109646,unlabelled_weak_top5_acc:99.786377415061  \n","[2022-04-19 18:20:10,102][experiments.experiment][INFO] - [EMA] Epoch 87. [Validation] raw_testing_loss: 0.2896, raw test Top1 acc:91.76, raw test Top5 acc: 99.7, ema_testing_loss: 0.2056, ema test Top1 acc:94.68, ema test Top5 acc: 99.88\n","[2022-04-19 18:20:10,221][experiments.experiment][INFO] - [Checkpoints] Epoch 87, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 18:20:10,223][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 18:30:08,342][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 88: use 598.2246315479279 seconds\n","--- Optimizer learning rate changed from 1.60e-02 to 1.57e-02 ---\n","[2022-04-19 18:30:08,447][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 18:30:10,265][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 18:30:10,266][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 18:30:12,015][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 18:30:12,018][experiments.experiment][INFO] - [EMA] Epoch 88.[Train] time:598.2246315479279 seconds, lr:0.0157, train_loss: 0.4855, unlabeled_losses_real_strong:0.4551,corrrect_unlabeled_num:405897.0,pro_above_threshold_num:414539.0,unlabelled_weak_top1_acc:94.28710823506117,unlabelled_weak_top5_acc:99.79422480612993  \n","[2022-04-19 18:30:12,021][experiments.experiment][INFO] - [EMA] Epoch 88. [Validation] raw_testing_loss: 0.2869, raw test Top1 acc:92.26, raw test Top5 acc: 99.72, ema_testing_loss: 0.2080, ema test Top1 acc:94.62, ema test Top5 acc: 99.9\n","[2022-04-19 18:30:12,022][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 18:40:13,051][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 89: use 601.1335878372192 seconds\n","--- Optimizer learning rate changed from 1.57e-02 to 1.54e-02 ---\n","[2022-04-19 18:40:13,155][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 18:40:14,957][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 18:40:14,957][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 18:40:16,750][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 18:40:16,752][experiments.experiment][INFO] - [EMA] Epoch 89.[Train] time:601.1335878372192 seconds, lr:0.0154, train_loss: 0.4819, unlabeled_losses_real_strong:0.4505,corrrect_unlabeled_num:406939.0,pro_above_threshold_num:415501.0,unlabelled_weak_top1_acc:94.37190353870392,unlabelled_weak_top5_acc:99.78637734800577  \n","[2022-04-19 18:40:16,756][experiments.experiment][INFO] - [EMA] Epoch 89. [Validation] raw_testing_loss: 0.2670, raw test Top1 acc:92.52, raw test Top5 acc: 99.84, ema_testing_loss: 0.2069, ema test Top1 acc:94.6, ema test Top5 acc: 99.86\n","[2022-04-19 18:40:16,881][experiments.experiment][INFO] - [Checkpoints] Epoch 89, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 18:40:16,883][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 18:50:19,095][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 90: use 602.32266497612 seconds\n","--- Optimizer learning rate changed from 1.54e-02 to 1.51e-02 ---\n","[2022-04-19 18:50:19,205][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 18:50:21,032][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 18:50:21,033][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 18:50:22,840][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 18:50:22,843][experiments.experiment][INFO] - [EMA] Epoch 90.[Train] time:602.32266497612 seconds, lr:0.0151, train_loss: 0.4781, unlabeled_losses_real_strong:0.4457,corrrect_unlabeled_num:407333.0,pro_above_threshold_num:415905.0,unlabelled_weak_top1_acc:94.40089519321918,unlabelled_weak_top5_acc:99.78659538179636  \n","[2022-04-19 18:50:22,847][experiments.experiment][INFO] - [EMA] Epoch 90. [Validation] raw_testing_loss: 0.2907, raw test Top1 acc:91.74, raw test Top5 acc: 99.8, ema_testing_loss: 0.2004, ema test Top1 acc:94.64, ema test Top5 acc: 99.9\n","[2022-04-19 18:50:22,847][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 19:00:22,431][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 91: use 599.6900413036346 seconds\n","--- Optimizer learning rate changed from 1.51e-02 to 1.48e-02 ---\n","[2022-04-19 19:00:22,537][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 19:00:24,299][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 19:00:24,300][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 19:00:26,063][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 19:00:26,066][experiments.experiment][INFO] - [EMA] Epoch 91.[Train] time:599.6900413036346 seconds, lr:0.0148, train_loss: 0.4753, unlabeled_losses_real_strong:0.4403,corrrect_unlabeled_num:407586.0,pro_above_threshold_num:416241.0,unlabelled_weak_top1_acc:94.42247549444437,unlabelled_weak_top5_acc:99.78637747466564  \n","[2022-04-19 19:00:26,068][experiments.experiment][INFO] - [EMA] Epoch 91. [Validation] raw_testing_loss: 0.3168, raw test Top1 acc:90.94, raw test Top5 acc: 99.82, ema_testing_loss: 0.1998, ema test Top1 acc:94.66, ema test Top5 acc: 99.92\n","[2022-04-19 19:00:26,187][experiments.experiment][INFO] - [Checkpoints] Epoch 91, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 19:00:26,189][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 19:10:24,674][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 92: use 598.5919358730316 seconds\n","--- Optimizer learning rate changed from 1.48e-02 to 1.45e-02 ---\n","[2022-04-19 19:10:24,781][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 19:10:26,557][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 19:10:26,558][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 19:10:28,345][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 19:10:28,347][experiments.experiment][INFO] - [EMA] Epoch 92.[Train] time:598.5919358730316 seconds, lr:0.0145, train_loss: 0.4746, unlabeled_losses_real_strong:0.4434,corrrect_unlabeled_num:408002.0,pro_above_threshold_num:416682.0,unlabelled_weak_top1_acc:94.43773428350687,unlabelled_weak_top5_acc:99.79466087371111  \n","[2022-04-19 19:10:28,349][experiments.experiment][INFO] - [EMA] Epoch 92. [Validation] raw_testing_loss: 0.2998, raw test Top1 acc:91.98, raw test Top5 acc: 99.78, ema_testing_loss: 0.2040, ema test Top1 acc:94.56, ema test Top5 acc: 99.88\n","[2022-04-19 19:10:28,351][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 19:20:24,616][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 93: use 596.3747246265411 seconds\n","--- Optimizer learning rate changed from 1.45e-02 to 1.42e-02 ---\n","[2022-04-19 19:20:24,726][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 19:20:26,496][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 19:20:26,497][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 19:20:28,293][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 19:20:28,295][experiments.experiment][INFO] - [EMA] Epoch 93.[Train] time:596.3747246265411 seconds, lr:0.0142, train_loss: 0.4745, unlabeled_losses_real_strong:0.4402,corrrect_unlabeled_num:408721.0,pro_above_threshold_num:417334.0,unlabelled_weak_top1_acc:94.50269308686256,unlabelled_weak_top5_acc:99.80970159173012  \n","[2022-04-19 19:20:28,298][experiments.experiment][INFO] - [EMA] Epoch 93. [Validation] raw_testing_loss: 0.2674, raw test Top1 acc:92.44, raw test Top5 acc: 99.84, ema_testing_loss: 0.1998, ema test Top1 acc:94.6, ema test Top5 acc: 99.88\n","[2022-04-19 19:20:28,415][experiments.experiment][INFO] - [Checkpoints] Epoch 93, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 19:20:28,417][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 19:30:26,232][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 94: use 597.9222321510315 seconds\n","--- Optimizer learning rate changed from 1.42e-02 to 1.39e-02 ---\n","[2022-04-19 19:30:26,339][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 19:30:28,148][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 19:30:28,149][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 19:30:29,934][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 19:30:29,936][experiments.experiment][INFO] - [EMA] Epoch 94.[Train] time:597.9222321510315 seconds, lr:0.0139, train_loss: 0.4666, unlabeled_losses_real_strong:0.4361,corrrect_unlabeled_num:408994.0,pro_above_threshold_num:417577.0,unlabelled_weak_top1_acc:94.51010459661484,unlabelled_weak_top5_acc:99.8035980463028  \n","[2022-04-19 19:30:29,939][experiments.experiment][INFO] - [EMA] Epoch 94. [Validation] raw_testing_loss: 0.2520, raw test Top1 acc:92.36, raw test Top5 acc: 99.78, ema_testing_loss: 0.2048, ema test Top1 acc:94.48, ema test Top5 acc: 99.86\n","[2022-04-19 19:30:29,940][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 19:40:30,578][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 95: use 600.7470009326935 seconds\n","--- Optimizer learning rate changed from 1.39e-02 to 1.36e-02 ---\n","[2022-04-19 19:40:30,687][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 19:40:32,452][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 19:40:32,453][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 19:40:34,256][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 19:40:34,258][experiments.experiment][INFO] - [EMA] Epoch 95.[Train] time:600.7470009326935 seconds, lr:0.0136, train_loss: 0.4651, unlabeled_losses_real_strong:0.4350,corrrect_unlabeled_num:409859.0,pro_above_threshold_num:418640.0,unlabelled_weak_top1_acc:94.58879628032446,unlabelled_weak_top5_acc:99.81079152971506  \n","[2022-04-19 19:40:34,259][experiments.experiment][INFO] - [EMA] Epoch 95. [Validation] raw_testing_loss: 0.3377, raw test Top1 acc:91.5, raw test Top5 acc: 99.76, ema_testing_loss: 0.2038, ema test Top1 acc:94.58, ema test Top5 acc: 99.9\n","[2022-04-19 19:40:34,377][experiments.experiment][INFO] - [Checkpoints] Epoch 95, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 19:40:34,378][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 19:50:33,578][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 96: use 599.3087737560272 seconds\n","--- Optimizer learning rate changed from 1.36e-02 to 1.33e-02 ---\n","[2022-04-19 19:50:33,687][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 19:50:35,467][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 19:50:35,467][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 19:50:37,228][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 19:50:37,231][experiments.experiment][INFO] - [EMA] Epoch 96.[Train] time:599.3087737560272 seconds, lr:0.0133, train_loss: 0.4651, unlabeled_losses_real_strong:0.4311,corrrect_unlabeled_num:410003.0,pro_above_threshold_num:418682.0,unlabelled_weak_top1_acc:94.61713436245918,unlabelled_weak_top5_acc:99.79880248010159  \n","[2022-04-19 19:50:37,233][experiments.experiment][INFO] - [EMA] Epoch 96. [Validation] raw_testing_loss: 0.2852, raw test Top1 acc:92.12, raw test Top5 acc: 99.76, ema_testing_loss: 0.2036, ema test Top1 acc:94.78, ema test Top5 acc: 99.88\n","[2022-04-19 19:50:37,234][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 20:00:34,190][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 97: use 597.0731315612793 seconds\n","--- Optimizer learning rate changed from 1.33e-02 to 1.30e-02 ---\n","[2022-04-19 20:00:34,307][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 20:00:36,095][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 20:00:36,096][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 20:00:37,854][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 20:00:37,856][experiments.experiment][INFO] - [EMA] Epoch 97.[Train] time:597.0731315612793 seconds, lr:0.0130, train_loss: 0.4636, unlabeled_losses_real_strong:0.4276,corrrect_unlabeled_num:410686.0,pro_above_threshold_num:419385.0,unlabelled_weak_top1_acc:94.68296483904123,unlabelled_weak_top5_acc:99.80359810590744  \n","[2022-04-19 20:00:37,859][experiments.experiment][INFO] - [EMA] Epoch 97. [Validation] raw_testing_loss: 0.2428, raw test Top1 acc:93.26, raw test Top5 acc: 99.9, ema_testing_loss: 0.2009, ema test Top1 acc:94.66, ema test Top5 acc: 99.88\n","[2022-04-19 20:00:37,983][experiments.experiment][INFO] - [Checkpoints] Epoch 97, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 20:00:37,984][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 20:10:34,413][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 98: use 596.5364897251129 seconds\n","--- Optimizer learning rate changed from 1.30e-02 to 1.27e-02 ---\n","[2022-04-19 20:10:34,520][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 20:10:36,267][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 20:10:36,268][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 20:10:38,032][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 20:10:38,034][experiments.experiment][INFO] - [EMA] Epoch 98.[Train] time:596.5364897251129 seconds, lr:0.0127, train_loss: 0.4584, unlabeled_losses_real_strong:0.4245,corrrect_unlabeled_num:411355.0,pro_above_threshold_num:420029.0,unlabelled_weak_top1_acc:94.70999468117952,unlabelled_weak_top5_acc:99.80490598082542  \n","[2022-04-19 20:10:38,037][experiments.experiment][INFO] - [EMA] Epoch 98. [Validation] raw_testing_loss: 0.3349, raw test Top1 acc:91.94, raw test Top5 acc: 99.62, ema_testing_loss: 0.2024, ema test Top1 acc:94.76, ema test Top5 acc: 99.88\n","[2022-04-19 20:10:38,038][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 20:20:35,610][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 99: use 597.6749799251556 seconds\n","--- Optimizer learning rate changed from 1.27e-02 to 1.24e-02 ---\n","[2022-04-19 20:20:35,713][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 20:20:37,486][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 20:20:37,487][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 20:20:39,241][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 20:20:39,243][experiments.experiment][INFO] - [EMA] Epoch 99.[Train] time:597.6749799251556 seconds, lr:0.0124, train_loss: 0.4568, unlabeled_losses_real_strong:0.4218,corrrect_unlabeled_num:411777.0,pro_above_threshold_num:420385.0,unlabelled_weak_top1_acc:94.74683376401663,unlabelled_weak_top5_acc:99.81471515446901  \n","[2022-04-19 20:20:39,244][experiments.experiment][INFO] - [EMA] Epoch 99. [Validation] raw_testing_loss: 0.2666, raw test Top1 acc:92.52, raw test Top5 acc: 99.82, ema_testing_loss: 0.1996, ema test Top1 acc:94.56, ema test Top5 acc: 99.9\n","[2022-04-19 20:20:39,367][experiments.experiment][INFO] - [Checkpoints] Epoch 99, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 20:20:39,369][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 20:30:37,007][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 100: use 597.7435173988342 seconds\n","--- Optimizer learning rate changed from 1.24e-02 to 1.21e-02 ---\n","[2022-04-19 20:30:37,113][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 20:30:38,890][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 20:30:38,891][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 20:30:40,645][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 20:30:40,647][experiments.experiment][INFO] - [EMA] Epoch 100.[Train] time:597.7435173988342 seconds, lr:0.0121, train_loss: 0.4524, unlabeled_losses_real_strong:0.4185,corrrect_unlabeled_num:411736.0,pro_above_threshold_num:420258.0,unlabelled_weak_top1_acc:94.84710579365492,unlabelled_weak_top5_acc:99.8051239028573  \n","[2022-04-19 20:30:40,651][experiments.experiment][INFO] - [EMA] Epoch 100. [Validation] raw_testing_loss: 0.2967, raw test Top1 acc:92.36, raw test Top5 acc: 99.8, ema_testing_loss: 0.1976, ema test Top1 acc:94.64, ema test Top5 acc: 99.9\n","[2022-04-19 20:30:40,652][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 20:40:37,127][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 101: use 596.5796656608582 seconds\n","--- Optimizer learning rate changed from 1.21e-02 to 1.18e-02 ---\n","[2022-04-19 20:40:37,231][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 20:40:39,014][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 20:40:39,014][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 20:40:40,785][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 20:40:40,787][experiments.experiment][INFO] - [EMA] Epoch 101.[Train] time:596.5796656608582 seconds, lr:0.0118, train_loss: 0.4514, unlabeled_losses_real_strong:0.4156,corrrect_unlabeled_num:412693.0,pro_above_threshold_num:421222.0,unlabelled_weak_top1_acc:94.85168351233006,unlabelled_weak_top5_acc:99.82147267460823  \n","[2022-04-19 20:40:40,790][experiments.experiment][INFO] - [EMA] Epoch 101. [Validation] raw_testing_loss: 0.2902, raw test Top1 acc:91.8, raw test Top5 acc: 99.56, ema_testing_loss: 0.1960, ema test Top1 acc:94.8, ema test Top5 acc: 99.9\n","[2022-04-19 20:40:40,907][experiments.experiment][INFO] - [Checkpoints] Epoch 101, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 20:40:40,909][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 20:50:40,778][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 102: use 599.971141576767 seconds\n","--- Optimizer learning rate changed from 1.18e-02 to 1.14e-02 ---\n","[2022-04-19 20:50:40,881][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 20:50:42,659][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 20:50:42,659][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 20:50:44,424][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 20:50:44,426][experiments.experiment][INFO] - [EMA] Epoch 102.[Train] time:599.971141576767 seconds, lr:0.0114, train_loss: 0.4514, unlabeled_losses_real_strong:0.4146,corrrect_unlabeled_num:412965.0,pro_above_threshold_num:421602.0,unlabelled_weak_top1_acc:94.8793671503663,unlabelled_weak_top5_acc:99.81013763695955  \n","[2022-04-19 20:50:44,428][experiments.experiment][INFO] - [EMA] Epoch 102. [Validation] raw_testing_loss: 0.2623, raw test Top1 acc:92.84, raw test Top5 acc: 99.84, ema_testing_loss: 0.1929, ema test Top1 acc:94.72, ema test Top5 acc: 99.94\n","[2022-04-19 20:50:44,430][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 21:00:43,588][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 103: use 599.2616243362427 seconds\n","--- Optimizer learning rate changed from 1.14e-02 to 1.11e-02 ---\n","[2022-04-19 21:00:43,692][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 21:00:45,420][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 21:00:45,421][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 21:00:47,178][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 21:00:47,180][experiments.experiment][INFO] - [EMA] Epoch 103.[Train] time:599.2616243362427 seconds, lr:0.0111, train_loss: 0.4441, unlabeled_losses_real_strong:0.4089,corrrect_unlabeled_num:413740.0,pro_above_threshold_num:422431.0,unlabelled_weak_top1_acc:94.92601558566093,unlabelled_weak_top5_acc:99.82125470787287  \n","[2022-04-19 21:00:47,182][experiments.experiment][INFO] - [EMA] Epoch 103. [Validation] raw_testing_loss: 0.2548, raw test Top1 acc:92.8, raw test Top5 acc: 99.72, ema_testing_loss: 0.1946, ema test Top1 acc:94.68, ema test Top5 acc: 99.92\n","[2022-04-19 21:00:47,299][experiments.experiment][INFO] - [Checkpoints] Epoch 103, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 21:00:47,304][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 21:10:42,623][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 104: use 595.4244740009308 seconds\n","--- Optimizer learning rate changed from 1.11e-02 to 1.08e-02 ---\n","[2022-04-19 21:10:42,728][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 21:10:44,458][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 21:10:44,459][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 21:10:46,203][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 21:10:46,205][experiments.experiment][INFO] - [EMA] Epoch 104.[Train] time:595.4244740009308 seconds, lr:0.0108, train_loss: 0.4415, unlabeled_losses_real_strong:0.4047,corrrect_unlabeled_num:414564.0,pro_above_threshold_num:423226.0,unlabelled_weak_top1_acc:94.99424416571856,unlabelled_weak_top5_acc:99.82910210639238  \n","[2022-04-19 21:10:46,206][experiments.experiment][INFO] - [EMA] Epoch 104. [Validation] raw_testing_loss: 0.2717, raw test Top1 acc:93.0, raw test Top5 acc: 99.7, ema_testing_loss: 0.1970, ema test Top1 acc:94.74, ema test Top5 acc: 99.92\n","[2022-04-19 21:10:46,209][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 21:20:42,273][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 105: use 596.1709532737732 seconds\n","--- Optimizer learning rate changed from 1.08e-02 to 1.05e-02 ---\n","[2022-04-19 21:20:42,381][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 21:20:44,155][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 21:20:44,155][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 21:20:45,952][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 21:20:45,954][experiments.experiment][INFO] - [EMA] Epoch 105.[Train] time:596.1709532737732 seconds, lr:0.0105, train_loss: 0.4409, unlabeled_losses_real_strong:0.4043,corrrect_unlabeled_num:414556.0,pro_above_threshold_num:423296.0,unlabelled_weak_top1_acc:94.99511593580246,unlabelled_weak_top5_acc:99.80512396991253  \n","[2022-04-19 21:20:45,957][experiments.experiment][INFO] - [EMA] Epoch 105. [Validation] raw_testing_loss: 0.2686, raw test Top1 acc:92.86, raw test Top5 acc: 99.82, ema_testing_loss: 0.1945, ema test Top1 acc:94.88, ema test Top5 acc: 99.92\n","[2022-04-19 21:20:46,074][experiments.experiment][INFO] - [Checkpoints] Epoch 105, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 21:20:46,076][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 21:30:42,757][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 106: use 596.7820012569427 seconds\n","--- Optimizer learning rate changed from 1.05e-02 to 1.02e-02 ---\n","[2022-04-19 21:30:42,859][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 21:30:44,635][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 21:30:44,635][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 21:30:46,409][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 21:30:46,412][experiments.experiment][INFO] - [EMA] Epoch 106.[Train] time:596.7820012569427 seconds, lr:0.0102, train_loss: 0.4344, unlabeled_losses_real_strong:0.4008,corrrect_unlabeled_num:415095.0,pro_above_threshold_num:423914.0,unlabelled_weak_top1_acc:94.97179205715656,unlabelled_weak_top5_acc:99.82583226263523  \n","[2022-04-19 21:30:46,414][experiments.experiment][INFO] - [EMA] Epoch 106. [Validation] raw_testing_loss: 0.2196, raw test Top1 acc:93.8, raw test Top5 acc: 99.92, ema_testing_loss: 0.1931, ema test Top1 acc:94.96, ema test Top5 acc: 99.94\n","[2022-04-19 21:30:46,415][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 21:40:41,605][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 107: use 595.2978739738464 seconds\n","--- Optimizer learning rate changed from 1.02e-02 to 9.83e-03 ---\n","[2022-04-19 21:40:41,713][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 21:40:43,485][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 21:40:43,486][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 21:40:45,208][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 21:40:45,210][experiments.experiment][INFO] - [EMA] Epoch 107.[Train] time:595.2978739738464 seconds, lr:0.0098, train_loss: 0.4309, unlabeled_losses_real_strong:0.3985,corrrect_unlabeled_num:416030.0,pro_above_threshold_num:424925.0,unlabelled_weak_top1_acc:95.07053811848164,unlabelled_weak_top5_acc:99.82430644333363  \n","[2022-04-19 21:40:45,212][experiments.experiment][INFO] - [EMA] Epoch 107. [Validation] raw_testing_loss: 0.2310, raw test Top1 acc:93.5, raw test Top5 acc: 99.94, ema_testing_loss: 0.1938, ema test Top1 acc:94.94, ema test Top5 acc: 99.9\n","[2022-04-19 21:40:45,336][experiments.experiment][INFO] - [Checkpoints] Epoch 107, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 21:40:45,344][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 21:50:30,064][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 108: use 584.8323485851288 seconds\n","--- Optimizer learning rate changed from 9.83e-03 to 9.50e-03 ---\n","[2022-04-19 21:50:30,176][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 21:50:31,875][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 21:50:31,875][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 21:50:33,678][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 21:50:33,680][experiments.experiment][INFO] - [EMA] Epoch 108.[Train] time:584.8323485851288 seconds, lr:0.0095, train_loss: 0.4286, unlabeled_losses_real_strong:0.3948,corrrect_unlabeled_num:416249.0,pro_above_threshold_num:425078.0,unlabelled_weak_top1_acc:95.07380799204111,unlabelled_weak_top5_acc:99.83019202202559  \n","[2022-04-19 21:50:33,683][experiments.experiment][INFO] - [EMA] Epoch 108. [Validation] raw_testing_loss: 0.2356, raw test Top1 acc:93.76, raw test Top5 acc: 99.82, ema_testing_loss: 0.1964, ema test Top1 acc:94.76, ema test Top5 acc: 99.92\n","[2022-04-19 21:50:33,684][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 22:00:18,968][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 109: use 585.3919525146484 seconds\n","--- Optimizer learning rate changed from 9.50e-03 to 9.18e-03 ---\n","[2022-04-19 22:00:19,076][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 22:00:20,775][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 22:00:20,776][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 22:00:22,572][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 22:00:22,575][experiments.experiment][INFO] - [EMA] Epoch 109.[Train] time:585.3919525146484 seconds, lr:0.0092, train_loss: 0.4237, unlabeled_losses_real_strong:0.3901,corrrect_unlabeled_num:416957.0,pro_above_threshold_num:425810.0,unlabelled_weak_top1_acc:95.1154425740242,unlabelled_weak_top5_acc:99.82278051972389  \n","[2022-04-19 22:00:22,577][experiments.experiment][INFO] - [EMA] Epoch 109. [Validation] raw_testing_loss: 0.2451, raw test Top1 acc:92.86, raw test Top5 acc: 99.88, ema_testing_loss: 0.1953, ema test Top1 acc:95.0, ema test Top5 acc: 99.94\n","[2022-04-19 22:00:22,697][experiments.experiment][INFO] - [Checkpoints] Epoch 109, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 22:00:22,707][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 22:10:07,966][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 110: use 585.3684849739075 seconds\n","--- Optimizer learning rate changed from 9.18e-03 to 8.85e-03 ---\n","[2022-04-19 22:10:08,075][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 22:10:09,862][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 22:10:09,862][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 22:10:11,596][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 22:10:11,597][experiments.experiment][INFO] - [EMA] Epoch 110.[Train] time:585.3684849739075 seconds, lr:0.0088, train_loss: 0.4241, unlabeled_losses_real_strong:0.3907,corrrect_unlabeled_num:417308.0,pro_above_threshold_num:426265.0,unlabelled_weak_top1_acc:95.17059208452702,unlabelled_weak_top5_acc:99.82888409495354  \n","[2022-04-19 22:10:11,601][experiments.experiment][INFO] - [EMA] Epoch 110. [Validation] raw_testing_loss: 0.2574, raw test Top1 acc:92.96, raw test Top5 acc: 99.84, ema_testing_loss: 0.1955, ema test Top1 acc:94.92, ema test Top5 acc: 99.94\n","[2022-04-19 22:10:11,602][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 22:20:00,849][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 111: use 589.3540396690369 seconds\n","--- Optimizer learning rate changed from 8.85e-03 to 8.52e-03 ---\n","[2022-04-19 22:20:00,956][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 22:20:02,684][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 22:20:02,684][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 22:20:04,438][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 22:20:04,440][experiments.experiment][INFO] - [EMA] Epoch 111.[Train] time:589.3540396690369 seconds, lr:0.0085, train_loss: 0.4159, unlabeled_losses_real_strong:0.3843,corrrect_unlabeled_num:417707.0,pro_above_threshold_num:426642.0,unlabelled_weak_top1_acc:95.17931148409843,unlabelled_weak_top5_acc:99.84065511077642  \n","[2022-04-19 22:20:04,442][experiments.experiment][INFO] - [EMA] Epoch 111. [Validation] raw_testing_loss: 0.2495, raw test Top1 acc:93.46, raw test Top5 acc: 99.86, ema_testing_loss: 0.1931, ema test Top1 acc:94.86, ema test Top5 acc: 99.94\n","[2022-04-19 22:20:04,561][experiments.experiment][INFO] - [Checkpoints] Epoch 111, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 22:20:04,564][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 22:29:50,283][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 112: use 585.8246042728424 seconds\n","--- Optimizer learning rate changed from 8.52e-03 to 8.19e-03 ---\n","[2022-04-19 22:29:50,389][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 22:29:52,181][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 22:29:52,181][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 22:29:53,932][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 22:29:53,934][experiments.experiment][INFO] - [EMA] Epoch 112.[Train] time:585.8246042728424 seconds, lr:0.0082, train_loss: 0.4114, unlabeled_losses_real_strong:0.3818,corrrect_unlabeled_num:418263.0,pro_above_threshold_num:427294.0,unlabelled_weak_top1_acc:95.2196382805705,unlabelled_weak_top5_acc:99.82256259769201  \n","[2022-04-19 22:29:53,937][experiments.experiment][INFO] - [EMA] Epoch 112. [Validation] raw_testing_loss: 0.2196, raw test Top1 acc:93.84, raw test Top5 acc: 99.76, ema_testing_loss: 0.1942, ema test Top1 acc:95.04, ema test Top5 acc: 99.94\n","[2022-04-19 22:29:53,938][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 22:39:39,496][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 113: use 585.6643273830414 seconds\n","--- Optimizer learning rate changed from 8.19e-03 to 7.86e-03 ---\n","[2022-04-19 22:39:39,602][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 22:39:41,303][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 22:39:41,303][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 22:39:43,054][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 22:39:43,056][experiments.experiment][INFO] - [EMA] Epoch 113.[Train] time:585.6643273830414 seconds, lr:0.0079, train_loss: 0.4117, unlabeled_losses_real_strong:0.3799,corrrect_unlabeled_num:418656.0,pro_above_threshold_num:427748.0,unlabelled_weak_top1_acc:95.24230860173702,unlabelled_weak_top5_acc:99.83673148602247  \n","[2022-04-19 22:39:43,060][experiments.experiment][INFO] - [EMA] Epoch 113. [Validation] raw_testing_loss: 0.2350, raw test Top1 acc:93.36, raw test Top5 acc: 99.86, ema_testing_loss: 0.1922, ema test Top1 acc:95.04, ema test Top5 acc: 99.96\n","[2022-04-19 22:39:43,199][experiments.experiment][INFO] - [Checkpoints] Epoch 113, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 22:39:43,203][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 22:50:01,686][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 114: use 618.6143054962158 seconds\n","--- Optimizer learning rate changed from 7.86e-03 to 7.53e-03 ---\n","[2022-04-19 22:50:01,817][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 22:50:03,672][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 22:50:03,673][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 22:50:05,546][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 22:50:05,548][experiments.experiment][INFO] - [EMA] Epoch 114.[Train] time:618.6143054962158 seconds, lr:0.0075, train_loss: 0.4051, unlabeled_losses_real_strong:0.3755,corrrect_unlabeled_num:419244.0,pro_above_threshold_num:428427.0,unlabelled_weak_top1_acc:95.24862992018461,unlabelled_weak_top5_acc:99.83128193765879  \n","[2022-04-19 22:50:05,550][experiments.experiment][INFO] - [EMA] Epoch 114. [Validation] raw_testing_loss: 0.2176, raw test Top1 acc:93.7, raw test Top5 acc: 99.94, ema_testing_loss: 0.1906, ema test Top1 acc:95.16, ema test Top5 acc: 99.92\n","[2022-04-19 22:50:05,551][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 23:00:07,031][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 115: use 601.5944464206696 seconds\n","--- Optimizer learning rate changed from 7.53e-03 to 7.19e-03 ---\n","[2022-04-19 23:00:07,145][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 23:00:08,988][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 23:00:08,989][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 23:00:10,810][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 23:00:10,813][experiments.experiment][INFO] - [EMA] Epoch 115.[Train] time:601.5944464206696 seconds, lr:0.0072, train_loss: 0.3972, unlabeled_losses_real_strong:0.3725,corrrect_unlabeled_num:420005.0,pro_above_threshold_num:429257.0,unlabelled_weak_top1_acc:95.30465161055326,unlabelled_weak_top5_acc:99.83694944530725  \n","[2022-04-19 23:00:10,817][experiments.experiment][INFO] - [EMA] Epoch 115. [Validation] raw_testing_loss: 0.2176, raw test Top1 acc:94.12, raw test Top5 acc: 99.88, ema_testing_loss: 0.1899, ema test Top1 acc:95.0, ema test Top5 acc: 99.92\n","[2022-04-19 23:00:10,939][experiments.experiment][INFO] - [Checkpoints] Epoch 115, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 23:00:10,941][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 23:10:15,399][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 116: use 604.5787837505341 seconds\n","--- Optimizer learning rate changed from 7.19e-03 to 6.86e-03 ---\n","[2022-04-19 23:10:15,520][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 23:10:17,420][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 23:10:17,420][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 23:10:19,319][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 23:10:19,321][experiments.experiment][INFO] - [EMA] Epoch 116.[Train] time:604.5787837505341 seconds, lr:0.0069, train_loss: 0.3977, unlabeled_losses_real_strong:0.3690,corrrect_unlabeled_num:420835.0,pro_above_threshold_num:430066.0,unlabelled_weak_top1_acc:95.37505984306335,unlabelled_weak_top5_acc:99.8251783773303  \n","[2022-04-19 23:10:19,326][experiments.experiment][INFO] - [EMA] Epoch 116. [Validation] raw_testing_loss: 0.2175, raw test Top1 acc:93.84, raw test Top5 acc: 99.88, ema_testing_loss: 0.1909, ema test Top1 acc:94.86, ema test Top5 acc: 99.94\n","[2022-04-19 23:10:19,326][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 23:20:41,081][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 117: use 621.8845393657684 seconds\n","--- Optimizer learning rate changed from 6.86e-03 to 6.53e-03 ---\n","[2022-04-19 23:20:41,211][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 23:20:43,085][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 23:20:43,085][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 23:20:44,987][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 23:20:44,989][experiments.experiment][INFO] - [EMA] Epoch 117.[Train] time:621.8845393657684 seconds, lr:0.0065, train_loss: 0.3931, unlabeled_losses_real_strong:0.3641,corrrect_unlabeled_num:421360.0,pro_above_threshold_num:430655.0,unlabelled_weak_top1_acc:95.42367008328438,unlabelled_weak_top5_acc:99.83564154803753  \n","[2022-04-19 23:20:44,992][experiments.experiment][INFO] - [EMA] Epoch 117. [Validation] raw_testing_loss: 0.2323, raw test Top1 acc:93.56, raw test Top5 acc: 99.86, ema_testing_loss: 0.1857, ema test Top1 acc:95.02, ema test Top5 acc: 99.94\n","[2022-04-19 23:20:45,117][experiments.experiment][INFO] - [Checkpoints] Epoch 117, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","[2022-04-19 23:20:45,119][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 23:30:58,398][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 118: use 613.3934264183044 seconds\n","--- Optimizer learning rate changed from 6.53e-03 to 6.19e-03 ---\n","[2022-04-19 23:30:58,513][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 23:31:00,353][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 23:31:00,353][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 23:31:02,177][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 23:31:02,179][experiments.experiment][INFO] - [EMA] Epoch 118.[Train] time:613.3934264183044 seconds, lr:0.0062, train_loss: 0.3878, unlabeled_losses_real_strong:0.3603,corrrect_unlabeled_num:421928.0,pro_above_threshold_num:431303.0,unlabelled_weak_top1_acc:95.44416044652462,unlabelled_weak_top5_acc:99.82801217585802  \n","[2022-04-19 23:31:02,182][experiments.experiment][INFO] - [EMA] Epoch 118. [Validation] raw_testing_loss: 0.2214, raw test Top1 acc:93.88, raw test Top5 acc: 99.88, ema_testing_loss: 0.1851, ema test Top1 acc:94.98, ema test Top5 acc: 99.9\n","[2022-04-19 23:31:02,183][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-19 23:41:02,415][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 119: use 600.3513991832733 seconds\n","--- Optimizer learning rate changed from 6.19e-03 to 5.85e-03 ---\n","[2022-04-19 23:41:02,535][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 23:41:04,407][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-19 23:41:04,408][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-19 23:41:06,260][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-19 23:41:06,262][experiments.experiment][INFO] - [EMA] Epoch 119.[Train] time:600.3513991832733 seconds, lr:0.0059, train_loss: 0.3845, unlabeled_losses_real_strong:0.3571,corrrect_unlabeled_num:422491.0,pro_above_threshold_num:431910.0,unlabelled_weak_top1_acc:95.47424203157425,unlabelled_weak_top5_acc:99.82387052476406  \n","[2022-04-19 23:41:06,264][experiments.experiment][INFO] - [EMA] Epoch 119. [Validation] raw_testing_loss: 0.1942, raw test Top1 acc:94.62, raw test Top5 acc: 99.84, ema_testing_loss: 0.1814, ema test Top1 acc:95.22, ema test Top5 acc: 99.9\n","[2022-04-19 23:41:06,389][experiments.experiment][INFO] - [Checkpoints] Epoch 119, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_2/FMExperiment.pth.tar\n","======= Training done =======\n","2022-04-19 23:41:06,424 - INFO - Train -   ======= Training done =======\n","[2022-04-19 23:41:06,424][Train][INFO] - ======= Training done =======\n","[2022-04-19 23:41:06,425][experiments.experiment][INFO] - Loading Testing Loader\n","[2022-04-19 23:41:06,436][experiments.experiment][INFO] - [Testing with EMA] apply shadow\n","[2022-04-19 23:41:06,437][experiments.experiment][INFO] - ***** Running testing *****\n","[2022-04-19 23:41:09,719][experiments.experiment][INFO] - [Testing(EMA)] testing_loss: 0.1839, test Top1 acc:95.04, test Top5 acc: 99.9\n","[2022-04-19 23:41:09,727][experiments.experiment][INFO] - [EMA] restore \n","======= Testing done =======\n","2022-04-19 23:41:09,727 - INFO - Train -   ======= Testing done =======\n","[2022-04-19 23:41:09,727][Train][INFO] - ======= Testing done =======\n"]}]}]}