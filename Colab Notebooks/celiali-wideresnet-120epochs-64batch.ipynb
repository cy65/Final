{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"celiali-wideresnet-120epochs-64batch.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN13BC5D0dw6sl4j8oXLRd8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"FyNjJzTJKwsP","executionInfo":{"status":"ok","timestamp":1650250715230,"user_tz":300,"elapsed":129219,"user":{"displayName":"CM Y","userId":"12660552299343911788"}},"outputId":"84fa15a9-cc2d-4f8f-c858-40cd30dd807b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/celiali\n","augmentations  datasets\t\t\tLICENSE    requirements.txt   run.py\n","checkpoints    experiments\t\tmodels\t   run_load_temp.log  utils\n","config\t       google_requirements.txt\toutputs    run_load_temp.py\n","data\t       __init__.py\t\tREADME.md  run.log\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 2)) (1.0.0)\n","Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 3)) (1.9)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 4)) (0.29.28)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 5)) (1.21.5)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 7)) (4.64.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 8)) (1.4.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 9)) (7.1.2)\n","Collecting torch==1.8.0\n","  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n","\u001b[K     |████████████████████████████████| 735.5 MB 15 kB/s \n","\u001b[?25hCollecting torchvision==0.9.0\n","  Downloading torchvision-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n","\u001b[K     |████████████████████████████████| 17.3 MB 18.1 MB/s \n","\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 12)) (0.10.0+cu111)\n","Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 13)) (0.11.0)\n","Collecting omegaconf\n","  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\n","\u001b[K     |████████████████████████████████| 74 kB 3.8 MB/s \n","\u001b[?25hCollecting hydra\n","  Downloading Hydra-2.5.tar.gz (82 kB)\n","\u001b[K     |████████████████████████████████| 82 kB 304 kB/s \n","\u001b[?25hCollecting hydra-core\n","  Downloading hydra_core-1.1.2-py3-none-any.whl (147 kB)\n","\u001b[K     |████████████████████████████████| 147 kB 67.7 MB/s \n","\u001b[?25hCollecting ignite\n","  Downloading ignite-1.1.0-py2.py3-none-any.whl (4.5 kB)\n","Collecting pytorch-ignite\n","  Downloading pytorch_ignite-0.4.8-py3-none-any.whl (251 kB)\n","\u001b[K     |████████████████████████████████| 251 kB 71.8 MB/s \n","\u001b[?25hCollecting tensorboardX\n","  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 77.5 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 20)) (1.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 21)) (3.2.2)\n","Collecting abel-pytorch\n","  Downloading abel_pytorch-0.0.1-py3-none-any.whl (4.2 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r google_requirements.txt (line 10)) (4.1.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->-r google_requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.1.2)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (57.4.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.14.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.1.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (13.0.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.8.0)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 72.1 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.24.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.6.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.3.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.17.3)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.5.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.1.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.44.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->-r google_requirements.txt (line 6)) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->-r google_requirements.txt (line 6)) (1.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2.23.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.3.6)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.0.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.35.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.2.0)\n","Collecting torchaudio\n","  Downloading torchaudio-0.11.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 40.5 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 51.8 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 63.2 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 57.6 MB/s \n","\u001b[?25h  Downloading torchaudio-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 69.8 MB/s \n","\u001b[?25h  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 51.6 MB/s \n","\u001b[?25h  Downloading torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 59.1 MB/s \n","\u001b[?25h  Downloading torchaudio-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 26.6 MB/s \n","\u001b[?25hCollecting torchtext\n","  Downloading torchtext-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n","\u001b[K     |████████████████████████████████| 10.4 MB 23.2 MB/s \n","\u001b[?25h  Downloading torchtext-0.11.2-cp37-cp37m-manylinux1_x86_64.whl (8.0 MB)\n","\u001b[K     |████████████████████████████████| 8.0 MB 32.5 MB/s \n","\u001b[?25h  Downloading torchtext-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (8.0 MB)\n","\u001b[K     |████████████████████████████████| 8.0 MB 35.1 MB/s \n","\u001b[?25h  Downloading torchtext-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 24.6 MB/s \n","\u001b[?25h  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 20.7 MB/s \n","\u001b[?25h  Downloading torchtext-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 35.4 MB/s \n","\u001b[?25h  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 30.2 MB/s \n","\u001b[?25hCollecting PyYAML>=5.1.0\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 54.3 MB/s \n","\u001b[?25hCollecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 71.2 MB/s \n","\u001b[?25hCollecting importlib-resources<5.3\n","  Downloading importlib_resources-5.2.3-py3-none-any.whl (27 kB)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r google_requirements.txt (line 20)) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r google_requirements.txt (line 20)) (3.1.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (1.4.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (3.0.8)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (0.11.0)\n","Building wheels for collected packages: antlr4-python3-runtime, hydra\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=002131dc304e8b39562edc7a05a8b8d041a1ad1962198d041ae37cd84f7f0eaa\n","  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n","  Building wheel for hydra (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hydra: filename=Hydra-2.5-cp37-cp37m-linux_x86_64.whl size=220768 sha256=f1a0dc8c59a9121475af4c285b3596cefe7e149982217249babb59709c281c1c\n","  Stored in directory: /root/.cache/pip/wheels/46/28/7d/3b38a41d900da90c4e17576f442bac9344eb1f5a4e78ee9f83\n","Successfully built antlr4-python3-runtime hydra\n","Installing collected packages: PyYAML, antlr4-python3-runtime, torch, tf-estimator-nightly, omegaconf, importlib-resources, torchvision, torchtext, torchaudio, tensorboardX, pytorch-ignite, ignite, hydra-core, hydra, abel-pytorch\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","  Attempting uninstall: importlib-resources\n","    Found existing installation: importlib-resources 5.6.0\n","    Uninstalling importlib-resources-5.6.0:\n","      Successfully uninstalled importlib-resources-5.6.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.11.1+cu111\n","    Uninstalling torchvision-0.11.1+cu111:\n","      Successfully uninstalled torchvision-0.11.1+cu111\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.11.0\n","    Uninstalling torchtext-0.11.0:\n","      Successfully uninstalled torchtext-0.11.0\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.10.0+cu111\n","    Uninstalling torchaudio-0.10.0+cu111:\n","      Successfully uninstalled torchaudio-0.10.0+cu111\n","Successfully installed PyYAML-6.0 abel-pytorch-0.0.1 antlr4-python3-runtime-4.8 hydra-2.5 hydra-core-1.1.2 ignite-1.1.0 importlib-resources-5.2.3 omegaconf-2.1.2 pytorch-ignite-0.4.8 tensorboardX-2.5 tf-estimator-nightly-2.8.0.dev2021122109 torch-1.8.0 torchaudio-0.8.0 torchtext-0.9.0 torchvision-0.9.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{}}],"source":["# Mount into drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","# Change directory to the package folder\n","%cd '/content/drive/MyDrive/celiali'\n","# Verify the contents of the current folder\n","!ls\n","requirements = \"\"\"\n","absl-py\n","easydict\n","cython\n","numpy\n","tensorflow\n","tqdm\n","scipy\n","pillow\n","torch==1.8.0\n","torchvision==0.9.0\n","torchaudio\n","torchtext\n","omegaconf\n","hydra\n","hydra-core\n","ignite\n","pytorch-ignite\n","tensorboardX\n","scikit-learn\n","matplotlib\n","abel-pytorch\n","\"\"\"\n","\n","with open(\"google_requirements.txt\", 'w') as txt_file:\n","  txt_file.write(requirements)\n","%pip install -r google_requirements.txt"]},{"cell_type":"code","source":["!python run.py DATASET.label_num=4000 DATASET.strongaugment='RA' EXPERIMENT.epoch_n=120 EXPERIMENT.batch_size=64 MODEL.name='WideResNet_Lk' MODEL.depth=28 MODEL.widen_factor=2 MODEL.num_classes=10 EXPERIMENT.out_model='./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch/' EXPERIMENT.log_path='./outputs/outputs_celiali-wideresnet-120epochs-64batch/' EXPERIMENT.decay_type='cosine'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wJ9dH-WiLETC","outputId":"426c7979-37d8-4544-8800-241fb051a6c5","executionInfo":{"status":"ok","timestamp":1650200339706,"user_tz":300,"elapsed":1502692,"user":{"displayName":"CM Y","userId":"12660552299343911788"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==> CONFIG is: \n"," DATASET:\n","  project_dir: ./\n","  data_dir: data\n","  loading_data: LOAD_LABEL_UNLABEL\n","  dataset: CIFAR10\n","  strongaugment: RA\n","  label_num: 4000\n","  num_expand_x: 65536\n","  mu: 7\n","  barely: false\n","  add_noisy_label: false\n","  both_strong: false\n","MODEL:\n","  name: WideResNet_Lk\n","  depth: 28\n","  widen_factor: 2\n","  num_classes: 10\n","  dropout: 0.0\n","  cardinality: 4\n","  width: 4\n","  base_width: 4\n","EXPERIMENT:\n","  name: FMExperiment\n","  out_model: ./checkpoints_celiali-wideresnet-120epochs-64batch/\n","  log_path: ./outputs_celiali-wideresnet-120epochs-64batch/\n","  used_gpu: true\n","  optim_lr: 0.03\n","  optim_momentum: 0.9\n","  used_nesterov: true\n","  warmup: 0\n","  wdecay: 0.0005\n","  clip: 1\n","  ema_used: true\n","  ema_decay: 0.999\n","  threshold: 0.95\n","  lambda_unlabeled: 1\n","  batch_size: 64\n","  num_workers: 4\n","  n_imgs_per_epoch: 65536\n","  epoch_n: 120\n","  save_every: 64\n","  save_matrix_every: 100\n","  resume: false\n","  resume_checkpoints: ./checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar\n","  save_cfmatrix: true\n","  batch_balanced: false\n","  neg_penalty: false\n","  equal_freq: false\n","  eta_negpenalty: 0.05\n","  eta_dynamic: false\n","  use_nlloss: false\n","  q: 0.0001\n","Logging:\n","  name: FM\n","  seed: 1265\n"," \n","\n","2022-04-16 22:06:04,865 - INFO - Train -   {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints_celiali-wideresnet-120epochs-64batch/', 'log_path': './outputs_celiali-wideresnet-120epochs-64batch/', 'used_gpu': True, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 1, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 64, 'save_matrix_every': 100, 'resume': False, 'resume_checkpoints': './checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar', 'save_cfmatrix': True, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","[2022-04-16 22:06:04,865][Train][INFO] - {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints_celiali-wideresnet-120epochs-64batch/', 'log_path': './outputs_celiali-wideresnet-120epochs-64batch/', 'used_gpu': True, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 1, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 64, 'save_matrix_every': 100, 'resume': False, 'resume_checkpoints': './checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar', 'save_cfmatrix': True, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","2022-04-16 22:06:05,147 - INFO - Train -   [Model] Building model WideResNet_Lk\n","[2022-04-16 22:06:05,147][Train][INFO] - [Model] Building model WideResNet_Lk\n","2022-04-16 22:06:07,944 - INFO - Train -   Total params: 1.47M\n","[2022-04-16 22:06:07,944][Train][INFO] - Total params: 1.47M\n","[2022-04-16 22:06:07,951][experiments.experiment][INFO] - [EMA] initial \n","[2022-04-16 22:06:09,425][datasets.datasets1][INFO] - Dataset: CIFAR10\n","[2022-04-16 22:06:09,463][datasets.datasets1][INFO] - Labeled examples: 65536 Unlabeled examples: 458752Validation examples: 5000\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-16 22:06:09,464][experiments.experiment][INFO] - Loading Labelled Loader\n","[2022-04-16 22:06:09,465][experiments.experiment][INFO] - Loading Unlabelled Loader\n","[2022-04-16 22:06:09,465][experiments.experiment][INFO] - Loading Validation Loader\n","[2022-04-16 22:06:09,471][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 22:13:37,546][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 0: use 448.1758463382721 seconds\n","--- Optimizer learning rate changed from inf to 3.00e-02 ---\n","[2022-04-16 22:13:37,646][experiments.experiment][INFO] - ***** Running validation *****\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-16 22:13:39,056][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 22:13:39,057][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 22:13:40,483][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 22:13:40,562][experiments.experiment][INFO] - [EMA] Epoch 0.[Train] time:448.1758463382721 seconds, lr:0.0300, train_loss: 1.2566, unlabeled_losses_real_strong:2.0060,corrrect_unlabeled_num:22387.0,pro_above_threshold_num:23635.0,unlabelled_weak_top1_acc:51.07618001755327,unlabelled_weak_top5_acc:92.7871693558991  \n","[2022-04-16 22:13:40,562][experiments.experiment][INFO] - [EMA] Epoch 0. [Validation] raw_testing_loss: 1.5782, raw test Top1 acc:44.66, raw test Top5 acc: 91.78, ema_testing_loss: 1.5949, ema test Top1 acc:46.92, ema test Top5 acc: 91.86\n","[2022-04-16 22:13:40,681][experiments.experiment][INFO] - [Checkpoints] Epoch 0, saving to ./checkpoints_celiali-wideresnet-120epochs-64batch/FMExperiment_epoch_0.pth.tar\n","[2022-04-16 22:13:40,681][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 22:21:09,722][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 1: use 449.1459994316101 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-16 22:21:09,828][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 22:21:11,231][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 22:21:11,232][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 22:21:12,653][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 22:21:12,655][experiments.experiment][INFO] - [EMA] Epoch 1.[Train] time:449.1459994316101 seconds, lr:0.0300, train_loss: 0.8507, unlabeled_losses_real_strong:1.8131,corrrect_unlabeled_num:108140.0,pro_above_threshold_num:114816.0,unlabelled_weak_top1_acc:64.68571170791984,unlabelled_weak_top5_acc:96.54649892449379  \n","[2022-04-16 22:21:12,656][experiments.experiment][INFO] - [EMA] Epoch 1. [Validation] raw_testing_loss: 2.9676, raw test Top1 acc:21.2, raw test Top5 acc: 75.12, ema_testing_loss: 1.0389, ema test Top1 acc:63.34, ema test Top5 acc: 96.34\n","[2022-04-16 22:21:12,657][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 22:28:40,825][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 2: use 448.26098442077637 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-16 22:28:40,918][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 22:28:42,342][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 22:28:42,343][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 22:28:43,681][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 22:28:43,683][experiments.experiment][INFO] - [EMA] Epoch 2.[Train] time:448.26098442077637 seconds, lr:0.0300, train_loss: 0.7097, unlabeled_losses_real_strong:1.6157,corrrect_unlabeled_num:171531.0,pro_above_threshold_num:185131.0,unlabelled_weak_top1_acc:69.59664373844862,unlabelled_weak_top5_acc:97.36524198949337  \n","[2022-04-16 22:28:43,684][experiments.experiment][INFO] - [EMA] Epoch 2. [Validation] raw_testing_loss: 3.0746, raw test Top1 acc:25.14, raw test Top5 acc: 74.84, ema_testing_loss: 0.8751, ema test Top1 acc:70.02, ema test Top5 acc: 97.72\n","[2022-04-16 22:28:43,686][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 22:36:12,030][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 3: use 448.44015169143677 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-16 22:36:12,126][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 22:36:13,563][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 22:36:13,564][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 22:36:14,952][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 22:36:14,954][experiments.experiment][INFO] - [EMA] Epoch 3.[Train] time:448.44015169143677 seconds, lr:0.0300, train_loss: 0.6341, unlabeled_losses_real_strong:1.4566,corrrect_unlabeled_num:215849.0,pro_above_threshold_num:234077.0,unlabelled_weak_top1_acc:73.36011508852243,unlabelled_weak_top5_acc:97.88469485193491  \n","[2022-04-16 22:36:14,955][experiments.experiment][INFO] - [EMA] Epoch 3. [Validation] raw_testing_loss: 2.2326, raw test Top1 acc:33.38, raw test Top5 acc: 87.68, ema_testing_loss: 0.8170, ema test Top1 acc:73.7, ema test Top5 acc: 98.22\n","[2022-04-16 22:36:14,956][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 22:43:41,773][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 4: use 446.9177072048187 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-16 22:43:41,874][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 22:43:43,277][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 22:43:43,277][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 22:43:44,682][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 22:43:44,683][experiments.experiment][INFO] - [EMA] Epoch 4.[Train] time:446.9177072048187 seconds, lr:0.0300, train_loss: 0.5914, unlabeled_losses_real_strong:1.3559,corrrect_unlabeled_num:241594.0,pro_above_threshold_num:261424.0,unlabelled_weak_top1_acc:75.76642606407404,unlabelled_weak_top5_acc:98.23630095273256  \n","[2022-04-16 22:43:44,686][experiments.experiment][INFO] - [EMA] Epoch 4. [Validation] raw_testing_loss: 2.1052, raw test Top1 acc:47.78, raw test Top5 acc: 88.6, ema_testing_loss: 0.7641, ema test Top1 acc:77.24, ema test Top5 acc: 98.66\n","[2022-04-16 22:43:44,687][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 22:51:12,730][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 5: use 448.1417360305786 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 2.99e-02 ---\n","[2022-04-16 22:51:12,828][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 22:51:14,220][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 22:51:14,221][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 22:51:15,567][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 22:51:15,568][experiments.experiment][INFO] - [EMA] Epoch 5.[Train] time:448.1417360305786 seconds, lr:0.0299, train_loss: 0.5547, unlabeled_losses_real_strong:1.2585,corrrect_unlabeled_num:261305.0,pro_above_threshold_num:281240.0,unlabelled_weak_top1_acc:77.8832561224699,unlabelled_weak_top5_acc:98.45689949393272  \n","[2022-04-16 22:51:15,571][experiments.experiment][INFO] - [EMA] Epoch 5. [Validation] raw_testing_loss: 1.9115, raw test Top1 acc:50.0, raw test Top5 acc: 93.42, ema_testing_loss: 0.7278, ema test Top1 acc:79.46, ema test Top5 acc: 98.92\n","[2022-04-16 22:51:15,572][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 22:58:42,799][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 6: use 447.33053255081177 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.99e-02 ---\n","[2022-04-16 22:58:42,903][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 22:58:44,314][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 22:58:44,314][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 22:58:45,712][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 22:58:45,713][experiments.experiment][INFO] - [EMA] Epoch 6.[Train] time:447.33053255081177 seconds, lr:0.0299, train_loss: 0.5209, unlabeled_losses_real_strong:1.1803,corrrect_unlabeled_num:277626.0,pro_above_threshold_num:297301.0,unlabelled_weak_top1_acc:79.70559151470661,unlabelled_weak_top5_acc:98.66354679316282  \n","[2022-04-16 22:58:45,715][experiments.experiment][INFO] - [EMA] Epoch 6. [Validation] raw_testing_loss: 2.4241, raw test Top1 acc:45.38, raw test Top5 acc: 93.7, ema_testing_loss: 0.6846, ema test Top1 acc:81.18, ema test Top5 acc: 99.0\n","[2022-04-16 22:58:45,716][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 23:06:11,479][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 7: use 445.8553874492645 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.99e-02 ---\n","[2022-04-16 23:06:11,572][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:06:12,943][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 23:06:12,943][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:06:14,283][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 23:06:14,285][experiments.experiment][INFO] - [EMA] Epoch 7.[Train] time:445.8553874492645 seconds, lr:0.0299, train_loss: 0.4981, unlabeled_losses_real_strong:1.1183,corrrect_unlabeled_num:288417.0,pro_above_threshold_num:307459.0,unlabelled_weak_top1_acc:80.96880117058754,unlabelled_weak_top5_acc:98.79782393574715  \n","[2022-04-16 23:06:14,286][experiments.experiment][INFO] - [EMA] Epoch 7. [Validation] raw_testing_loss: 1.8370, raw test Top1 acc:56.86, raw test Top5 acc: 95.92, ema_testing_loss: 0.6496, ema test Top1 acc:82.92, ema test Top5 acc: 99.12\n","[2022-04-16 23:06:14,287][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 23:13:35,705][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 8: use 441.5113558769226 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.98e-02 ---\n","[2022-04-16 23:13:35,799][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:13:37,149][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 23:13:37,150][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:13:38,487][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 23:13:38,488][experiments.experiment][INFO] - [EMA] Epoch 8.[Train] time:441.5113558769226 seconds, lr:0.0298, train_loss: 0.4765, unlabeled_losses_real_strong:1.0684,corrrect_unlabeled_num:298119.0,pro_above_threshold_num:316611.0,unlabelled_weak_top1_acc:81.99157614260912,unlabelled_weak_top5_acc:98.93275513499975  \n","[2022-04-16 23:13:38,490][experiments.experiment][INFO] - [EMA] Epoch 8. [Validation] raw_testing_loss: 0.7308, raw test Top1 acc:76.46, raw test Top5 acc: 98.66, ema_testing_loss: 0.6057, ema test Top1 acc:84.26, ema test Top5 acc: 99.14\n","[2022-04-16 23:13:38,491][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 23:21:00,868][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 9: use 442.4813024997711 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.98e-02 ---\n","[2022-04-16 23:21:00,973][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:21:02,319][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 23:21:02,319][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:21:03,665][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 23:21:03,666][experiments.experiment][INFO] - [EMA] Epoch 9.[Train] time:442.4813024997711 seconds, lr:0.0298, train_loss: 0.4592, unlabeled_losses_real_strong:1.0181,corrrect_unlabeled_num:306729.0,pro_above_threshold_num:324709.0,unlabelled_weak_top1_acc:83.02525006979704,unlabelled_weak_top5_acc:99.0073052868247  \n","[2022-04-16 23:21:03,668][experiments.experiment][INFO] - [EMA] Epoch 9. [Validation] raw_testing_loss: 1.5818, raw test Top1 acc:61.54, raw test Top5 acc: 94.86, ema_testing_loss: 0.5793, ema test Top1 acc:85.12, ema test Top5 acc: 99.38\n","[2022-04-16 23:21:03,670][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 23:28:25,134][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 10: use 441.57298827171326 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.98e-02 ---\n","[2022-04-16 23:28:25,243][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:28:26,578][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 23:28:26,578][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:28:27,932][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 23:28:27,933][experiments.experiment][INFO] - [EMA] Epoch 10.[Train] time:441.57298827171326 seconds, lr:0.0298, train_loss: 0.4438, unlabeled_losses_real_strong:0.9842,corrrect_unlabeled_num:313071.0,pro_above_threshold_num:330555.0,unlabelled_weak_top1_acc:83.74066918343306,unlabelled_weak_top5_acc:99.09994791448116  \n","[2022-04-16 23:28:27,934][experiments.experiment][INFO] - [EMA] Epoch 10. [Validation] raw_testing_loss: 0.9949, raw test Top1 acc:73.58, raw test Top5 acc: 97.78, ema_testing_loss: 0.5499, ema test Top1 acc:85.88, ema test Top5 acc: 99.36\n","[2022-04-16 23:28:27,935][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 23:35:49,169][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 11: use 441.3371031284332 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.97e-02 ---\n","[2022-04-16 23:35:49,272][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:35:50,623][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 23:35:50,624][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:35:51,960][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 23:35:51,961][experiments.experiment][INFO] - [EMA] Epoch 11.[Train] time:441.3371031284332 seconds, lr:0.0297, train_loss: 0.4297, unlabeled_losses_real_strong:0.9477,corrrect_unlabeled_num:319850.0,pro_above_threshold_num:336910.0,unlabelled_weak_top1_acc:84.52933054417372,unlabelled_weak_top5_acc:99.14005667716265  \n","[2022-04-16 23:35:51,964][experiments.experiment][INFO] - [EMA] Epoch 11. [Validation] raw_testing_loss: 0.8623, raw test Top1 acc:77.34, raw test Top5 acc: 98.6, ema_testing_loss: 0.5202, ema test Top1 acc:86.46, ema test Top5 acc: 99.42\n","[2022-04-16 23:35:51,965][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 23:43:14,491][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 12: use 442.62079644203186 seconds\n","--- Optimizer learning rate changed from 2.97e-02 to 2.97e-02 ---\n","[2022-04-16 23:43:14,585][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:43:15,940][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 23:43:15,940][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:43:17,308][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 23:43:17,309][experiments.experiment][INFO] - [EMA] Epoch 12.[Train] time:442.62079644203186 seconds, lr:0.0297, train_loss: 0.4161, unlabeled_losses_real_strong:0.9151,corrrect_unlabeled_num:325115.0,pro_above_threshold_num:341358.0,unlabelled_weak_top1_acc:85.22382359951735,unlabelled_weak_top5_acc:99.20022002607584  \n","[2022-04-16 23:43:17,312][experiments.experiment][INFO] - [EMA] Epoch 12. [Validation] raw_testing_loss: 1.1551, raw test Top1 acc:74.62, raw test Top5 acc: 97.9, ema_testing_loss: 0.4953, ema test Top1 acc:87.26, ema test Top5 acc: 99.54\n","[2022-04-16 23:43:17,312][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 23:50:39,938][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 13: use 442.7248156070709 seconds\n","--- Optimizer learning rate changed from 2.97e-02 to 2.96e-02 ---\n","[2022-04-16 23:50:40,037][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:50:41,421][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 23:50:41,421][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:50:42,783][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 23:50:42,785][experiments.experiment][INFO] - [EMA] Epoch 13.[Train] time:442.7248156070709 seconds, lr:0.0296, train_loss: 0.4041, unlabeled_losses_real_strong:0.8865,corrrect_unlabeled_num:330550.0,pro_above_threshold_num:346640.0,unlabelled_weak_top1_acc:85.77640973776579,unlabelled_weak_top5_acc:99.22289031744003  \n","[2022-04-16 23:50:42,786][experiments.experiment][INFO] - [EMA] Epoch 13. [Validation] raw_testing_loss: 0.6996, raw test Top1 acc:80.78, raw test Top5 acc: 99.1, ema_testing_loss: 0.4863, ema test Top1 acc:87.58, ema test Top5 acc: 99.5\n","[2022-04-16 23:50:42,787][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 23:58:07,062][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 14: use 444.3679687976837 seconds\n","--- Optimizer learning rate changed from 2.96e-02 to 2.96e-02 ---\n","[2022-04-16 23:58:07,155][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:58:08,515][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 23:58:08,516][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:58:09,851][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 23:58:09,853][experiments.experiment][INFO] - [EMA] Epoch 14.[Train] time:444.3679687976837 seconds, lr:0.0296, train_loss: 0.3940, unlabeled_losses_real_strong:0.8612,corrrect_unlabeled_num:335516.0,pro_above_threshold_num:351190.0,unlabelled_weak_top1_acc:86.31853276491165,unlabelled_weak_top5_acc:99.28261752426624  \n","[2022-04-16 23:58:09,856][experiments.experiment][INFO] - [EMA] Epoch 14. [Validation] raw_testing_loss: 0.7100, raw test Top1 acc:80.58, raw test Top5 acc: 98.6, ema_testing_loss: 0.4628, ema test Top1 acc:88.18, ema test Top5 acc: 99.58\n","[2022-04-16 23:58:09,856][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 00:05:32,197][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 15: use 442.437059879303 seconds\n","--- Optimizer learning rate changed from 2.96e-02 to 2.95e-02 ---\n","[2022-04-17 00:05:32,293][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:05:33,642][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 00:05:33,642][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:05:34,967][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 00:05:34,969][experiments.experiment][INFO] - [EMA] Epoch 15.[Train] time:442.437059879303 seconds, lr:0.0295, train_loss: 0.3885, unlabeled_losses_real_strong:0.8427,corrrect_unlabeled_num:338347.0,pro_above_threshold_num:353627.0,unlabelled_weak_top1_acc:86.71853099763393,unlabelled_weak_top5_acc:99.33188193291426  \n","[2022-04-17 00:05:34,970][experiments.experiment][INFO] - [EMA] Epoch 15. [Validation] raw_testing_loss: 0.7339, raw test Top1 acc:80.36, raw test Top5 acc: 98.34, ema_testing_loss: 0.4387, ema test Top1 acc:88.58, ema test Top5 acc: 99.6\n","[2022-04-17 00:05:34,971][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 00:12:58,032][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 16: use 443.1654999256134 seconds\n","--- Optimizer learning rate changed from 2.95e-02 to 2.94e-02 ---\n","[2022-04-17 00:12:58,137][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:12:59,479][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 00:12:59,480][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:13:00,847][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 00:13:00,849][experiments.experiment][INFO] - [EMA] Epoch 16.[Train] time:443.1654999256134 seconds, lr:0.0294, train_loss: 0.3815, unlabeled_losses_real_strong:0.8214,corrrect_unlabeled_num:343588.0,pro_above_threshold_num:358620.0,unlabelled_weak_top1_acc:87.2512807995081,unlabelled_weak_top5_acc:99.35825800895691  \n","[2022-04-17 00:13:00,851][experiments.experiment][INFO] - [EMA] Epoch 16. [Validation] raw_testing_loss: 0.6488, raw test Top1 acc:81.84, raw test Top5 acc: 98.34, ema_testing_loss: 0.4324, ema test Top1 acc:89.02, ema test Top5 acc: 99.68\n","[2022-04-17 00:13:00,851][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 00:20:24,329][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 17: use 443.57619071006775 seconds\n","--- Optimizer learning rate changed from 2.94e-02 to 2.94e-02 ---\n","[2022-04-17 00:20:24,428][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:20:25,835][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 00:20:25,836][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:20:27,190][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 00:20:27,191][experiments.experiment][INFO] - [EMA] Epoch 17.[Train] time:443.57619071006775 seconds, lr:0.0294, train_loss: 0.3755, unlabeled_losses_real_strong:0.8052,corrrect_unlabeled_num:346078.0,pro_above_threshold_num:360703.0,unlabelled_weak_top1_acc:87.55514862388372,unlabelled_weak_top5_acc:99.37526046484709  \n","[2022-04-17 00:20:27,193][experiments.experiment][INFO] - [EMA] Epoch 17. [Validation] raw_testing_loss: 0.7041, raw test Top1 acc:82.26, raw test Top5 acc: 99.24, ema_testing_loss: 0.4198, ema test Top1 acc:89.02, ema test Top5 acc: 99.68\n","[2022-04-17 00:20:27,194][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 00:27:49,011][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 18: use 441.91278624534607 seconds\n","--- Optimizer learning rate changed from 2.94e-02 to 2.93e-02 ---\n","[2022-04-17 00:27:49,107][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:27:50,446][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 00:27:50,446][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:27:51,787][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 00:27:51,788][experiments.experiment][INFO] - [EMA] Epoch 18.[Train] time:441.91278624534607 seconds, lr:0.0293, train_loss: 0.3696, unlabeled_losses_real_strong:0.7931,corrrect_unlabeled_num:349296.0,pro_above_threshold_num:363809.0,unlabelled_weak_top1_acc:87.92005151510239,unlabelled_weak_top5_acc:99.36697714030743  \n","[2022-04-17 00:27:51,790][experiments.experiment][INFO] - [EMA] Epoch 18. [Validation] raw_testing_loss: 0.7253, raw test Top1 acc:82.7, raw test Top5 acc: 98.12, ema_testing_loss: 0.4152, ema test Top1 acc:89.5, ema test Top5 acc: 99.74\n","[2022-04-17 00:27:51,792][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 00:35:13,599][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 19: use 441.90587186813354 seconds\n","--- Optimizer learning rate changed from 2.93e-02 to 2.92e-02 ---\n","[2022-04-17 00:35:13,698][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:35:15,049][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 00:35:15,050][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:35:16,392][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 00:35:16,393][experiments.experiment][INFO] - [EMA] Epoch 19.[Train] time:441.90587186813354 seconds, lr:0.0292, train_loss: 0.3633, unlabeled_losses_real_strong:0.7718,corrrect_unlabeled_num:351555.0,pro_above_threshold_num:365840.0,unlabelled_weak_top1_acc:88.23678034543991,unlabelled_weak_top5_acc:99.42823059856892  \n","[2022-04-17 00:35:16,394][experiments.experiment][INFO] - [EMA] Epoch 19. [Validation] raw_testing_loss: 0.8009, raw test Top1 acc:80.8, raw test Top5 acc: 98.42, ema_testing_loss: 0.3987, ema test Top1 acc:89.84, ema test Top5 acc: 99.74\n","[2022-04-17 00:35:16,395][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 00:42:38,145][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 20: use 441.85075283050537 seconds\n","--- Optimizer learning rate changed from 2.92e-02 to 2.91e-02 ---\n","[2022-04-17 00:42:38,246][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:42:39,588][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 00:42:39,589][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:42:40,976][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 00:42:40,978][experiments.experiment][INFO] - [EMA] Epoch 20.[Train] time:441.85075283050537 seconds, lr:0.0291, train_loss: 0.3596, unlabeled_losses_real_strong:0.7629,corrrect_unlabeled_num:354001.0,pro_above_threshold_num:367622.0,unlabelled_weak_top1_acc:88.54805983603,unlabelled_weak_top5_acc:99.43280825018883  \n","[2022-04-17 00:42:40,980][experiments.experiment][INFO] - [EMA] Epoch 20. [Validation] raw_testing_loss: 0.6215, raw test Top1 acc:83.9, raw test Top5 acc: 98.58, ema_testing_loss: 0.3866, ema test Top1 acc:90.22, ema test Top5 acc: 99.74\n","[2022-04-17 00:42:40,981][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 00:50:01,281][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 21: use 440.3958971500397 seconds\n","--- Optimizer learning rate changed from 2.91e-02 to 2.91e-02 ---\n","[2022-04-17 00:50:01,377][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:50:02,760][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 00:50:02,760][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:50:04,088][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 00:50:04,089][experiments.experiment][INFO] - [EMA] Epoch 21.[Train] time:440.3958971500397 seconds, lr:0.0291, train_loss: 0.3555, unlabeled_losses_real_strong:0.7487,corrrect_unlabeled_num:356368.0,pro_above_threshold_num:369913.0,unlabelled_weak_top1_acc:88.7723638266325,unlabelled_weak_top5_acc:99.4347700253129  \n","[2022-04-17 00:50:04,091][experiments.experiment][INFO] - [EMA] Epoch 21. [Validation] raw_testing_loss: 0.7533, raw test Top1 acc:81.7, raw test Top5 acc: 99.06, ema_testing_loss: 0.3804, ema test Top1 acc:90.42, ema test Top5 acc: 99.74\n","[2022-04-17 00:50:04,092][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 00:57:25,718][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 22: use 441.7320306301117 seconds\n","--- Optimizer learning rate changed from 2.91e-02 to 2.90e-02 ---\n","[2022-04-17 00:57:25,824][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:57:27,168][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 00:57:27,168][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:57:28,536][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 00:57:28,538][experiments.experiment][INFO] - [EMA] Epoch 22.[Train] time:441.7320306301117 seconds, lr:0.0290, train_loss: 0.3525, unlabeled_losses_real_strong:0.7375,corrrect_unlabeled_num:358217.0,pro_above_threshold_num:371359.0,unlabelled_weak_top1_acc:88.96506073325872,unlabelled_weak_top5_acc:99.47531492263079  \n","[2022-04-17 00:57:28,540][experiments.experiment][INFO] - [EMA] Epoch 22. [Validation] raw_testing_loss: 1.1859, raw test Top1 acc:72.8, raw test Top5 acc: 98.64, ema_testing_loss: 0.3708, ema test Top1 acc:90.66, ema test Top5 acc: 99.72\n","[2022-04-17 00:57:28,541][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 01:04:53,659][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 23: use 445.21584916114807 seconds\n","--- Optimizer learning rate changed from 2.90e-02 to 2.89e-02 ---\n","[2022-04-17 01:04:53,757][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:04:55,101][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 01:04:55,101][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:04:56,449][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 01:04:56,451][experiments.experiment][INFO] - [EMA] Epoch 23.[Train] time:445.21584916114807 seconds, lr:0.0289, train_loss: 0.3470, unlabeled_losses_real_strong:0.7271,corrrect_unlabeled_num:360466.0,pro_above_threshold_num:373547.0,unlabelled_weak_top1_acc:89.19045488536358,unlabelled_weak_top5_acc:99.49035590142012  \n","[2022-04-17 01:04:56,453][experiments.experiment][INFO] - [EMA] Epoch 23. [Validation] raw_testing_loss: 0.5535, raw test Top1 acc:84.78, raw test Top5 acc: 99.14, ema_testing_loss: 0.3634, ema test Top1 acc:90.86, ema test Top5 acc: 99.76\n","[2022-04-17 01:04:56,454][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 01:12:18,273][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 24: use 441.91323494911194 seconds\n","--- Optimizer learning rate changed from 2.89e-02 to 2.88e-02 ---\n","[2022-04-17 01:12:18,367][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:12:19,719][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 01:12:19,720][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:12:21,074][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 01:12:21,075][experiments.experiment][INFO] - [EMA] Epoch 24.[Train] time:441.91323494911194 seconds, lr:0.0288, train_loss: 0.3436, unlabeled_losses_real_strong:0.7129,corrrect_unlabeled_num:363532.0,pro_above_threshold_num:376460.0,unlabelled_weak_top1_acc:89.56276927888393,unlabelled_weak_top5_acc:99.49820334464312  \n","[2022-04-17 01:12:21,077][experiments.experiment][INFO] - [EMA] Epoch 24. [Validation] raw_testing_loss: 0.5928, raw test Top1 acc:85.9, raw test Top5 acc: 99.36, ema_testing_loss: 0.3513, ema test Top1 acc:91.08, ema test Top5 acc: 99.76\n","[2022-04-17 01:12:21,077][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 01:19:42,815][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 25: use 441.8317105770111 seconds\n","--- Optimizer learning rate changed from 2.88e-02 to 2.87e-02 ---\n","[2022-04-17 01:19:42,909][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:19:44,246][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 01:19:44,246][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:19:45,601][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 01:19:45,602][experiments.experiment][INFO] - [EMA] Epoch 25.[Train] time:441.8317105770111 seconds, lr:0.0287, train_loss: 0.3425, unlabeled_losses_real_strong:0.7055,corrrect_unlabeled_num:364839.0,pro_above_threshold_num:377847.0,unlabelled_weak_top1_acc:89.64582066982985,unlabelled_weak_top5_acc:99.51324409991503  \n","[2022-04-17 01:19:45,605][experiments.experiment][INFO] - [EMA] Epoch 25. [Validation] raw_testing_loss: 0.7060, raw test Top1 acc:82.82, raw test Top5 acc: 98.92, ema_testing_loss: 0.3530, ema test Top1 acc:91.18, ema test Top5 acc: 99.72\n","[2022-04-17 01:19:45,606][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 01:27:07,670][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 26: use 442.1624014377594 seconds\n","--- Optimizer learning rate changed from 2.87e-02 to 2.86e-02 ---\n","[2022-04-17 01:27:07,768][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:27:09,134][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 01:27:09,134][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:27:10,500][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 01:27:10,502][experiments.experiment][INFO] - [EMA] Epoch 26.[Train] time:442.1624014377594 seconds, lr:0.0286, train_loss: 0.3407, unlabeled_losses_real_strong:0.7018,corrrect_unlabeled_num:365617.0,pro_above_threshold_num:378225.0,unlabelled_weak_top1_acc:89.80690982192755,unlabelled_weak_top5_acc:99.5230533927679  \n","[2022-04-17 01:27:10,503][experiments.experiment][INFO] - [EMA] Epoch 26. [Validation] raw_testing_loss: 0.5364, raw test Top1 acc:86.64, raw test Top5 acc: 99.38, ema_testing_loss: 0.3500, ema test Top1 acc:91.06, ema test Top5 acc: 99.72\n","[2022-04-17 01:27:10,504][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 01:34:32,197][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 27: use 441.78674817085266 seconds\n","--- Optimizer learning rate changed from 2.86e-02 to 2.85e-02 ---\n","[2022-04-17 01:34:32,291][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:34:33,678][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 01:34:33,679][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:34:35,027][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 01:34:35,029][experiments.experiment][INFO] - [EMA] Epoch 27.[Train] time:441.78674817085266 seconds, lr:0.0285, train_loss: 0.3366, unlabeled_losses_real_strong:0.6928,corrrect_unlabeled_num:367060.0,pro_above_threshold_num:379666.0,unlabelled_weak_top1_acc:89.97824411839247,unlabelled_weak_top5_acc:99.54071016609669  \n","[2022-04-17 01:34:35,032][experiments.experiment][INFO] - [EMA] Epoch 27. [Validation] raw_testing_loss: 0.5071, raw test Top1 acc:86.1, raw test Top5 acc: 98.82, ema_testing_loss: 0.3422, ema test Top1 acc:91.16, ema test Top5 acc: 99.76\n","[2022-04-17 01:34:35,033][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 01:41:56,193][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 28: use 441.2567329406738 seconds\n","--- Optimizer learning rate changed from 2.85e-02 to 2.84e-02 ---\n","[2022-04-17 01:41:56,290][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:41:57,630][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 01:41:57,630][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:41:58,979][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 01:41:58,981][experiments.experiment][INFO] - [EMA] Epoch 28.[Train] time:441.2567329406738 seconds, lr:0.0284, train_loss: 0.3309, unlabeled_losses_real_strong:0.6818,corrrect_unlabeled_num:369377.0,pro_above_threshold_num:381646.0,unlabelled_weak_top1_acc:90.22042299807072,unlabelled_weak_top5_acc:99.5365684852004  \n","[2022-04-17 01:41:58,984][experiments.experiment][INFO] - [EMA] Epoch 28. [Validation] raw_testing_loss: 0.5387, raw test Top1 acc:86.24, raw test Top5 acc: 99.08, ema_testing_loss: 0.3332, ema test Top1 acc:91.24, ema test Top5 acc: 99.74\n","[2022-04-17 01:41:58,984][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 01:49:22,427][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 29: use 443.5511968135834 seconds\n","--- Optimizer learning rate changed from 2.84e-02 to 2.82e-02 ---\n","[2022-04-17 01:49:22,536][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:49:23,940][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 01:49:23,941][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:49:25,329][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 01:49:25,330][experiments.experiment][INFO] - [EMA] Epoch 29.[Train] time:443.5511968135834 seconds, lr:0.0282, train_loss: 0.3332, unlabeled_losses_real_strong:0.6763,corrrect_unlabeled_num:370008.0,pro_above_threshold_num:382478.0,unlabelled_weak_top1_acc:90.23807960003614,unlabelled_weak_top5_acc:99.54332596063614  \n","[2022-04-17 01:49:25,333][experiments.experiment][INFO] - [EMA] Epoch 29. [Validation] raw_testing_loss: 0.7836, raw test Top1 acc:81.8, raw test Top5 acc: 98.98, ema_testing_loss: 0.3334, ema test Top1 acc:91.28, ema test Top5 acc: 99.74\n","[2022-04-17 01:49:25,334][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 01:56:45,960][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 30: use 440.72837710380554 seconds\n","--- Optimizer learning rate changed from 2.82e-02 to 2.81e-02 ---\n","[2022-04-17 01:56:46,062][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:56:47,421][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 01:56:47,422][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:56:48,746][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 01:56:48,747][experiments.experiment][INFO] - [EMA] Epoch 30.[Train] time:440.72837710380554 seconds, lr:0.0281, train_loss: 0.3284, unlabeled_losses_real_strong:0.6690,corrrect_unlabeled_num:371355.0,pro_above_threshold_num:383390.0,unlabelled_weak_top1_acc:90.45606243610382,unlabelled_weak_top5_acc:99.54964757710695  \n","[2022-04-17 01:56:48,750][experiments.experiment][INFO] - [EMA] Epoch 30. [Validation] raw_testing_loss: 0.5306, raw test Top1 acc:87.08, raw test Top5 acc: 99.4, ema_testing_loss: 0.3219, ema test Top1 acc:91.68, ema test Top5 acc: 99.74\n","[2022-04-17 01:56:48,750][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 02:04:09,485][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 31: use 440.83124470710754 seconds\n","--- Optimizer learning rate changed from 2.81e-02 to 2.80e-02 ---\n","[2022-04-17 02:04:09,582][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:04:10,939][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 02:04:10,939][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:04:12,282][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 02:04:12,284][experiments.experiment][INFO] - [EMA] Epoch 31.[Train] time:440.83124470710754 seconds, lr:0.0280, train_loss: 0.3281, unlabeled_losses_real_strong:0.6617,corrrect_unlabeled_num:372453.0,pro_above_threshold_num:384538.0,unlabelled_weak_top1_acc:90.53911380469799,unlabelled_weak_top5_acc:99.553571164608  \n","[2022-04-17 02:04:12,285][experiments.experiment][INFO] - [EMA] Epoch 31. [Validation] raw_testing_loss: 0.5498, raw test Top1 acc:85.34, raw test Top5 acc: 99.14, ema_testing_loss: 0.3159, ema test Top1 acc:91.96, ema test Top5 acc: 99.8\n","[2022-04-17 02:04:12,287][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 02:11:32,500][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 32: use 440.3103313446045 seconds\n","--- Optimizer learning rate changed from 2.80e-02 to 2.79e-02 ---\n","[2022-04-17 02:11:32,598][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:11:33,963][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 02:11:33,966][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:11:35,332][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 02:11:35,334][experiments.experiment][INFO] - [EMA] Epoch 32.[Train] time:440.3103313446045 seconds, lr:0.0279, train_loss: 0.3232, unlabeled_losses_real_strong:0.6521,corrrect_unlabeled_num:374054.0,pro_above_threshold_num:385651.0,unlabelled_weak_top1_acc:90.82401703298092,unlabelled_weak_top5_acc:99.59782184660435  \n","[2022-04-17 02:11:35,335][experiments.experiment][INFO] - [EMA] Epoch 32. [Validation] raw_testing_loss: 0.4481, raw test Top1 acc:87.5, raw test Top5 acc: 99.3, ema_testing_loss: 0.3119, ema test Top1 acc:91.98, ema test Top5 acc: 99.8\n","[2022-04-17 02:11:35,337][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 02:18:56,676][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 33: use 441.43919110298157 seconds\n","--- Optimizer learning rate changed from 2.79e-02 to 2.78e-02 ---\n","[2022-04-17 02:18:56,777][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:18:58,151][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 02:18:58,151][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:18:59,490][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 02:18:59,492][experiments.experiment][INFO] - [EMA] Epoch 33.[Train] time:441.43919110298157 seconds, lr:0.0278, train_loss: 0.3235, unlabeled_losses_real_strong:0.6501,corrrect_unlabeled_num:374860.0,pro_above_threshold_num:386645.0,unlabelled_weak_top1_acc:90.84799505025148,unlabelled_weak_top5_acc:99.5677400007844  \n","[2022-04-17 02:18:59,493][experiments.experiment][INFO] - [EMA] Epoch 33. [Validation] raw_testing_loss: 0.4542, raw test Top1 acc:87.8, raw test Top5 acc: 99.72, ema_testing_loss: 0.3135, ema test Top1 acc:91.92, ema test Top5 acc: 99.78\n","[2022-04-17 02:18:59,494][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 02:26:21,049][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 34: use 441.6500904560089 seconds\n","--- Optimizer learning rate changed from 2.78e-02 to 2.76e-02 ---\n","[2022-04-17 02:26:21,144][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:26:22,506][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 02:26:22,507][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:26:23,855][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 02:26:23,857][experiments.experiment][INFO] - [EMA] Epoch 34.[Train] time:441.6500904560089 seconds, lr:0.0276, train_loss: 0.3191, unlabeled_losses_real_strong:0.6408,corrrect_unlabeled_num:376420.0,pro_above_threshold_num:388098.0,unlabelled_weak_top1_acc:91.00080098211765,unlabelled_weak_top5_acc:99.60370744019747  \n","[2022-04-17 02:26:23,858][experiments.experiment][INFO] - [EMA] Epoch 34. [Validation] raw_testing_loss: 0.4280, raw test Top1 acc:87.64, raw test Top5 acc: 99.48, ema_testing_loss: 0.3137, ema test Top1 acc:92.0, ema test Top5 acc: 99.8\n","[2022-04-17 02:26:23,859][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 02:33:51,641][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 35: use 447.8951449394226 seconds\n","--- Optimizer learning rate changed from 2.76e-02 to 2.75e-02 ---\n","[2022-04-17 02:33:51,755][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:33:53,176][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 02:33:53,176][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:33:54,587][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 02:33:54,589][experiments.experiment][INFO] - [EMA] Epoch 35.[Train] time:447.8951449394226 seconds, lr:0.0275, train_loss: 0.3181, unlabeled_losses_real_strong:0.6365,corrrect_unlabeled_num:377598.0,pro_above_threshold_num:389384.0,unlabelled_weak_top1_acc:91.12265353649855,unlabelled_weak_top5_acc:99.61395260691643  \n","[2022-04-17 02:33:54,592][experiments.experiment][INFO] - [EMA] Epoch 35. [Validation] raw_testing_loss: 0.4552, raw test Top1 acc:87.74, raw test Top5 acc: 99.46, ema_testing_loss: 0.3104, ema test Top1 acc:91.88, ema test Top5 acc: 99.82\n","[2022-04-17 02:33:54,592][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 02:41:16,789][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 36: use 442.2993006706238 seconds\n","--- Optimizer learning rate changed from 2.75e-02 to 2.73e-02 ---\n","[2022-04-17 02:41:16,892][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:41:18,269][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 02:41:18,269][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:41:19,608][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 02:41:19,609][experiments.experiment][INFO] - [EMA] Epoch 36.[Train] time:442.2993006706238 seconds, lr:0.0273, train_loss: 0.3159, unlabeled_losses_real_strong:0.6298,corrrect_unlabeled_num:378122.0,pro_above_threshold_num:389590.0,unlabelled_weak_top1_acc:91.24080008268356,unlabelled_weak_top5_acc:99.61809429526329  \n","[2022-04-17 02:41:19,612][experiments.experiment][INFO] - [EMA] Epoch 36. [Validation] raw_testing_loss: 0.5999, raw test Top1 acc:84.84, raw test Top5 acc: 99.14, ema_testing_loss: 0.3025, ema test Top1 acc:92.08, ema test Top5 acc: 99.8\n","[2022-04-17 02:41:19,613][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 02:48:42,048][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 37: use 442.53427743911743 seconds\n","--- Optimizer learning rate changed from 2.73e-02 to 2.72e-02 ---\n","[2022-04-17 02:48:42,147][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:48:43,503][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 02:48:43,504][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:48:44,843][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 02:48:44,845][experiments.experiment][INFO] - [EMA] Epoch 37.[Train] time:442.53427743911743 seconds, lr:0.0272, train_loss: 0.3134, unlabeled_losses_real_strong:0.6266,corrrect_unlabeled_num:379003.0,pro_above_threshold_num:390395.0,unlabelled_weak_top1_acc:91.33496862649918,unlabelled_weak_top5_acc:99.63269923627377  \n","[2022-04-17 02:48:44,846][experiments.experiment][INFO] - [EMA] Epoch 37. [Validation] raw_testing_loss: 0.5959, raw test Top1 acc:84.26, raw test Top5 acc: 99.18, ema_testing_loss: 0.3013, ema test Top1 acc:91.96, ema test Top5 acc: 99.84\n","[2022-04-17 02:48:44,848][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 02:56:07,313][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 38: use 442.5712585449219 seconds\n","--- Optimizer learning rate changed from 2.72e-02 to 2.71e-02 ---\n","[2022-04-17 02:56:07,419][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:56:08,798][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 02:56:08,798][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:56:10,172][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 02:56:10,174][experiments.experiment][INFO] - [EMA] Epoch 38.[Train] time:442.5712585449219 seconds, lr:0.0271, train_loss: 0.3142, unlabeled_losses_real_strong:0.6242,corrrect_unlabeled_num:379040.0,pro_above_threshold_num:390270.0,unlabelled_weak_top1_acc:91.37376947700977,unlabelled_weak_top5_acc:99.61983822286129  \n","[2022-04-17 02:56:10,176][experiments.experiment][INFO] - [EMA] Epoch 38. [Validation] raw_testing_loss: 0.4352, raw test Top1 acc:87.64, raw test Top5 acc: 99.64, ema_testing_loss: 0.2946, ema test Top1 acc:92.3, ema test Top5 acc: 99.82\n","[2022-04-17 02:56:10,177][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 03:03:33,034][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 39: use 442.95139026641846 seconds\n","--- Optimizer learning rate changed from 2.71e-02 to 2.69e-02 ---\n","[2022-04-17 03:03:33,128][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:03:34,545][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 03:03:34,546][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:03:35,912][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 03:03:35,914][experiments.experiment][INFO] - [EMA] Epoch 39.[Train] time:442.95139026641846 seconds, lr:0.0269, train_loss: 0.3124, unlabeled_losses_real_strong:0.6184,corrrect_unlabeled_num:380521.0,pro_above_threshold_num:391753.0,unlabelled_weak_top1_acc:91.46706611663103,unlabelled_weak_top5_acc:99.62703166157007  \n","[2022-04-17 03:03:35,916][experiments.experiment][INFO] - [EMA] Epoch 39. [Validation] raw_testing_loss: 0.5253, raw test Top1 acc:86.8, raw test Top5 acc: 99.52, ema_testing_loss: 0.2932, ema test Top1 acc:92.26, ema test Top5 acc: 99.84\n","[2022-04-17 03:03:35,916][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 03:10:58,821][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 40: use 443.0037167072296 seconds\n","--- Optimizer learning rate changed from 2.69e-02 to 2.68e-02 ---\n","[2022-04-17 03:10:58,920][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:11:00,269][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 03:11:00,270][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:11:01,622][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 03:11:01,624][experiments.experiment][INFO] - [EMA] Epoch 40.[Train] time:443.0037167072296 seconds, lr:0.0268, train_loss: 0.3085, unlabeled_losses_real_strong:0.6091,corrrect_unlabeled_num:382123.0,pro_above_threshold_num:393115.0,unlabelled_weak_top1_acc:91.66434044390917,unlabelled_weak_top5_acc:99.62921144813299  \n","[2022-04-17 03:11:01,626][experiments.experiment][INFO] - [EMA] Epoch 40. [Validation] raw_testing_loss: 0.5314, raw test Top1 acc:87.52, raw test Top5 acc: 99.12, ema_testing_loss: 0.2889, ema test Top1 acc:92.56, ema test Top5 acc: 99.84\n","[2022-04-17 03:11:01,627][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 03:18:26,642][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 41: use 445.11181354522705 seconds\n","--- Optimizer learning rate changed from 2.68e-02 to 2.66e-02 ---\n","[2022-04-17 03:18:26,739][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:18:28,114][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 03:18:28,115][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:18:29,483][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 03:18:29,485][experiments.experiment][INFO] - [EMA] Epoch 41.[Train] time:445.11181354522705 seconds, lr:0.0266, train_loss: 0.3100, unlabeled_losses_real_strong:0.6097,corrrect_unlabeled_num:382420.0,pro_above_threshold_num:393602.0,unlabelled_weak_top1_acc:91.6440680027008,unlabelled_weak_top5_acc:99.64774010330439  \n","[2022-04-17 03:18:29,486][experiments.experiment][INFO] - [EMA] Epoch 41. [Validation] raw_testing_loss: 0.4644, raw test Top1 acc:88.3, raw test Top5 acc: 99.66, ema_testing_loss: 0.2832, ema test Top1 acc:92.36, ema test Top5 acc: 99.82\n","[2022-04-17 03:18:29,488][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 03:25:53,105][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 42: use 443.7121696472168 seconds\n","--- Optimizer learning rate changed from 2.66e-02 to 2.64e-02 ---\n","[2022-04-17 03:25:53,200][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:25:54,566][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 03:25:54,567][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:25:55,897][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 03:25:55,899][experiments.experiment][INFO] - [EMA] Epoch 42.[Train] time:443.7121696472168 seconds, lr:0.0264, train_loss: 0.3073, unlabeled_losses_real_strong:0.6025,corrrect_unlabeled_num:383191.0,pro_above_threshold_num:394457.0,unlabelled_weak_top1_acc:91.74368607252836,unlabelled_weak_top5_acc:99.6326991468668  \n","[2022-04-17 03:25:55,901][experiments.experiment][INFO] - [EMA] Epoch 42. [Validation] raw_testing_loss: 0.4314, raw test Top1 acc:87.84, raw test Top5 acc: 99.58, ema_testing_loss: 0.2824, ema test Top1 acc:92.7, ema test Top5 acc: 99.8\n","[2022-04-17 03:25:55,902][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 03:33:20,435][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 43: use 444.6344783306122 seconds\n","--- Optimizer learning rate changed from 2.64e-02 to 2.63e-02 ---\n","[2022-04-17 03:33:20,537][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:33:21,887][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 03:33:21,887][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:33:23,260][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 03:33:23,261][experiments.experiment][INFO] - [EMA] Epoch 43.[Train] time:444.6344783306122 seconds, lr:0.0263, train_loss: 0.3075, unlabeled_losses_real_strong:0.6003,corrrect_unlabeled_num:384126.0,pro_above_threshold_num:395106.0,unlabelled_weak_top1_acc:91.87425772100687,unlabelled_weak_top5_acc:99.65384364873171  \n","[2022-04-17 03:33:23,263][experiments.experiment][INFO] - [EMA] Epoch 43. [Validation] raw_testing_loss: 0.3892, raw test Top1 acc:89.2, raw test Top5 acc: 99.72, ema_testing_loss: 0.2822, ema test Top1 acc:92.82, ema test Top5 acc: 99.82\n","[2022-04-17 03:33:23,264][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 03:40:47,200][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 44: use 444.03522181510925 seconds\n","--- Optimizer learning rate changed from 2.63e-02 to 2.61e-02 ---\n","[2022-04-17 03:40:47,299][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:40:48,661][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 03:40:48,662][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:40:50,022][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 03:40:50,024][experiments.experiment][INFO] - [EMA] Epoch 44.[Train] time:444.03522181510925 seconds, lr:0.0261, train_loss: 0.3041, unlabeled_losses_real_strong:0.5930,corrrect_unlabeled_num:385600.0,pro_above_threshold_num:396622.0,unlabelled_weak_top1_acc:91.96232281625271,unlabelled_weak_top5_acc:99.65842125564814  \n","[2022-04-17 03:40:50,025][experiments.experiment][INFO] - [EMA] Epoch 44. [Validation] raw_testing_loss: 0.4640, raw test Top1 acc:87.48, raw test Top5 acc: 99.5, ema_testing_loss: 0.2821, ema test Top1 acc:92.8, ema test Top5 acc: 99.88\n","[2022-04-17 03:40:50,026][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 03:48:13,197][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 45: use 443.2699451446533 seconds\n","--- Optimizer learning rate changed from 2.61e-02 to 2.59e-02 ---\n","[2022-04-17 03:48:13,296][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:48:14,656][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 03:48:14,656][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:48:15,999][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 03:48:16,001][experiments.experiment][INFO] - [EMA] Epoch 45.[Train] time:443.2699451446533 seconds, lr:0.0259, train_loss: 0.3020, unlabeled_losses_real_strong:0.5878,corrrect_unlabeled_num:385909.0,pro_above_threshold_num:396928.0,unlabelled_weak_top1_acc:92.0490798279643,unlabelled_weak_top5_acc:99.67869374155998  \n","[2022-04-17 03:48:16,003][experiments.experiment][INFO] - [EMA] Epoch 45. [Validation] raw_testing_loss: 0.4510, raw test Top1 acc:88.56, raw test Top5 acc: 99.46, ema_testing_loss: 0.2836, ema test Top1 acc:92.52, ema test Top5 acc: 99.86\n","[2022-04-17 03:48:16,004][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 03:55:38,843][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 46: use 442.9367883205414 seconds\n","--- Optimizer learning rate changed from 2.59e-02 to 2.58e-02 ---\n","[2022-04-17 03:55:38,941][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:55:40,287][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 03:55:40,287][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:55:41,622][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 03:55:41,623][experiments.experiment][INFO] - [EMA] Epoch 46.[Train] time:442.9367883205414 seconds, lr:0.0258, train_loss: 0.3034, unlabeled_losses_real_strong:0.5858,corrrect_unlabeled_num:386161.0,pro_above_threshold_num:397085.0,unlabelled_weak_top1_acc:92.09006069600582,unlabelled_weak_top5_acc:99.67041040956974  \n","[2022-04-17 03:55:41,626][experiments.experiment][INFO] - [EMA] Epoch 46. [Validation] raw_testing_loss: 0.3757, raw test Top1 acc:89.92, raw test Top5 acc: 99.62, ema_testing_loss: 0.2778, ema test Top1 acc:92.86, ema test Top5 acc: 99.84\n","[2022-04-17 03:55:41,626][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 04:03:04,889][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 47: use 443.3596692085266 seconds\n","--- Optimizer learning rate changed from 2.58e-02 to 2.56e-02 ---\n","[2022-04-17 04:03:04,986][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:03:06,339][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 04:03:06,339][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:03:07,670][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 04:03:07,672][experiments.experiment][INFO] - [EMA] Epoch 47.[Train] time:443.3596692085266 seconds, lr:0.0256, train_loss: 0.2991, unlabeled_losses_real_strong:0.5825,corrrect_unlabeled_num:386916.0,pro_above_threshold_num:397563.0,unlabelled_weak_top1_acc:92.17202218621969,unlabelled_weak_top5_acc:99.67389819025993  \n","[2022-04-17 04:03:07,673][experiments.experiment][INFO] - [EMA] Epoch 47. [Validation] raw_testing_loss: 0.4596, raw test Top1 acc:88.58, raw test Top5 acc: 99.5, ema_testing_loss: 0.2751, ema test Top1 acc:93.14, ema test Top5 acc: 99.82\n","[2022-04-17 04:03:07,674][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 04:10:29,875][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 48: use 442.29697918891907 seconds\n","--- Optimizer learning rate changed from 2.56e-02 to 2.54e-02 ---\n","[2022-04-17 04:10:29,971][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:10:31,293][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 04:10:31,294][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:10:32,631][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 04:10:32,632][experiments.experiment][INFO] - [EMA] Epoch 48.[Train] time:442.29697918891907 seconds, lr:0.0254, train_loss: 0.2992, unlabeled_losses_real_strong:0.5769,corrrect_unlabeled_num:388077.0,pro_above_threshold_num:398737.0,unlabelled_weak_top1_acc:92.23109538853168,unlabelled_weak_top5_acc:99.67477011680603  \n","[2022-04-17 04:10:32,635][experiments.experiment][INFO] - [EMA] Epoch 48. [Validation] raw_testing_loss: 0.3943, raw test Top1 acc:89.34, raw test Top5 acc: 99.56, ema_testing_loss: 0.2749, ema test Top1 acc:92.76, ema test Top5 acc: 99.84\n","[2022-04-17 04:10:32,636][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 04:17:56,478][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 49: use 443.9399416446686 seconds\n","--- Optimizer learning rate changed from 2.54e-02 to 2.52e-02 ---\n","[2022-04-17 04:17:56,576][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:17:57,954][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 04:17:57,954][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:17:59,279][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 04:17:59,280][experiments.experiment][INFO] - [EMA] Epoch 49.[Train] time:443.9399416446686 seconds, lr:0.0252, train_loss: 0.2979, unlabeled_losses_real_strong:0.5736,corrrect_unlabeled_num:388567.0,pro_above_threshold_num:399121.0,unlabelled_weak_top1_acc:92.30738950520754,unlabelled_weak_top5_acc:99.68806706368923  \n","[2022-04-17 04:17:59,281][experiments.experiment][INFO] - [EMA] Epoch 49. [Validation] raw_testing_loss: 0.4667, raw test Top1 acc:87.92, raw test Top5 acc: 99.48, ema_testing_loss: 0.2720, ema test Top1 acc:92.92, ema test Top5 acc: 99.82\n","[2022-04-17 04:17:59,282][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 04:25:21,955][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 50: use 442.7695107460022 seconds\n","--- Optimizer learning rate changed from 2.52e-02 to 2.50e-02 ---\n","[2022-04-17 04:25:22,052][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:25:23,451][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 04:25:23,452][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:25:24,809][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 04:25:24,811][experiments.experiment][INFO] - [EMA] Epoch 50.[Train] time:442.7695107460022 seconds, lr:0.0250, train_loss: 0.2956, unlabeled_losses_real_strong:0.5686,corrrect_unlabeled_num:388952.0,pro_above_threshold_num:399473.0,unlabelled_weak_top1_acc:92.36777055263519,unlabelled_weak_top5_acc:99.70049200952053  \n","[2022-04-17 04:25:24,813][experiments.experiment][INFO] - [EMA] Epoch 50. [Validation] raw_testing_loss: 0.4635, raw test Top1 acc:89.46, raw test Top5 acc: 99.66, ema_testing_loss: 0.2705, ema test Top1 acc:92.94, ema test Top5 acc: 99.82\n","[2022-04-17 04:25:24,814][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 04:32:47,374][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 51: use 442.65559911727905 seconds\n","--- Optimizer learning rate changed from 2.50e-02 to 2.48e-02 ---\n","[2022-04-17 04:32:47,470][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:32:48,810][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 04:32:48,811][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:32:50,147][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 04:32:50,148][experiments.experiment][INFO] - [EMA] Epoch 51.[Train] time:442.65559911727905 seconds, lr:0.0248, train_loss: 0.2940, unlabeled_losses_real_strong:0.5664,corrrect_unlabeled_num:389376.0,pro_above_threshold_num:399908.0,unlabelled_weak_top1_acc:92.39589035511017,unlabelled_weak_top5_acc:99.70463370531797  \n","[2022-04-17 04:32:50,152][experiments.experiment][INFO] - [EMA] Epoch 51. [Validation] raw_testing_loss: 0.4163, raw test Top1 acc:88.86, raw test Top5 acc: 99.46, ema_testing_loss: 0.2678, ema test Top1 acc:92.88, ema test Top5 acc: 99.8\n","[2022-04-17 04:32:50,152][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 04:40:12,932][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 52: use 442.8757064342499 seconds\n","--- Optimizer learning rate changed from 2.48e-02 to 2.46e-02 ---\n","[2022-04-17 04:40:13,028][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:40:14,421][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 04:40:14,421][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:40:15,821][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 04:40:15,823][experiments.experiment][INFO] - [EMA] Epoch 52.[Train] time:442.8757064342499 seconds, lr:0.0246, train_loss: 0.2946, unlabeled_losses_real_strong:0.5629,corrrect_unlabeled_num:390221.0,pro_above_threshold_num:400547.0,unlabelled_weak_top1_acc:92.5159987360239,unlabelled_weak_top5_acc:99.70288989692926  \n","[2022-04-17 04:40:15,824][experiments.experiment][INFO] - [EMA] Epoch 52. [Validation] raw_testing_loss: 0.3731, raw test Top1 acc:89.98, raw test Top5 acc: 99.64, ema_testing_loss: 0.2645, ema test Top1 acc:93.2, ema test Top5 acc: 99.82\n","[2022-04-17 04:40:15,825][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 04:47:37,949][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 53: use 442.2229061126709 seconds\n","--- Optimizer learning rate changed from 2.46e-02 to 2.44e-02 ---\n","[2022-04-17 04:47:38,048][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:47:39,398][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 04:47:39,398][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:47:40,757][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 04:47:40,759][experiments.experiment][INFO] - [EMA] Epoch 53.[Train] time:442.2229061126709 seconds, lr:0.0244, train_loss: 0.2934, unlabeled_losses_real_strong:0.5612,corrrect_unlabeled_num:390559.0,pro_above_threshold_num:400924.0,unlabelled_weak_top1_acc:92.58575324714184,unlabelled_weak_top5_acc:99.71030130237341  \n","[2022-04-17 04:47:40,761][experiments.experiment][INFO] - [EMA] Epoch 53. [Validation] raw_testing_loss: 0.4351, raw test Top1 acc:89.48, raw test Top5 acc: 99.64, ema_testing_loss: 0.2638, ema test Top1 acc:93.04, ema test Top5 acc: 99.82\n","[2022-04-17 04:47:40,762][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 04:55:02,623][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 54: use 441.9557406902313 seconds\n","--- Optimizer learning rate changed from 2.44e-02 to 2.42e-02 ---\n","[2022-04-17 04:55:02,718][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:55:04,060][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 04:55:04,060][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:55:05,408][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 04:55:05,410][experiments.experiment][INFO] - [EMA] Epoch 54.[Train] time:441.9557406902313 seconds, lr:0.0242, train_loss: 0.2907, unlabeled_losses_real_strong:0.5563,corrrect_unlabeled_num:391475.0,pro_above_threshold_num:401666.0,unlabelled_weak_top1_acc:92.63828713446856,unlabelled_weak_top5_acc:99.7041977494955  \n","[2022-04-17 04:55:05,411][experiments.experiment][INFO] - [EMA] Epoch 54. [Validation] raw_testing_loss: 0.4583, raw test Top1 acc:88.24, raw test Top5 acc: 99.52, ema_testing_loss: 0.2626, ema test Top1 acc:93.22, ema test Top5 acc: 99.84\n","[2022-04-17 04:55:05,412][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 05:02:27,535][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 55: use 442.2178440093994 seconds\n","--- Optimizer learning rate changed from 2.42e-02 to 2.40e-02 ---\n","[2022-04-17 05:02:27,630][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:02:28,965][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 05:02:28,965][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:02:30,342][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 05:02:30,344][experiments.experiment][INFO] - [EMA] Epoch 55.[Train] time:442.2178440093994 seconds, lr:0.0240, train_loss: 0.2905, unlabeled_losses_real_strong:0.5519,corrrect_unlabeled_num:392099.0,pro_above_threshold_num:402260.0,unlabelled_weak_top1_acc:92.7509840875864,unlabelled_weak_top5_acc:99.71727681905031  \n","[2022-04-17 05:02:30,346][experiments.experiment][INFO] - [EMA] Epoch 55. [Validation] raw_testing_loss: 0.3716, raw test Top1 acc:90.14, raw test Top5 acc: 99.62, ema_testing_loss: 0.2569, ema test Top1 acc:93.04, ema test Top5 acc: 99.86\n","[2022-04-17 05:02:30,347][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 05:09:52,410][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 56: use 442.15649676322937 seconds\n","--- Optimizer learning rate changed from 2.40e-02 to 2.38e-02 ---\n","[2022-04-17 05:09:52,504][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:09:53,862][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 05:09:53,862][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:09:55,203][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 05:09:55,204][experiments.experiment][INFO] - [EMA] Epoch 56.[Train] time:442.15649676322937 seconds, lr:0.0238, train_loss: 0.2883, unlabeled_losses_real_strong:0.5480,corrrect_unlabeled_num:392617.0,pro_above_threshold_num:402838.0,unlabelled_weak_top1_acc:92.79894031584263,unlabelled_weak_top5_acc:99.69068295508623  \n","[2022-04-17 05:09:55,206][experiments.experiment][INFO] - [EMA] Epoch 56. [Validation] raw_testing_loss: 0.4712, raw test Top1 acc:87.78, raw test Top5 acc: 99.52, ema_testing_loss: 0.2611, ema test Top1 acc:93.3, ema test Top5 acc: 99.84\n","[2022-04-17 05:09:55,206][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 05:17:17,436][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 57: use 442.3274850845337 seconds\n","--- Optimizer learning rate changed from 2.38e-02 to 2.36e-02 ---\n","[2022-04-17 05:17:17,534][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:17:18,901][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 05:17:18,901][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:17:20,294][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 05:17:20,296][experiments.experiment][INFO] - [EMA] Epoch 57.[Train] time:442.3274850845337 seconds, lr:0.0236, train_loss: 0.2890, unlabeled_losses_real_strong:0.5439,corrrect_unlabeled_num:393379.0,pro_above_threshold_num:403775.0,unlabelled_weak_top1_acc:92.83076582849026,unlabelled_weak_top5_acc:99.70005609095097  \n","[2022-04-17 05:17:20,298][experiments.experiment][INFO] - [EMA] Epoch 57. [Validation] raw_testing_loss: 0.3432, raw test Top1 acc:90.42, raw test Top5 acc: 99.58, ema_testing_loss: 0.2609, ema test Top1 acc:93.46, ema test Top5 acc: 99.86\n","[2022-04-17 05:17:20,299][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 05:24:43,531][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 58: use 443.3295085430145 seconds\n","--- Optimizer learning rate changed from 2.36e-02 to 2.34e-02 ---\n","[2022-04-17 05:24:43,629][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:24:44,975][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 05:24:44,975][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:24:46,337][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 05:24:46,339][experiments.experiment][INFO] - [EMA] Epoch 58.[Train] time:443.3295085430145 seconds, lr:0.0234, train_loss: 0.2869, unlabeled_losses_real_strong:0.5440,corrrect_unlabeled_num:393302.0,pro_above_threshold_num:403651.0,unlabelled_weak_top1_acc:92.80700573325157,unlabelled_weak_top5_acc:99.7120451554656  \n","[2022-04-17 05:24:46,342][experiments.experiment][INFO] - [EMA] Epoch 58. [Validation] raw_testing_loss: 0.4996, raw test Top1 acc:88.8, raw test Top5 acc: 99.48, ema_testing_loss: 0.2560, ema test Top1 acc:93.5, ema test Top5 acc: 99.84\n","[2022-04-17 05:24:46,342][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 05:32:08,875][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 59: use 442.6390850543976 seconds\n","--- Optimizer learning rate changed from 2.34e-02 to 2.32e-02 ---\n","[2022-04-17 05:32:08,981][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:32:10,348][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 05:32:10,348][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:32:11,686][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 05:32:11,687][experiments.experiment][INFO] - [EMA] Epoch 59.[Train] time:442.6390850543976 seconds, lr:0.0232, train_loss: 0.2851, unlabeled_losses_real_strong:0.5394,corrrect_unlabeled_num:394079.0,pro_above_threshold_num:404337.0,unlabelled_weak_top1_acc:92.91665124893188,unlabelled_weak_top5_acc:99.71182725578547  \n","[2022-04-17 05:32:11,689][experiments.experiment][INFO] - [EMA] Epoch 59. [Validation] raw_testing_loss: 0.4075, raw test Top1 acc:89.16, raw test Top5 acc: 99.4, ema_testing_loss: 0.2534, ema test Top1 acc:93.56, ema test Top5 acc: 99.88\n","[2022-04-17 05:32:11,691][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 05:39:35,481][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 60: use 443.8849892616272 seconds\n","--- Optimizer learning rate changed from 2.32e-02 to 2.30e-02 ---\n","[2022-04-17 05:39:35,576][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:39:36,934][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 05:39:36,934][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:39:38,265][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 05:39:38,267][experiments.experiment][INFO] - [EMA] Epoch 60.[Train] time:443.8849892616272 seconds, lr:0.0230, train_loss: 0.2841, unlabeled_losses_real_strong:0.5378,corrrect_unlabeled_num:394475.0,pro_above_threshold_num:404564.0,unlabelled_weak_top1_acc:92.9639533162117,unlabelled_weak_top5_acc:99.73493353277445  \n","[2022-04-17 05:39:38,274][experiments.experiment][INFO] - [EMA] Epoch 60. [Validation] raw_testing_loss: 0.3921, raw test Top1 acc:90.32, raw test Top5 acc: 99.7, ema_testing_loss: 0.2494, ema test Top1 acc:93.6, ema test Top5 acc: 99.82\n","[2022-04-17 05:39:38,276][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 05:47:01,696][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 61: use 443.5244507789612 seconds\n","--- Optimizer learning rate changed from 2.30e-02 to 2.27e-02 ---\n","[2022-04-17 05:47:01,801][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:47:03,183][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 05:47:03,184][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:47:04,528][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 05:47:04,530][experiments.experiment][INFO] - [EMA] Epoch 61.[Train] time:443.5244507789612 seconds, lr:0.0227, train_loss: 0.2830, unlabeled_losses_real_strong:0.5339,corrrect_unlabeled_num:395092.0,pro_above_threshold_num:405171.0,unlabelled_weak_top1_acc:93.07468850165606,unlabelled_weak_top5_acc:99.73209967464209  \n","[2022-04-17 05:47:04,531][experiments.experiment][INFO] - [EMA] Epoch 61. [Validation] raw_testing_loss: 0.3307, raw test Top1 acc:90.9, raw test Top5 acc: 99.74, ema_testing_loss: 0.2448, ema test Top1 acc:93.72, ema test Top5 acc: 99.86\n","[2022-04-17 05:47:04,533][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 05:54:27,325][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 62: use 442.89071702957153 seconds\n","--- Optimizer learning rate changed from 2.27e-02 to 2.25e-02 ---\n","[2022-04-17 05:54:27,424][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:54:28,794][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 05:54:28,794][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:54:30,153][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 05:54:30,155][experiments.experiment][INFO] - [EMA] Epoch 62.[Train] time:442.89071702957153 seconds, lr:0.0225, train_loss: 0.2810, unlabeled_losses_real_strong:0.5319,corrrect_unlabeled_num:395973.0,pro_above_threshold_num:406018.0,unlabelled_weak_top1_acc:93.08340787887573,unlabelled_weak_top5_acc:99.72599617391825  \n","[2022-04-17 05:54:30,157][experiments.experiment][INFO] - [EMA] Epoch 62. [Validation] raw_testing_loss: 0.4036, raw test Top1 acc:89.46, raw test Top5 acc: 99.58, ema_testing_loss: 0.2484, ema test Top1 acc:93.8, ema test Top5 acc: 99.82\n","[2022-04-17 05:54:30,158][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 06:01:52,407][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 63: use 442.34545850753784 seconds\n","--- Optimizer learning rate changed from 2.25e-02 to 2.23e-02 ---\n","[2022-04-17 06:01:52,503][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:01:53,865][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 06:01:53,865][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:01:55,237][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 06:01:55,238][experiments.experiment][INFO] - [EMA] Epoch 63.[Train] time:442.34545850753784 seconds, lr:0.0223, train_loss: 0.2797, unlabeled_losses_real_strong:0.5280,corrrect_unlabeled_num:395999.0,pro_above_threshold_num:405847.0,unlabelled_weak_top1_acc:93.14575079828501,unlabelled_weak_top5_acc:99.73057375848293  \n","[2022-04-17 06:01:55,240][experiments.experiment][INFO] - [EMA] Epoch 63. [Validation] raw_testing_loss: 0.3441, raw test Top1 acc:90.64, raw test Top5 acc: 99.72, ema_testing_loss: 0.2457, ema test Top1 acc:93.66, ema test Top5 acc: 99.84\n","[2022-04-17 06:01:55,361][experiments.experiment][INFO] - [Checkpoints] Epoch 63, saving to ./checkpoints_celiali-wideresnet-120epochs-64batch/FMExperiment_epoch_63.pth.tar\n","[2022-04-17 06:01:55,362][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 06:09:17,767][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 64: use 442.50068616867065 seconds\n","--- Optimizer learning rate changed from 2.23e-02 to 2.21e-02 ---\n","[2022-04-17 06:09:17,862][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:09:19,205][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 06:09:19,206][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:09:20,603][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 06:09:20,604][experiments.experiment][INFO] - [EMA] Epoch 64.[Train] time:442.50068616867065 seconds, lr:0.0221, train_loss: 0.2798, unlabeled_losses_real_strong:0.5231,corrrect_unlabeled_num:397010.0,pro_above_threshold_num:407030.0,unlabelled_weak_top1_acc:93.26367948204279,unlabelled_weak_top5_acc:99.73188170790672  \n","[2022-04-17 06:09:20,607][experiments.experiment][INFO] - [EMA] Epoch 64. [Validation] raw_testing_loss: 0.3367, raw test Top1 acc:90.86, raw test Top5 acc: 99.66, ema_testing_loss: 0.2439, ema test Top1 acc:93.86, ema test Top5 acc: 99.86\n","[2022-04-17 06:09:20,608][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 06:16:44,155][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 65: use 443.64182114601135 seconds\n","--- Optimizer learning rate changed from 2.21e-02 to 2.18e-02 ---\n","[2022-04-17 06:16:44,250][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:16:45,601][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 06:16:45,601][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:16:46,953][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 06:16:46,954][experiments.experiment][INFO] - [EMA] Epoch 65.[Train] time:443.64182114601135 seconds, lr:0.0218, train_loss: 0.2791, unlabeled_losses_real_strong:0.5238,corrrect_unlabeled_num:397110.0,pro_above_threshold_num:406985.0,unlabelled_weak_top1_acc:93.19915659725666,unlabelled_weak_top5_acc:99.72359821200371  \n","[2022-04-17 06:16:46,956][experiments.experiment][INFO] - [EMA] Epoch 65. [Validation] raw_testing_loss: 0.3710, raw test Top1 acc:90.22, raw test Top5 acc: 99.54, ema_testing_loss: 0.2477, ema test Top1 acc:93.48, ema test Top5 acc: 99.86\n","[2022-04-17 06:16:46,957][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 06:24:09,430][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 66: use 442.5731883049011 seconds\n","--- Optimizer learning rate changed from 2.18e-02 to 2.16e-02 ---\n","[2022-04-17 06:24:09,531][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:24:10,888][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 06:24:10,889][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:24:12,261][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 06:24:12,262][experiments.experiment][INFO] - [EMA] Epoch 66.[Train] time:442.5731883049011 seconds, lr:0.0216, train_loss: 0.2778, unlabeled_losses_real_strong:0.5195,corrrect_unlabeled_num:397482.0,pro_above_threshold_num:407428.0,unlabelled_weak_top1_acc:93.2822078615427,unlabelled_weak_top5_acc:99.74190889298916  \n","[2022-04-17 06:24:12,265][experiments.experiment][INFO] - [EMA] Epoch 66. [Validation] raw_testing_loss: 0.3912, raw test Top1 acc:90.04, raw test Top5 acc: 99.6, ema_testing_loss: 0.2451, ema test Top1 acc:93.76, ema test Top5 acc: 99.86\n","[2022-04-17 06:24:12,266][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 06:31:39,338][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 67: use 447.1790978908539 seconds\n","--- Optimizer learning rate changed from 2.16e-02 to 2.14e-02 ---\n","[2022-04-17 06:31:39,445][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:31:40,826][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 06:31:40,826][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:31:42,254][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 06:31:42,256][experiments.experiment][INFO] - [EMA] Epoch 67.[Train] time:447.1790978908539 seconds, lr:0.0214, train_loss: 0.2764, unlabeled_losses_real_strong:0.5166,corrrect_unlabeled_num:398380.0,pro_above_threshold_num:408093.0,unlabelled_weak_top1_acc:93.36569540202618,unlabelled_weak_top5_acc:99.73580544441938  \n","[2022-04-17 06:31:42,258][experiments.experiment][INFO] - [EMA] Epoch 67. [Validation] raw_testing_loss: 0.3866, raw test Top1 acc:89.92, raw test Top5 acc: 99.48, ema_testing_loss: 0.2456, ema test Top1 acc:93.9, ema test Top5 acc: 99.84\n","[2022-04-17 06:31:42,259][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 06:39:07,777][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 68: use 445.6167690753937 seconds\n","--- Optimizer learning rate changed from 2.14e-02 to 2.11e-02 ---\n","[2022-04-17 06:39:07,876][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:39:09,256][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 06:39:09,257][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:39:10,722][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 06:39:10,724][experiments.experiment][INFO] - [EMA] Epoch 68.[Train] time:445.6167690753937 seconds, lr:0.0211, train_loss: 0.2751, unlabeled_losses_real_strong:0.5152,corrrect_unlabeled_num:398706.0,pro_above_threshold_num:408345.0,unlabelled_weak_top1_acc:93.42237091809511,unlabelled_weak_top5_acc:99.74147286266088  \n","[2022-04-17 06:39:10,725][experiments.experiment][INFO] - [EMA] Epoch 68. [Validation] raw_testing_loss: 0.3360, raw test Top1 acc:90.86, raw test Top5 acc: 99.84, ema_testing_loss: 0.2403, ema test Top1 acc:94.04, ema test Top5 acc: 99.86\n","[2022-04-17 06:39:10,726][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 06:46:36,155][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 69: use 445.5298192501068 seconds\n","--- Optimizer learning rate changed from 2.11e-02 to 2.09e-02 ---\n","[2022-04-17 06:46:36,256][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:46:37,635][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 06:46:37,636][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:46:39,066][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 06:46:39,068][experiments.experiment][INFO] - [EMA] Epoch 69.[Train] time:445.5298192501068 seconds, lr:0.0209, train_loss: 0.2735, unlabeled_losses_real_strong:0.5097,corrrect_unlabeled_num:399325.0,pro_above_threshold_num:409264.0,unlabelled_weak_top1_acc:93.43501392751932,unlabelled_weak_top5_acc:99.74844842404127  \n","[2022-04-17 06:46:39,069][experiments.experiment][INFO] - [EMA] Epoch 69. [Validation] raw_testing_loss: 0.3939, raw test Top1 acc:89.66, raw test Top5 acc: 99.46, ema_testing_loss: 0.2351, ema test Top1 acc:94.0, ema test Top5 acc: 99.88\n","[2022-04-17 06:46:39,071][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 06:54:03,704][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 70: use 444.73500633239746 seconds\n","--- Optimizer learning rate changed from 2.09e-02 to 2.06e-02 ---\n","[2022-04-17 06:54:03,806][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:54:05,174][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 06:54:05,174][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:54:06,564][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 06:54:06,565][experiments.experiment][INFO] - [EMA] Epoch 70.[Train] time:444.73500633239746 seconds, lr:0.0206, train_loss: 0.2740, unlabeled_losses_real_strong:0.5088,corrrect_unlabeled_num:399500.0,pro_above_threshold_num:409322.0,unlabelled_weak_top1_acc:93.43871962279081,unlabelled_weak_top5_acc:99.73820313811302  \n","[2022-04-17 06:54:06,566][experiments.experiment][INFO] - [EMA] Epoch 70. [Validation] raw_testing_loss: 0.3833, raw test Top1 acc:90.36, raw test Top5 acc: 99.62, ema_testing_loss: 0.2375, ema test Top1 acc:93.96, ema test Top5 acc: 99.86\n","[2022-04-17 06:54:06,568][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 07:01:29,412][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 71: use 442.93709087371826 seconds\n","--- Optimizer learning rate changed from 2.06e-02 to 2.04e-02 ---\n","[2022-04-17 07:01:29,506][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:01:30,874][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 07:01:30,874][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:01:32,239][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 07:01:32,241][experiments.experiment][INFO] - [EMA] Epoch 71.[Train] time:442.93709087371826 seconds, lr:0.0204, train_loss: 0.2722, unlabeled_losses_real_strong:0.5039,corrrect_unlabeled_num:400150.0,pro_above_threshold_num:409717.0,unlabelled_weak_top1_acc:93.54313325881958,unlabelled_weak_top5_acc:99.74735847860575  \n","[2022-04-17 07:01:32,242][experiments.experiment][INFO] - [EMA] Epoch 71. [Validation] raw_testing_loss: 0.3407, raw test Top1 acc:91.36, raw test Top5 acc: 99.7, ema_testing_loss: 0.2361, ema test Top1 acc:93.86, ema test Top5 acc: 99.84\n","[2022-04-17 07:01:32,243][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 07:08:53,582][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 72: use 441.4353153705597 seconds\n","--- Optimizer learning rate changed from 2.04e-02 to 2.01e-02 ---\n","[2022-04-17 07:08:53,679][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:08:55,028][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 07:08:55,029][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:08:56,369][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 07:08:56,370][experiments.experiment][INFO] - [EMA] Epoch 72.[Train] time:441.4353153705597 seconds, lr:0.0201, train_loss: 0.2721, unlabeled_losses_real_strong:0.5004,corrrect_unlabeled_num:400777.0,pro_above_threshold_num:410443.0,unlabelled_weak_top1_acc:93.59414121508598,unlabelled_weak_top5_acc:99.748884357512  \n","[2022-04-17 07:08:56,372][experiments.experiment][INFO] - [EMA] Epoch 72. [Validation] raw_testing_loss: 0.2915, raw test Top1 acc:91.78, raw test Top5 acc: 99.64, ema_testing_loss: 0.2330, ema test Top1 acc:94.06, ema test Top5 acc: 99.84\n","[2022-04-17 07:08:56,373][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 07:16:20,798][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 73: use 444.53087520599365 seconds\n","--- Optimizer learning rate changed from 2.01e-02 to 1.99e-02 ---\n","[2022-04-17 07:16:20,904][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:16:22,283][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 07:16:22,284][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:16:23,651][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 07:16:23,652][experiments.experiment][INFO] - [EMA] Epoch 73.[Train] time:444.53087520599365 seconds, lr:0.0199, train_loss: 0.2718, unlabeled_losses_real_strong:0.5004,corrrect_unlabeled_num:401171.0,pro_above_threshold_num:410793.0,unlabelled_weak_top1_acc:93.65081679821014,unlabelled_weak_top5_acc:99.75825756043196  \n","[2022-04-17 07:16:23,654][experiments.experiment][INFO] - [EMA] Epoch 73. [Validation] raw_testing_loss: 0.3431, raw test Top1 acc:91.26, raw test Top5 acc: 99.74, ema_testing_loss: 0.2348, ema test Top1 acc:93.78, ema test Top5 acc: 99.84\n","[2022-04-17 07:16:23,655][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 07:23:51,179][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 74: use 447.6294701099396 seconds\n","--- Optimizer learning rate changed from 1.99e-02 to 1.96e-02 ---\n","[2022-04-17 07:23:51,284][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:23:52,653][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 07:23:52,653][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:23:54,022][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 07:23:54,023][experiments.experiment][INFO] - [EMA] Epoch 74.[Train] time:447.6294701099396 seconds, lr:0.0196, train_loss: 0.2699, unlabeled_losses_real_strong:0.4963,corrrect_unlabeled_num:401529.0,pro_above_threshold_num:411128.0,unlabelled_weak_top1_acc:93.66781941056252,unlabelled_weak_top5_acc:99.76130942255259  \n","[2022-04-17 07:23:54,024][experiments.experiment][INFO] - [EMA] Epoch 74. [Validation] raw_testing_loss: 0.4653, raw test Top1 acc:89.38, raw test Top5 acc: 99.74, ema_testing_loss: 0.2322, ema test Top1 acc:93.92, ema test Top5 acc: 99.84\n","[2022-04-17 07:23:54,026][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 07:31:18,786][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 75: use 444.858674287796 seconds\n","--- Optimizer learning rate changed from 1.96e-02 to 1.93e-02 ---\n","[2022-04-17 07:31:18,885][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:31:20,336][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 07:31:20,337][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:31:21,697][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 07:31:21,699][experiments.experiment][INFO] - [EMA] Epoch 75.[Train] time:444.858674287796 seconds, lr:0.0193, train_loss: 0.2674, unlabeled_losses_real_strong:0.4953,corrrect_unlabeled_num:401869.0,pro_above_threshold_num:411462.0,unlabelled_weak_top1_acc:93.69811902195215,unlabelled_weak_top5_acc:99.77417047321796  \n","[2022-04-17 07:31:21,701][experiments.experiment][INFO] - [EMA] Epoch 75. [Validation] raw_testing_loss: 0.3040, raw test Top1 acc:91.74, raw test Top5 acc: 99.82, ema_testing_loss: 0.2291, ema test Top1 acc:93.92, ema test Top5 acc: 99.86\n","[2022-04-17 07:31:21,702][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 07:38:44,866][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 76: use 443.2670621871948 seconds\n","--- Optimizer learning rate changed from 1.93e-02 to 1.91e-02 ---\n","[2022-04-17 07:38:44,969][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:38:46,370][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 07:38:46,370][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:38:47,761][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 07:38:47,762][experiments.experiment][INFO] - [EMA] Epoch 76.[Train] time:443.2670621871948 seconds, lr:0.0191, train_loss: 0.2672, unlabeled_losses_real_strong:0.4925,corrrect_unlabeled_num:402284.0,pro_above_threshold_num:411759.0,unlabelled_weak_top1_acc:93.6900537237525,unlabelled_weak_top5_acc:99.76021947711706  \n","[2022-04-17 07:38:47,764][experiments.experiment][INFO] - [EMA] Epoch 76. [Validation] raw_testing_loss: 0.3498, raw test Top1 acc:90.64, raw test Top5 acc: 99.66, ema_testing_loss: 0.2320, ema test Top1 acc:94.1, ema test Top5 acc: 99.86\n","[2022-04-17 07:38:47,765][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 07:46:12,331][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 77: use 444.6623389720917 seconds\n","--- Optimizer learning rate changed from 1.91e-02 to 1.88e-02 ---\n","[2022-04-17 07:46:12,428][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:46:13,787][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 07:46:13,787][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:46:15,168][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 07:46:15,170][experiments.experiment][INFO] - [EMA] Epoch 77.[Train] time:444.6623389720917 seconds, lr:0.0188, train_loss: 0.2644, unlabeled_losses_real_strong:0.4854,corrrect_unlabeled_num:403062.0,pro_above_threshold_num:412640.0,unlabelled_weak_top1_acc:93.82716475427151,unlabelled_weak_top5_acc:99.7645790874958  \n","[2022-04-17 07:46:15,171][experiments.experiment][INFO] - [EMA] Epoch 77. [Validation] raw_testing_loss: 0.3483, raw test Top1 acc:90.84, raw test Top5 acc: 99.76, ema_testing_loss: 0.2313, ema test Top1 acc:94.12, ema test Top5 acc: 99.84\n","[2022-04-17 07:46:15,173][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 07:53:39,616][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 78: use 444.54794216156006 seconds\n","--- Optimizer learning rate changed from 1.88e-02 to 1.85e-02 ---\n","[2022-04-17 07:53:39,721][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:53:41,134][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 07:53:41,135][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:53:42,517][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 07:53:42,519][experiments.experiment][INFO] - [EMA] Epoch 78.[Train] time:444.54794216156006 seconds, lr:0.0185, train_loss: 0.2641, unlabeled_losses_real_strong:0.4848,corrrect_unlabeled_num:403370.0,pro_above_threshold_num:412665.0,unlabelled_weak_top1_acc:93.87730073928833,unlabelled_weak_top5_acc:99.75716771930456  \n","[2022-04-17 07:53:42,520][experiments.experiment][INFO] - [EMA] Epoch 78. [Validation] raw_testing_loss: 0.2994, raw test Top1 acc:92.12, raw test Top5 acc: 99.78, ema_testing_loss: 0.2253, ema test Top1 acc:94.28, ema test Top5 acc: 99.86\n","[2022-04-17 07:53:42,522][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 08:01:06,201][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 79: use 443.77944111824036 seconds\n","--- Optimizer learning rate changed from 1.85e-02 to 1.83e-02 ---\n","[2022-04-17 08:01:06,302][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:01:07,679][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 08:01:07,679][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:01:09,045][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 08:01:09,047][experiments.experiment][INFO] - [EMA] Epoch 79.[Train] time:443.77944111824036 seconds, lr:0.0183, train_loss: 0.2644, unlabeled_losses_real_strong:0.4831,corrrect_unlabeled_num:404095.0,pro_above_threshold_num:413464.0,unlabelled_weak_top1_acc:93.95730047672987,unlabelled_weak_top5_acc:99.77068264782429  \n","[2022-04-17 08:01:09,049][experiments.experiment][INFO] - [EMA] Epoch 79. [Validation] raw_testing_loss: 0.3104, raw test Top1 acc:92.0, raw test Top5 acc: 99.66, ema_testing_loss: 0.2250, ema test Top1 acc:94.16, ema test Top5 acc: 99.9\n","[2022-04-17 08:01:09,050][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 08:08:32,360][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 80: use 443.41466903686523 seconds\n","--- Optimizer learning rate changed from 1.83e-02 to 1.80e-02 ---\n","[2022-04-17 08:08:32,465][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:08:33,881][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 08:08:33,882][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:08:35,254][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 08:08:35,255][experiments.experiment][INFO] - [EMA] Epoch 80.[Train] time:443.41466903686523 seconds, lr:0.0180, train_loss: 0.2626, unlabeled_losses_real_strong:0.4798,corrrect_unlabeled_num:404457.0,pro_above_threshold_num:413893.0,unlabelled_weak_top1_acc:93.95424858480692,unlabelled_weak_top5_acc:99.77308049798012  \n","[2022-04-17 08:08:35,258][experiments.experiment][INFO] - [EMA] Epoch 80. [Validation] raw_testing_loss: 0.3396, raw test Top1 acc:91.26, raw test Top5 acc: 99.86, ema_testing_loss: 0.2214, ema test Top1 acc:94.36, ema test Top5 acc: 99.9\n","[2022-04-17 08:08:35,258][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 08:15:59,065][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 81: use 443.908451795578 seconds\n","--- Optimizer learning rate changed from 1.80e-02 to 1.77e-02 ---\n","[2022-04-17 08:15:59,167][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:16:00,541][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 08:16:00,541][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:16:01,929][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 08:16:01,930][experiments.experiment][INFO] - [EMA] Epoch 81.[Train] time:443.908451795578 seconds, lr:0.0177, train_loss: 0.2609, unlabeled_losses_real_strong:0.4753,corrrect_unlabeled_num:404670.0,pro_above_threshold_num:413914.0,unlabelled_weak_top1_acc:94.01397594809532,unlabelled_weak_top5_acc:99.7582575455308  \n","[2022-04-17 08:16:01,931][experiments.experiment][INFO] - [EMA] Epoch 81. [Validation] raw_testing_loss: 0.3575, raw test Top1 acc:90.78, raw test Top5 acc: 99.78, ema_testing_loss: 0.2185, ema test Top1 acc:94.2, ema test Top5 acc: 99.9\n","[2022-04-17 08:16:01,933][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 08:23:27,482][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 82: use 445.6489713191986 seconds\n","--- Optimizer learning rate changed from 1.77e-02 to 1.74e-02 ---\n","[2022-04-17 08:23:27,582][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:23:28,958][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 08:23:28,959][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:23:30,331][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 08:23:30,333][experiments.experiment][INFO] - [EMA] Epoch 82.[Train] time:445.6489713191986 seconds, lr:0.0174, train_loss: 0.2597, unlabeled_losses_real_strong:0.4735,corrrect_unlabeled_num:405206.0,pro_above_threshold_num:414595.0,unlabelled_weak_top1_acc:94.01724564284086,unlabelled_weak_top5_acc:99.77765811234713  \n","[2022-04-17 08:23:30,335][experiments.experiment][INFO] - [EMA] Epoch 82. [Validation] raw_testing_loss: 0.3165, raw test Top1 acc:91.3, raw test Top5 acc: 99.74, ema_testing_loss: 0.2199, ema test Top1 acc:94.2, ema test Top5 acc: 99.9\n","[2022-04-17 08:23:30,336][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 08:30:55,700][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 83: use 445.46815061569214 seconds\n","--- Optimizer learning rate changed from 1.74e-02 to 1.72e-02 ---\n","[2022-04-17 08:30:55,804][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:30:57,164][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 08:30:57,165][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:30:58,563][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 08:30:58,564][experiments.experiment][INFO] - [EMA] Epoch 83.[Train] time:445.46815061569214 seconds, lr:0.0172, train_loss: 0.2589, unlabeled_losses_real_strong:0.4723,corrrect_unlabeled_num:405758.0,pro_above_threshold_num:415032.0,unlabelled_weak_top1_acc:94.08700023591518,unlabelled_weak_top5_acc:99.778529971838  \n","[2022-04-17 08:30:58,566][experiments.experiment][INFO] - [EMA] Epoch 83. [Validation] raw_testing_loss: 0.3037, raw test Top1 acc:91.64, raw test Top5 acc: 99.86, ema_testing_loss: 0.2187, ema test Top1 acc:94.4, ema test Top5 acc: 99.88\n","[2022-04-17 08:30:58,567][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 08:38:22,253][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 84: use 443.7942428588867 seconds\n","--- Optimizer learning rate changed from 1.72e-02 to 1.69e-02 ---\n","[2022-04-17 08:38:22,361][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:38:23,741][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 08:38:23,742][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:38:25,102][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 08:38:25,103][experiments.experiment][INFO] - [EMA] Epoch 84.[Train] time:443.7942428588867 seconds, lr:0.0169, train_loss: 0.2567, unlabeled_losses_real_strong:0.4680,corrrect_unlabeled_num:406627.0,pro_above_threshold_num:415917.0,unlabelled_weak_top1_acc:94.17528307437897,unlabelled_weak_top5_acc:99.77809405326843  \n","[2022-04-17 08:38:25,106][experiments.experiment][INFO] - [EMA] Epoch 84. [Validation] raw_testing_loss: 0.2604, raw test Top1 acc:92.7, raw test Top5 acc: 99.9, ema_testing_loss: 0.2177, ema test Top1 acc:94.44, ema test Top5 acc: 99.92\n","[2022-04-17 08:38:25,107][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 08:45:47,418][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 85: use 442.4096739292145 seconds\n","--- Optimizer learning rate changed from 1.69e-02 to 1.66e-02 ---\n","[2022-04-17 08:45:47,517][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:45:48,892][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 08:45:48,893][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:45:50,258][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 08:45:50,259][experiments.experiment][INFO] - [EMA] Epoch 85.[Train] time:442.4096739292145 seconds, lr:0.0166, train_loss: 0.2545, unlabeled_losses_real_strong:0.4651,corrrect_unlabeled_num:406821.0,pro_above_threshold_num:416234.0,unlabelled_weak_top1_acc:94.18487440049648,unlabelled_weak_top5_acc:99.77329836785793  \n","[2022-04-17 08:45:50,261][experiments.experiment][INFO] - [EMA] Epoch 85. [Validation] raw_testing_loss: 0.3184, raw test Top1 acc:91.76, raw test Top5 acc: 99.76, ema_testing_loss: 0.2163, ema test Top1 acc:94.22, ema test Top5 acc: 99.9\n","[2022-04-17 08:45:50,263][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 08:53:13,203][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 86: use 443.0434606075287 seconds\n","--- Optimizer learning rate changed from 1.66e-02 to 1.63e-02 ---\n","[2022-04-17 08:53:13,306][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:53:14,701][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 08:53:14,701][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:53:16,064][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 08:53:16,066][experiments.experiment][INFO] - [EMA] Epoch 86.[Train] time:443.0434606075287 seconds, lr:0.0163, train_loss: 0.2554, unlabeled_losses_real_strong:0.4639,corrrect_unlabeled_num:407365.0,pro_above_threshold_num:416766.0,unlabelled_weak_top1_acc:94.23675435781479,unlabelled_weak_top5_acc:99.78506947308779  \n","[2022-04-17 08:53:16,069][experiments.experiment][INFO] - [EMA] Epoch 86. [Validation] raw_testing_loss: 0.3392, raw test Top1 acc:91.56, raw test Top5 acc: 99.64, ema_testing_loss: 0.2176, ema test Top1 acc:94.32, ema test Top5 acc: 99.9\n","[2022-04-17 08:53:16,069][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 09:00:39,342][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 87: use 443.3736264705658 seconds\n","--- Optimizer learning rate changed from 1.63e-02 to 1.60e-02 ---\n","[2022-04-17 09:00:39,443][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:00:40,802][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 09:00:40,803][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:00:42,184][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 09:00:42,185][experiments.experiment][INFO] - [EMA] Epoch 87.[Train] time:443.3736264705658 seconds, lr:0.0160, train_loss: 0.2536, unlabeled_losses_real_strong:0.4597,corrrect_unlabeled_num:407776.0,pro_above_threshold_num:416987.0,unlabelled_weak_top1_acc:94.2600784599781,unlabelled_weak_top5_acc:99.77569627761841  \n","[2022-04-17 09:00:42,187][experiments.experiment][INFO] - [EMA] Epoch 87. [Validation] raw_testing_loss: 0.3039, raw test Top1 acc:91.78, raw test Top5 acc: 99.76, ema_testing_loss: 0.2190, ema test Top1 acc:94.52, ema test Top5 acc: 99.92\n","[2022-04-17 09:00:42,189][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 09:08:04,352][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 88: use 442.26317977905273 seconds\n","--- Optimizer learning rate changed from 1.60e-02 to 1.57e-02 ---\n","[2022-04-17 09:08:04,452][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:08:05,824][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 09:08:05,825][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:08:07,202][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 09:08:07,204][experiments.experiment][INFO] - [EMA] Epoch 88.[Train] time:442.26317977905273 seconds, lr:0.0157, train_loss: 0.2534, unlabeled_losses_real_strong:0.4589,corrrect_unlabeled_num:408123.0,pro_above_threshold_num:417393.0,unlabelled_weak_top1_acc:94.34269395470619,unlabelled_weak_top5_acc:99.7754782885313  \n","[2022-04-17 09:08:07,206][experiments.experiment][INFO] - [EMA] Epoch 88. [Validation] raw_testing_loss: 0.2666, raw test Top1 acc:92.26, raw test Top5 acc: 99.78, ema_testing_loss: 0.2137, ema test Top1 acc:94.58, ema test Top5 acc: 99.92\n","[2022-04-17 09:08:07,207][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 09:15:33,373][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 89: use 446.26963090896606 seconds\n","--- Optimizer learning rate changed from 1.57e-02 to 1.54e-02 ---\n","[2022-04-17 09:15:33,476][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:15:34,850][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 09:15:34,850][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:15:36,253][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 09:15:36,254][experiments.experiment][INFO] - [EMA] Epoch 89.[Train] time:446.26963090896606 seconds, lr:0.0154, train_loss: 0.2515, unlabeled_losses_real_strong:0.4532,corrrect_unlabeled_num:408805.0,pro_above_threshold_num:418065.0,unlabelled_weak_top1_acc:94.35424692928791,unlabelled_weak_top5_acc:99.78528755903244  \n","[2022-04-17 09:15:36,257][experiments.experiment][INFO] - [EMA] Epoch 89. [Validation] raw_testing_loss: 0.2755, raw test Top1 acc:93.02, raw test Top5 acc: 99.9, ema_testing_loss: 0.2139, ema test Top1 acc:94.46, ema test Top5 acc: 99.94\n","[2022-04-17 09:15:36,258][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 09:23:02,072][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 90: use 445.9197099208832 seconds\n","--- Optimizer learning rate changed from 1.54e-02 to 1.51e-02 ---\n","[2022-04-17 09:23:02,178][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:23:03,536][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 09:23:03,536][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:23:04,882][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 09:23:04,883][experiments.experiment][INFO] - [EMA] Epoch 90.[Train] time:445.9197099208832 seconds, lr:0.0151, train_loss: 0.2500, unlabeled_losses_real_strong:0.4510,corrrect_unlabeled_num:409266.0,pro_above_threshold_num:418447.0,unlabelled_weak_top1_acc:94.39544567465782,unlabelled_weak_top5_acc:99.7850694656372  \n","[2022-04-17 09:23:04,885][experiments.experiment][INFO] - [EMA] Epoch 90. [Validation] raw_testing_loss: 0.4069, raw test Top1 acc:90.44, raw test Top5 acc: 99.58, ema_testing_loss: 0.2105, ema test Top1 acc:94.48, ema test Top5 acc: 99.92\n","[2022-04-17 09:23:04,886][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 09:30:30,861][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 91: use 446.0739095211029 seconds\n","--- Optimizer learning rate changed from 1.51e-02 to 1.48e-02 ---\n","[2022-04-17 09:30:30,960][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:30:32,352][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 09:30:32,352][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:30:33,738][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 09:30:33,739][experiments.experiment][INFO] - [EMA] Epoch 91.[Train] time:446.0739095211029 seconds, lr:0.0148, train_loss: 0.2484, unlabeled_losses_real_strong:0.4461,corrrect_unlabeled_num:409813.0,pro_above_threshold_num:418980.0,unlabelled_weak_top1_acc:94.4582247287035,unlabelled_weak_top5_acc:99.78724931925535  \n","[2022-04-17 09:30:33,741][experiments.experiment][INFO] - [EMA] Epoch 91. [Validation] raw_testing_loss: 0.2989, raw test Top1 acc:92.14, raw test Top5 acc: 99.86, ema_testing_loss: 0.2077, ema test Top1 acc:94.46, ema test Top5 acc: 99.94\n","[2022-04-17 09:30:33,743][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 09:37:58,664][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 92: use 445.02330136299133 seconds\n","--- Optimizer learning rate changed from 1.48e-02 to 1.45e-02 ---\n","[2022-04-17 09:37:58,766][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:38:00,157][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 09:38:00,157][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:38:01,546][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 09:38:01,547][experiments.experiment][INFO] - [EMA] Epoch 92.[Train] time:445.02330136299133 seconds, lr:0.0145, train_loss: 0.2470, unlabeled_losses_real_strong:0.4455,corrrect_unlabeled_num:410296.0,pro_above_threshold_num:419554.0,unlabelled_weak_top1_acc:94.46040450781584,unlabelled_weak_top5_acc:99.7809277921915  \n","[2022-04-17 09:38:01,548][experiments.experiment][INFO] - [EMA] Epoch 92. [Validation] raw_testing_loss: 0.2585, raw test Top1 acc:92.76, raw test Top5 acc: 99.78, ema_testing_loss: 0.2072, ema test Top1 acc:94.5, ema test Top5 acc: 99.94\n","[2022-04-17 09:38:01,550][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 09:45:26,966][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 93: use 445.5136568546295 seconds\n","--- Optimizer learning rate changed from 1.45e-02 to 1.42e-02 ---\n","[2022-04-17 09:45:27,064][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:45:28,461][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 09:45:28,461][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:45:29,832][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 09:45:29,833][experiments.experiment][INFO] - [EMA] Epoch 93.[Train] time:445.5136568546295 seconds, lr:0.0142, train_loss: 0.2461, unlabeled_losses_real_strong:0.4410,corrrect_unlabeled_num:411129.0,pro_above_threshold_num:420369.0,unlabelled_weak_top1_acc:94.55130337923765,unlabelled_weak_top5_acc:99.79531469941139  \n","[2022-04-17 09:45:29,835][experiments.experiment][INFO] - [EMA] Epoch 93. [Validation] raw_testing_loss: 0.2877, raw test Top1 acc:92.16, raw test Top5 acc: 99.78, ema_testing_loss: 0.2032, ema test Top1 acc:94.62, ema test Top5 acc: 99.92\n","[2022-04-17 09:45:29,836][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 09:52:53,320][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 94: use 443.585426568985 seconds\n","--- Optimizer learning rate changed from 1.42e-02 to 1.39e-02 ---\n","[2022-04-17 09:52:53,422][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:52:54,797][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 09:52:54,798][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:52:56,184][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 09:52:56,186][experiments.experiment][INFO] - [EMA] Epoch 94.[Train] time:443.585426568985 seconds, lr:0.0139, train_loss: 0.2455, unlabeled_losses_real_strong:0.4399,corrrect_unlabeled_num:411539.0,pro_above_threshold_num:420744.0,unlabelled_weak_top1_acc:94.60470905900002,unlabelled_weak_top5_acc:99.8083937317133  \n","[2022-04-17 09:52:56,187][experiments.experiment][INFO] - [EMA] Epoch 94. [Validation] raw_testing_loss: 0.2635, raw test Top1 acc:92.34, raw test Top5 acc: 99.76, ema_testing_loss: 0.1993, ema test Top1 acc:94.72, ema test Top5 acc: 99.92\n","[2022-04-17 09:52:56,188][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 10:00:19,939][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 95: use 443.8517966270447 seconds\n","--- Optimizer learning rate changed from 1.39e-02 to 1.36e-02 ---\n","[2022-04-17 10:00:20,040][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:00:21,425][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 10:00:21,425][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:00:22,871][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 10:00:22,873][experiments.experiment][INFO] - [EMA] Epoch 95.[Train] time:443.8517966270447 seconds, lr:0.0136, train_loss: 0.2420, unlabeled_losses_real_strong:0.4363,corrrect_unlabeled_num:411951.0,pro_above_threshold_num:421203.0,unlabelled_weak_top1_acc:94.61844202131033,unlabelled_weak_top5_acc:99.79684062302113  \n","[2022-04-17 10:00:22,874][experiments.experiment][INFO] - [EMA] Epoch 95. [Validation] raw_testing_loss: 0.2828, raw test Top1 acc:92.8, raw test Top5 acc: 99.9, ema_testing_loss: 0.1974, ema test Top1 acc:94.92, ema test Top5 acc: 99.96\n","[2022-04-17 10:00:22,875][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 10:07:46,865][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 96: use 444.0933163166046 seconds\n","--- Optimizer learning rate changed from 1.36e-02 to 1.33e-02 ---\n","[2022-04-17 10:07:46,969][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:07:48,385][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 10:07:48,385][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:07:49,746][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 10:07:49,747][experiments.experiment][INFO] - [EMA] Epoch 96.[Train] time:444.0933163166046 seconds, lr:0.0133, train_loss: 0.2413, unlabeled_losses_real_strong:0.4324,corrrect_unlabeled_num:412163.0,pro_above_threshold_num:421433.0,unlabelled_weak_top1_acc:94.6735917404294,unlabelled_weak_top5_acc:99.79902055114508  \n","[2022-04-17 10:07:49,749][experiments.experiment][INFO] - [EMA] Epoch 96. [Validation] raw_testing_loss: 0.2931, raw test Top1 acc:91.76, raw test Top5 acc: 99.76, ema_testing_loss: 0.2000, ema test Top1 acc:94.64, ema test Top5 acc: 99.94\n","[2022-04-17 10:07:49,750][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 10:15:14,910][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 97: use 445.25624108314514 seconds\n","--- Optimizer learning rate changed from 1.33e-02 to 1.30e-02 ---\n","[2022-04-17 10:15:15,007][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:15:16,363][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 10:15:16,364][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:15:17,719][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 10:15:17,720][experiments.experiment][INFO] - [EMA] Epoch 97.[Train] time:445.25624108314514 seconds, lr:0.0130, train_loss: 0.2398, unlabeled_losses_real_strong:0.4293,corrrect_unlabeled_num:412930.0,pro_above_threshold_num:421986.0,unlabelled_weak_top1_acc:94.73397292941809,unlabelled_weak_top5_acc:99.80250819772482  \n","[2022-04-17 10:15:17,722][experiments.experiment][INFO] - [EMA] Epoch 97. [Validation] raw_testing_loss: 0.2981, raw test Top1 acc:91.82, raw test Top5 acc: 99.78, ema_testing_loss: 0.1997, ema test Top1 acc:94.82, ema test Top5 acc: 99.94\n","[2022-04-17 10:15:17,724][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 10:22:40,280][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 98: use 442.6566686630249 seconds\n","--- Optimizer learning rate changed from 1.30e-02 to 1.27e-02 ---\n","[2022-04-17 10:22:40,381][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:22:41,749][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 10:22:41,749][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:22:43,110][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 10:22:43,112][experiments.experiment][INFO] - [EMA] Epoch 98.[Train] time:442.6566686630249 seconds, lr:0.0127, train_loss: 0.2387, unlabeled_losses_real_strong:0.4270,corrrect_unlabeled_num:414018.0,pro_above_threshold_num:423105.0,unlabelled_weak_top1_acc:94.78323689103127,unlabelled_weak_top5_acc:99.8014182522893  \n","[2022-04-17 10:22:43,113][experiments.experiment][INFO] - [EMA] Epoch 98. [Validation] raw_testing_loss: 0.3336, raw test Top1 acc:90.98, raw test Top5 acc: 99.7, ema_testing_loss: 0.1990, ema test Top1 acc:94.72, ema test Top5 acc: 99.92\n","[2022-04-17 10:22:43,115][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 10:30:08,902][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 99: use 445.8874406814575 seconds\n","--- Optimizer learning rate changed from 1.27e-02 to 1.24e-02 ---\n","[2022-04-17 10:30:09,002][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:30:10,364][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 10:30:10,364][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:30:11,711][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 10:30:11,713][experiments.experiment][INFO] - [EMA] Epoch 99.[Train] time:445.8874406814575 seconds, lr:0.0124, train_loss: 0.2360, unlabeled_losses_real_strong:0.4242,corrrect_unlabeled_num:413736.0,pro_above_threshold_num:422941.0,unlabelled_weak_top1_acc:94.81179271638393,unlabelled_weak_top5_acc:99.81122754514217  \n","[2022-04-17 10:30:11,715][experiments.experiment][INFO] - [EMA] Epoch 99. [Validation] raw_testing_loss: 0.2925, raw test Top1 acc:91.5, raw test Top5 acc: 99.84, ema_testing_loss: 0.1996, ema test Top1 acc:94.9, ema test Top5 acc: 99.92\n","[2022-04-17 10:30:11,716][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 10:37:36,016][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 100: use 444.3968358039856 seconds\n","--- Optimizer learning rate changed from 1.24e-02 to 1.21e-02 ---\n","[2022-04-17 10:37:36,113][experiments.experiment][INFO] - ***** Running validation *****\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-17 10:37:37,488][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 10:37:37,489][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:37:38,830][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 10:37:38,831][experiments.experiment][INFO] - [EMA] Epoch 100.[Train] time:444.3968358039856 seconds, lr:0.0121, train_loss: 0.2355, unlabeled_losses_real_strong:0.4230,corrrect_unlabeled_num:413892.0,pro_above_threshold_num:422911.0,unlabelled_weak_top1_acc:94.83925851434469,unlabelled_weak_top5_acc:99.82081869989634  \n","[2022-04-17 10:37:38,833][experiments.experiment][INFO] - [EMA] Epoch 100. [Validation] raw_testing_loss: 0.3308, raw test Top1 acc:91.88, raw test Top5 acc: 99.74, ema_testing_loss: 0.2011, ema test Top1 acc:94.72, ema test Top5 acc: 99.9\n","[2022-04-17 10:37:38,835][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 10:45:00,995][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 101: use 442.2585825920105 seconds\n","--- Optimizer learning rate changed from 1.21e-02 to 1.18e-02 ---\n","[2022-04-17 10:45:01,093][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:45:02,474][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 10:45:02,474][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:45:03,840][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 10:45:03,842][experiments.experiment][INFO] - [EMA] Epoch 101.[Train] time:442.2585825920105 seconds, lr:0.0118, train_loss: 0.2335, unlabeled_losses_real_strong:0.4187,corrrect_unlabeled_num:414544.0,pro_above_threshold_num:423636.0,unlabelled_weak_top1_acc:94.83816852420568,unlabelled_weak_top5_acc:99.82190867513418  \n","[2022-04-17 10:45:03,844][experiments.experiment][INFO] - [EMA] Epoch 101. [Validation] raw_testing_loss: 0.2634, raw test Top1 acc:92.7, raw test Top5 acc: 99.82, ema_testing_loss: 0.1990, ema test Top1 acc:95.08, ema test Top5 acc: 99.92\n","[2022-04-17 10:45:03,845][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 10:52:26,491][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 102: use 442.7442088127136 seconds\n","--- Optimizer learning rate changed from 1.18e-02 to 1.14e-02 ---\n","[2022-04-17 10:52:26,589][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:52:27,942][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 10:52:27,943][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:52:29,280][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 10:52:29,282][experiments.experiment][INFO] - [EMA] Epoch 102.[Train] time:442.7442088127136 seconds, lr:0.0114, train_loss: 0.2326, unlabeled_losses_real_strong:0.4160,corrrect_unlabeled_num:415152.0,pro_above_threshold_num:424260.0,unlabelled_weak_top1_acc:94.93015728145838,unlabelled_weak_top5_acc:99.81580514460802  \n","[2022-04-17 10:52:29,284][experiments.experiment][INFO] - [EMA] Epoch 102. [Validation] raw_testing_loss: 0.2808, raw test Top1 acc:92.7, raw test Top5 acc: 99.9, ema_testing_loss: 0.1948, ema test Top1 acc:95.34, ema test Top5 acc: 99.92\n","[2022-04-17 10:52:29,285][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 10:59:52,059][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 103: use 442.8832423686981 seconds\n","--- Optimizer learning rate changed from 1.14e-02 to 1.11e-02 ---\n","[2022-04-17 10:59:52,168][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:59:53,504][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 10:59:53,504][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:59:54,862][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 10:59:54,864][experiments.experiment][INFO] - [EMA] Epoch 103.[Train] time:442.8832423686981 seconds, lr:0.0111, train_loss: 0.2309, unlabeled_losses_real_strong:0.4124,corrrect_unlabeled_num:415638.0,pro_above_threshold_num:424885.0,unlabelled_weak_top1_acc:94.97375378012657,unlabelled_weak_top5_acc:99.80817572772503  \n","[2022-04-17 10:59:54,866][experiments.experiment][INFO] - [EMA] Epoch 103. [Validation] raw_testing_loss: 0.2826, raw test Top1 acc:92.52, raw test Top5 acc: 99.74, ema_testing_loss: 0.1954, ema test Top1 acc:95.04, ema test Top5 acc: 99.88\n","[2022-04-17 10:59:54,867][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 11:07:17,287][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 104: use 442.53801703453064 seconds\n","--- Optimizer learning rate changed from 1.11e-02 to 1.08e-02 ---\n","[2022-04-17 11:07:17,405][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:07:18,770][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 11:07:18,770][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:07:20,146][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 11:07:20,147][experiments.experiment][INFO] - [EMA] Epoch 104.[Train] time:442.53801703453064 seconds, lr:0.0108, train_loss: 0.2299, unlabeled_losses_real_strong:0.4090,corrrect_unlabeled_num:416011.0,pro_above_threshold_num:425279.0,unlabelled_weak_top1_acc:94.9866147339344,unlabelled_weak_top5_acc:99.81057353317738  \n","[2022-04-17 11:07:20,149][experiments.experiment][INFO] - [EMA] Epoch 104. [Validation] raw_testing_loss: 0.2333, raw test Top1 acc:93.46, raw test Top5 acc: 99.82, ema_testing_loss: 0.1955, ema test Top1 acc:94.92, ema test Top5 acc: 99.9\n","[2022-04-17 11:07:20,150][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 11:14:41,651][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 105: use 441.59894323349 seconds\n","--- Optimizer learning rate changed from 1.08e-02 to 1.05e-02 ---\n","[2022-04-17 11:14:41,749][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:14:43,125][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 11:14:43,125][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:14:44,522][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 11:14:44,523][experiments.experiment][INFO] - [EMA] Epoch 105.[Train] time:441.59894323349 seconds, lr:0.0105, train_loss: 0.2292, unlabeled_losses_real_strong:0.4062,corrrect_unlabeled_num:416678.0,pro_above_threshold_num:426066.0,unlabelled_weak_top1_acc:95.01233674585819,unlabelled_weak_top5_acc:99.81275337934494  \n","[2022-04-17 11:14:44,525][experiments.experiment][INFO] - [EMA] Epoch 105. [Validation] raw_testing_loss: 0.2976, raw test Top1 acc:91.6, raw test Top5 acc: 99.86, ema_testing_loss: 0.1883, ema test Top1 acc:95.14, ema test Top5 acc: 99.9\n","[2022-04-17 11:14:44,527][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 11:22:10,296][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 106: use 445.86601400375366 seconds\n","--- Optimizer learning rate changed from 1.05e-02 to 1.02e-02 ---\n","[2022-04-17 11:22:10,393][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:22:11,766][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 11:22:11,766][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:22:13,098][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 11:22:13,099][experiments.experiment][INFO] - [EMA] Epoch 106.[Train] time:445.86601400375366 seconds, lr:0.0102, train_loss: 0.2259, unlabeled_losses_real_strong:0.4032,corrrect_unlabeled_num:417223.0,pro_above_threshold_num:426621.0,unlabelled_weak_top1_acc:95.02890346944332,unlabelled_weak_top5_acc:99.80120023339987  \n","[2022-04-17 11:22:13,102][experiments.experiment][INFO] - [EMA] Epoch 106. [Validation] raw_testing_loss: 0.2543, raw test Top1 acc:93.1, raw test Top5 acc: 99.78, ema_testing_loss: 0.1873, ema test Top1 acc:95.2, ema test Top5 acc: 99.9\n","[2022-04-17 11:22:13,103][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 11:29:37,633][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 107: use 444.6263017654419 seconds\n","--- Optimizer learning rate changed from 1.02e-02 to 9.83e-03 ---\n","[2022-04-17 11:29:37,729][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:29:39,098][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 11:29:39,098][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:29:40,473][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 11:29:40,475][experiments.experiment][INFO] - [EMA] Epoch 107.[Train] time:444.6263017654419 seconds, lr:0.0098, train_loss: 0.2249, unlabeled_losses_real_strong:0.4014,corrrect_unlabeled_num:417953.0,pro_above_threshold_num:427375.0,unlabelled_weak_top1_acc:95.11500667780638,unlabelled_weak_top5_acc:99.81100954860449  \n","[2022-04-17 11:29:40,478][experiments.experiment][INFO] - [EMA] Epoch 107. [Validation] raw_testing_loss: 0.2459, raw test Top1 acc:93.02, raw test Top5 acc: 99.9, ema_testing_loss: 0.1897, ema test Top1 acc:95.26, ema test Top5 acc: 99.9\n","[2022-04-17 11:29:40,478][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 11:37:04,044][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 108: use 443.665646314621 seconds\n","--- Optimizer learning rate changed from 9.83e-03 to 9.50e-03 ---\n","[2022-04-17 11:37:04,144][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:37:05,500][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 11:37:05,500][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:37:06,859][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 11:37:06,860][experiments.experiment][INFO] - [EMA] Epoch 108.[Train] time:443.665646314621 seconds, lr:0.0095, train_loss: 0.2229, unlabeled_losses_real_strong:0.3978,corrrect_unlabeled_num:418359.0,pro_above_threshold_num:427674.0,unlabelled_weak_top1_acc:95.16165497153997,unlabelled_weak_top5_acc:99.8173310905695  \n","[2022-04-17 11:37:06,861][experiments.experiment][INFO] - [EMA] Epoch 108. [Validation] raw_testing_loss: 0.2511, raw test Top1 acc:93.24, raw test Top5 acc: 99.8, ema_testing_loss: 0.1911, ema test Top1 acc:95.22, ema test Top5 acc: 99.9\n","[2022-04-17 11:37:06,863][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 11:44:30,158][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 109: use 443.39010787010193 seconds\n","--- Optimizer learning rate changed from 9.50e-03 to 9.18e-03 ---\n","[2022-04-17 11:44:30,253][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:44:31,614][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 11:44:31,615][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:44:32,974][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 11:44:32,975][experiments.experiment][INFO] - [EMA] Epoch 109.[Train] time:443.39010787010193 seconds, lr:0.0092, train_loss: 0.2203, unlabeled_losses_real_strong:0.3931,corrrect_unlabeled_num:419134.0,pro_above_threshold_num:428647.0,unlabelled_weak_top1_acc:95.17342588305473,unlabelled_weak_top5_acc:99.82430645823479  \n","[2022-04-17 11:44:32,977][experiments.experiment][INFO] - [EMA] Epoch 109. [Validation] raw_testing_loss: 0.2721, raw test Top1 acc:92.82, raw test Top5 acc: 99.86, ema_testing_loss: 0.1923, ema test Top1 acc:95.36, ema test Top5 acc: 99.88\n","[2022-04-17 11:44:32,978][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 11:51:55,937][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 110: use 443.0559422969818 seconds\n","--- Optimizer learning rate changed from 9.18e-03 to 8.85e-03 ---\n","[2022-04-17 11:51:56,034][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:51:57,418][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 11:51:57,418][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:51:58,744][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 11:51:58,746][experiments.experiment][INFO] - [EMA] Epoch 110.[Train] time:443.0559422969818 seconds, lr:0.0088, train_loss: 0.2185, unlabeled_losses_real_strong:0.3907,corrrect_unlabeled_num:419187.0,pro_above_threshold_num:428841.0,unlabelled_weak_top1_acc:95.17015624046326,unlabelled_weak_top5_acc:99.81188145279884  \n","[2022-04-17 11:51:58,748][experiments.experiment][INFO] - [EMA] Epoch 110. [Validation] raw_testing_loss: 0.2655, raw test Top1 acc:93.18, raw test Top5 acc: 99.78, ema_testing_loss: 0.1928, ema test Top1 acc:95.28, ema test Top5 acc: 99.86\n","[2022-04-17 11:51:58,749][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 11:59:23,026][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 111: use 444.3748116493225 seconds\n","--- Optimizer learning rate changed from 8.85e-03 to 8.52e-03 ---\n","[2022-04-17 11:59:23,124][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:59:24,478][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 11:59:24,478][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:59:25,824][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 11:59:25,826][experiments.experiment][INFO] - [EMA] Epoch 111.[Train] time:444.3748116493225 seconds, lr:0.0085, train_loss: 0.2160, unlabeled_losses_real_strong:0.3860,corrrect_unlabeled_num:420009.0,pro_above_threshold_num:429542.0,unlabelled_weak_top1_acc:95.23794877529144,unlabelled_weak_top5_acc:99.81558717787266  \n","[2022-04-17 11:59:25,829][experiments.experiment][INFO] - [EMA] Epoch 111. [Validation] raw_testing_loss: 0.2380, raw test Top1 acc:93.54, raw test Top5 acc: 99.84, ema_testing_loss: 0.1851, ema test Top1 acc:95.3, ema test Top5 acc: 99.86\n","[2022-04-17 11:59:25,829][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 12:06:48,018][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 112: use 442.2871904373169 seconds\n","--- Optimizer learning rate changed from 8.52e-03 to 8.19e-03 ---\n","[2022-04-17 12:06:48,117][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:06:49,469][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 12:06:49,470][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:06:50,841][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 12:06:50,843][experiments.experiment][INFO] - [EMA] Epoch 112.[Train] time:442.2871904373169 seconds, lr:0.0082, train_loss: 0.2147, unlabeled_losses_real_strong:0.3840,corrrect_unlabeled_num:420596.0,pro_above_threshold_num:430309.0,unlabelled_weak_top1_acc:95.26977436989546,unlabelled_weak_top5_acc:99.82430642843246  \n","[2022-04-17 12:06:50,844][experiments.experiment][INFO] - [EMA] Epoch 112. [Validation] raw_testing_loss: 0.2222, raw test Top1 acc:94.16, raw test Top5 acc: 99.88, ema_testing_loss: 0.1838, ema test Top1 acc:95.58, ema test Top5 acc: 99.88\n","[2022-04-17 12:06:50,845][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 12:14:13,779][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 113: use 443.0321514606476 seconds\n","--- Optimizer learning rate changed from 8.19e-03 to 7.86e-03 ---\n","[2022-04-17 12:14:13,878][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:14:15,240][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 12:14:15,241][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:14:16,606][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 12:14:16,607][experiments.experiment][INFO] - [EMA] Epoch 113.[Train] time:443.0321514606476 seconds, lr:0.0079, train_loss: 0.2132, unlabeled_losses_real_strong:0.3808,corrrect_unlabeled_num:420686.0,pro_above_threshold_num:430346.0,unlabelled_weak_top1_acc:95.30377962440252,unlabelled_weak_top5_acc:99.81929282844067  \n","[2022-04-17 12:14:16,610][experiments.experiment][INFO] - [EMA] Epoch 113. [Validation] raw_testing_loss: 0.2473, raw test Top1 acc:93.68, raw test Top5 acc: 99.88, ema_testing_loss: 0.1850, ema test Top1 acc:95.32, ema test Top5 acc: 99.9\n","[2022-04-17 12:14:16,611][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 12:21:40,342][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 114: use 443.8299548625946 seconds\n","--- Optimizer learning rate changed from 7.86e-03 to 7.53e-03 ---\n","[2022-04-17 12:21:40,441][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:21:41,779][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 12:21:41,779][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:21:43,146][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 12:21:43,147][experiments.experiment][INFO] - [EMA] Epoch 114.[Train] time:443.8299548625946 seconds, lr:0.0075, train_loss: 0.2104, unlabeled_losses_real_strong:0.3777,corrrect_unlabeled_num:421554.0,pro_above_threshold_num:431321.0,unlabelled_weak_top1_acc:95.31293492764235,unlabelled_weak_top5_acc:99.80708582699299  \n","[2022-04-17 12:21:43,149][experiments.experiment][INFO] - [EMA] Epoch 114. [Validation] raw_testing_loss: 0.2255, raw test Top1 acc:93.76, raw test Top5 acc: 99.94, ema_testing_loss: 0.1832, ema test Top1 acc:95.36, ema test Top5 acc: 99.92\n","[2022-04-17 12:21:43,150][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 12:29:07,822][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 115: use 444.7788882255554 seconds\n","--- Optimizer learning rate changed from 7.53e-03 to 7.19e-03 ---\n","[2022-04-17 12:29:07,929][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:29:09,273][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 12:29:09,273][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:29:10,666][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 12:29:10,667][experiments.experiment][INFO] - [EMA] Epoch 115.[Train] time:444.7788882255554 seconds, lr:0.0072, train_loss: 0.2070, unlabeled_losses_real_strong:0.3727,corrrect_unlabeled_num:422312.0,pro_above_threshold_num:432088.0,unlabelled_weak_top1_acc:95.38661298155785,unlabelled_weak_top5_acc:99.82321650534868  \n","[2022-04-17 12:29:10,670][experiments.experiment][INFO] - [EMA] Epoch 115. [Validation] raw_testing_loss: 0.2208, raw test Top1 acc:93.88, raw test Top5 acc: 99.88, ema_testing_loss: 0.1801, ema test Top1 acc:95.3, ema test Top5 acc: 99.88\n","[2022-04-17 12:29:10,671][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 12:36:34,574][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 116: use 444.00203585624695 seconds\n","--- Optimizer learning rate changed from 7.19e-03 to 6.86e-03 ---\n","[2022-04-17 12:36:34,673][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:36:36,087][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 12:36:36,088][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:36:37,488][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 12:36:37,490][experiments.experiment][INFO] - [EMA] Epoch 116.[Train] time:444.00203585624695 seconds, lr:0.0069, train_loss: 0.2063, unlabeled_losses_real_strong:0.3706,corrrect_unlabeled_num:423047.0,pro_above_threshold_num:432925.0,unlabelled_weak_top1_acc:95.4249779433012,unlabelled_weak_top5_acc:99.8208187520504  \n","[2022-04-17 12:36:37,493][experiments.experiment][INFO] - [EMA] Epoch 116. [Validation] raw_testing_loss: 0.2121, raw test Top1 acc:94.16, raw test Top5 acc: 99.86, ema_testing_loss: 0.1824, ema test Top1 acc:95.42, ema test Top5 acc: 99.88\n","[2022-04-17 12:36:37,493][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 12:44:00,644][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 117: use 443.2480592727661 seconds\n","--- Optimizer learning rate changed from 6.86e-03 to 6.53e-03 ---\n","[2022-04-17 12:44:00,742][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:44:02,081][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 12:44:02,082][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:44:03,418][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 12:44:03,420][experiments.experiment][INFO] - [EMA] Epoch 117.[Train] time:443.2480592727661 seconds, lr:0.0065, train_loss: 0.2034, unlabeled_losses_real_strong:0.3684,corrrect_unlabeled_num:423252.0,pro_above_threshold_num:433187.0,unlabelled_weak_top1_acc:95.47271630167961,unlabelled_weak_top5_acc:99.81493316590786  \n","[2022-04-17 12:44:03,421][experiments.experiment][INFO] - [EMA] Epoch 117. [Validation] raw_testing_loss: 0.2310, raw test Top1 acc:93.68, raw test Top5 acc: 99.9, ema_testing_loss: 0.1767, ema test Top1 acc:95.42, ema test Top5 acc: 99.9\n","[2022-04-17 12:44:03,423][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 12:51:27,270][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 118: use 443.96107149124146 seconds\n","--- Optimizer learning rate changed from 6.53e-03 to 6.19e-03 ---\n","[2022-04-17 12:51:27,384][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:51:28,753][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 12:51:28,753][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:51:30,120][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 12:51:30,122][experiments.experiment][INFO] - [EMA] Epoch 118.[Train] time:443.96107149124146 seconds, lr:0.0062, train_loss: 0.1997, unlabeled_losses_real_strong:0.3621,corrrect_unlabeled_num:423396.0,pro_above_threshold_num:433313.0,unlabelled_weak_top1_acc:95.48928295075893,unlabelled_weak_top5_acc:99.8286661207676  \n","[2022-04-17 12:51:30,125][experiments.experiment][INFO] - [EMA] Epoch 118. [Validation] raw_testing_loss: 0.2125, raw test Top1 acc:93.88, raw test Top5 acc: 99.86, ema_testing_loss: 0.1738, ema test Top1 acc:95.48, ema test Top5 acc: 99.94\n","[2022-04-17 12:51:30,126][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 12:58:53,494][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 119: use 443.46691250801086 seconds\n","--- Optimizer learning rate changed from 6.19e-03 to 5.85e-03 ---\n","[2022-04-17 12:58:53,593][experiments.experiment][INFO] - ***** Running validation *****\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-17 12:58:54,967][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 12:58:54,967][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:58:56,311][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 12:58:56,313][experiments.experiment][INFO] - [EMA] Epoch 119.[Train] time:443.46691250801086 seconds, lr:0.0059, train_loss: 0.1992, unlabeled_losses_real_strong:0.3595,corrrect_unlabeled_num:424438.0,pro_above_threshold_num:434470.0,unlabelled_weak_top1_acc:95.52328822761774,unlabelled_weak_top5_acc:99.82932005822659  \n","[2022-04-17 12:58:56,314][experiments.experiment][INFO] - [EMA] Epoch 119. [Validation] raw_testing_loss: 0.2027, raw test Top1 acc:94.06, raw test Top5 acc: 99.84, ema_testing_loss: 0.1693, ema test Top1 acc:95.54, ema test Top5 acc: 99.94\n","======= Training done =======\n","2022-04-17 12:58:56,347 - INFO - Train -   ======= Training done =======\n","[2022-04-17 12:58:56,347][Train][INFO] - ======= Training done =======\n","[2022-04-17 12:58:56,348][experiments.experiment][INFO] - Loading Testing Loader\n","[2022-04-17 12:58:56,356][experiments.experiment][INFO] - [Testing with EMA] apply shadow\n","[2022-04-17 12:58:56,356][experiments.experiment][INFO] - ***** Running testing *****\n","[2022-04-17 12:58:58,753][experiments.experiment][INFO] - [Testing(EMA)] testing_loss: 0.1838, test Top1 acc:95.03, test Top5 acc: 99.84\n","[2022-04-17 12:58:58,759][experiments.experiment][INFO] - [EMA] restore \n","======= Testing done =======\n","2022-04-17 12:58:58,759 - INFO - Train -   ======= Testing done =======\n","[2022-04-17 12:58:58,759][Train][INFO] - ======= Testing done =======\n"]}]},{"cell_type":"code","source":["%pip install -r google_requirements.txt\n","!python run.py DATASET.label_num=4000 DATASET.strongaugment='RA' EXPERIMENT.epoch_n=120 EXPERIMENT.batch_size=64 MODEL.name='WideResNet_Lk' MODEL.depth=28 MODEL.widen_factor=2 MODEL.num_classes=10 EXPERIMENT.out_model='./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/' EXPERIMENT.log_path='./outputs/outputs_celiali-wideresnet-120epochs-64batch-ema099/' EXPERIMENT.save_cfmatrix=False EXPERIMENT.decay_type='cosine' EXPERIMENT.ema_decay=0.99"],"metadata":{"id":"CitjVmEjrLWF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"279ea25b-3c99-4e3a-c2c9-5ca552d0f902"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 2)) (1.0.0)\n","Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 3)) (1.9)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 4)) (0.29.28)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 5)) (1.21.5)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 7)) (4.64.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 8)) (1.4.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 9)) (7.1.2)\n","Requirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 10)) (1.8.0)\n","Requirement already satisfied: torchvision==0.9.0 in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 11)) (0.9.0)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 12)) (0.8.0)\n","Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 13)) (0.9.0)\n","Requirement already satisfied: omegaconf in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 14)) (2.1.2)\n","Requirement already satisfied: hydra in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 15)) (2.5)\n","Requirement already satisfied: hydra-core in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 16)) (1.1.2)\n","Requirement already satisfied: ignite in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 17)) (1.1.0)\n","Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 18)) (0.4.8)\n","Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 19)) (2.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 20)) (1.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 21)) (3.2.2)\n","Requirement already satisfied: abel-pytorch in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 22)) (0.0.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r google_requirements.txt (line 10)) (4.1.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->-r google_requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.44.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.24.0)\n","Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.8.0.dev2021122109)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.14.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.1.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (57.4.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.3.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (13.0.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.2.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.5.3)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.6.3)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.1.2)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.17.3)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->-r google_requirements.txt (line 6)) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->-r google_requirements.txt (line 6)) (1.5.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.3.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.6.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.0.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.35.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2.23.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.2.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from omegaconf->-r google_requirements.txt (line 14)) (4.8)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf->-r google_requirements.txt (line 14)) (6.0)\n","Requirement already satisfied: importlib-resources<5.3 in /usr/local/lib/python3.7/dist-packages (from hydra-core->-r google_requirements.txt (line 16)) (5.2.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r google_requirements.txt (line 20)) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r google_requirements.txt (line 20)) (1.1.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (1.4.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (3.0.8)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (0.11.0)\n","==> CONFIG is: \n"," DATASET:\n","  project_dir: ./\n","  data_dir: data\n","  loading_data: LOAD_LABEL_UNLABEL\n","  dataset: CIFAR10\n","  strongaugment: RA\n","  label_num: 4000\n","  num_expand_x: 65536\n","  mu: 7\n","  barely: false\n","  add_noisy_label: false\n","  both_strong: false\n","MODEL:\n","  name: WideResNet_Lk\n","  depth: 28\n","  widen_factor: 2\n","  num_classes: 10\n","  dropout: 0.0\n","  cardinality: 4\n","  width: 4\n","  base_width: 4\n","EXPERIMENT:\n","  name: FMExperiment\n","  out_model: ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/\n","  log_path: ./outputs/outputs_celiali-wideresnet-120epochs-64batch-ema099/\n","  used_gpu: true\n","  use_cosine: true\n","  use_abel: false\n","  abel_decay: 0.1\n","  optim_lr: 0.03\n","  optim_momentum: 0.9\n","  used_nesterov: true\n","  warmup: 0\n","  wdecay: 0.0005\n","  clip: 1\n","  ema_used: true\n","  ema_decay: 0.99\n","  threshold: 0.95\n","  lambda_unlabeled: 1\n","  batch_size: 64\n","  num_workers: 4\n","  n_imgs_per_epoch: 65536\n","  epoch_n: 120\n","  save_every: 2\n","  save_matrix_every: 20\n","  resume: false\n","  resume_checkpoints: ./checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar\n","  save_cfmatrix: false\n","  batch_balanced: false\n","  neg_penalty: false\n","  equal_freq: false\n","  eta_negpenalty: 0.05\n","  eta_dynamic: false\n","  use_nlloss: false\n","  q: 0.0001\n","Logging:\n","  name: FM\n","  seed: 1265\n"," \n","\n","2022-04-17 21:39:47,803 - INFO - Train -   {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/', 'log_path': './outputs/outputs_celiali-wideresnet-120epochs-64batch-ema099/', 'used_gpu': True, 'use_cosine': True, 'use_abel': False, 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.99, 'threshold': 0.95, 'lambda_unlabeled': 1, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': False, 'resume_checkpoints': './checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","[2022-04-17 21:39:47,803][Train][INFO] - {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/', 'log_path': './outputs/outputs_celiali-wideresnet-120epochs-64batch-ema099/', 'used_gpu': True, 'use_cosine': True, 'use_abel': False, 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.99, 'threshold': 0.95, 'lambda_unlabeled': 1, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': False, 'resume_checkpoints': './checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","2022-04-17 21:39:48,238 - INFO - Train -   [Model] Building model WideResNet_Lk\n","[2022-04-17 21:39:48,238][Train][INFO] - [Model] Building model WideResNet_Lk\n","2022-04-17 21:39:50,880 - INFO - Train -   Total params: 1.47M\n","[2022-04-17 21:39:50,880][Train][INFO] - Total params: 1.47M\n","[2022-04-17 21:39:50,881][experiments.experiment][INFO] - I'm using cosine decay!\n","[2022-04-17 21:39:50,884][experiments.experiment][INFO] - [EMA] initial \n","[2022-04-17 21:39:57,851][datasets.datasets1][INFO] - Dataset: CIFAR10\n","[2022-04-17 21:39:57,905][datasets.datasets1][INFO] - Labeled examples: 65536 Unlabeled examples: 458752Validation examples: 5000\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-17 21:39:57,907][experiments.experiment][INFO] - Loading Labelled Loader\n","[2022-04-17 21:39:57,907][experiments.experiment][INFO] - Loading Unlabelled Loader\n","[2022-04-17 21:39:57,907][experiments.experiment][INFO] - Loading Validation Loader\n","[2022-04-17 21:39:57,917][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 21:47:32,956][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 0: use 455.13335371017456 seconds\n","--- Optimizer learning rate changed from inf to 3.00e-02 ---\n","[2022-04-17 21:47:33,051][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 21:47:34,400][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 21:47:34,401][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 21:47:35,738][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 21:47:35,814][experiments.experiment][INFO] - [EMA] Epoch 0.[Train] time:455.13335371017456 seconds, lr:0.0300, train_loss: 1.2566, unlabeled_losses_real_strong:2.0060,corrrect_unlabeled_num:22387.0,pro_above_threshold_num:23635.0,unlabelled_weak_top1_acc:51.07618001755327,unlabelled_weak_top5_acc:92.7871693558991  \n","[2022-04-17 21:47:35,815][experiments.experiment][INFO] - [EMA] Epoch 0. [Validation] raw_testing_loss: 1.5782, raw test Top1 acc:44.66, raw test Top5 acc: 91.78, ema_testing_loss: 1.4923, ema test Top1 acc:46.46, ema test Top5 acc: 91.8\n","[2022-04-17 21:47:35,908][experiments.experiment][INFO] - [Checkpoints] Epoch 0, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_0.pth.tar\n","[2022-04-17 21:47:35,909][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 21:55:13,539][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 1: use 457.728214263916 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-17 21:55:13,638][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 21:55:14,981][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 21:55:14,981][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 21:55:16,335][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 21:55:16,337][experiments.experiment][INFO] - [EMA] Epoch 1.[Train] time:457.728214263916 seconds, lr:0.0300, train_loss: 0.8507, unlabeled_losses_real_strong:1.8131,corrrect_unlabeled_num:108140.0,pro_above_threshold_num:114816.0,unlabelled_weak_top1_acc:64.68571170791984,unlabelled_weak_top5_acc:96.54649892449379  \n","[2022-04-17 21:55:16,337][experiments.experiment][INFO] - [EMA] Epoch 1. [Validation] raw_testing_loss: 2.9676, raw test Top1 acc:21.2, raw test Top5 acc: 75.12, ema_testing_loss: 2.1368, ema test Top1 acc:36.7, ema test Top5 acc: 80.02\n","[2022-04-17 21:55:16,429][experiments.experiment][INFO] - [Checkpoints] Epoch 1, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_1.pth.tar\n","[2022-04-17 21:55:16,430][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 22:02:48,904][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 2: use 452.5709397792816 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-17 22:02:49,001][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:02:50,346][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 22:02:50,346][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:02:51,701][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 22:02:51,702][experiments.experiment][INFO] - [EMA] Epoch 2.[Train] time:452.5709397792816 seconds, lr:0.0300, train_loss: 0.7097, unlabeled_losses_real_strong:1.6157,corrrect_unlabeled_num:171531.0,pro_above_threshold_num:185131.0,unlabelled_weak_top1_acc:69.59664373844862,unlabelled_weak_top5_acc:97.36524198949337  \n","[2022-04-17 22:02:51,703][experiments.experiment][INFO] - [EMA] Epoch 2. [Validation] raw_testing_loss: 3.0746, raw test Top1 acc:25.14, raw test Top5 acc: 74.84, ema_testing_loss: 2.4902, ema test Top1 acc:33.66, ema test Top5 acc: 82.66\n","[2022-04-17 22:02:51,704][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 22:10:22,786][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 3: use 451.17604994773865 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-17 22:10:22,880][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:10:24,217][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 22:10:24,218][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:10:25,559][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 22:10:25,560][experiments.experiment][INFO] - [EMA] Epoch 3.[Train] time:451.17604994773865 seconds, lr:0.0300, train_loss: 0.6341, unlabeled_losses_real_strong:1.4566,corrrect_unlabeled_num:215849.0,pro_above_threshold_num:234077.0,unlabelled_weak_top1_acc:73.36011508852243,unlabelled_weak_top5_acc:97.88469485193491  \n","[2022-04-17 22:10:25,562][experiments.experiment][INFO] - [EMA] Epoch 3. [Validation] raw_testing_loss: 2.2326, raw test Top1 acc:33.38, raw test Top5 acc: 87.68, ema_testing_loss: 2.1990, ema test Top1 acc:39.94, ema test Top5 acc: 87.52\n","[2022-04-17 22:10:25,650][experiments.experiment][INFO] - [Checkpoints] Epoch 3, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_3.pth.tar\n","[2022-04-17 22:10:25,651][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 22:17:52,720][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 4: use 447.17082834243774 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-17 22:17:52,821][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:17:54,157][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 22:17:54,158][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:17:55,471][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 22:17:55,473][experiments.experiment][INFO] - [EMA] Epoch 4.[Train] time:447.17082834243774 seconds, lr:0.0300, train_loss: 0.5914, unlabeled_losses_real_strong:1.3559,corrrect_unlabeled_num:241594.0,pro_above_threshold_num:261424.0,unlabelled_weak_top1_acc:75.76642606407404,unlabelled_weak_top5_acc:98.23630095273256  \n","[2022-04-17 22:17:55,475][experiments.experiment][INFO] - [EMA] Epoch 4. [Validation] raw_testing_loss: 2.1052, raw test Top1 acc:47.78, raw test Top5 acc: 88.6, ema_testing_loss: 1.5997, ema test Top1 acc:56.32, ema test Top5 acc: 93.74\n","[2022-04-17 22:17:55,476][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 22:25:20,912][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 5: use 445.5320131778717 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 2.99e-02 ---\n","[2022-04-17 22:25:21,008][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:25:22,359][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 22:25:22,359][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:25:23,692][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 22:25:23,694][experiments.experiment][INFO] - [EMA] Epoch 5.[Train] time:445.5320131778717 seconds, lr:0.0299, train_loss: 0.5547, unlabeled_losses_real_strong:1.2585,corrrect_unlabeled_num:261305.0,pro_above_threshold_num:281240.0,unlabelled_weak_top1_acc:77.8832561224699,unlabelled_weak_top5_acc:98.45689949393272  \n","[2022-04-17 22:25:23,696][experiments.experiment][INFO] - [EMA] Epoch 5. [Validation] raw_testing_loss: 1.9115, raw test Top1 acc:50.0, raw test Top5 acc: 93.42, ema_testing_loss: 1.4312, ema test Top1 acc:60.62, ema test Top5 acc: 95.54\n","[2022-04-17 22:25:23,786][experiments.experiment][INFO] - [Checkpoints] Epoch 5, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_5.pth.tar\n","[2022-04-17 22:25:23,786][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 22:32:51,426][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 6: use 447.741215467453 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.99e-02 ---\n","[2022-04-17 22:32:51,528][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:32:52,917][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 22:32:52,917][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:32:54,319][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 22:32:54,321][experiments.experiment][INFO] - [EMA] Epoch 6.[Train] time:447.741215467453 seconds, lr:0.0299, train_loss: 0.5209, unlabeled_losses_real_strong:1.1803,corrrect_unlabeled_num:277626.0,pro_above_threshold_num:297301.0,unlabelled_weak_top1_acc:79.70559151470661,unlabelled_weak_top5_acc:98.66354679316282  \n","[2022-04-17 22:32:54,322][experiments.experiment][INFO] - [EMA] Epoch 6. [Validation] raw_testing_loss: 2.4241, raw test Top1 acc:45.38, raw test Top5 acc: 93.7, ema_testing_loss: 1.4204, ema test Top1 acc:63.12, ema test Top5 acc: 94.94\n","[2022-04-17 22:32:54,324][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 22:40:20,941][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 7: use 446.7127876281738 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.99e-02 ---\n","[2022-04-17 22:40:21,036][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:40:22,388][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 22:40:22,389][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:40:23,706][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 22:40:23,707][experiments.experiment][INFO] - [EMA] Epoch 7.[Train] time:446.7127876281738 seconds, lr:0.0299, train_loss: 0.4981, unlabeled_losses_real_strong:1.1183,corrrect_unlabeled_num:288417.0,pro_above_threshold_num:307459.0,unlabelled_weak_top1_acc:80.96880117058754,unlabelled_weak_top5_acc:98.79782393574715  \n","[2022-04-17 22:40:23,711][experiments.experiment][INFO] - [EMA] Epoch 7. [Validation] raw_testing_loss: 1.8370, raw test Top1 acc:56.86, raw test Top5 acc: 95.92, ema_testing_loss: 0.8090, ema test Top1 acc:76.08, ema test Top5 acc: 98.06\n","[2022-04-17 22:40:23,802][experiments.experiment][INFO] - [Checkpoints] Epoch 7, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_7.pth.tar\n","[2022-04-17 22:40:23,803][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 22:47:49,588][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 8: use 445.8786563873291 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.98e-02 ---\n","[2022-04-17 22:47:49,682][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:47:51,000][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 22:47:51,000][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:47:52,335][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 22:47:52,336][experiments.experiment][INFO] - [EMA] Epoch 8.[Train] time:445.8786563873291 seconds, lr:0.0298, train_loss: 0.4765, unlabeled_losses_real_strong:1.0684,corrrect_unlabeled_num:298119.0,pro_above_threshold_num:316611.0,unlabelled_weak_top1_acc:81.99157614260912,unlabelled_weak_top5_acc:98.93275513499975  \n","[2022-04-17 22:47:52,338][experiments.experiment][INFO] - [EMA] Epoch 8. [Validation] raw_testing_loss: 0.7308, raw test Top1 acc:76.46, raw test Top5 acc: 98.66, ema_testing_loss: 0.7251, ema test Top1 acc:78.74, ema test Top5 acc: 98.6\n","[2022-04-17 22:47:52,339][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 22:55:16,821][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 9: use 444.58571767807007 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.98e-02 ---\n","[2022-04-17 22:55:16,925][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:55:18,245][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 22:55:18,246][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:55:19,563][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 22:55:19,565][experiments.experiment][INFO] - [EMA] Epoch 9.[Train] time:444.58571767807007 seconds, lr:0.0298, train_loss: 0.4592, unlabeled_losses_real_strong:1.0181,corrrect_unlabeled_num:306729.0,pro_above_threshold_num:324709.0,unlabelled_weak_top1_acc:83.02525006979704,unlabelled_weak_top5_acc:99.0073052868247  \n","[2022-04-17 22:55:19,566][experiments.experiment][INFO] - [EMA] Epoch 9. [Validation] raw_testing_loss: 1.5818, raw test Top1 acc:61.54, raw test Top5 acc: 94.86, ema_testing_loss: 0.8543, ema test Top1 acc:76.26, ema test Top5 acc: 98.04\n","[2022-04-17 22:55:19,654][experiments.experiment][INFO] - [Checkpoints] Epoch 9, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_9.pth.tar\n","[2022-04-17 22:55:19,655][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 23:02:44,217][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 10: use 444.662437915802 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.98e-02 ---\n","[2022-04-17 23:02:44,317][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:02:45,663][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 23:02:45,663][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:02:47,052][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 23:02:47,054][experiments.experiment][INFO] - [EMA] Epoch 10.[Train] time:444.662437915802 seconds, lr:0.0298, train_loss: 0.4438, unlabeled_losses_real_strong:0.9842,corrrect_unlabeled_num:313071.0,pro_above_threshold_num:330555.0,unlabelled_weak_top1_acc:83.74066918343306,unlabelled_weak_top5_acc:99.09994791448116  \n","[2022-04-17 23:02:47,055][experiments.experiment][INFO] - [EMA] Epoch 10. [Validation] raw_testing_loss: 0.9949, raw test Top1 acc:73.58, raw test Top5 acc: 97.78, ema_testing_loss: 0.5592, ema test Top1 acc:83.58, ema test Top5 acc: 99.12\n","[2022-04-17 23:02:47,056][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 23:10:20,693][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 11: use 453.73438358306885 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.97e-02 ---\n","[2022-04-17 23:10:20,790][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:10:22,194][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 23:10:22,194][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:10:23,578][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 23:10:23,580][experiments.experiment][INFO] - [EMA] Epoch 11.[Train] time:453.73438358306885 seconds, lr:0.0297, train_loss: 0.4297, unlabeled_losses_real_strong:0.9477,corrrect_unlabeled_num:319850.0,pro_above_threshold_num:336910.0,unlabelled_weak_top1_acc:84.52933054417372,unlabelled_weak_top5_acc:99.14005667716265  \n","[2022-04-17 23:10:23,582][experiments.experiment][INFO] - [EMA] Epoch 11. [Validation] raw_testing_loss: 0.8623, raw test Top1 acc:77.34, raw test Top5 acc: 98.6, ema_testing_loss: 0.5079, ema test Top1 acc:84.62, ema test Top5 acc: 99.46\n","[2022-04-17 23:10:23,689][experiments.experiment][INFO] - [Checkpoints] Epoch 11, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_11.pth.tar\n","[2022-04-17 23:10:23,690][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 23:17:58,302][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 12: use 454.7234923839569 seconds\n","--- Optimizer learning rate changed from 2.97e-02 to 2.97e-02 ---\n","[2022-04-17 23:17:58,413][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:17:59,754][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 23:17:59,755][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:18:01,095][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 23:18:01,096][experiments.experiment][INFO] - [EMA] Epoch 12.[Train] time:454.7234923839569 seconds, lr:0.0297, train_loss: 0.4161, unlabeled_losses_real_strong:0.9151,corrrect_unlabeled_num:325115.0,pro_above_threshold_num:341358.0,unlabelled_weak_top1_acc:85.22382359951735,unlabelled_weak_top5_acc:99.20022002607584  \n","[2022-04-17 23:18:01,097][experiments.experiment][INFO] - [EMA] Epoch 12. [Validation] raw_testing_loss: 1.1551, raw test Top1 acc:74.62, raw test Top5 acc: 97.9, ema_testing_loss: 0.5143, ema test Top1 acc:85.94, ema test Top5 acc: 99.44\n","[2022-04-17 23:18:01,099][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 23:25:32,712][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 13: use 451.7144515514374 seconds\n","--- Optimizer learning rate changed from 2.97e-02 to 2.96e-02 ---\n","[2022-04-17 23:25:32,813][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:25:34,182][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 23:25:34,182][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:25:35,547][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 23:25:35,549][experiments.experiment][INFO] - [EMA] Epoch 13.[Train] time:451.7144515514374 seconds, lr:0.0296, train_loss: 0.4041, unlabeled_losses_real_strong:0.8865,corrrect_unlabeled_num:330550.0,pro_above_threshold_num:346640.0,unlabelled_weak_top1_acc:85.77640973776579,unlabelled_weak_top5_acc:99.22289031744003  \n","[2022-04-17 23:25:35,551][experiments.experiment][INFO] - [EMA] Epoch 13. [Validation] raw_testing_loss: 0.6996, raw test Top1 acc:80.78, raw test Top5 acc: 99.1, ema_testing_loss: 0.4917, ema test Top1 acc:86.58, ema test Top5 acc: 99.36\n","[2022-04-17 23:25:35,645][experiments.experiment][INFO] - [Checkpoints] Epoch 13, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_13.pth.tar\n","[2022-04-17 23:25:35,646][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 23:33:05,381][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 14: use 449.835875749588 seconds\n","--- Optimizer learning rate changed from 2.96e-02 to 2.96e-02 ---\n","[2022-04-17 23:33:05,482][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:33:06,897][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 23:33:06,897][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:33:08,252][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 23:33:08,254][experiments.experiment][INFO] - [EMA] Epoch 14.[Train] time:449.835875749588 seconds, lr:0.0296, train_loss: 0.3940, unlabeled_losses_real_strong:0.8612,corrrect_unlabeled_num:335516.0,pro_above_threshold_num:351190.0,unlabelled_weak_top1_acc:86.31853276491165,unlabelled_weak_top5_acc:99.28261752426624  \n","[2022-04-17 23:33:08,257][experiments.experiment][INFO] - [EMA] Epoch 14. [Validation] raw_testing_loss: 0.7100, raw test Top1 acc:80.58, raw test Top5 acc: 98.6, ema_testing_loss: 0.4911, ema test Top1 acc:86.28, ema test Top5 acc: 99.54\n","[2022-04-17 23:33:08,257][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 23:40:38,473][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 15: use 450.31716322898865 seconds\n","--- Optimizer learning rate changed from 2.96e-02 to 2.95e-02 ---\n","[2022-04-17 23:40:38,574][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:40:39,946][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 23:40:39,946][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:40:41,288][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 23:40:41,290][experiments.experiment][INFO] - [EMA] Epoch 15.[Train] time:450.31716322898865 seconds, lr:0.0295, train_loss: 0.3885, unlabeled_losses_real_strong:0.8427,corrrect_unlabeled_num:338347.0,pro_above_threshold_num:353627.0,unlabelled_weak_top1_acc:86.71853099763393,unlabelled_weak_top5_acc:99.33188193291426  \n","[2022-04-17 23:40:41,291][experiments.experiment][INFO] - [EMA] Epoch 15. [Validation] raw_testing_loss: 0.7339, raw test Top1 acc:80.36, raw test Top5 acc: 98.34, ema_testing_loss: 0.4307, ema test Top1 acc:87.66, ema test Top5 acc: 99.46\n","[2022-04-17 23:40:41,378][experiments.experiment][INFO] - [Checkpoints] Epoch 15, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_15.pth.tar\n","[2022-04-17 23:40:41,379][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 23:48:11,239][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 16: use 449.9639525413513 seconds\n","--- Optimizer learning rate changed from 2.95e-02 to 2.94e-02 ---\n","[2022-04-17 23:48:11,343][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:48:12,683][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 23:48:12,683][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:48:14,023][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 23:48:14,025][experiments.experiment][INFO] - [EMA] Epoch 16.[Train] time:449.9639525413513 seconds, lr:0.0294, train_loss: 0.3815, unlabeled_losses_real_strong:0.8214,corrrect_unlabeled_num:343588.0,pro_above_threshold_num:358620.0,unlabelled_weak_top1_acc:87.2512807995081,unlabelled_weak_top5_acc:99.35825800895691  \n","[2022-04-17 23:48:14,027][experiments.experiment][INFO] - [EMA] Epoch 16. [Validation] raw_testing_loss: 0.6488, raw test Top1 acc:81.84, raw test Top5 acc: 98.34, ema_testing_loss: 0.4207, ema test Top1 acc:88.06, ema test Top5 acc: 99.62\n","[2022-04-17 23:48:14,028][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 23:55:42,851][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 17: use 448.92143177986145 seconds\n","--- Optimizer learning rate changed from 2.94e-02 to 2.94e-02 ---\n","[2022-04-17 23:55:42,949][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:55:44,294][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 23:55:44,295][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:55:45,629][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 23:55:45,630][experiments.experiment][INFO] - [EMA] Epoch 17.[Train] time:448.92143177986145 seconds, lr:0.0294, train_loss: 0.3755, unlabeled_losses_real_strong:0.8052,corrrect_unlabeled_num:346078.0,pro_above_threshold_num:360703.0,unlabelled_weak_top1_acc:87.55514862388372,unlabelled_weak_top5_acc:99.37526046484709  \n","[2022-04-17 23:55:45,634][experiments.experiment][INFO] - [EMA] Epoch 17. [Validation] raw_testing_loss: 0.7041, raw test Top1 acc:82.26, raw test Top5 acc: 99.24, ema_testing_loss: 0.4391, ema test Top1 acc:88.02, ema test Top5 acc: 99.6\n","[2022-04-17 23:55:45,721][experiments.experiment][INFO] - [Checkpoints] Epoch 17, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_17.pth.tar\n","[2022-04-17 23:55:45,721][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 00:03:14,564][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 18: use 448.9409136772156 seconds\n","--- Optimizer learning rate changed from 2.94e-02 to 2.93e-02 ---\n","[2022-04-18 00:03:14,662][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 00:03:16,034][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 00:03:16,034][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 00:03:17,421][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 00:03:17,423][experiments.experiment][INFO] - [EMA] Epoch 18.[Train] time:448.9409136772156 seconds, lr:0.0293, train_loss: 0.3696, unlabeled_losses_real_strong:0.7931,corrrect_unlabeled_num:349296.0,pro_above_threshold_num:363809.0,unlabelled_weak_top1_acc:87.92005151510239,unlabelled_weak_top5_acc:99.36697714030743  \n","[2022-04-18 00:03:17,425][experiments.experiment][INFO] - [EMA] Epoch 18. [Validation] raw_testing_loss: 0.7253, raw test Top1 acc:82.7, raw test Top5 acc: 98.12, ema_testing_loss: 0.4015, ema test Top1 acc:88.7, ema test Top5 acc: 99.74\n","[2022-04-18 00:03:17,426][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 00:10:48,047][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 19: use 450.73051261901855 seconds\n","--- Optimizer learning rate changed from 2.93e-02 to 2.92e-02 ---\n","[2022-04-18 00:10:48,156][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 00:10:49,528][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 00:10:49,528][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 00:10:50,898][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 00:10:50,900][experiments.experiment][INFO] - [EMA] Epoch 19.[Train] time:450.73051261901855 seconds, lr:0.0292, train_loss: 0.3633, unlabeled_losses_real_strong:0.7718,corrrect_unlabeled_num:351555.0,pro_above_threshold_num:365840.0,unlabelled_weak_top1_acc:88.23678034543991,unlabelled_weak_top5_acc:99.42823059856892  \n","[2022-04-18 00:10:50,901][experiments.experiment][INFO] - [EMA] Epoch 19. [Validation] raw_testing_loss: 0.8009, raw test Top1 acc:80.8, raw test Top5 acc: 98.42, ema_testing_loss: 0.4727, ema test Top1 acc:88.0, ema test Top5 acc: 99.48\n","[2022-04-18 00:10:50,988][experiments.experiment][INFO] - [Checkpoints] Epoch 19, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_19.pth.tar\n","[2022-04-18 00:10:50,989][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 00:18:20,789][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 20: use 449.90017771720886 seconds\n","--- Optimizer learning rate changed from 2.92e-02 to 2.91e-02 ---\n","[2022-04-18 00:18:20,890][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 00:18:22,240][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 00:18:22,241][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 00:18:23,608][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 00:18:23,609][experiments.experiment][INFO] - [EMA] Epoch 20.[Train] time:449.90017771720886 seconds, lr:0.0291, train_loss: 0.3596, unlabeled_losses_real_strong:0.7629,corrrect_unlabeled_num:354001.0,pro_above_threshold_num:367622.0,unlabelled_weak_top1_acc:88.54805983603,unlabelled_weak_top5_acc:99.43280825018883  \n","[2022-04-18 00:18:23,611][experiments.experiment][INFO] - [EMA] Epoch 20. [Validation] raw_testing_loss: 0.6215, raw test Top1 acc:83.9, raw test Top5 acc: 98.58, ema_testing_loss: 0.3844, ema test Top1 acc:89.48, ema test Top5 acc: 99.62\n","[2022-04-18 00:18:23,612][experiments.experiment][INFO] - ***** Running training *****\n"]}]},{"cell_type":"code","source":["# Resume training\n","!python run.py DATASET.label_num=4000 DATASET.strongaugment='RA' EXPERIMENT.epoch_n=120 EXPERIMENT.batch_size=64 MODEL.name='WideResNet_Lk' MODEL.depth=28 MODEL.widen_factor=2 MODEL.num_classes=10 EXPERIMENT.out_model='./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/' EXPERIMENT.log_path='./outputs/outputs_celiali-wideresnet-120epochs-64batch-ema099/' EXPERIMENT.save_cfmatrix=False EXPERIMENT.decay_type='cosine' EXPERIMENT.ema_decay=0.99 EXPERIMENT.resume=True EXPERIMENT.resume_checkpoints='./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_19.pth.tar'"],"metadata":{"id":"dQa2iR1dNM87","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650295861927,"user_tz":300,"elapsed":15433928,"user":{"displayName":"CM Y","userId":"12660552299343911788"}},"outputId":"d4b5256b-998c-4836-865e-12d565e2a464"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==> CONFIG is: \n"," DATASET:\n","  project_dir: ./\n","  data_dir: data\n","  loading_data: LOAD_LABEL_UNLABEL\n","  dataset: CIFAR10\n","  strongaugment: RA\n","  label_num: 4000\n","  num_expand_x: 65536\n","  mu: 7\n","  barely: false\n","  add_noisy_label: false\n","  both_strong: false\n","MODEL:\n","  name: WideResNet_Lk\n","  depth: 28\n","  widen_factor: 2\n","  num_classes: 10\n","  dropout: 0.0\n","  cardinality: 4\n","  width: 4\n","  base_width: 4\n","EXPERIMENT:\n","  name: FMExperiment\n","  out_model: ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/\n","  log_path: ./outputs/outputs_celiali-wideresnet-120epochs-64batch-ema099/\n","  used_gpu: true\n","  use_cosine: true\n","  use_abel: false\n","  abel_decay: 0.1\n","  optim_lr: 0.03\n","  optim_momentum: 0.9\n","  used_nesterov: true\n","  warmup: 0\n","  wdecay: 0.0005\n","  clip: 1\n","  ema_used: true\n","  ema_decay: 0.99\n","  threshold: 0.95\n","  lambda_unlabeled: 1\n","  batch_size: 64\n","  num_workers: 4\n","  n_imgs_per_epoch: 65536\n","  epoch_n: 120\n","  save_every: 2\n","  save_matrix_every: 20\n","  resume: true\n","  resume_checkpoints: ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_19.pth.tar\n","  save_cfmatrix: false\n","  batch_balanced: false\n","  neg_penalty: false\n","  equal_freq: false\n","  eta_negpenalty: 0.05\n","  eta_dynamic: false\n","  use_nlloss: false\n","  q: 0.0001\n","Logging:\n","  name: FM\n","  seed: 1265\n"," \n","\n","2022-04-18 03:02:13,725 - INFO - Train -   {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/', 'log_path': './outputs/outputs_celiali-wideresnet-120epochs-64batch-ema099/', 'used_gpu': True, 'use_cosine': True, 'use_abel': False, 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.99, 'threshold': 0.95, 'lambda_unlabeled': 1, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': True, 'resume_checkpoints': './checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_19.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","[2022-04-18 03:02:13,725][Train][INFO] - {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/', 'log_path': './outputs/outputs_celiali-wideresnet-120epochs-64batch-ema099/', 'used_gpu': True, 'use_cosine': True, 'use_abel': False, 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.99, 'threshold': 0.95, 'lambda_unlabeled': 1, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': True, 'resume_checkpoints': './checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_19.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","2022-04-18 03:02:14,138 - INFO - Train -   [Model] Building model WideResNet_Lk\n","[2022-04-18 03:02:14,138][Train][INFO] - [Model] Building model WideResNet_Lk\n","2022-04-18 03:02:16,665 - INFO - Train -   Total params: 1.47M\n","[2022-04-18 03:02:16,665][Train][INFO] - Total params: 1.47M\n","[2022-04-18 03:02:16,666][experiments.experiment][INFO] - I'm using cosine decay!\n","[2022-04-18 03:02:16,670][experiments.experiment][INFO] - [EMA] initial \n","[2022-04-18 03:02:22,215][datasets.datasets1][INFO] - Dataset: CIFAR10\n","[2022-04-18 03:02:22,265][datasets.datasets1][INFO] - Labeled examples: 65536 Unlabeled examples: 458752Validation examples: 5000\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-18 03:02:22,266][experiments.experiment][INFO] - Loading Labelled Loader\n","[2022-04-18 03:02:22,267][experiments.experiment][INFO] - Loading Unlabelled Loader\n","[2022-04-18 03:02:22,267][experiments.experiment][INFO] - Loading Validation Loader\n","=> loading checkpoint './checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_19.pth.tar'\n","[2022-04-18 03:02:23,033][experiments.experiment][INFO] - ==> Resuming from checkpoint..\n","=> loaded checkpoint './checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_19.pth.tar' (epoch 19)\n","[2022-04-18 03:02:23,643][experiments.experiment][INFO] - => loaded checkpoint './checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_19.pth.tar' (epoch 19)\n","[2022-04-18 03:02:23,644][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 03:09:43,257][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 19: use 439.71381187438965 seconds\n","--- Optimizer learning rate changed from inf to 2.91e-02 ---\n","[2022-04-18 03:09:43,358][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 03:09:44,684][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 03:09:44,684][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 03:09:45,996][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 03:09:58,677][experiments.experiment][INFO] - [EMA] Epoch 19.[Train] time:439.71381187438965 seconds, lr:0.0291, train_loss: 0.3594, unlabeled_losses_real_strong:0.7605,corrrect_unlabeled_num:355110.0,pro_above_threshold_num:368777.0,unlabelled_weak_top1_acc:88.62566158175468,unlabelled_weak_top5_acc:99.41057393699884  \n","[2022-04-18 03:09:58,678][experiments.experiment][INFO] - [EMA] Epoch 19. [Validation] raw_testing_loss: 0.5638, raw test Top1 acc:85.22, raw test Top5 acc: 99.18, ema_testing_loss: 0.3824, ema test Top1 acc:89.58, ema test Top5 acc: 99.6\n","[2022-04-18 03:09:58,771][experiments.experiment][INFO] - [Checkpoints] Epoch 19, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_19.pth.tar\n","[2022-04-18 03:09:58,774][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 03:17:19,993][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 20: use 441.3123531341553 seconds\n","--- Optimizer learning rate changed from 2.91e-02 to 2.91e-02 ---\n","[2022-04-18 03:17:20,087][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 03:17:21,400][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 03:17:21,400][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 03:17:22,754][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 03:17:22,756][experiments.experiment][INFO] - [EMA] Epoch 20.[Train] time:441.3123531341553 seconds, lr:0.0291, train_loss: 0.3556, unlabeled_losses_real_strong:0.7461,corrrect_unlabeled_num:357031.0,pro_above_threshold_num:370675.0,unlabelled_weak_top1_acc:88.82119212299585,unlabelled_weak_top5_acc:99.43869381397963  \n","[2022-04-18 03:17:22,757][experiments.experiment][INFO] - [EMA] Epoch 20. [Validation] raw_testing_loss: 0.7135, raw test Top1 acc:83.26, raw test Top5 acc: 99.44, ema_testing_loss: 0.3967, ema test Top1 acc:89.12, ema test Top5 acc: 99.6\n","[2022-04-18 03:17:22,759][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 03:24:39,939][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 21: use 437.28367710113525 seconds\n","--- Optimizer learning rate changed from 2.91e-02 to 2.90e-02 ---\n","[2022-04-18 03:24:40,042][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 03:24:41,367][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 03:24:41,367][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 03:24:42,693][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 03:24:42,695][experiments.experiment][INFO] - [EMA] Epoch 21.[Train] time:437.28367710113525 seconds, lr:0.0290, train_loss: 0.3528, unlabeled_losses_real_strong:0.7360,corrrect_unlabeled_num:358521.0,pro_above_threshold_num:371794.0,unlabelled_weak_top1_acc:89.0435344055295,unlabelled_weak_top5_acc:99.47073745727539  \n","[2022-04-18 03:24:42,696][experiments.experiment][INFO] - [EMA] Epoch 21. [Validation] raw_testing_loss: 0.5588, raw test Top1 acc:84.96, raw test Top5 acc: 99.22, ema_testing_loss: 0.3623, ema test Top1 acc:89.82, ema test Top5 acc: 99.74\n","[2022-04-18 03:24:42,789][experiments.experiment][INFO] - [Checkpoints] Epoch 21, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_21.pth.tar\n","[2022-04-18 03:24:42,790][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 03:32:02,542][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 22: use 439.8524820804596 seconds\n","--- Optimizer learning rate changed from 2.90e-02 to 2.89e-02 ---\n","[2022-04-18 03:32:02,642][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 03:32:03,948][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 03:32:03,948][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 03:32:05,249][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 03:32:05,250][experiments.experiment][INFO] - [EMA] Epoch 22.[Train] time:439.8524820804596 seconds, lr:0.0289, train_loss: 0.3481, unlabeled_losses_real_strong:0.7248,corrrect_unlabeled_num:361007.0,pro_above_threshold_num:374054.0,unlabelled_weak_top1_acc:89.28069956600666,unlabelled_weak_top5_acc:99.49209976941347  \n","[2022-04-18 03:32:05,251][experiments.experiment][INFO] - [EMA] Epoch 22. [Validation] raw_testing_loss: 0.6898, raw test Top1 acc:81.78, raw test Top5 acc: 98.46, ema_testing_loss: 0.3754, ema test Top1 acc:89.44, ema test Top5 acc: 99.62\n","[2022-04-18 03:32:05,253][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 03:39:23,871][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 23: use 438.71643590927124 seconds\n","--- Optimizer learning rate changed from 2.89e-02 to 2.88e-02 ---\n","[2022-04-18 03:39:23,969][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 03:39:25,303][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 03:39:25,303][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 03:39:26,689][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 03:39:26,691][experiments.experiment][INFO] - [EMA] Epoch 23.[Train] time:438.71643590927124 seconds, lr:0.0288, train_loss: 0.3462, unlabeled_losses_real_strong:0.7137,corrrect_unlabeled_num:363157.0,pro_above_threshold_num:376252.0,unlabelled_weak_top1_acc:89.54620257019997,unlabelled_weak_top5_acc:99.50757653266191  \n","[2022-04-18 03:39:26,693][experiments.experiment][INFO] - [EMA] Epoch 23. [Validation] raw_testing_loss: 0.5450, raw test Top1 acc:86.02, raw test Top5 acc: 99.62, ema_testing_loss: 0.3582, ema test Top1 acc:90.36, ema test Top5 acc: 99.72\n","[2022-04-18 03:39:26,789][experiments.experiment][INFO] - [Checkpoints] Epoch 23, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_23.pth.tar\n","[2022-04-18 03:39:26,790][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 03:46:44,474][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 24: use 437.77763414382935 seconds\n","--- Optimizer learning rate changed from 2.88e-02 to 2.87e-02 ---\n","[2022-04-18 03:46:44,567][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 03:46:45,858][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 03:46:45,858][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 03:46:47,165][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 03:46:47,166][experiments.experiment][INFO] - [EMA] Epoch 24.[Train] time:437.77763414382935 seconds, lr:0.0287, train_loss: 0.3407, unlabeled_losses_real_strong:0.7052,corrrect_unlabeled_num:364428.0,pro_above_threshold_num:377267.0,unlabelled_weak_top1_acc:89.68723732978106,unlabelled_weak_top5_acc:99.51433417201042  \n","[2022-04-18 03:46:47,168][experiments.experiment][INFO] - [EMA] Epoch 24. [Validation] raw_testing_loss: 0.7573, raw test Top1 acc:82.44, raw test Top5 acc: 98.78, ema_testing_loss: 0.4027, ema test Top1 acc:89.8, ema test Top5 acc: 99.7\n","[2022-04-18 03:46:47,170][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 03:54:04,980][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 25: use 437.904479265213 seconds\n","--- Optimizer learning rate changed from 2.87e-02 to 2.86e-02 ---\n","[2022-04-18 03:54:05,075][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 03:54:06,384][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 03:54:06,384][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 03:54:07,695][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 03:54:07,696][experiments.experiment][INFO] - [EMA] Epoch 25.[Train] time:437.904479265213 seconds, lr:0.0286, train_loss: 0.3384, unlabeled_losses_real_strong:0.6941,corrrect_unlabeled_num:366576.0,pro_above_threshold_num:379129.0,unlabelled_weak_top1_acc:89.83917126059532,unlabelled_weak_top5_acc:99.51041039079428  \n","[2022-04-18 03:54:07,697][experiments.experiment][INFO] - [EMA] Epoch 25. [Validation] raw_testing_loss: 0.5751, raw test Top1 acc:84.4, raw test Top5 acc: 99.28, ema_testing_loss: 0.3475, ema test Top1 acc:90.64, ema test Top5 acc: 99.78\n","[2022-04-18 03:54:07,789][experiments.experiment][INFO] - [Checkpoints] Epoch 25, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_25.pth.tar\n","[2022-04-18 03:54:07,790][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 04:01:24,621][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 26: use 436.9309346675873 seconds\n","--- Optimizer learning rate changed from 2.86e-02 to 2.85e-02 ---\n","[2022-04-18 04:01:24,721][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:01:26,010][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 04:01:26,011][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:01:27,297][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 04:01:27,299][experiments.experiment][INFO] - [EMA] Epoch 26.[Train] time:436.9309346675873 seconds, lr:0.0285, train_loss: 0.3363, unlabeled_losses_real_strong:0.6902,corrrect_unlabeled_num:367451.0,pro_above_threshold_num:379734.0,unlabelled_weak_top1_acc:90.0804781243205,unlabelled_weak_top5_acc:99.53526059538126  \n","[2022-04-18 04:01:27,300][experiments.experiment][INFO] - [EMA] Epoch 26. [Validation] raw_testing_loss: 0.5638, raw test Top1 acc:84.94, raw test Top5 acc: 98.9, ema_testing_loss: 0.3375, ema test Top1 acc:90.7, ema test Top5 acc: 99.7\n","[2022-04-18 04:01:27,301][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 04:08:45,945][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 27: use 438.74104857444763 seconds\n","--- Optimizer learning rate changed from 2.85e-02 to 2.84e-02 ---\n","[2022-04-18 04:08:46,042][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:08:47,350][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 04:08:47,350][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:08:48,728][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 04:08:48,730][experiments.experiment][INFO] - [EMA] Epoch 27.[Train] time:438.74104857444763 seconds, lr:0.0284, train_loss: 0.3341, unlabeled_losses_real_strong:0.6822,corrrect_unlabeled_num:368630.0,pro_above_threshold_num:380925.0,unlabelled_weak_top1_acc:90.17944234609604,unlabelled_weak_top5_acc:99.54594170302153  \n","[2022-04-18 04:08:48,732][experiments.experiment][INFO] - [EMA] Epoch 27. [Validation] raw_testing_loss: 0.5876, raw test Top1 acc:84.38, raw test Top5 acc: 99.26, ema_testing_loss: 0.3498, ema test Top1 acc:90.46, ema test Top5 acc: 99.78\n","[2022-04-18 04:08:48,821][experiments.experiment][INFO] - [Checkpoints] Epoch 27, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_27.pth.tar\n","[2022-04-18 04:08:48,822][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 04:16:08,100][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 28: use 439.37403321266174 seconds\n","--- Optimizer learning rate changed from 2.84e-02 to 2.82e-02 ---\n","[2022-04-18 04:16:08,196][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:16:09,536][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 04:16:09,536][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:16:10,842][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 04:16:10,844][experiments.experiment][INFO] - [EMA] Epoch 28.[Train] time:439.37403321266174 seconds, lr:0.0282, train_loss: 0.3300, unlabeled_losses_real_strong:0.6727,corrrect_unlabeled_num:370307.0,pro_above_threshold_num:382560.0,unlabelled_weak_top1_acc:90.37104898691177,unlabelled_weak_top5_acc:99.53722237050533  \n","[2022-04-18 04:16:10,847][experiments.experiment][INFO] - [EMA] Epoch 28. [Validation] raw_testing_loss: 0.6132, raw test Top1 acc:84.72, raw test Top5 acc: 98.78, ema_testing_loss: 0.3391, ema test Top1 acc:90.84, ema test Top5 acc: 99.8\n","[2022-04-18 04:16:10,847][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 04:23:31,102][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 29: use 440.3588128089905 seconds\n","--- Optimizer learning rate changed from 2.82e-02 to 2.81e-02 ---\n","[2022-04-18 04:23:31,206][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:23:32,527][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 04:23:32,528][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:23:33,840][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 04:23:33,842][experiments.experiment][INFO] - [EMA] Epoch 29.[Train] time:440.3588128089905 seconds, lr:0.0281, train_loss: 0.3279, unlabeled_losses_real_strong:0.6665,corrrect_unlabeled_num:371413.0,pro_above_threshold_num:383473.0,unlabelled_weak_top1_acc:90.45802414417267,unlabelled_weak_top5_acc:99.56403429061174  \n","[2022-04-18 04:23:33,842][experiments.experiment][INFO] - [EMA] Epoch 29. [Validation] raw_testing_loss: 0.4971, raw test Top1 acc:87.56, raw test Top5 acc: 99.46, ema_testing_loss: 0.3357, ema test Top1 acc:90.78, ema test Top5 acc: 99.78\n","[2022-04-18 04:23:33,935][experiments.experiment][INFO] - [Checkpoints] Epoch 29, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_29.pth.tar\n","[2022-04-18 04:23:33,936][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 04:30:51,834][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 30: use 438.00049352645874 seconds\n","--- Optimizer learning rate changed from 2.81e-02 to 2.80e-02 ---\n","[2022-04-18 04:30:51,937][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:30:53,268][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 04:30:53,268][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:30:54,575][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 04:30:54,577][experiments.experiment][INFO] - [EMA] Epoch 30.[Train] time:438.00049352645874 seconds, lr:0.0280, train_loss: 0.3279, unlabeled_losses_real_strong:0.6612,corrrect_unlabeled_num:373043.0,pro_above_threshold_num:385014.0,unlabelled_weak_top1_acc:90.65093883126974,unlabelled_weak_top5_acc:99.57733136415482  \n","[2022-04-18 04:30:54,578][experiments.experiment][INFO] - [EMA] Epoch 30. [Validation] raw_testing_loss: 0.4938, raw test Top1 acc:86.34, raw test Top5 acc: 99.14, ema_testing_loss: 0.3152, ema test Top1 acc:90.94, ema test Top5 acc: 99.74\n","[2022-04-18 04:30:54,579][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 04:38:12,973][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 31: use 438.4913079738617 seconds\n","--- Optimizer learning rate changed from 2.80e-02 to 2.79e-02 ---\n","[2022-04-18 04:38:13,071][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:38:14,403][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 04:38:14,403][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:38:15,704][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 04:38:15,705][experiments.experiment][INFO] - [EMA] Epoch 31.[Train] time:438.4913079738617 seconds, lr:0.0279, train_loss: 0.3249, unlabeled_losses_real_strong:0.6532,corrrect_unlabeled_num:373941.0,pro_above_threshold_num:385808.0,unlabelled_weak_top1_acc:90.79938495904207,unlabelled_weak_top5_acc:99.57885723561049  \n","[2022-04-18 04:38:15,708][experiments.experiment][INFO] - [EMA] Epoch 31. [Validation] raw_testing_loss: 0.5415, raw test Top1 acc:86.22, raw test Top5 acc: 99.36, ema_testing_loss: 0.3341, ema test Top1 acc:91.0, ema test Top5 acc: 99.68\n","[2022-04-18 04:38:15,798][experiments.experiment][INFO] - [Checkpoints] Epoch 31, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_31.pth.tar\n","[2022-04-18 04:38:15,799][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 04:45:35,872][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 32: use 440.16713190078735 seconds\n","--- Optimizer learning rate changed from 2.79e-02 to 2.78e-02 ---\n","[2022-04-18 04:45:35,966][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:45:37,294][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 04:45:37,294][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:45:38,589][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 04:45:38,591][experiments.experiment][INFO] - [EMA] Epoch 32.[Train] time:440.16713190078735 seconds, lr:0.0278, train_loss: 0.3208, unlabeled_losses_real_strong:0.6467,corrrect_unlabeled_num:375084.0,pro_above_threshold_num:386708.0,unlabelled_weak_top1_acc:90.86630567163229,unlabelled_weak_top5_acc:99.58321699500084  \n","[2022-04-18 04:45:38,592][experiments.experiment][INFO] - [EMA] Epoch 32. [Validation] raw_testing_loss: 0.4666, raw test Top1 acc:86.98, raw test Top5 acc: 99.3, ema_testing_loss: 0.3455, ema test Top1 acc:90.72, ema test Top5 acc: 99.68\n","[2022-04-18 04:45:38,593][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 04:52:56,173][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 33: use 437.67300391197205 seconds\n","--- Optimizer learning rate changed from 2.78e-02 to 2.76e-02 ---\n","[2022-04-18 04:52:56,266][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:52:57,574][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 04:52:57,575][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:52:58,927][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 04:52:58,930][experiments.experiment][INFO] - [EMA] Epoch 33.[Train] time:437.67300391197205 seconds, lr:0.0276, train_loss: 0.3207, unlabeled_losses_real_strong:0.6399,corrrect_unlabeled_num:376894.0,pro_above_threshold_num:388673.0,unlabelled_weak_top1_acc:91.00058314949274,unlabelled_weak_top5_acc:99.61547850817442  \n","[2022-04-18 04:52:58,931][experiments.experiment][INFO] - [EMA] Epoch 33. [Validation] raw_testing_loss: 0.4730, raw test Top1 acc:87.16, raw test Top5 acc: 99.54, ema_testing_loss: 0.3352, ema test Top1 acc:91.34, ema test Top5 acc: 99.78\n","[2022-04-18 04:52:59,028][experiments.experiment][INFO] - [Checkpoints] Epoch 33, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_33.pth.tar\n","[2022-04-18 04:52:59,029][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 05:00:20,032][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 34: use 441.1004922389984 seconds\n","--- Optimizer learning rate changed from 2.76e-02 to 2.75e-02 ---\n","[2022-04-18 05:00:20,130][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:00:21,441][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 05:00:21,441][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:00:22,788][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 05:00:22,789][experiments.experiment][INFO] - [EMA] Epoch 34.[Train] time:441.1004922389984 seconds, lr:0.0275, train_loss: 0.3190, unlabeled_losses_real_strong:0.6353,corrrect_unlabeled_num:377550.0,pro_above_threshold_num:389346.0,unlabelled_weak_top1_acc:91.10477899760008,unlabelled_weak_top5_acc:99.60937489569187  \n","[2022-04-18 05:00:22,791][experiments.experiment][INFO] - [EMA] Epoch 34. [Validation] raw_testing_loss: 0.5737, raw test Top1 acc:85.26, raw test Top5 acc: 99.44, ema_testing_loss: 0.3076, ema test Top1 acc:91.58, ema test Top5 acc: 99.74\n","[2022-04-18 05:00:22,792][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 05:07:45,385][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 35: use 442.6892762184143 seconds\n","--- Optimizer learning rate changed from 2.75e-02 to 2.73e-02 ---\n","[2022-04-18 05:07:45,482][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:07:46,812][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 05:07:46,813][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:07:48,146][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 05:07:48,148][experiments.experiment][INFO] - [EMA] Epoch 35.[Train] time:442.6892762184143 seconds, lr:0.0273, train_loss: 0.3167, unlabeled_losses_real_strong:0.6302,corrrect_unlabeled_num:378281.0,pro_above_threshold_num:389843.0,unlabelled_weak_top1_acc:91.22793889045715,unlabelled_weak_top5_acc:99.6156964302063  \n","[2022-04-18 05:07:48,150][experiments.experiment][INFO] - [EMA] Epoch 35. [Validation] raw_testing_loss: 0.4089, raw test Top1 acc:88.86, raw test Top5 acc: 99.46, ema_testing_loss: 0.3214, ema test Top1 acc:91.58, ema test Top5 acc: 99.7\n","[2022-04-18 05:07:48,248][experiments.experiment][INFO] - [Checkpoints] Epoch 35, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_35.pth.tar\n","[2022-04-18 05:07:48,248][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 05:15:09,017][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 36: use 440.8609838485718 seconds\n","--- Optimizer learning rate changed from 2.73e-02 to 2.72e-02 ---\n","[2022-04-18 05:15:09,110][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:15:10,409][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 05:15:10,410][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:15:11,726][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 05:15:11,727][experiments.experiment][INFO] - [EMA] Epoch 36.[Train] time:440.8609838485718 seconds, lr:0.0272, train_loss: 0.3153, unlabeled_losses_real_strong:0.6250,corrrect_unlabeled_num:379450.0,pro_above_threshold_num:390839.0,unlabelled_weak_top1_acc:91.34434178471565,unlabelled_weak_top5_acc:99.61853024363518  \n","[2022-04-18 05:15:11,730][experiments.experiment][INFO] - [EMA] Epoch 36. [Validation] raw_testing_loss: 0.5267, raw test Top1 acc:85.52, raw test Top5 acc: 98.8, ema_testing_loss: 0.3027, ema test Top1 acc:91.64, ema test Top5 acc: 99.74\n","[2022-04-18 05:15:11,730][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 05:22:30,132][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 37: use 438.5012264251709 seconds\n","--- Optimizer learning rate changed from 2.72e-02 to 2.71e-02 ---\n","[2022-04-18 05:22:30,232][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:22:31,588][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 05:22:31,588][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:22:32,895][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 05:22:32,897][experiments.experiment][INFO] - [EMA] Epoch 37.[Train] time:438.5012264251709 seconds, lr:0.0271, train_loss: 0.3142, unlabeled_losses_real_strong:0.6191,corrrect_unlabeled_num:380692.0,pro_above_threshold_num:391912.0,unlabelled_weak_top1_acc:91.49998151510954,unlabelled_weak_top5_acc:99.62485176324844  \n","[2022-04-18 05:22:32,899][experiments.experiment][INFO] - [EMA] Epoch 37. [Validation] raw_testing_loss: 0.4088, raw test Top1 acc:89.18, raw test Top5 acc: 99.8, ema_testing_loss: 0.3080, ema test Top1 acc:91.68, ema test Top5 acc: 99.8\n","[2022-04-18 05:22:32,992][experiments.experiment][INFO] - [Checkpoints] Epoch 37, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_37.pth.tar\n","[2022-04-18 05:22:32,993][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 05:29:54,165][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 38: use 441.26597332954407 seconds\n","--- Optimizer learning rate changed from 2.71e-02 to 2.69e-02 ---\n","[2022-04-18 05:29:54,259][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:29:55,564][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 05:29:55,564][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:29:56,881][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 05:29:56,882][experiments.experiment][INFO] - [EMA] Epoch 38.[Train] time:441.26597332954407 seconds, lr:0.0269, train_loss: 0.3115, unlabeled_losses_real_strong:0.6132,corrrect_unlabeled_num:381248.0,pro_above_threshold_num:392430.0,unlabelled_weak_top1_acc:91.55949079245329,unlabelled_weak_top5_acc:99.63466104120016  \n","[2022-04-18 05:29:56,883][experiments.experiment][INFO] - [EMA] Epoch 38. [Validation] raw_testing_loss: 0.5067, raw test Top1 acc:87.0, raw test Top5 acc: 99.04, ema_testing_loss: 0.3255, ema test Top1 acc:91.44, ema test Top5 acc: 99.74\n","[2022-04-18 05:29:56,884][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 05:37:17,283][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 39: use 440.4925801753998 seconds\n","--- Optimizer learning rate changed from 2.69e-02 to 2.68e-02 ---\n","[2022-04-18 05:37:17,377][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:37:18,686][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 05:37:18,686][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:37:20,004][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 05:37:20,006][experiments.experiment][INFO] - [EMA] Epoch 39.[Train] time:440.4925801753998 seconds, lr:0.0268, train_loss: 0.3078, unlabeled_losses_real_strong:0.6111,corrrect_unlabeled_num:381684.0,pro_above_threshold_num:392918.0,unlabelled_weak_top1_acc:91.60635694116354,unlabelled_weak_top5_acc:99.64054650068283  \n","[2022-04-18 05:37:20,007][experiments.experiment][INFO] - [EMA] Epoch 39. [Validation] raw_testing_loss: 0.4385, raw test Top1 acc:87.52, raw test Top5 acc: 99.38, ema_testing_loss: 0.3002, ema test Top1 acc:91.68, ema test Top5 acc: 99.74\n","[2022-04-18 05:37:20,097][experiments.experiment][INFO] - [Checkpoints] Epoch 39, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_39.pth.tar\n","[2022-04-18 05:37:20,098][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 05:44:41,528][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 40: use 441.52592873573303 seconds\n","--- Optimizer learning rate changed from 2.68e-02 to 2.66e-02 ---\n","[2022-04-18 05:44:41,624][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:44:42,927][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 05:44:42,928][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:44:44,219][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 05:44:44,221][experiments.experiment][INFO] - [EMA] Epoch 40.[Train] time:441.52592873573303 seconds, lr:0.0266, train_loss: 0.3086, unlabeled_losses_real_strong:0.6049,corrrect_unlabeled_num:382924.0,pro_above_threshold_num:394042.0,unlabelled_weak_top1_acc:91.70248740166426,unlabelled_weak_top5_acc:99.63836680352688  \n","[2022-04-18 05:44:44,222][experiments.experiment][INFO] - [EMA] Epoch 40. [Validation] raw_testing_loss: 0.4957, raw test Top1 acc:87.58, raw test Top5 acc: 99.62, ema_testing_loss: 0.3066, ema test Top1 acc:91.94, ema test Top5 acc: 99.82\n","[2022-04-18 05:44:44,223][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 05:52:04,224][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 41: use 440.0926432609558 seconds\n","--- Optimizer learning rate changed from 2.66e-02 to 2.64e-02 ---\n","[2022-04-18 05:52:04,316][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:52:05,640][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 05:52:05,641][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:52:06,969][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 05:52:06,970][experiments.experiment][INFO] - [EMA] Epoch 41.[Train] time:440.0926432609558 seconds, lr:0.0264, train_loss: 0.3085, unlabeled_losses_real_strong:0.6046,corrrect_unlabeled_num:383364.0,pro_above_threshold_num:394494.0,unlabelled_weak_top1_acc:91.776819601655,unlabelled_weak_top5_acc:99.66060107201338  \n","[2022-04-18 05:52:06,971][experiments.experiment][INFO] - [EMA] Epoch 41. [Validation] raw_testing_loss: 0.4464, raw test Top1 acc:88.62, raw test Top5 acc: 99.56, ema_testing_loss: 0.3280, ema test Top1 acc:91.44, ema test Top5 acc: 99.66\n","[2022-04-18 05:52:07,063][experiments.experiment][INFO] - [Checkpoints] Epoch 41, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_41.pth.tar\n","[2022-04-18 05:52:07,063][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 05:59:26,630][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 42: use 439.6621141433716 seconds\n","--- Optimizer learning rate changed from 2.64e-02 to 2.63e-02 ---\n","[2022-04-18 05:59:26,726][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:59:28,036][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 05:59:28,037][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:59:29,334][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 05:59:29,336][experiments.experiment][INFO] - [EMA] Epoch 42.[Train] time:439.6621141433716 seconds, lr:0.0263, train_loss: 0.3048, unlabeled_losses_real_strong:0.5976,corrrect_unlabeled_num:383710.0,pro_above_threshold_num:394582.0,unlabelled_weak_top1_acc:91.82586561888456,unlabelled_weak_top5_acc:99.66648671030998  \n","[2022-04-18 05:59:29,338][experiments.experiment][INFO] - [EMA] Epoch 42. [Validation] raw_testing_loss: 0.4335, raw test Top1 acc:89.2, raw test Top5 acc: 99.42, ema_testing_loss: 0.2946, ema test Top1 acc:92.24, ema test Top5 acc: 99.74\n","[2022-04-18 05:59:29,339][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 06:06:50,207][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 43: use 440.9638977050781 seconds\n","--- Optimizer learning rate changed from 2.63e-02 to 2.61e-02 ---\n","[2022-04-18 06:06:50,303][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:06:51,613][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 06:06:51,613][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:06:52,942][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 06:06:52,944][experiments.experiment][INFO] - [EMA] Epoch 43.[Train] time:440.9638977050781 seconds, lr:0.0261, train_loss: 0.3023, unlabeled_losses_real_strong:0.5933,corrrect_unlabeled_num:384458.0,pro_above_threshold_num:395154.0,unlabelled_weak_top1_acc:91.96929831802845,unlabelled_weak_top5_acc:99.66735856980085  \n","[2022-04-18 06:06:52,945][experiments.experiment][INFO] - [EMA] Epoch 43. [Validation] raw_testing_loss: 0.5312, raw test Top1 acc:87.06, raw test Top5 acc: 99.64, ema_testing_loss: 0.2937, ema test Top1 acc:92.1, ema test Top5 acc: 99.74\n","[2022-04-18 06:06:53,038][experiments.experiment][INFO] - [Checkpoints] Epoch 43, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_43.pth.tar\n","[2022-04-18 06:06:53,038][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 06:14:15,697][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 44: use 442.75376653671265 seconds\n","--- Optimizer learning rate changed from 2.61e-02 to 2.59e-02 ---\n","[2022-04-18 06:14:15,792][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:14:17,117][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 06:14:17,117][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:14:18,440][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 06:14:18,442][experiments.experiment][INFO] - [EMA] Epoch 44.[Train] time:442.75376653671265 seconds, lr:0.0259, train_loss: 0.3023, unlabeled_losses_real_strong:0.5876,corrrect_unlabeled_num:385958.0,pro_above_threshold_num:396663.0,unlabelled_weak_top1_acc:92.05736334621906,unlabelled_weak_top5_acc:99.65689527988434  \n","[2022-04-18 06:14:18,443][experiments.experiment][INFO] - [EMA] Epoch 44. [Validation] raw_testing_loss: 0.4024, raw test Top1 acc:88.74, raw test Top5 acc: 99.42, ema_testing_loss: 0.2805, ema test Top1 acc:92.28, ema test Top5 acc: 99.74\n","[2022-04-18 06:14:18,445][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 06:21:39,111][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 45: use 440.7616560459137 seconds\n","--- Optimizer learning rate changed from 2.59e-02 to 2.58e-02 ---\n","[2022-04-18 06:21:39,206][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:21:40,522][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 06:21:40,522][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:21:41,846][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 06:21:41,848][experiments.experiment][INFO] - [EMA] Epoch 45.[Train] time:440.7616560459137 seconds, lr:0.0258, train_loss: 0.3021, unlabeled_losses_real_strong:0.5853,corrrect_unlabeled_num:386335.0,pro_above_threshold_num:396935.0,unlabelled_weak_top1_acc:92.17333011329174,unlabelled_weak_top5_acc:99.67171826213598  \n","[2022-04-18 06:21:41,850][experiments.experiment][INFO] - [EMA] Epoch 45. [Validation] raw_testing_loss: 0.4273, raw test Top1 acc:89.1, raw test Top5 acc: 99.62, ema_testing_loss: 0.2819, ema test Top1 acc:92.62, ema test Top5 acc: 99.82\n","[2022-04-18 06:21:41,949][experiments.experiment][INFO] - [Checkpoints] Epoch 45, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_45.pth.tar\n","[2022-04-18 06:21:41,950][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 06:29:01,205][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 46: use 439.34847021102905 seconds\n","--- Optimizer learning rate changed from 2.58e-02 to 2.56e-02 ---\n","[2022-04-18 06:29:01,299][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:29:02,639][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 06:29:02,639][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:29:03,955][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 06:29:03,957][experiments.experiment][INFO] - [EMA] Epoch 46.[Train] time:439.34847021102905 seconds, lr:0.0256, train_loss: 0.3006, unlabeled_losses_real_strong:0.5845,corrrect_unlabeled_num:386830.0,pro_above_threshold_num:397409.0,unlabelled_weak_top1_acc:92.20188591629267,unlabelled_weak_top5_acc:99.66103703528643  \n","[2022-04-18 06:29:03,959][experiments.experiment][INFO] - [EMA] Epoch 46. [Validation] raw_testing_loss: 0.3797, raw test Top1 acc:89.92, raw test Top5 acc: 99.46, ema_testing_loss: 0.2778, ema test Top1 acc:92.6, ema test Top5 acc: 99.8\n","[2022-04-18 06:29:03,961][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 06:36:22,893][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 47: use 439.02588629722595 seconds\n","--- Optimizer learning rate changed from 2.56e-02 to 2.54e-02 ---\n","[2022-04-18 06:36:22,987][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:36:24,315][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 06:36:24,315][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:36:25,621][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 06:36:25,622][experiments.experiment][INFO] - [EMA] Epoch 47.[Train] time:439.02588629722595 seconds, lr:0.0254, train_loss: 0.2963, unlabeled_losses_real_strong:0.5741,corrrect_unlabeled_num:388196.0,pro_above_threshold_num:398558.0,unlabelled_weak_top1_acc:92.31567277014256,unlabelled_weak_top5_acc:99.68174547702074  \n","[2022-04-18 06:36:25,624][experiments.experiment][INFO] - [EMA] Epoch 47. [Validation] raw_testing_loss: 0.4206, raw test Top1 acc:89.22, raw test Top5 acc: 99.5, ema_testing_loss: 0.3022, ema test Top1 acc:92.14, ema test Top5 acc: 99.8\n","[2022-04-18 06:36:25,714][experiments.experiment][INFO] - [Checkpoints] Epoch 47, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_47.pth.tar\n","[2022-04-18 06:36:25,715][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 06:43:44,706][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 48: use 439.0916106700897 seconds\n","--- Optimizer learning rate changed from 2.54e-02 to 2.52e-02 ---\n","[2022-04-18 06:43:44,807][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:43:46,215][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 06:43:46,215][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:43:47,594][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 06:43:47,596][experiments.experiment][INFO] - [EMA] Epoch 48.[Train] time:439.0916106700897 seconds, lr:0.0252, train_loss: 0.2983, unlabeled_losses_real_strong:0.5758,corrrect_unlabeled_num:388215.0,pro_above_threshold_num:398734.0,unlabelled_weak_top1_acc:92.2834113240242,unlabelled_weak_top5_acc:99.67607790976763  \n","[2022-04-18 06:43:47,597][experiments.experiment][INFO] - [EMA] Epoch 48. [Validation] raw_testing_loss: 0.4418, raw test Top1 acc:89.06, raw test Top5 acc: 99.5, ema_testing_loss: 0.2961, ema test Top1 acc:92.06, ema test Top5 acc: 99.84\n","[2022-04-18 06:43:47,599][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 06:51:06,646][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 49: use 439.1429057121277 seconds\n","--- Optimizer learning rate changed from 2.52e-02 to 2.50e-02 ---\n","[2022-04-18 06:51:06,742][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:51:08,061][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 06:51:08,061][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:51:09,383][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 06:51:09,385][experiments.experiment][INFO] - [EMA] Epoch 49.[Train] time:439.1429057121277 seconds, lr:0.0250, train_loss: 0.2948, unlabeled_losses_real_strong:0.5697,corrrect_unlabeled_num:389342.0,pro_above_threshold_num:399842.0,unlabelled_weak_top1_acc:92.42335613816977,unlabelled_weak_top5_acc:99.66735851019621  \n","[2022-04-18 06:51:09,387][experiments.experiment][INFO] - [EMA] Epoch 49. [Validation] raw_testing_loss: 0.3879, raw test Top1 acc:89.36, raw test Top5 acc: 99.56, ema_testing_loss: 0.2807, ema test Top1 acc:92.12, ema test Top5 acc: 99.8\n","[2022-04-18 06:51:09,478][experiments.experiment][INFO] - [Checkpoints] Epoch 49, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_49.pth.tar\n","[2022-04-18 06:51:09,478][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 06:58:28,753][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 50: use 439.36930227279663 seconds\n","--- Optimizer learning rate changed from 2.50e-02 to 2.48e-02 ---\n","[2022-04-18 06:58:28,848][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:58:30,182][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 06:58:30,182][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:58:31,487][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 06:58:31,488][experiments.experiment][INFO] - [EMA] Epoch 50.[Train] time:439.36930227279663 seconds, lr:0.0248, train_loss: 0.2955, unlabeled_losses_real_strong:0.5655,corrrect_unlabeled_num:389515.0,pro_above_threshold_num:400100.0,unlabelled_weak_top1_acc:92.43774304538965,unlabelled_weak_top5_acc:99.69983813911676  \n","[2022-04-18 06:58:31,490][experiments.experiment][INFO] - [EMA] Epoch 50. [Validation] raw_testing_loss: 0.4765, raw test Top1 acc:87.78, raw test Top5 acc: 99.28, ema_testing_loss: 0.2922, ema test Top1 acc:92.38, ema test Top5 acc: 99.74\n","[2022-04-18 06:58:31,491][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 07:05:52,094][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 51: use 440.7027802467346 seconds\n","--- Optimizer learning rate changed from 2.48e-02 to 2.46e-02 ---\n","[2022-04-18 07:05:52,194][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:05:53,519][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 07:05:53,520][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:05:54,827][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 07:05:54,828][experiments.experiment][INFO] - [EMA] Epoch 51.[Train] time:440.7027802467346 seconds, lr:0.0246, train_loss: 0.2924, unlabeled_losses_real_strong:0.5606,corrrect_unlabeled_num:390299.0,pro_above_threshold_num:400737.0,unlabelled_weak_top1_acc:92.52885986864567,unlabelled_weak_top5_acc:99.69068276882172  \n","[2022-04-18 07:05:54,830][experiments.experiment][INFO] - [EMA] Epoch 51. [Validation] raw_testing_loss: 0.4016, raw test Top1 acc:88.98, raw test Top5 acc: 99.48, ema_testing_loss: 0.2780, ema test Top1 acc:92.78, ema test Top5 acc: 99.76\n","[2022-04-18 07:05:54,921][experiments.experiment][INFO] - [Checkpoints] Epoch 51, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_51.pth.tar\n","[2022-04-18 07:05:54,922][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 07:13:17,321][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 52: use 442.49405097961426 seconds\n","--- Optimizer learning rate changed from 2.46e-02 to 2.44e-02 ---\n","[2022-04-18 07:13:17,416][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:13:18,766][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 07:13:18,767][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:13:20,094][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 07:13:20,095][experiments.experiment][INFO] - [EMA] Epoch 52.[Train] time:442.49405097961426 seconds, lr:0.0244, train_loss: 0.2937, unlabeled_losses_real_strong:0.5602,corrrect_unlabeled_num:390535.0,pro_above_threshold_num:400828.0,unlabelled_weak_top1_acc:92.56024936586618,unlabelled_weak_top5_acc:99.6852331161499  \n","[2022-04-18 07:13:20,097][experiments.experiment][INFO] - [EMA] Epoch 52. [Validation] raw_testing_loss: 0.3806, raw test Top1 acc:89.22, raw test Top5 acc: 99.62, ema_testing_loss: 0.2838, ema test Top1 acc:92.1, ema test Top5 acc: 99.72\n","[2022-04-18 07:13:20,098][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 07:20:42,590][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 53: use 442.5877923965454 seconds\n","--- Optimizer learning rate changed from 2.44e-02 to 2.42e-02 ---\n","[2022-04-18 07:20:42,686][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:20:44,056][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 07:20:44,056][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:20:45,421][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 07:20:45,423][experiments.experiment][INFO] - [EMA] Epoch 53.[Train] time:442.5877923965454 seconds, lr:0.0242, train_loss: 0.2908, unlabeled_losses_real_strong:0.5564,corrrect_unlabeled_num:391436.0,pro_above_threshold_num:401798.0,unlabelled_weak_top1_acc:92.59621641784906,unlabelled_weak_top5_acc:99.70005618780851  \n","[2022-04-18 07:20:45,425][experiments.experiment][INFO] - [EMA] Epoch 53. [Validation] raw_testing_loss: 0.3431, raw test Top1 acc:89.84, raw test Top5 acc: 99.72, ema_testing_loss: 0.2783, ema test Top1 acc:92.42, ema test Top5 acc: 99.7\n","[2022-04-18 07:20:45,522][experiments.experiment][INFO] - [Checkpoints] Epoch 53, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_53.pth.tar\n","[2022-04-18 07:20:45,523][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 07:28:06,550][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 54: use 441.13252115249634 seconds\n","--- Optimizer learning rate changed from 2.42e-02 to 2.40e-02 ---\n","[2022-04-18 07:28:06,655][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:28:07,988][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 07:28:07,988][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:28:09,287][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 07:28:09,288][experiments.experiment][INFO] - [EMA] Epoch 54.[Train] time:441.13252115249634 seconds, lr:0.0240, train_loss: 0.2904, unlabeled_losses_real_strong:0.5527,corrrect_unlabeled_num:392205.0,pro_above_threshold_num:402531.0,unlabelled_weak_top1_acc:92.74226492643356,unlabelled_weak_top5_acc:99.69918416440487  \n","[2022-04-18 07:28:09,290][experiments.experiment][INFO] - [EMA] Epoch 54. [Validation] raw_testing_loss: 0.5036, raw test Top1 acc:88.44, raw test Top5 acc: 99.38, ema_testing_loss: 0.3048, ema test Top1 acc:92.34, ema test Top5 acc: 99.84\n","[2022-04-18 07:28:09,291][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 07:35:33,228][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 55: use 444.03500604629517 seconds\n","--- Optimizer learning rate changed from 2.40e-02 to 2.38e-02 ---\n","[2022-04-18 07:35:33,326][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:35:34,663][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 07:35:34,663][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:35:36,033][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 07:35:36,035][experiments.experiment][INFO] - [EMA] Epoch 55.[Train] time:444.03500604629517 seconds, lr:0.0238, train_loss: 0.2877, unlabeled_losses_real_strong:0.5478,corrrect_unlabeled_num:393066.0,pro_above_threshold_num:403238.0,unlabelled_weak_top1_acc:92.81398113071918,unlabelled_weak_top5_acc:99.69722231477499  \n","[2022-04-18 07:35:36,037][experiments.experiment][INFO] - [EMA] Epoch 55. [Validation] raw_testing_loss: 0.3751, raw test Top1 acc:89.88, raw test Top5 acc: 99.46, ema_testing_loss: 0.2777, ema test Top1 acc:92.7, ema test Top5 acc: 99.7\n","[2022-04-18 07:35:36,126][experiments.experiment][INFO] - [Checkpoints] Epoch 55, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_55.pth.tar\n","[2022-04-18 07:35:36,127][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 07:43:00,015][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 56: use 443.9857804775238 seconds\n","--- Optimizer learning rate changed from 2.38e-02 to 2.36e-02 ---\n","[2022-04-18 07:43:00,113][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:43:01,446][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 07:43:01,446][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:43:02,805][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 07:43:02,806][experiments.experiment][INFO] - [EMA] Epoch 56.[Train] time:443.9857804775238 seconds, lr:0.0236, train_loss: 0.2880, unlabeled_losses_real_strong:0.5437,corrrect_unlabeled_num:393353.0,pro_above_threshold_num:403497.0,unlabelled_weak_top1_acc:92.86520721018314,unlabelled_weak_top5_acc:99.71531495451927  \n","[2022-04-18 07:43:02,808][experiments.experiment][INFO] - [EMA] Epoch 56. [Validation] raw_testing_loss: 0.3462, raw test Top1 acc:90.54, raw test Top5 acc: 99.76, ema_testing_loss: 0.2814, ema test Top1 acc:92.82, ema test Top5 acc: 99.84\n","[2022-04-18 07:43:02,810][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 07:50:27,796][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 57: use 445.0889105796814 seconds\n","--- Optimizer learning rate changed from 2.36e-02 to 2.34e-02 ---\n","[2022-04-18 07:50:27,899][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:50:29,282][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 07:50:29,283][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:50:30,614][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 07:50:30,616][experiments.experiment][INFO] - [EMA] Epoch 57.[Train] time:445.0889105796814 seconds, lr:0.0234, train_loss: 0.2878, unlabeled_losses_real_strong:0.5436,corrrect_unlabeled_num:394004.0,pro_above_threshold_num:404203.0,unlabelled_weak_top1_acc:92.94041113555431,unlabelled_weak_top5_acc:99.70572373270988  \n","[2022-04-18 07:50:30,617][experiments.experiment][INFO] - [EMA] Epoch 57. [Validation] raw_testing_loss: 0.4022, raw test Top1 acc:89.6, raw test Top5 acc: 99.44, ema_testing_loss: 0.2712, ema test Top1 acc:92.8, ema test Top5 acc: 99.78\n","[2022-04-18 07:50:30,708][experiments.experiment][INFO] - [Checkpoints] Epoch 57, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_57.pth.tar\n","[2022-04-18 07:50:30,708][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 07:57:53,914][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 58: use 443.3097195625305 seconds\n","--- Optimizer learning rate changed from 2.34e-02 to 2.32e-02 ---\n","[2022-04-18 07:57:54,018][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:57:55,334][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 07:57:55,334][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:57:56,657][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 07:57:56,658][experiments.experiment][INFO] - [EMA] Epoch 58.[Train] time:443.3097195625305 seconds, lr:0.0232, train_loss: 0.2858, unlabeled_losses_real_strong:0.5425,corrrect_unlabeled_num:394059.0,pro_above_threshold_num:404146.0,unlabelled_weak_top1_acc:92.90313605219126,unlabelled_weak_top5_acc:99.71139118075371  \n","[2022-04-18 07:57:56,659][experiments.experiment][INFO] - [EMA] Epoch 58. [Validation] raw_testing_loss: 0.3754, raw test Top1 acc:90.06, raw test Top5 acc: 99.56, ema_testing_loss: 0.2664, ema test Top1 acc:92.82, ema test Top5 acc: 99.82\n","[2022-04-18 07:57:56,661][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 08:05:18,303][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 59: use 441.7369546890259 seconds\n","--- Optimizer learning rate changed from 2.32e-02 to 2.30e-02 ---\n","[2022-04-18 08:05:18,398][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:05:19,764][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 08:05:19,764][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:05:21,076][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 08:05:21,078][experiments.experiment][INFO] - [EMA] Epoch 59.[Train] time:441.7369546890259 seconds, lr:0.0230, train_loss: 0.2823, unlabeled_losses_real_strong:0.5348,corrrect_unlabeled_num:394819.0,pro_above_threshold_num:404749.0,unlabelled_weak_top1_acc:93.00275418907404,unlabelled_weak_top5_acc:99.7214185744524  \n","[2022-04-18 08:05:21,081][experiments.experiment][INFO] - [EMA] Epoch 59. [Validation] raw_testing_loss: 0.5335, raw test Top1 acc:87.18, raw test Top5 acc: 99.32, ema_testing_loss: 0.2529, ema test Top1 acc:93.08, ema test Top5 acc: 99.8\n","[2022-04-18 08:05:21,175][experiments.experiment][INFO] - [Checkpoints] Epoch 59, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_59.pth.tar\n","[2022-04-18 08:05:21,176][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 08:12:42,156][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 60: use 441.0761544704437 seconds\n","--- Optimizer learning rate changed from 2.30e-02 to 2.27e-02 ---\n","[2022-04-18 08:12:42,252][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:12:43,556][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 08:12:43,556][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:12:44,871][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 08:12:44,874][experiments.experiment][INFO] - [EMA] Epoch 60.[Train] time:441.0761544704437 seconds, lr:0.0227, train_loss: 0.2856, unlabeled_losses_real_strong:0.5353,corrrect_unlabeled_num:395600.0,pro_above_threshold_num:405717.0,unlabelled_weak_top1_acc:93.05398017168045,unlabelled_weak_top5_acc:99.72534217685461  \n","[2022-04-18 08:12:44,876][experiments.experiment][INFO] - [EMA] Epoch 60. [Validation] raw_testing_loss: 0.3605, raw test Top1 acc:89.58, raw test Top5 acc: 99.8, ema_testing_loss: 0.2642, ema test Top1 acc:92.44, ema test Top5 acc: 99.82\n","[2022-04-18 08:12:44,877][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 08:20:05,513][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 61: use 440.7338695526123 seconds\n","--- Optimizer learning rate changed from 2.27e-02 to 2.25e-02 ---\n","[2022-04-18 08:20:05,611][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:20:06,946][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 08:20:06,946][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:20:08,268][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 08:20:08,270][experiments.experiment][INFO] - [EMA] Epoch 61.[Train] time:440.7338695526123 seconds, lr:0.0225, train_loss: 0.2821, unlabeled_losses_real_strong:0.5299,corrrect_unlabeled_num:395863.0,pro_above_threshold_num:405927.0,unlabelled_weak_top1_acc:93.08209993690252,unlabelled_weak_top5_acc:99.71487893164158  \n","[2022-04-18 08:20:08,271][experiments.experiment][INFO] - [EMA] Epoch 61. [Validation] raw_testing_loss: 0.5172, raw test Top1 acc:87.8, raw test Top5 acc: 99.46, ema_testing_loss: 0.2718, ema test Top1 acc:92.72, ema test Top5 acc: 99.84\n","[2022-04-18 08:20:08,363][experiments.experiment][INFO] - [Checkpoints] Epoch 61, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_61.pth.tar\n","[2022-04-18 08:20:08,363][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 08:27:29,204][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 62: use 440.9382839202881 seconds\n","--- Optimizer learning rate changed from 2.25e-02 to 2.23e-02 ---\n","[2022-04-18 08:27:29,302][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:27:30,628][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 08:27:30,628][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:27:31,920][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 08:27:31,921][experiments.experiment][INFO] - [EMA] Epoch 62.[Train] time:440.9382839202881 seconds, lr:0.0223, train_loss: 0.2817, unlabeled_losses_real_strong:0.5300,corrrect_unlabeled_num:396579.0,pro_above_threshold_num:406525.0,unlabelled_weak_top1_acc:93.15076449513435,unlabelled_weak_top5_acc:99.72316237539053  \n","[2022-04-18 08:27:31,922][experiments.experiment][INFO] - [EMA] Epoch 62. [Validation] raw_testing_loss: 0.3827, raw test Top1 acc:89.7, raw test Top5 acc: 99.64, ema_testing_loss: 0.2641, ema test Top1 acc:92.86, ema test Top5 acc: 99.84\n","[2022-04-18 08:27:31,924][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 08:34:52,073][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 63: use 440.2458851337433 seconds\n","--- Optimizer learning rate changed from 2.23e-02 to 2.21e-02 ---\n","[2022-04-18 08:34:52,170][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:34:53,510][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 08:34:53,510][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:34:54,824][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 08:34:54,825][experiments.experiment][INFO] - [EMA] Epoch 63.[Train] time:440.2458851337433 seconds, lr:0.0221, train_loss: 0.2805, unlabeled_losses_real_strong:0.5248,corrrect_unlabeled_num:397080.0,pro_above_threshold_num:407099.0,unlabelled_weak_top1_acc:93.18237196654081,unlabelled_weak_top5_acc:99.7386392056942  \n","[2022-04-18 08:34:54,828][experiments.experiment][INFO] - [EMA] Epoch 63. [Validation] raw_testing_loss: 0.3083, raw test Top1 acc:91.34, raw test Top5 acc: 99.78, ema_testing_loss: 0.2835, ema test Top1 acc:93.06, ema test Top5 acc: 99.8\n","[2022-04-18 08:34:54,918][experiments.experiment][INFO] - [Checkpoints] Epoch 63, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_63.pth.tar\n","[2022-04-18 08:34:54,919][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 08:42:16,447][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 64: use 441.62329602241516 seconds\n","--- Optimizer learning rate changed from 2.21e-02 to 2.18e-02 ---\n","[2022-04-18 08:42:16,542][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:42:17,837][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 08:42:17,837][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:42:19,133][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 08:42:19,134][experiments.experiment][INFO] - [EMA] Epoch 64.[Train] time:441.62329602241516 seconds, lr:0.0218, train_loss: 0.2774, unlabeled_losses_real_strong:0.5234,corrrect_unlabeled_num:397181.0,pro_above_threshold_num:407293.0,unlabelled_weak_top1_acc:93.2185571193695,unlabelled_weak_top5_acc:99.73013786226511  \n","[2022-04-18 08:42:19,136][experiments.experiment][INFO] - [EMA] Epoch 64. [Validation] raw_testing_loss: 0.3099, raw test Top1 acc:91.02, raw test Top5 acc: 99.74, ema_testing_loss: 0.2706, ema test Top1 acc:92.88, ema test Top5 acc: 99.8\n","[2022-04-18 08:42:19,137][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 08:49:38,494][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 65: use 439.4530255794525 seconds\n","--- Optimizer learning rate changed from 2.18e-02 to 2.16e-02 ---\n","[2022-04-18 08:49:38,590][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:49:39,966][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 08:49:39,967][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:49:41,283][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 08:49:41,285][experiments.experiment][INFO] - [EMA] Epoch 65.[Train] time:439.4530255794525 seconds, lr:0.0216, train_loss: 0.2793, unlabeled_losses_real_strong:0.5207,corrrect_unlabeled_num:397787.0,pro_above_threshold_num:407825.0,unlabelled_weak_top1_acc:93.28286200016737,unlabelled_weak_top5_acc:99.7318816408515  \n","[2022-04-18 08:49:41,286][experiments.experiment][INFO] - [EMA] Epoch 65. [Validation] raw_testing_loss: 0.3756, raw test Top1 acc:90.08, raw test Top5 acc: 99.44, ema_testing_loss: 0.2661, ema test Top1 acc:92.9, ema test Top5 acc: 99.76\n","[2022-04-18 08:49:41,399][experiments.experiment][INFO] - [Checkpoints] Epoch 65, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_65.pth.tar\n","[2022-04-18 08:49:41,399][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 08:57:03,727][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 66: use 442.42093324661255 seconds\n","--- Optimizer learning rate changed from 2.16e-02 to 2.14e-02 ---\n","[2022-04-18 08:57:03,820][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:57:05,108][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 08:57:05,109][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:57:06,417][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 08:57:06,418][experiments.experiment][INFO] - [EMA] Epoch 66.[Train] time:442.42093324661255 seconds, lr:0.0214, train_loss: 0.2760, unlabeled_losses_real_strong:0.5175,corrrect_unlabeled_num:398413.0,pro_above_threshold_num:408160.0,unlabelled_weak_top1_acc:93.34171736985445,unlabelled_weak_top5_acc:99.74060101807117  \n","[2022-04-18 08:57:06,421][experiments.experiment][INFO] - [EMA] Epoch 66. [Validation] raw_testing_loss: 0.3711, raw test Top1 acc:89.9, raw test Top5 acc: 99.74, ema_testing_loss: 0.2634, ema test Top1 acc:93.0, ema test Top5 acc: 99.78\n","[2022-04-18 08:57:06,422][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 09:04:28,706][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 67: use 442.3808867931366 seconds\n","--- Optimizer learning rate changed from 2.14e-02 to 2.11e-02 ---\n","[2022-04-18 09:04:28,803][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:04:30,174][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 09:04:30,174][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:04:31,504][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 09:04:31,505][experiments.experiment][INFO] - [EMA] Epoch 67.[Train] time:442.3808867931366 seconds, lr:0.0211, train_loss: 0.2754, unlabeled_losses_real_strong:0.5144,corrrect_unlabeled_num:398889.0,pro_above_threshold_num:408851.0,unlabelled_weak_top1_acc:93.33975540846586,unlabelled_weak_top5_acc:99.735805362463  \n","[2022-04-18 09:04:31,507][experiments.experiment][INFO] - [EMA] Epoch 67. [Validation] raw_testing_loss: 0.3675, raw test Top1 acc:90.4, raw test Top5 acc: 99.54, ema_testing_loss: 0.2513, ema test Top1 acc:93.48, ema test Top5 acc: 99.84\n","[2022-04-18 09:04:31,598][experiments.experiment][INFO] - [Checkpoints] Epoch 67, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_67.pth.tar\n","[2022-04-18 09:04:31,600][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 09:11:52,368][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 68: use 440.8652102947235 seconds\n","--- Optimizer learning rate changed from 2.11e-02 to 2.09e-02 ---\n","[2022-04-18 09:11:52,465][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:11:53,817][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 09:11:53,818][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:11:55,157][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 09:11:55,159][experiments.experiment][INFO] - [EMA] Epoch 68.[Train] time:440.8652102947235 seconds, lr:0.0209, train_loss: 0.2748, unlabeled_losses_real_strong:0.5115,corrrect_unlabeled_num:399791.0,pro_above_threshold_num:409798.0,unlabelled_weak_top1_acc:93.453324444592,unlabelled_weak_top5_acc:99.72163653373718  \n","[2022-04-18 09:11:55,161][experiments.experiment][INFO] - [EMA] Epoch 68. [Validation] raw_testing_loss: 0.3628, raw test Top1 acc:90.4, raw test Top5 acc: 99.68, ema_testing_loss: 0.2499, ema test Top1 acc:92.9, ema test Top5 acc: 99.86\n","[2022-04-18 09:11:55,162][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 09:19:15,691][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 69: use 440.62294030189514 seconds\n","--- Optimizer learning rate changed from 2.09e-02 to 2.06e-02 ---\n","[2022-04-18 09:19:15,785][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:19:17,108][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 09:19:17,108][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:19:18,416][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 09:19:18,418][experiments.experiment][INFO] - [EMA] Epoch 69.[Train] time:440.62294030189514 seconds, lr:0.0206, train_loss: 0.2716, unlabeled_losses_real_strong:0.5074,corrrect_unlabeled_num:399655.0,pro_above_threshold_num:409420.0,unlabelled_weak_top1_acc:93.45768404752016,unlabelled_weak_top5_acc:99.74299876391888  \n","[2022-04-18 09:19:18,420][experiments.experiment][INFO] - [EMA] Epoch 69. [Validation] raw_testing_loss: 0.3541, raw test Top1 acc:91.14, raw test Top5 acc: 99.48, ema_testing_loss: 0.2515, ema test Top1 acc:93.38, ema test Top5 acc: 99.92\n","[2022-04-18 09:19:18,515][experiments.experiment][INFO] - [Checkpoints] Epoch 69, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_69.pth.tar\n","[2022-04-18 09:19:18,516][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 09:26:38,274][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 70: use 439.8541417121887 seconds\n","--- Optimizer learning rate changed from 2.06e-02 to 2.04e-02 ---\n","[2022-04-18 09:26:38,370][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:26:39,677][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 09:26:39,677][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:26:40,977][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 09:26:40,978][experiments.experiment][INFO] - [EMA] Epoch 70.[Train] time:439.8541417121887 seconds, lr:0.0204, train_loss: 0.2719, unlabeled_losses_real_strong:0.5065,corrrect_unlabeled_num:400373.0,pro_above_threshold_num:410107.0,unlabelled_weak_top1_acc:93.53833777457476,unlabelled_weak_top5_acc:99.7501922622323  \n","[2022-04-18 09:26:40,981][experiments.experiment][INFO] - [EMA] Epoch 70. [Validation] raw_testing_loss: 0.3560, raw test Top1 acc:91.12, raw test Top5 acc: 99.66, ema_testing_loss: 0.2731, ema test Top1 acc:93.2, ema test Top5 acc: 99.86\n","[2022-04-18 09:26:40,982][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 09:34:02,570][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 71: use 441.68439269065857 seconds\n","--- Optimizer learning rate changed from 2.04e-02 to 2.01e-02 ---\n","[2022-04-18 09:34:02,666][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:34:04,006][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 09:34:04,007][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:34:05,348][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 09:34:05,349][experiments.experiment][INFO] - [EMA] Epoch 71.[Train] time:441.68439269065857 seconds, lr:0.0201, train_loss: 0.2703, unlabeled_losses_real_strong:0.4998,corrrect_unlabeled_num:400966.0,pro_above_threshold_num:410837.0,unlabelled_weak_top1_acc:93.57038103044033,unlabelled_weak_top5_acc:99.75564178824425  \n","[2022-04-18 09:34:05,351][experiments.experiment][INFO] - [EMA] Epoch 71. [Validation] raw_testing_loss: 0.3347, raw test Top1 acc:91.0, raw test Top5 acc: 99.56, ema_testing_loss: 0.2432, ema test Top1 acc:93.24, ema test Top5 acc: 99.8\n","[2022-04-18 09:34:05,442][experiments.experiment][INFO] - [Checkpoints] Epoch 71, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_71.pth.tar\n","[2022-04-18 09:34:05,443][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 09:41:26,847][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 72: use 441.50368642807007 seconds\n","--- Optimizer learning rate changed from 2.01e-02 to 1.99e-02 ---\n","[2022-04-18 09:41:26,947][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:41:28,322][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 09:41:28,323][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:41:29,647][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 09:41:29,648][experiments.experiment][INFO] - [EMA] Epoch 72.[Train] time:441.50368642807007 seconds, lr:0.0199, train_loss: 0.2686, unlabeled_losses_real_strong:0.4982,corrrect_unlabeled_num:401538.0,pro_above_threshold_num:411246.0,unlabelled_weak_top1_acc:93.59610313177109,unlabelled_weak_top5_acc:99.75520579516888  \n","[2022-04-18 09:41:29,650][experiments.experiment][INFO] - [EMA] Epoch 72. [Validation] raw_testing_loss: 0.3144, raw test Top1 acc:91.46, raw test Top5 acc: 99.66, ema_testing_loss: 0.2353, ema test Top1 acc:93.52, ema test Top5 acc: 99.9\n","[2022-04-18 09:41:29,651][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 09:48:49,658][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 73: use 440.10312366485596 seconds\n","--- Optimizer learning rate changed from 1.99e-02 to 1.96e-02 ---\n","[2022-04-18 09:48:49,755][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:48:51,061][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 09:48:51,061][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:48:52,397][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 09:48:52,399][experiments.experiment][INFO] - [EMA] Epoch 73.[Train] time:440.10312366485596 seconds, lr:0.0196, train_loss: 0.2686, unlabeled_losses_real_strong:0.4994,corrrect_unlabeled_num:401392.0,pro_above_threshold_num:411024.0,unlabelled_weak_top1_acc:93.67762864381075,unlabelled_weak_top5_acc:99.75607771426439  \n","[2022-04-18 09:48:52,400][experiments.experiment][INFO] - [EMA] Epoch 73. [Validation] raw_testing_loss: 0.3359, raw test Top1 acc:91.24, raw test Top5 acc: 99.82, ema_testing_loss: 0.2702, ema test Top1 acc:93.02, ema test Top5 acc: 99.86\n","[2022-04-18 09:48:52,492][experiments.experiment][INFO] - [Checkpoints] Epoch 73, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_73.pth.tar\n","[2022-04-18 09:48:52,492][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 09:56:15,182][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 74: use 442.78582644462585 seconds\n","--- Optimizer learning rate changed from 1.96e-02 to 1.93e-02 ---\n","[2022-04-18 09:56:15,278][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:56:16,636][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 09:56:16,636][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:56:17,953][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 09:56:17,954][experiments.experiment][INFO] - [EMA] Epoch 74.[Train] time:442.78582644462585 seconds, lr:0.0193, train_loss: 0.2684, unlabeled_losses_real_strong:0.4952,corrrect_unlabeled_num:402082.0,pro_above_threshold_num:411752.0,unlabelled_weak_top1_acc:93.71512169390917,unlabelled_weak_top5_acc:99.75062827765942  \n","[2022-04-18 09:56:17,957][experiments.experiment][INFO] - [EMA] Epoch 74. [Validation] raw_testing_loss: 0.3147, raw test Top1 acc:91.54, raw test Top5 acc: 99.82, ema_testing_loss: 0.2423, ema test Top1 acc:93.24, ema test Top5 acc: 99.92\n","[2022-04-18 09:56:17,958][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 10:03:40,421][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 75: use 442.55826926231384 seconds\n","--- Optimizer learning rate changed from 1.93e-02 to 1.91e-02 ---\n","[2022-04-18 10:03:40,516][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:03:41,877][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 10:03:41,878][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:03:43,233][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 10:03:43,234][experiments.experiment][INFO] - [EMA] Epoch 75.[Train] time:442.55826926231384 seconds, lr:0.0191, train_loss: 0.2656, unlabeled_losses_real_strong:0.4913,corrrect_unlabeled_num:402731.0,pro_above_threshold_num:412292.0,unlabelled_weak_top1_acc:93.77201505750418,unlabelled_weak_top5_acc:99.75084614008665  \n","[2022-04-18 10:03:43,236][experiments.experiment][INFO] - [EMA] Epoch 75. [Validation] raw_testing_loss: 0.3058, raw test Top1 acc:91.84, raw test Top5 acc: 99.78, ema_testing_loss: 0.2543, ema test Top1 acc:93.78, ema test Top5 acc: 99.86\n","[2022-04-18 10:03:43,330][experiments.experiment][INFO] - [Checkpoints] Epoch 75, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_75.pth.tar\n","[2022-04-18 10:03:43,330][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 10:11:07,865][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 76: use 444.6275520324707 seconds\n","--- Optimizer learning rate changed from 1.91e-02 to 1.88e-02 ---\n","[2022-04-18 10:11:07,958][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:11:09,330][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 10:11:09,330][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:11:10,747][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 10:11:10,749][experiments.experiment][INFO] - [EMA] Epoch 76.[Train] time:444.6275520324707 seconds, lr:0.0188, train_loss: 0.2645, unlabeled_losses_real_strong:0.4869,corrrect_unlabeled_num:403274.0,pro_above_threshold_num:412864.0,unlabelled_weak_top1_acc:93.84612920880318,unlabelled_weak_top5_acc:99.76392514258623  \n","[2022-04-18 10:11:10,750][experiments.experiment][INFO] - [EMA] Epoch 76. [Validation] raw_testing_loss: 0.3351, raw test Top1 acc:91.6, raw test Top5 acc: 99.62, ema_testing_loss: 0.2456, ema test Top1 acc:93.78, ema test Top5 acc: 99.84\n","[2022-04-18 10:11:10,752][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 10:18:35,062][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 77: use 444.40611815452576 seconds\n","--- Optimizer learning rate changed from 1.88e-02 to 1.85e-02 ---\n","[2022-04-18 10:18:35,158][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:18:36,488][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 10:18:36,488][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:18:37,822][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 10:18:37,823][experiments.experiment][INFO] - [EMA] Epoch 77.[Train] time:444.40611815452576 seconds, lr:0.0185, train_loss: 0.2629, unlabeled_losses_real_strong:0.4867,corrrect_unlabeled_num:403299.0,pro_above_threshold_num:413062.0,unlabelled_weak_top1_acc:93.7999170422554,unlabelled_weak_top5_acc:99.75564185529947  \n","[2022-04-18 10:18:37,826][experiments.experiment][INFO] - [EMA] Epoch 77. [Validation] raw_testing_loss: 0.3682, raw test Top1 acc:90.68, raw test Top5 acc: 99.6, ema_testing_loss: 0.2562, ema test Top1 acc:93.16, ema test Top5 acc: 99.84\n","[2022-04-18 10:18:37,931][experiments.experiment][INFO] - [Checkpoints] Epoch 77, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_77.pth.tar\n","[2022-04-18 10:18:37,932][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 10:26:00,035][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 78: use 442.2015244960785 seconds\n","--- Optimizer learning rate changed from 1.85e-02 to 1.83e-02 ---\n","[2022-04-18 10:26:00,133][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:26:01,455][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 10:26:01,456][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:26:02,778][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 10:26:02,780][experiments.experiment][INFO] - [EMA] Epoch 78.[Train] time:442.2015244960785 seconds, lr:0.0183, train_loss: 0.2628, unlabeled_losses_real_strong:0.4836,corrrect_unlabeled_num:404120.0,pro_above_threshold_num:413874.0,unlabelled_weak_top1_acc:93.84176956117153,unlabelled_weak_top5_acc:99.74932029098272  \n","[2022-04-18 10:26:02,782][experiments.experiment][INFO] - [EMA] Epoch 78. [Validation] raw_testing_loss: 0.4308, raw test Top1 acc:89.4, raw test Top5 acc: 99.42, ema_testing_loss: 0.2538, ema test Top1 acc:93.04, ema test Top5 acc: 99.76\n","[2022-04-18 10:26:02,782][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 10:33:23,132][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 79: use 440.446640253067 seconds\n","--- Optimizer learning rate changed from 1.83e-02 to 1.80e-02 ---\n","[2022-04-18 10:33:23,229][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:33:24,534][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 10:33:24,534][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:33:25,850][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 10:33:25,851][experiments.experiment][INFO] - [EMA] Epoch 79.[Train] time:440.446640253067 seconds, lr:0.0180, train_loss: 0.2623, unlabeled_losses_real_strong:0.4811,corrrect_unlabeled_num:404492.0,pro_above_threshold_num:414137.0,unlabelled_weak_top1_acc:93.932232581079,unlabelled_weak_top5_acc:99.77482440322638  \n","[2022-04-18 10:33:25,854][experiments.experiment][INFO] - [EMA] Epoch 79. [Validation] raw_testing_loss: 0.3224, raw test Top1 acc:91.58, raw test Top5 acc: 99.74, ema_testing_loss: 0.2278, ema test Top1 acc:93.68, ema test Top5 acc: 99.9\n","[2022-04-18 10:33:25,952][experiments.experiment][INFO] - [Checkpoints] Epoch 79, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_79.pth.tar\n","[2022-04-18 10:33:25,953][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 10:40:45,894][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 80: use 440.04649662971497 seconds\n","--- Optimizer learning rate changed from 1.80e-02 to 1.77e-02 ---\n","[2022-04-18 10:40:46,000][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:40:47,334][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 10:40:47,334][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:40:48,626][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 10:40:48,627][experiments.experiment][INFO] - [EMA] Epoch 80.[Train] time:440.04649662971497 seconds, lr:0.0177, train_loss: 0.2609, unlabeled_losses_real_strong:0.4791,corrrect_unlabeled_num:405000.0,pro_above_threshold_num:414643.0,unlabelled_weak_top1_acc:93.96514791995287,unlabelled_weak_top5_acc:99.74605059623718  \n","[2022-04-18 10:40:48,630][experiments.experiment][INFO] - [EMA] Epoch 80. [Validation] raw_testing_loss: 0.3024, raw test Top1 acc:91.32, raw test Top5 acc: 99.82, ema_testing_loss: 0.2327, ema test Top1 acc:93.62, ema test Top5 acc: 99.88\n","[2022-04-18 10:40:48,632][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 10:48:09,912][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 81: use 441.3779604434967 seconds\n","--- Optimizer learning rate changed from 1.77e-02 to 1.74e-02 ---\n","[2022-04-18 10:48:10,010][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:48:11,318][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 10:48:11,319][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:48:12,657][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 10:48:12,659][experiments.experiment][INFO] - [EMA] Epoch 81.[Train] time:441.3779604434967 seconds, lr:0.0174, train_loss: 0.2603, unlabeled_losses_real_strong:0.4770,corrrect_unlabeled_num:405592.0,pro_above_threshold_num:415098.0,unlabelled_weak_top1_acc:94.03751812875271,unlabelled_weak_top5_acc:99.76327121257782  \n","[2022-04-18 10:48:12,661][experiments.experiment][INFO] - [EMA] Epoch 81. [Validation] raw_testing_loss: 0.3003, raw test Top1 acc:91.5, raw test Top5 acc: 99.64, ema_testing_loss: 0.2402, ema test Top1 acc:93.68, ema test Top5 acc: 99.84\n","[2022-04-18 10:48:12,756][experiments.experiment][INFO] - [Checkpoints] Epoch 81, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_81.pth.tar\n","[2022-04-18 10:48:12,758][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 10:55:34,165][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 82: use 441.5049731731415 seconds\n","--- Optimizer learning rate changed from 1.74e-02 to 1.72e-02 ---\n","[2022-04-18 10:55:34,263][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:55:35,580][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 10:55:35,580][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:55:36,892][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 10:55:36,894][experiments.experiment][INFO] - [EMA] Epoch 82.[Train] time:441.5049731731415 seconds, lr:0.0172, train_loss: 0.2561, unlabeled_losses_real_strong:0.4704,corrrect_unlabeled_num:405855.0,pro_above_threshold_num:415176.0,unlabelled_weak_top1_acc:94.13473848998547,unlabelled_weak_top5_acc:99.76261730492115  \n","[2022-04-18 10:55:36,896][experiments.experiment][INFO] - [EMA] Epoch 82. [Validation] raw_testing_loss: 0.2977, raw test Top1 acc:91.94, raw test Top5 acc: 99.74, ema_testing_loss: 0.2417, ema test Top1 acc:93.36, ema test Top5 acc: 99.9\n","[2022-04-18 10:55:36,897][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 11:02:58,450][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 83: use 441.6490397453308 seconds\n","--- Optimizer learning rate changed from 1.72e-02 to 1.69e-02 ---\n","[2022-04-18 11:02:58,546][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:02:59,863][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 11:02:59,863][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:03:01,183][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 11:03:01,185][experiments.experiment][INFO] - [EMA] Epoch 83.[Train] time:441.6490397453308 seconds, lr:0.0169, train_loss: 0.2569, unlabeled_losses_real_strong:0.4691,corrrect_unlabeled_num:406701.0,pro_above_threshold_num:416084.0,unlabelled_weak_top1_acc:94.16481982171535,unlabelled_weak_top5_acc:99.78223580867052  \n","[2022-04-18 11:03:01,187][experiments.experiment][INFO] - [EMA] Epoch 83. [Validation] raw_testing_loss: 0.3088, raw test Top1 acc:91.52, raw test Top5 acc: 99.58, ema_testing_loss: 0.2320, ema test Top1 acc:93.32, ema test Top5 acc: 99.86\n","[2022-04-18 11:03:01,281][experiments.experiment][INFO] - [Checkpoints] Epoch 83, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_83.pth.tar\n","[2022-04-18 11:03:01,282][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 11:10:23,993][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 84: use 442.8128399848938 seconds\n","--- Optimizer learning rate changed from 1.69e-02 to 1.66e-02 ---\n","[2022-04-18 11:10:24,095][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:10:25,421][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 11:10:25,421][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:10:26,755][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 11:10:26,757][experiments.experiment][INFO] - [EMA] Epoch 84.[Train] time:442.8128399848938 seconds, lr:0.0166, train_loss: 0.2558, unlabeled_losses_real_strong:0.4663,corrrect_unlabeled_num:406764.0,pro_above_threshold_num:416312.0,unlabelled_weak_top1_acc:94.17528317123652,unlabelled_weak_top5_acc:99.77678613364697  \n","[2022-04-18 11:10:26,758][experiments.experiment][INFO] - [EMA] Epoch 84. [Validation] raw_testing_loss: 0.3003, raw test Top1 acc:91.44, raw test Top5 acc: 99.84, ema_testing_loss: 0.2097, ema test Top1 acc:94.26, ema test Top5 acc: 99.86\n","[2022-04-18 11:10:26,759][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 11:17:49,985][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 85: use 443.329998254776 seconds\n","--- Optimizer learning rate changed from 1.66e-02 to 1.63e-02 ---\n","[2022-04-18 11:17:50,089][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:17:51,459][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 11:17:51,459][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:17:52,800][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 11:17:52,802][experiments.experiment][INFO] - [EMA] Epoch 85.[Train] time:443.329998254776 seconds, lr:0.0163, train_loss: 0.2544, unlabeled_losses_real_strong:0.4640,corrrect_unlabeled_num:407123.0,pro_above_threshold_num:416588.0,unlabelled_weak_top1_acc:94.18683619052172,unlabelled_weak_top5_acc:99.77068259567022  \n","[2022-04-18 11:17:52,804][experiments.experiment][INFO] - [EMA] Epoch 85. [Validation] raw_testing_loss: 0.2774, raw test Top1 acc:92.48, raw test Top5 acc: 99.78, ema_testing_loss: 0.2246, ema test Top1 acc:93.88, ema test Top5 acc: 99.92\n","[2022-04-18 11:17:52,895][experiments.experiment][INFO] - [Checkpoints] Epoch 85, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_85.pth.tar\n","[2022-04-18 11:17:52,896][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 11:25:14,743][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 86: use 441.94524097442627 seconds\n","--- Optimizer learning rate changed from 1.63e-02 to 1.60e-02 ---\n","[2022-04-18 11:25:14,841][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:25:16,216][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 11:25:16,217][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:25:17,554][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 11:25:17,556][experiments.experiment][INFO] - [EMA] Epoch 86.[Train] time:441.94524097442627 seconds, lr:0.0160, train_loss: 0.2530, unlabeled_losses_real_strong:0.4612,corrrect_unlabeled_num:407749.0,pro_above_threshold_num:417140.0,unlabelled_weak_top1_acc:94.24067799001932,unlabelled_weak_top5_acc:99.76981068402529  \n","[2022-04-18 11:25:17,558][experiments.experiment][INFO] - [EMA] Epoch 86. [Validation] raw_testing_loss: 0.2955, raw test Top1 acc:92.46, raw test Top5 acc: 99.8, ema_testing_loss: 0.2467, ema test Top1 acc:93.6, ema test Top5 acc: 99.88\n","[2022-04-18 11:25:17,559][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 11:32:41,096][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 87: use 443.6324486732483 seconds\n","--- Optimizer learning rate changed from 1.60e-02 to 1.57e-02 ---\n","[2022-04-18 11:32:41,191][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:32:42,557][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 11:32:42,557][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:32:43,895][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 11:32:43,897][experiments.experiment][INFO] - [EMA] Epoch 87.[Train] time:443.6324486732483 seconds, lr:0.0157, train_loss: 0.2510, unlabeled_losses_real_strong:0.4615,corrrect_unlabeled_num:407804.0,pro_above_threshold_num:417274.0,unlabelled_weak_top1_acc:94.25833457708359,unlabelled_weak_top5_acc:99.76784880459309  \n","[2022-04-18 11:32:43,899][experiments.experiment][INFO] - [EMA] Epoch 87. [Validation] raw_testing_loss: 0.2696, raw test Top1 acc:92.26, raw test Top5 acc: 99.72, ema_testing_loss: 0.2243, ema test Top1 acc:93.58, ema test Top5 acc: 99.84\n","[2022-04-18 11:32:43,993][experiments.experiment][INFO] - [Checkpoints] Epoch 87, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_87.pth.tar\n","[2022-04-18 11:32:43,994][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 11:40:06,272][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 88: use 442.38461089134216 seconds\n","--- Optimizer learning rate changed from 1.57e-02 to 1.54e-02 ---\n","[2022-04-18 11:40:06,379][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:40:07,740][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 11:40:07,740][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:40:09,035][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 11:40:09,037][experiments.experiment][INFO] - [EMA] Epoch 88.[Train] time:442.38461089134216 seconds, lr:0.0154, train_loss: 0.2510, unlabeled_losses_real_strong:0.4565,corrrect_unlabeled_num:408694.0,pro_above_threshold_num:418160.0,unlabelled_weak_top1_acc:94.33811613917351,unlabelled_weak_top5_acc:99.78070987015963  \n","[2022-04-18 11:40:09,039][experiments.experiment][INFO] - [EMA] Epoch 88. [Validation] raw_testing_loss: 0.2873, raw test Top1 acc:92.46, raw test Top5 acc: 99.72, ema_testing_loss: 0.2272, ema test Top1 acc:93.86, ema test Top5 acc: 99.86\n","[2022-04-18 11:40:09,040][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 11:47:32,662][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 89: use 443.71726727485657 seconds\n","--- Optimizer learning rate changed from 1.54e-02 to 1.51e-02 ---\n","[2022-04-18 11:47:32,757][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:47:34,116][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 11:47:34,116][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:47:35,452][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 11:47:35,453][experiments.experiment][INFO] - [EMA] Epoch 89.[Train] time:443.71726727485657 seconds, lr:0.0151, train_loss: 0.2483, unlabeled_losses_real_strong:0.4525,corrrect_unlabeled_num:409546.0,pro_above_threshold_num:418904.0,unlabelled_weak_top1_acc:94.36885184049606,unlabelled_weak_top5_acc:99.78877530992031  \n","[2022-04-18 11:47:35,455][experiments.experiment][INFO] - [EMA] Epoch 89. [Validation] raw_testing_loss: 0.2500, raw test Top1 acc:92.52, raw test Top5 acc: 99.76, ema_testing_loss: 0.2143, ema test Top1 acc:94.22, ema test Top5 acc: 99.84\n","[2022-04-18 11:47:35,546][experiments.experiment][INFO] - [Checkpoints] Epoch 89, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_89.pth.tar\n","[2022-04-18 11:47:35,547][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 11:54:58,291][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 90: use 442.8423421382904 seconds\n","--- Optimizer learning rate changed from 1.51e-02 to 1.48e-02 ---\n","[2022-04-18 11:54:58,389][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:54:59,701][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 11:54:59,701][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:55:01,023][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 11:55:01,025][experiments.experiment][INFO] - [EMA] Epoch 90.[Train] time:442.8423421382904 seconds, lr:0.0148, train_loss: 0.2467, unlabeled_losses_real_strong:0.4497,corrrect_unlabeled_num:409573.0,pro_above_threshold_num:419004.0,unlabelled_weak_top1_acc:94.40024130046368,unlabelled_weak_top5_acc:99.7785300835967  \n","[2022-04-18 11:55:01,026][experiments.experiment][INFO] - [EMA] Epoch 90. [Validation] raw_testing_loss: 0.2731, raw test Top1 acc:92.76, raw test Top5 acc: 99.8, ema_testing_loss: 0.2237, ema test Top1 acc:94.0, ema test Top5 acc: 99.82\n","[2022-04-18 11:55:01,028][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 12:02:23,036][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 91: use 442.1064531803131 seconds\n","--- Optimizer learning rate changed from 1.48e-02 to 1.45e-02 ---\n","[2022-04-18 12:02:23,134][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:02:24,463][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 12:02:24,464][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:02:25,813][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 12:02:25,815][experiments.experiment][INFO] - [EMA] Epoch 91.[Train] time:442.1064531803131 seconds, lr:0.0145, train_loss: 0.2460, unlabeled_losses_real_strong:0.4456,corrrect_unlabeled_num:409957.0,pro_above_threshold_num:419396.0,unlabelled_weak_top1_acc:94.45342899858952,unlabelled_weak_top5_acc:99.79771251231432  \n","[2022-04-18 12:02:25,818][experiments.experiment][INFO] - [EMA] Epoch 91. [Validation] raw_testing_loss: 0.2997, raw test Top1 acc:91.78, raw test Top5 acc: 99.82, ema_testing_loss: 0.2337, ema test Top1 acc:93.52, ema test Top5 acc: 99.96\n","[2022-04-18 12:02:25,907][experiments.experiment][INFO] - [Checkpoints] Epoch 91, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_91.pth.tar\n","[2022-04-18 12:02:25,908][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 12:09:48,785][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 92: use 442.97044682502747 seconds\n","--- Optimizer learning rate changed from 1.45e-02 to 1.42e-02 ---\n","[2022-04-18 12:09:48,878][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:09:50,203][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 12:09:50,204][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:09:51,516][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 12:09:51,517][experiments.experiment][INFO] - [EMA] Epoch 92.[Train] time:442.97044682502747 seconds, lr:0.0142, train_loss: 0.2465, unlabeled_losses_real_strong:0.4462,corrrect_unlabeled_num:410759.0,pro_above_threshold_num:420005.0,unlabelled_weak_top1_acc:94.50182121992111,unlabelled_weak_top5_acc:99.7868134751916  \n","[2022-04-18 12:09:51,520][experiments.experiment][INFO] - [EMA] Epoch 92. [Validation] raw_testing_loss: 0.3514, raw test Top1 acc:91.1, raw test Top5 acc: 99.82, ema_testing_loss: 0.2239, ema test Top1 acc:94.02, ema test Top5 acc: 99.9\n","[2022-04-18 12:09:51,521][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 12:17:14,679][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 93: use 443.2566604614258 seconds\n","--- Optimizer learning rate changed from 1.42e-02 to 1.39e-02 ---\n","[2022-04-18 12:17:14,777][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:17:16,105][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 12:17:16,106][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:17:17,420][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 12:17:17,421][experiments.experiment][INFO] - [EMA] Epoch 93.[Train] time:443.2566604614258 seconds, lr:0.0139, train_loss: 0.2430, unlabeled_losses_real_strong:0.4407,corrrect_unlabeled_num:410668.0,pro_above_threshold_num:419759.0,unlabelled_weak_top1_acc:94.55740681290627,unlabelled_weak_top5_acc:99.77983809262514  \n","[2022-04-18 12:17:17,422][experiments.experiment][INFO] - [EMA] Epoch 93. [Validation] raw_testing_loss: 0.3047, raw test Top1 acc:92.36, raw test Top5 acc: 99.78, ema_testing_loss: 0.2212, ema test Top1 acc:94.1, ema test Top5 acc: 99.94\n","[2022-04-18 12:17:17,514][experiments.experiment][INFO] - [Checkpoints] Epoch 93, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_93.pth.tar\n","[2022-04-18 12:17:17,515][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 12:24:40,607][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 94: use 443.19375252723694 seconds\n","--- Optimizer learning rate changed from 1.39e-02 to 1.36e-02 ---\n","[2022-04-18 12:24:40,709][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:24:42,062][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 12:24:42,063][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:24:43,353][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 12:24:43,355][experiments.experiment][INFO] - [EMA] Epoch 94.[Train] time:443.19375252723694 seconds, lr:0.0136, train_loss: 0.2419, unlabeled_losses_real_strong:0.4390,corrrect_unlabeled_num:412217.0,pro_above_threshold_num:421748.0,unlabelled_weak_top1_acc:94.59686170518398,unlabelled_weak_top5_acc:99.80185429751873  \n","[2022-04-18 12:24:43,357][experiments.experiment][INFO] - [EMA] Epoch 94. [Validation] raw_testing_loss: 0.2564, raw test Top1 acc:92.92, raw test Top5 acc: 99.84, ema_testing_loss: 0.2177, ema test Top1 acc:94.08, ema test Top5 acc: 99.86\n","[2022-04-18 12:24:43,358][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 12:32:06,856][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 95: use 443.59533405303955 seconds\n","--- Optimizer learning rate changed from 1.36e-02 to 1.33e-02 ---\n","[2022-04-18 12:32:06,953][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:32:08,367][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 12:32:08,367][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:32:09,683][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 12:32:09,684][experiments.experiment][INFO] - [EMA] Epoch 95.[Train] time:443.59533405303955 seconds, lr:0.0133, train_loss: 0.2411, unlabeled_losses_real_strong:0.4364,corrrect_unlabeled_num:412351.0,pro_above_threshold_num:421710.0,unlabelled_weak_top1_acc:94.641766063869,unlabelled_weak_top5_acc:99.80272620916367  \n","[2022-04-18 12:32:09,687][experiments.experiment][INFO] - [EMA] Epoch 95. [Validation] raw_testing_loss: 0.2673, raw test Top1 acc:92.38, raw test Top5 acc: 99.78, ema_testing_loss: 0.2189, ema test Top1 acc:93.94, ema test Top5 acc: 99.88\n","[2022-04-18 12:32:09,776][experiments.experiment][INFO] - [Checkpoints] Epoch 95, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_95.pth.tar\n","[2022-04-18 12:32:09,776][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 12:39:33,038][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 96: use 443.3585045337677 seconds\n","--- Optimizer learning rate changed from 1.33e-02 to 1.30e-02 ---\n","[2022-04-18 12:39:33,135][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:39:34,482][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 12:39:34,482][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:39:35,780][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 12:39:35,782][experiments.experiment][INFO] - [EMA] Epoch 96.[Train] time:443.3585045337677 seconds, lr:0.0130, train_loss: 0.2398, unlabeled_losses_real_strong:0.4323,corrrect_unlabeled_num:412653.0,pro_above_threshold_num:421988.0,unlabelled_weak_top1_acc:94.65288334339857,unlabelled_weak_top5_acc:99.80011036992073  \n","[2022-04-18 12:39:35,783][experiments.experiment][INFO] - [EMA] Epoch 96. [Validation] raw_testing_loss: 0.3063, raw test Top1 acc:91.74, raw test Top5 acc: 99.8, ema_testing_loss: 0.2142, ema test Top1 acc:94.3, ema test Top5 acc: 99.9\n","[2022-04-18 12:39:35,784][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 12:46:58,857][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 97: use 443.18005204200745 seconds\n","--- Optimizer learning rate changed from 1.30e-02 to 1.27e-02 ---\n","[2022-04-18 12:46:58,964][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:47:00,301][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 12:47:00,301][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:47:01,677][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 12:47:01,678][experiments.experiment][INFO] - [EMA] Epoch 97.[Train] time:443.18005204200745 seconds, lr:0.0127, train_loss: 0.2368, unlabeled_losses_real_strong:0.4284,corrrect_unlabeled_num:413260.0,pro_above_threshold_num:422614.0,unlabelled_weak_top1_acc:94.71697017550468,unlabelled_weak_top5_acc:99.79858449846506  \n","[2022-04-18 12:47:01,681][experiments.experiment][INFO] - [EMA] Epoch 97. [Validation] raw_testing_loss: 0.2592, raw test Top1 acc:92.76, raw test Top5 acc: 99.76, ema_testing_loss: 0.2078, ema test Top1 acc:94.12, ema test Top5 acc: 99.84\n","[2022-04-18 12:47:01,772][experiments.experiment][INFO] - [Checkpoints] Epoch 97, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_97.pth.tar\n","[2022-04-18 12:47:01,772][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 12:54:28,443][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 98: use 446.7666206359863 seconds\n","--- Optimizer learning rate changed from 1.27e-02 to 1.24e-02 ---\n","[2022-04-18 12:54:28,539][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:54:29,845][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 12:54:29,845][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:54:31,137][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 12:54:31,139][experiments.experiment][INFO] - [EMA] Epoch 98.[Train] time:446.7666206359863 seconds, lr:0.0124, train_loss: 0.2374, unlabeled_losses_real_strong:0.4268,corrrect_unlabeled_num:413754.0,pro_above_threshold_num:423107.0,unlabelled_weak_top1_acc:94.72307367622852,unlabelled_weak_top5_acc:99.79836647212505  \n","[2022-04-18 12:54:31,141][experiments.experiment][INFO] - [EMA] Epoch 98. [Validation] raw_testing_loss: 0.2939, raw test Top1 acc:92.34, raw test Top5 acc: 99.8, ema_testing_loss: 0.2089, ema test Top1 acc:94.7, ema test Top5 acc: 99.86\n","[2022-04-18 12:54:31,142][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 13:01:54,680][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 99: use 443.6379075050354 seconds\n","--- Optimizer learning rate changed from 1.24e-02 to 1.21e-02 ---\n","[2022-04-18 13:01:54,780][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:01:56,142][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 13:01:56,142][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:01:57,451][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 13:01:57,453][experiments.experiment][INFO] - [EMA] Epoch 99.[Train] time:443.6379075050354 seconds, lr:0.0121, train_loss: 0.2345, unlabeled_losses_real_strong:0.4242,corrrect_unlabeled_num:414092.0,pro_above_threshold_num:423548.0,unlabelled_weak_top1_acc:94.78825046867132,unlabelled_weak_top5_acc:99.80643181502819  \n","[2022-04-18 13:01:57,456][experiments.experiment][INFO] - [EMA] Epoch 99. [Validation] raw_testing_loss: 0.2936, raw test Top1 acc:91.96, raw test Top5 acc: 99.78, ema_testing_loss: 0.2062, ema test Top1 acc:94.3, ema test Top5 acc: 99.9\n","[2022-04-18 13:01:57,546][experiments.experiment][INFO] - [Checkpoints] Epoch 99, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_99.pth.tar\n","[2022-04-18 13:01:57,547][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 13:09:21,609][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 100: use 444.16090536117554 seconds\n","--- Optimizer learning rate changed from 1.21e-02 to 1.18e-02 ---\n","[2022-04-18 13:09:21,708][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:09:23,083][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 13:09:23,083][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:09:24,435][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 13:09:24,437][experiments.experiment][INFO] - [EMA] Epoch 100.[Train] time:444.16090536117554 seconds, lr:0.0118, train_loss: 0.2319, unlabeled_losses_real_strong:0.4196,corrrect_unlabeled_num:414336.0,pro_above_threshold_num:423662.0,unlabelled_weak_top1_acc:94.85691507160664,unlabelled_weak_top5_acc:99.80773978680372  \n","[2022-04-18 13:09:24,438][experiments.experiment][INFO] - [EMA] Epoch 100. [Validation] raw_testing_loss: 0.2943, raw test Top1 acc:92.34, raw test Top5 acc: 99.82, ema_testing_loss: 0.2107, ema test Top1 acc:94.28, ema test Top5 acc: 99.88\n","[2022-04-18 13:09:24,440][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 13:16:50,054][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 101: use 445.7098562717438 seconds\n","--- Optimizer learning rate changed from 1.18e-02 to 1.14e-02 ---\n","[2022-04-18 13:16:50,150][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:16:51,473][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 13:16:51,474][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:16:52,809][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 13:16:52,811][experiments.experiment][INFO] - [EMA] Epoch 101.[Train] time:445.7098562717438 seconds, lr:0.0114, train_loss: 0.2310, unlabeled_losses_real_strong:0.4180,corrrect_unlabeled_num:415227.0,pro_above_threshold_num:424728.0,unlabelled_weak_top1_acc:94.84231031686068,unlabelled_weak_top5_acc:99.80229019373655  \n","[2022-04-18 13:16:52,813][experiments.experiment][INFO] - [EMA] Epoch 101. [Validation] raw_testing_loss: 0.2697, raw test Top1 acc:92.62, raw test Top5 acc: 99.82, ema_testing_loss: 0.2110, ema test Top1 acc:94.18, ema test Top5 acc: 99.92\n","[2022-04-18 13:16:52,904][experiments.experiment][INFO] - [Checkpoints] Epoch 101, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_101.pth.tar\n","[2022-04-18 13:16:52,905][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 13:24:16,390][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 102: use 443.5871727466583 seconds\n","--- Optimizer learning rate changed from 1.14e-02 to 1.11e-02 ---\n","[2022-04-18 13:24:16,492][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:24:17,881][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 13:24:17,881][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:24:19,173][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 13:24:19,174][experiments.experiment][INFO] - [EMA] Epoch 102.[Train] time:443.5871727466583 seconds, lr:0.0111, train_loss: 0.2304, unlabeled_losses_real_strong:0.4149,corrrect_unlabeled_num:415744.0,pro_above_threshold_num:425106.0,unlabelled_weak_top1_acc:94.90225534886122,unlabelled_weak_top5_acc:99.80294405668974  \n","[2022-04-18 13:24:19,176][experiments.experiment][INFO] - [EMA] Epoch 102. [Validation] raw_testing_loss: 0.3471, raw test Top1 acc:91.2, raw test Top5 acc: 99.56, ema_testing_loss: 0.2113, ema test Top1 acc:94.14, ema test Top5 acc: 99.9\n","[2022-04-18 13:24:19,178][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 13:31:42,482][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 103: use 443.4036567211151 seconds\n","--- Optimizer learning rate changed from 1.11e-02 to 1.08e-02 ---\n","[2022-04-18 13:31:42,581][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:31:43,912][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 13:31:43,913][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:31:45,239][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 13:31:45,241][experiments.experiment][INFO] - [EMA] Epoch 103.[Train] time:443.4036567211151 seconds, lr:0.0108, train_loss: 0.2296, unlabeled_losses_real_strong:0.4122,corrrect_unlabeled_num:416589.0,pro_above_threshold_num:425956.0,unlabelled_weak_top1_acc:94.9619827568531,unlabelled_weak_top5_acc:99.80752176046371  \n","[2022-04-18 13:31:45,242][experiments.experiment][INFO] - [EMA] Epoch 103. [Validation] raw_testing_loss: 0.2796, raw test Top1 acc:92.36, raw test Top5 acc: 99.82, ema_testing_loss: 0.2042, ema test Top1 acc:94.34, ema test Top5 acc: 99.92\n","[2022-04-18 13:31:45,332][experiments.experiment][INFO] - [Checkpoints] Epoch 103, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_103.pth.tar\n","[2022-04-18 13:31:45,333][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 13:39:07,884][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 104: use 442.66072630882263 seconds\n","--- Optimizer learning rate changed from 1.08e-02 to 1.05e-02 ---\n","[2022-04-18 13:39:07,994][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:39:09,318][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 13:39:09,319][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:39:10,650][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 13:39:10,652][experiments.experiment][INFO] - [EMA] Epoch 104.[Train] time:442.66072630882263 seconds, lr:0.0105, train_loss: 0.2263, unlabeled_losses_real_strong:0.4078,corrrect_unlabeled_num:416654.0,pro_above_threshold_num:426162.0,unlabelled_weak_top1_acc:94.97200991213322,unlabelled_weak_top5_acc:99.80555983632803  \n","[2022-04-18 13:39:10,654][experiments.experiment][INFO] - [EMA] Epoch 104. [Validation] raw_testing_loss: 0.2141, raw test Top1 acc:93.46, raw test Top5 acc: 99.92, ema_testing_loss: 0.2005, ema test Top1 acc:94.2, ema test Top5 acc: 99.92\n","[2022-04-18 13:39:10,655][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 13:46:33,943][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 105: use 443.3859760761261 seconds\n","--- Optimizer learning rate changed from 1.05e-02 to 1.02e-02 ---\n","[2022-04-18 13:46:34,041][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:46:35,360][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 13:46:35,360][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:46:36,685][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 13:46:36,686][experiments.experiment][INFO] - [EMA] Epoch 105.[Train] time:443.3859760761261 seconds, lr:0.0102, train_loss: 0.2267, unlabeled_losses_real_strong:0.4059,corrrect_unlabeled_num:417437.0,pro_above_threshold_num:426913.0,unlabelled_weak_top1_acc:95.05375343561172,unlabelled_weak_top5_acc:99.79553274065256  \n","[2022-04-18 13:46:36,687][experiments.experiment][INFO] - [EMA] Epoch 105. [Validation] raw_testing_loss: 0.2424, raw test Top1 acc:93.34, raw test Top5 acc: 99.88, ema_testing_loss: 0.2092, ema test Top1 acc:94.44, ema test Top5 acc: 99.96\n","[2022-04-18 13:46:36,779][experiments.experiment][INFO] - [Checkpoints] Epoch 105, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_105.pth.tar\n","[2022-04-18 13:46:36,780][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 13:54:00,194][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 106: use 443.5139286518097 seconds\n","--- Optimizer learning rate changed from 1.02e-02 to 9.83e-03 ---\n","[2022-04-18 13:54:00,294][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:54:01,605][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 13:54:01,605][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:54:03,002][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 13:54:03,004][experiments.experiment][INFO] - [EMA] Epoch 106.[Train] time:443.5139286518097 seconds, lr:0.0098, train_loss: 0.2229, unlabeled_losses_real_strong:0.3998,corrrect_unlabeled_num:417807.0,pro_above_threshold_num:427370.0,unlabelled_weak_top1_acc:95.06203681230545,unlabelled_weak_top5_acc:99.80447006970644  \n","[2022-04-18 13:54:03,006][experiments.experiment][INFO] - [EMA] Epoch 106. [Validation] raw_testing_loss: 0.2472, raw test Top1 acc:92.9, raw test Top5 acc: 99.78, ema_testing_loss: 0.1979, ema test Top1 acc:94.42, ema test Top5 acc: 99.92\n","[2022-04-18 13:54:03,007][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 14:01:26,684][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 107: use 443.77416491508484 seconds\n","--- Optimizer learning rate changed from 9.83e-03 to 9.50e-03 ---\n","[2022-04-18 14:01:26,781][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:01:28,134][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 14:01:28,134][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:01:29,469][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 14:01:29,471][experiments.experiment][INFO] - [EMA] Epoch 107.[Train] time:443.77416491508484 seconds, lr:0.0095, train_loss: 0.2216, unlabeled_losses_real_strong:0.4002,corrrect_unlabeled_num:418255.0,pro_above_threshold_num:427964.0,unlabelled_weak_top1_acc:95.08514297753572,unlabelled_weak_top5_acc:99.7953148111701  \n","[2022-04-18 14:01:29,472][experiments.experiment][INFO] - [EMA] Epoch 107. [Validation] raw_testing_loss: 0.2844, raw test Top1 acc:92.56, raw test Top5 acc: 99.74, ema_testing_loss: 0.2222, ema test Top1 acc:93.88, ema test Top5 acc: 99.88\n","[2022-04-18 14:01:29,569][experiments.experiment][INFO] - [Checkpoints] Epoch 107, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_107.pth.tar\n","[2022-04-18 14:01:29,570][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 14:08:55,413][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 108: use 445.9383497238159 seconds\n","--- Optimizer learning rate changed from 9.50e-03 to 9.18e-03 ---\n","[2022-04-18 14:08:55,509][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:08:56,893][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 14:08:56,894][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:08:58,285][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 14:08:58,286][experiments.experiment][INFO] - [EMA] Epoch 108.[Train] time:445.9383497238159 seconds, lr:0.0092, train_loss: 0.2196, unlabeled_losses_real_strong:0.3947,corrrect_unlabeled_num:418547.0,pro_above_threshold_num:428096.0,unlabelled_weak_top1_acc:95.13004741072655,unlabelled_weak_top5_acc:99.81602311879396  \n","[2022-04-18 14:08:58,288][experiments.experiment][INFO] - [EMA] Epoch 108. [Validation] raw_testing_loss: 0.2606, raw test Top1 acc:93.28, raw test Top5 acc: 99.86, ema_testing_loss: 0.2226, ema test Top1 acc:93.76, ema test Top5 acc: 99.9\n","[2022-04-18 14:08:58,290][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 14:16:22,564][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 109: use 444.3712875843048 seconds\n","--- Optimizer learning rate changed from 9.18e-03 to 8.85e-03 ---\n","[2022-04-18 14:16:22,661][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:16:24,000][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 14:16:24,001][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:16:25,317][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 14:16:25,318][experiments.experiment][INFO] - [EMA] Epoch 109.[Train] time:444.3712875843048 seconds, lr:0.0088, train_loss: 0.2175, unlabeled_losses_real_strong:0.3916,corrrect_unlabeled_num:419172.0,pro_above_threshold_num:428865.0,unlabelled_weak_top1_acc:95.157949231565,unlabelled_weak_top5_acc:99.82081875950098  \n","[2022-04-18 14:16:25,320][experiments.experiment][INFO] - [EMA] Epoch 109. [Validation] raw_testing_loss: 0.2666, raw test Top1 acc:93.0, raw test Top5 acc: 99.78, ema_testing_loss: 0.2115, ema test Top1 acc:94.06, ema test Top5 acc: 99.84\n","[2022-04-18 14:16:25,411][experiments.experiment][INFO] - [Checkpoints] Epoch 109, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_109.pth.tar\n","[2022-04-18 14:16:25,412][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 14:23:50,373][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 110: use 445.0576424598694 seconds\n","--- Optimizer learning rate changed from 8.85e-03 to 8.52e-03 ---\n","[2022-04-18 14:23:50,470][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:23:51,842][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 14:23:51,843][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:23:53,165][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 14:23:53,166][experiments.experiment][INFO] - [EMA] Epoch 110.[Train] time:445.0576424598694 seconds, lr:0.0085, train_loss: 0.2157, unlabeled_losses_real_strong:0.3861,corrrect_unlabeled_num:419795.0,pro_above_threshold_num:429392.0,unlabelled_weak_top1_acc:95.20372539013624,unlabelled_weak_top5_acc:99.82321652770042  \n","[2022-04-18 14:23:53,168][experiments.experiment][INFO] - [EMA] Epoch 110. [Validation] raw_testing_loss: 0.2565, raw test Top1 acc:92.84, raw test Top5 acc: 99.94, ema_testing_loss: 0.2021, ema test Top1 acc:94.56, ema test Top5 acc: 99.92\n","[2022-04-18 14:23:53,171][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 14:31:17,133][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 111: use 444.06193566322327 seconds\n","--- Optimizer learning rate changed from 8.52e-03 to 8.19e-03 ---\n","[2022-04-18 14:31:17,233][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:31:18,595][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 14:31:18,595][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:31:19,957][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 14:31:19,958][experiments.experiment][INFO] - [EMA] Epoch 111.[Train] time:444.06193566322327 seconds, lr:0.0082, train_loss: 0.2145, unlabeled_losses_real_strong:0.3838,corrrect_unlabeled_num:420683.0,pro_above_threshold_num:430345.0,unlabelled_weak_top1_acc:95.27282619476318,unlabelled_weak_top5_acc:99.82234463840723  \n","[2022-04-18 14:31:19,961][experiments.experiment][INFO] - [EMA] Epoch 111. [Validation] raw_testing_loss: 0.2436, raw test Top1 acc:93.16, raw test Top5 acc: 99.84, ema_testing_loss: 0.1988, ema test Top1 acc:94.44, ema test Top5 acc: 99.94\n","[2022-04-18 14:31:20,058][experiments.experiment][INFO] - [Checkpoints] Epoch 111, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_111.pth.tar\n","[2022-04-18 14:31:20,059][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 14:38:44,535][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 112: use 444.57409620285034 seconds\n","--- Optimizer learning rate changed from 8.19e-03 to 7.86e-03 ---\n","[2022-04-18 14:38:44,633][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:38:45,939][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 14:38:45,940][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:38:47,267][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 14:38:47,269][experiments.experiment][INFO] - [EMA] Epoch 112.[Train] time:444.57409620285034 seconds, lr:0.0079, train_loss: 0.2123, unlabeled_losses_real_strong:0.3797,corrrect_unlabeled_num:421103.0,pro_above_threshold_num:430749.0,unlabelled_weak_top1_acc:95.33233542740345,unlabelled_weak_top5_acc:99.82583225518465  \n","[2022-04-18 14:38:47,271][experiments.experiment][INFO] - [EMA] Epoch 112. [Validation] raw_testing_loss: 0.2256, raw test Top1 acc:93.8, raw test Top5 acc: 99.9, ema_testing_loss: 0.1928, ema test Top1 acc:94.76, ema test Top5 acc: 99.92\n","[2022-04-18 14:38:47,272][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 14:46:10,415][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 113: use 443.23803186416626 seconds\n","--- Optimizer learning rate changed from 7.86e-03 to 7.53e-03 ---\n","[2022-04-18 14:46:10,510][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:46:11,846][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 14:46:11,846][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:46:13,177][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 14:46:13,179][experiments.experiment][INFO] - [EMA] Epoch 113.[Train] time:443.23803186416626 seconds, lr:0.0075, train_loss: 0.2089, unlabeled_losses_real_strong:0.3775,corrrect_unlabeled_num:421636.0,pro_above_threshold_num:431565.0,unlabelled_weak_top1_acc:95.31729459762573,unlabelled_weak_top5_acc:99.81536918878555  \n","[2022-04-18 14:46:13,181][experiments.experiment][INFO] - [EMA] Epoch 113. [Validation] raw_testing_loss: 0.2341, raw test Top1 acc:93.66, raw test Top5 acc: 99.78, ema_testing_loss: 0.1924, ema test Top1 acc:94.44, ema test Top5 acc: 99.94\n","[2022-04-18 14:46:13,274][experiments.experiment][INFO] - [Checkpoints] Epoch 113, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_113.pth.tar\n","[2022-04-18 14:46:13,275][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 14:53:36,793][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 114: use 443.619423866272 seconds\n","--- Optimizer learning rate changed from 7.53e-03 to 7.19e-03 ---\n","[2022-04-18 14:53:36,895][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:53:38,233][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 14:53:38,234][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:53:39,556][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 14:53:39,558][experiments.experiment][INFO] - [EMA] Epoch 114.[Train] time:443.619423866272 seconds, lr:0.0072, train_loss: 0.2070, unlabeled_losses_real_strong:0.3747,corrrect_unlabeled_num:422235.0,pro_above_threshold_num:432157.0,unlabelled_weak_top1_acc:95.36546867340803,unlabelled_weak_top5_acc:99.82016481459141  \n","[2022-04-18 14:53:39,561][experiments.experiment][INFO] - [EMA] Epoch 114. [Validation] raw_testing_loss: 0.2496, raw test Top1 acc:93.3, raw test Top5 acc: 99.8, ema_testing_loss: 0.1984, ema test Top1 acc:94.9, ema test Top5 acc: 99.86\n","[2022-04-18 14:53:39,561][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 15:01:03,834][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 115: use 444.3658661842346 seconds\n","--- Optimizer learning rate changed from 7.19e-03 to 6.86e-03 ---\n","[2022-04-18 15:01:03,927][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 15:01:05,247][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 15:01:05,247][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 15:01:06,545][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 15:01:06,547][experiments.experiment][INFO] - [EMA] Epoch 115.[Train] time:444.3658661842346 seconds, lr:0.0069, train_loss: 0.2045, unlabeled_losses_real_strong:0.3709,corrrect_unlabeled_num:422491.0,pro_above_threshold_num:432438.0,unlabelled_weak_top1_acc:95.39838411659002,unlabelled_weak_top5_acc:99.8253963291645  \n","[2022-04-18 15:01:06,549][experiments.experiment][INFO] - [EMA] Epoch 115. [Validation] raw_testing_loss: 0.2124, raw test Top1 acc:93.84, raw test Top5 acc: 99.9, ema_testing_loss: 0.1935, ema test Top1 acc:94.52, ema test Top5 acc: 99.96\n","[2022-04-18 15:01:06,638][experiments.experiment][INFO] - [Checkpoints] Epoch 115, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_115.pth.tar\n","[2022-04-18 15:01:06,639][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 15:08:31,695][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 116: use 445.1532051563263 seconds\n","--- Optimizer learning rate changed from 6.86e-03 to 6.53e-03 ---\n","[2022-04-18 15:08:31,792][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 15:08:33,106][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 15:08:33,106][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 15:08:34,471][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 15:08:34,473][experiments.experiment][INFO] - [EMA] Epoch 116.[Train] time:445.1532051563263 seconds, lr:0.0065, train_loss: 0.2031, unlabeled_losses_real_strong:0.3659,corrrect_unlabeled_num:423319.0,pro_above_threshold_num:433221.0,unlabelled_weak_top1_acc:95.45658551901579,unlabelled_weak_top5_acc:99.83476954698563  \n","[2022-04-18 15:08:34,475][experiments.experiment][INFO] - [EMA] Epoch 116. [Validation] raw_testing_loss: 0.2131, raw test Top1 acc:93.9, raw test Top5 acc: 99.86, ema_testing_loss: 0.1934, ema test Top1 acc:94.52, ema test Top5 acc: 99.86\n","[2022-04-18 15:08:34,476][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 15:15:59,529][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 117: use 445.15170788764954 seconds\n","--- Optimizer learning rate changed from 6.53e-03 to 6.19e-03 ---\n","[2022-04-18 15:15:59,627][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 15:16:00,940][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 15:16:00,940][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 15:16:02,250][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 15:16:02,252][experiments.experiment][INFO] - [EMA] Epoch 117.[Train] time:445.15170788764954 seconds, lr:0.0062, train_loss: 0.1995, unlabeled_losses_real_strong:0.3626,corrrect_unlabeled_num:423888.0,pro_above_threshold_num:433805.0,unlabelled_weak_top1_acc:95.49843814224005,unlabelled_weak_top5_acc:99.8269221931696  \n","[2022-04-18 15:16:02,253][experiments.experiment][INFO] - [EMA] Epoch 117. [Validation] raw_testing_loss: 0.2345, raw test Top1 acc:93.48, raw test Top5 acc: 99.84, ema_testing_loss: 0.1926, ema test Top1 acc:94.76, ema test Top5 acc: 99.88\n","[2022-04-18 15:16:02,350][experiments.experiment][INFO] - [Checkpoints] Epoch 117, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_117.pth.tar\n","[2022-04-18 15:16:02,351][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 15:23:27,681][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 118: use 445.4260313510895 seconds\n","--- Optimizer learning rate changed from 6.19e-03 to 5.85e-03 ---\n","[2022-04-18 15:23:27,777][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 15:23:29,105][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 15:23:29,105][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 15:23:30,424][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 15:23:30,425][experiments.experiment][INFO] - [EMA] Epoch 118.[Train] time:445.4260313510895 seconds, lr:0.0059, train_loss: 0.1973, unlabeled_losses_real_strong:0.3611,corrrect_unlabeled_num:424108.0,pro_above_threshold_num:434205.0,unlabelled_weak_top1_acc:95.50170786678791,unlabelled_weak_top5_acc:99.82081872969866  \n","[2022-04-18 15:23:30,428][experiments.experiment][INFO] - [EMA] Epoch 118. [Validation] raw_testing_loss: 0.2155, raw test Top1 acc:94.1, raw test Top5 acc: 99.88, ema_testing_loss: 0.1749, ema test Top1 acc:94.98, ema test Top5 acc: 99.92\n","[2022-04-18 15:23:30,429][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-18 15:30:55,725][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 119: use 445.3957223892212 seconds\n","--- Optimizer learning rate changed from 5.85e-03 to 5.52e-03 ---\n","[2022-04-18 15:30:55,825][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 15:30:57,140][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-18 15:30:57,141][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 15:30:58,472][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-18 15:30:58,474][experiments.experiment][INFO] - [EMA] Epoch 119.[Train] time:445.3957223892212 seconds, lr:0.0055, train_loss: 0.1961, unlabeled_losses_real_strong:0.3586,corrrect_unlabeled_num:424843.0,pro_above_threshold_num:435239.0,unlabelled_weak_top1_acc:95.52764784544706,unlabelled_weak_top5_acc:99.82997398078442  \n","[2022-04-18 15:30:58,475][experiments.experiment][INFO] - [EMA] Epoch 119. [Validation] raw_testing_loss: 0.2326, raw test Top1 acc:93.84, raw test Top5 acc: 99.94, ema_testing_loss: 0.1999, ema test Top1 acc:94.78, ema test Top5 acc: 99.9\n","[2022-04-18 15:30:58,570][experiments.experiment][INFO] - [Checkpoints] Epoch 119, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-ema099/FMExperiment_epoch_119.pth.tar\n","======= Training done =======\n","2022-04-18 15:30:58,587 - INFO - Train -   ======= Training done =======\n","[2022-04-18 15:30:58,587][Train][INFO] - ======= Training done =======\n","[2022-04-18 15:30:58,588][experiments.experiment][INFO] - Loading Testing Loader\n","[2022-04-18 15:30:58,596][experiments.experiment][INFO] - [Testing with EMA] apply shadow\n","[2022-04-18 15:30:58,596][experiments.experiment][INFO] - ***** Running testing *****\n","[2022-04-18 15:31:01,052][experiments.experiment][INFO] - [Testing(EMA)] testing_loss: 0.2023, test Top1 acc:94.57, test Top5 acc: 99.88\n","[2022-04-18 15:31:01,059][experiments.experiment][INFO] - [EMA] restore \n","======= Testing done =======\n","2022-04-18 15:31:01,060 - INFO - Train -   ======= Testing done =======\n","[2022-04-18 15:31:01,060][Train][INFO] - ======= Testing done =======\n"]}]}]}