{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"celiali-lambda6.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNhm42pIW12JIBwiuEBUDU+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"bcwY_Kj72fU1","executionInfo":{"status":"ok","timestamp":1650685903011,"user_tz":300,"elapsed":133670,"user":{"displayName":"CM Y","userId":"12660552299343911788"}},"outputId":"78131ce6-8703-460a-fd50-3e8bc801af15"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/celiali\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 2)) (1.0.0)\n","Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 3)) (1.9)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 4)) (0.29.28)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 5)) (1.21.6)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 7)) (4.64.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 8)) (1.4.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 9)) (7.1.2)\n","Collecting torch==1.8.0\n","  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n","\u001b[K     |████████████████████████████████| 735.5 MB 15 kB/s \n","\u001b[?25hCollecting torchvision==0.9.0\n","  Downloading torchvision-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n","\u001b[K     |████████████████████████████████| 17.3 MB 124 kB/s \n","\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 12)) (0.10.0+cu111)\n","Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 13)) (0.11.0)\n","Collecting omegaconf\n","  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\n","\u001b[K     |████████████████████████████████| 74 kB 3.7 MB/s \n","\u001b[?25hCollecting hydra\n","  Downloading Hydra-2.5.tar.gz (82 kB)\n","\u001b[K     |████████████████████████████████| 82 kB 766 kB/s \n","\u001b[?25hCollecting hydra-core\n","  Downloading hydra_core-1.1.2-py3-none-any.whl (147 kB)\n","\u001b[K     |████████████████████████████████| 147 kB 63.6 MB/s \n","\u001b[?25hCollecting ignite\n","  Downloading ignite-1.1.0-py2.py3-none-any.whl (4.5 kB)\n","Collecting pytorch-ignite\n","  Downloading pytorch_ignite-0.4.8-py3-none-any.whl (251 kB)\n","\u001b[K     |████████████████████████████████| 251 kB 49.5 MB/s \n","\u001b[?25hCollecting tensorboardX\n","  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 67.5 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 20)) (1.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 21)) (3.2.2)\n","Collecting abel-pytorch\n","  Downloading abel_pytorch-0.0.1-py3-none-any.whl (4.2 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r google_requirements.txt (line 10)) (4.1.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->-r google_requirements.txt (line 2)) (1.15.0)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 66.8 MB/s \n","\u001b[?25hRequirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.5.3)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.6.3)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.24.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.2.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.44.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (57.4.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.1.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (13.0.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.17.3)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.1.2)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.1.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.14.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.3.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->-r google_requirements.txt (line 6)) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->-r google_requirements.txt (line 6)) (1.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.0.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2.23.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.2.0)\n","Collecting torchaudio\n","  Downloading torchaudio-0.11.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 54.1 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 44.6 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 35.6 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 35.2 MB/s \n","\u001b[?25h  Downloading torchaudio-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 26.6 MB/s \n","\u001b[?25h  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 57.0 MB/s \n","\u001b[?25h  Downloading torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 52.1 MB/s \n","\u001b[?25h  Downloading torchaudio-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 27.2 MB/s \n","\u001b[?25hCollecting torchtext\n","  Downloading torchtext-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n","\u001b[K     |████████████████████████████████| 10.4 MB 22.8 MB/s \n","\u001b[?25h  Downloading torchtext-0.11.2-cp37-cp37m-manylinux1_x86_64.whl (8.0 MB)\n","\u001b[K     |████████████████████████████████| 8.0 MB 21.2 MB/s \n","\u001b[?25h  Downloading torchtext-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (8.0 MB)\n","\u001b[K     |████████████████████████████████| 8.0 MB 27.1 MB/s \n","\u001b[?25h  Downloading torchtext-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 29.7 MB/s \n","\u001b[?25h  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 51.8 MB/s \n","\u001b[?25h  Downloading torchtext-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 25.0 MB/s \n","\u001b[?25h  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 47.5 MB/s \n","\u001b[?25hCollecting PyYAML>=5.1.0\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 66.4 MB/s \n","\u001b[?25hCollecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 72.7 MB/s \n","\u001b[?25hCollecting importlib-resources<5.3\n","  Downloading importlib_resources-5.2.3-py3-none-any.whl (27 kB)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r google_requirements.txt (line 20)) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r google_requirements.txt (line 20)) (3.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (1.4.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (3.0.8)\n","Building wheels for collected packages: antlr4-python3-runtime, hydra\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=15780b2358bcd1c9b5e6e068f1b6b7684f7e5c1c507341b1b4c6bdf33dc452f6\n","  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n","  Building wheel for hydra (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hydra: filename=Hydra-2.5-cp37-cp37m-linux_x86_64.whl size=220762 sha256=6bfeec0b84ff8cac0268f4ebb8e8f32e1821751bd22534175e7c9d41e841e162\n","  Stored in directory: /root/.cache/pip/wheels/46/28/7d/3b38a41d900da90c4e17576f442bac9344eb1f5a4e78ee9f83\n","Successfully built antlr4-python3-runtime hydra\n","Installing collected packages: PyYAML, antlr4-python3-runtime, torch, tf-estimator-nightly, omegaconf, importlib-resources, torchvision, torchtext, torchaudio, tensorboardX, pytorch-ignite, ignite, hydra-core, hydra, abel-pytorch\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","  Attempting uninstall: importlib-resources\n","    Found existing installation: importlib-resources 5.7.0\n","    Uninstalling importlib-resources-5.7.0:\n","      Successfully uninstalled importlib-resources-5.7.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.11.1+cu111\n","    Uninstalling torchvision-0.11.1+cu111:\n","      Successfully uninstalled torchvision-0.11.1+cu111\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.11.0\n","    Uninstalling torchtext-0.11.0:\n","      Successfully uninstalled torchtext-0.11.0\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.10.0+cu111\n","    Uninstalling torchaudio-0.10.0+cu111:\n","      Successfully uninstalled torchaudio-0.10.0+cu111\n","Successfully installed PyYAML-6.0 abel-pytorch-0.0.1 antlr4-python3-runtime-4.8 hydra-2.5 hydra-core-1.1.2 ignite-1.1.0 importlib-resources-5.2.3 omegaconf-2.1.2 pytorch-ignite-0.4.8 tensorboardX-2.5 tf-estimator-nightly-2.8.0.dev2021122109 torch-1.8.0 torchaudio-0.8.0 torchtext-0.9.0 torchvision-0.9.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{}}],"source":["# Mount into drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","# Change directory to the package folder\n","%cd '/content/drive/MyDrive/celiali'\n","%pip install -r google_requirements.txt"]},{"cell_type":"code","source":["!python run.py DATASET.label_num=4000 DATASET.strongaugment='RA' EXPERIMENT.epoch_n=120 EXPERIMENT.batch_size=64 MODEL.name='WideResNet_Lk' MODEL.depth=28 MODEL.widen_factor=2 MODEL.num_classes=10 EXPERIMENT.out_model='./checkpoints/checkpoints_celiali-lambda_unlabled_6/' EXPERIMENT.log_path='./outputs/outputs_lambda_unlabled_6/' EXPERIMENT.save_cfmatrix=False EXPERIMENT.decay_type='cosine' DATASET.cut_type='cutout' EXPERIMENT.lambda_unlabeled=6"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OC9gAUaR2k0k","outputId":"1019fc27-de7c-4f84-c1cd-f5ed2c1de213"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==> CONFIG is: \n"," DATASET:\n","  project_dir: ./\n","  data_dir: data\n","  loading_data: LOAD_LABEL_UNLABEL\n","  dataset: CIFAR10\n","  strongaugment: RA\n","  cut_type: cutout\n","  label_num: 4000\n","  num_expand_x: 65536\n","  mu: 7\n","  barely: false\n","  add_noisy_label: false\n","  both_strong: false\n","MODEL:\n","  name: WideResNet_Lk\n","  depth: 28\n","  widen_factor: 2\n","  num_classes: 10\n","  dropout: 0.0\n","  cardinality: 4\n","  width: 4\n","  base_width: 4\n","EXPERIMENT:\n","  name: FMExperiment\n","  out_model: ./checkpoints/checkpoints_celiali-lambda_unlabled_6/\n","  log_path: ./outputs/outputs_lambda_unlabled_6/\n","  used_gpu: true\n","  decay_type: cosine\n","  abel_decay: 0.1\n","  optim_lr: 0.03\n","  optim_momentum: 0.9\n","  used_nesterov: true\n","  warmup: 0\n","  wdecay: 0.0005\n","  clip: 1\n","  ema_used: true\n","  ema_decay: 0.999\n","  threshold: 0.95\n","  lambda_unlabeled: 6\n","  batch_size: 64\n","  num_workers: 4\n","  n_imgs_per_epoch: 65536\n","  epoch_n: 120\n","  save_every: 2\n","  save_matrix_every: 20\n","  resume: false\n","  resume_checkpoints: ./checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar\n","  save_cfmatrix: false\n","  batch_balanced: false\n","  neg_penalty: false\n","  equal_freq: false\n","  eta_negpenalty: 0.05\n","  eta_dynamic: false\n","  use_nlloss: false\n","  q: 0.0001\n","Logging:\n","  name: FM\n","  seed: 1265\n"," \n","\n","2022-04-22 20:01:04,918 - INFO - Train -   {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'cut_type': 'cutout', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-lambda_unlabled_6/', 'log_path': './outputs/outputs_lambda_unlabled_6/', 'used_gpu': True, 'decay_type': 'cosine', 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 6, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': False, 'resume_checkpoints': './checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","[2022-04-22 20:01:04,918][Train][INFO] - {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'cut_type': 'cutout', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-lambda_unlabled_6/', 'log_path': './outputs/outputs_lambda_unlabled_6/', 'used_gpu': True, 'decay_type': 'cosine', 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 6, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': False, 'resume_checkpoints': './checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","2022-04-22 20:01:05,380 - INFO - Train -   [Model] Building model WideResNet_Lk\n","[2022-04-22 20:01:05,380][Train][INFO] - [Model] Building model WideResNet_Lk\n","2022-04-22 20:01:08,099 - INFO - Train -   Total params: 1.47M\n","[2022-04-22 20:01:08,099][Train][INFO] - Total params: 1.47M\n","[2022-04-22 20:01:08,101][experiments.experiment][INFO] - I'm using cosine decay!\n","[2022-04-22 20:01:08,105][experiments.experiment][INFO] - [EMA] initial \n","[2022-04-22 20:01:15,426][datasets.datasets1][INFO] - Dataset: CIFAR10\n","[2022-04-22 20:01:15,481][datasets.datasets1][INFO] - Labeled examples: 65536 Unlabeled examples: 458752Validation examples: 5000\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-22 20:01:15,483][experiments.experiment][INFO] - Loading Labelled Loader\n","[2022-04-22 20:01:15,483][experiments.experiment][INFO] - Loading Unlabelled Loader\n","[2022-04-22 20:01:15,484][experiments.experiment][INFO] - Loading Validation Loader\n","[2022-04-22 20:01:15,492][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 20:11:21,911][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 0: use 606.5220820903778 seconds\n","--- Optimizer learning rate changed from inf to 3.00e-02 ---\n","[2022-04-22 20:11:22,014][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:11:23,824][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 20:11:23,824][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:11:25,635][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 20:11:25,720][experiments.experiment][INFO] - [EMA] Epoch 0.[Train] time:606.5220820903778 seconds, lr:0.0300, train_loss: 1.4840, unlabeled_losses_real_strong:2.1565,corrrect_unlabeled_num:26709.0,pro_above_threshold_num:28557.0,unlabelled_weak_top1_acc:50.616018551401794,unlabelled_weak_top5_acc:92.62150245532393  \n","[2022-04-22 20:11:25,720][experiments.experiment][INFO] - [EMA] Epoch 0. [Validation] raw_testing_loss: 1.8109, raw test Top1 acc:42.12, raw test Top5 acc: 89.8, ema_testing_loss: 1.5845, ema test Top1 acc:44.52, ema test Top5 acc: 91.64\n","[2022-04-22 20:11:25,833][experiments.experiment][INFO] - [Checkpoints] Epoch 0, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-22 20:11:25,834][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 20:21:38,148][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 1: use 612.4158234596252 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-22 20:21:38,250][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:21:40,086][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 20:21:40,086][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:21:41,902][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 20:21:41,905][experiments.experiment][INFO] - [EMA] Epoch 1.[Train] time:612.4158234596252 seconds, lr:0.0300, train_loss: 1.6576, unlabeled_losses_real_strong:1.8969,corrrect_unlabeled_num:113815.0,pro_above_threshold_num:120482.0,unlabelled_weak_top1_acc:64.93050610646605,unlabelled_weak_top5_acc:96.60688026994467  \n","[2022-04-22 20:21:41,907][experiments.experiment][INFO] - [EMA] Epoch 1. [Validation] raw_testing_loss: 2.3428, raw test Top1 acc:29.46, raw test Top5 acc: 87.0, ema_testing_loss: 1.0861, ema test Top1 acc:61.9, ema test Top5 acc: 95.72\n","[2022-04-22 20:21:42,029][experiments.experiment][INFO] - [Checkpoints] Epoch 1, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-22 20:21:42,038][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 20:31:49,133][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 2: use 607.1980266571045 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-22 20:31:49,237][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:31:51,013][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 20:31:51,013][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:31:52,797][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 20:31:52,799][experiments.experiment][INFO] - [EMA] Epoch 2.[Train] time:607.1980266571045 seconds, lr:0.0300, train_loss: 1.7800, unlabeled_losses_real_strong:1.5599,corrrect_unlabeled_num:168831.0,pro_above_threshold_num:178278.0,unlabelled_weak_top1_acc:70.78617536276579,unlabelled_weak_top5_acc:97.58693042397499  \n","[2022-04-22 20:31:52,802][experiments.experiment][INFO] - [EMA] Epoch 2. [Validation] raw_testing_loss: 2.9078, raw test Top1 acc:23.68, raw test Top5 acc: 82.02, ema_testing_loss: 0.8728, ema test Top1 acc:69.48, ema test Top5 acc: 97.52\n","[2022-04-22 20:31:52,803][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 20:41:57,069][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 3: use 604.366349697113 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-22 20:41:57,169][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:41:58,943][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 20:41:58,943][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:42:00,687][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 20:42:00,689][experiments.experiment][INFO] - [EMA] Epoch 3.[Train] time:604.366349697113 seconds, lr:0.0300, train_loss: 1.8921, unlabeled_losses_real_strong:1.3014,corrrect_unlabeled_num:212359.0,pro_above_threshold_num:223441.0,unlabelled_weak_top1_acc:75.35138703137636,unlabelled_weak_top5_acc:98.24567424505949  \n","[2022-04-22 20:42:00,692][experiments.experiment][INFO] - [EMA] Epoch 3. [Validation] raw_testing_loss: 2.7549, raw test Top1 acc:31.64, raw test Top5 acc: 93.5, ema_testing_loss: 0.7477, ema test Top1 acc:74.62, ema test Top5 acc: 98.52\n","[2022-04-22 20:42:00,814][experiments.experiment][INFO] - [Checkpoints] Epoch 3, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-22 20:42:00,816][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 20:52:10,193][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 4: use 609.4955191612244 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-22 20:52:10,312][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:52:12,118][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 20:52:12,118][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:52:13,936][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 20:52:13,938][experiments.experiment][INFO] - [EMA] Epoch 4.[Train] time:609.4955191612244 seconds, lr:0.0300, train_loss: 1.9079, unlabeled_losses_real_strong:1.1724,corrrect_unlabeled_num:242538.0,pro_above_threshold_num:254449.0,unlabelled_weak_top1_acc:78.50298094004393,unlabelled_weak_top5_acc:98.60992313176394  \n","[2022-04-22 20:52:13,942][experiments.experiment][INFO] - [EMA] Epoch 4. [Validation] raw_testing_loss: 1.6269, raw test Top1 acc:54.16, raw test Top5 acc: 92.32, ema_testing_loss: 0.6661, ema test Top1 acc:78.72, ema test Top5 acc: 98.82\n","[2022-04-22 20:52:13,942][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 21:02:31,822][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 5: use 617.991536617279 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 2.99e-02 ---\n","[2022-04-22 21:02:31,934][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:02:33,775][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 21:02:33,776][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:02:35,589][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 21:02:35,591][experiments.experiment][INFO] - [EMA] Epoch 5.[Train] time:617.991536617279 seconds, lr:0.0299, train_loss: 1.8898, unlabeled_losses_real_strong:1.0802,corrrect_unlabeled_num:264194.0,pro_above_threshold_num:276564.0,unlabelled_weak_top1_acc:80.52346254140139,unlabelled_weak_top5_acc:98.82485387474298  \n","[2022-04-22 21:02:35,595][experiments.experiment][INFO] - [EMA] Epoch 5. [Validation] raw_testing_loss: 1.0640, raw test Top1 acc:65.36, raw test Top5 acc: 97.3, ema_testing_loss: 0.6017, ema test Top1 acc:81.16, ema test Top5 acc: 99.1\n","[2022-04-22 21:02:35,716][experiments.experiment][INFO] - [Checkpoints] Epoch 5, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-22 21:02:35,729][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 21:12:56,641][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 6: use 621.028050661087 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.99e-02 ---\n","[2022-04-22 21:12:56,757][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:12:58,607][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 21:12:58,607][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:13:00,411][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 21:13:00,413][experiments.experiment][INFO] - [EMA] Epoch 6.[Train] time:621.028050661087 seconds, lr:0.0299, train_loss: 1.8734, unlabeled_losses_real_strong:1.0118,corrrect_unlabeled_num:279819.0,pro_above_threshold_num:291910.0,unlabelled_weak_top1_acc:82.17947719246149,unlabelled_weak_top5_acc:98.98637890070677  \n","[2022-04-22 21:13:00,415][experiments.experiment][INFO] - [EMA] Epoch 6. [Validation] raw_testing_loss: 1.0206, raw test Top1 acc:68.74, raw test Top5 acc: 97.56, ema_testing_loss: 0.5514, ema test Top1 acc:82.96, ema test Top5 acc: 99.26\n","[2022-04-22 21:13:00,417][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 21:23:18,711][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 7: use 618.4016675949097 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.99e-02 ---\n","[2022-04-22 21:23:18,819][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:23:20,653][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 21:23:20,653][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:23:22,484][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 21:23:22,487][experiments.experiment][INFO] - [EMA] Epoch 7.[Train] time:618.4016675949097 seconds, lr:0.0299, train_loss: 1.8584, unlabeled_losses_real_strong:0.9619,corrrect_unlabeled_num:291119.0,pro_above_threshold_num:303131.0,unlabelled_weak_top1_acc:83.40039828419685,unlabelled_weak_top5_acc:99.08098340034485  \n","[2022-04-22 21:23:22,488][experiments.experiment][INFO] - [EMA] Epoch 7. [Validation] raw_testing_loss: 0.6959, raw test Top1 acc:77.62, raw test Top5 acc: 98.62, ema_testing_loss: 0.5065, ema test Top1 acc:84.6, ema test Top5 acc: 99.32\n","[2022-04-22 21:23:22,608][experiments.experiment][INFO] - [Checkpoints] Epoch 7, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-22 21:23:22,618][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 21:33:37,739][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 8: use 615.2266623973846 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.98e-02 ---\n","[2022-04-22 21:33:37,845][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:33:39,672][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 21:33:39,673][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:33:41,484][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 21:33:41,486][experiments.experiment][INFO] - [EMA] Epoch 8.[Train] time:615.2266623973846 seconds, lr:0.0298, train_loss: 1.8445, unlabeled_losses_real_strong:0.9190,corrrect_unlabeled_num:300925.0,pro_above_threshold_num:312634.0,unlabelled_weak_top1_acc:84.34012167155743,unlabelled_weak_top5_acc:99.14572417736053  \n","[2022-04-22 21:33:41,488][experiments.experiment][INFO] - [EMA] Epoch 8. [Validation] raw_testing_loss: 0.8700, raw test Top1 acc:72.94, raw test Top5 acc: 98.1, ema_testing_loss: 0.4731, ema test Top1 acc:85.96, ema test Top5 acc: 99.44\n","[2022-04-22 21:33:41,490][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 21:43:58,271][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 9: use 616.887862443924 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.98e-02 ---\n","[2022-04-22 21:43:58,378][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:44:00,193][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 21:44:00,194][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:44:02,017][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 21:44:02,019][experiments.experiment][INFO] - [EMA] Epoch 9.[Train] time:616.887862443924 seconds, lr:0.0298, train_loss: 1.8276, unlabeled_losses_real_strong:0.8860,corrrect_unlabeled_num:308458.0,pro_above_threshold_num:320041.0,unlabelled_weak_top1_acc:85.10393311083317,unlabelled_weak_top5_acc:99.22899378091097  \n","[2022-04-22 21:44:02,022][experiments.experiment][INFO] - [EMA] Epoch 9. [Validation] raw_testing_loss: 0.7752, raw test Top1 acc:78.46, raw test Top5 acc: 98.24, ema_testing_loss: 0.4457, ema test Top1 acc:86.54, ema test Top5 acc: 99.48\n","[2022-04-22 21:44:02,161][experiments.experiment][INFO] - [Checkpoints] Epoch 9, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-22 21:44:02,161][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 21:54:17,760][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 10: use 615.7094612121582 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.98e-02 ---\n","[2022-04-22 21:54:17,871][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:54:19,759][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 21:54:19,759][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:54:21,624][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 21:54:21,626][experiments.experiment][INFO] - [EMA] Epoch 10.[Train] time:615.7094612121582 seconds, lr:0.0298, train_loss: 1.8026, unlabeled_losses_real_strong:0.8565,corrrect_unlabeled_num:315112.0,pro_above_threshold_num:326271.0,unlabelled_weak_top1_acc:85.80692721903324,unlabelled_weak_top5_acc:99.2758602052927  \n","[2022-04-22 21:54:21,627][experiments.experiment][INFO] - [EMA] Epoch 10. [Validation] raw_testing_loss: 0.7394, raw test Top1 acc:77.72, raw test Top5 acc: 98.5, ema_testing_loss: 0.4190, ema test Top1 acc:87.3, ema test Top5 acc: 99.58\n","[2022-04-22 21:54:21,629][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 22:04:44,703][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 11: use 623.1790637969971 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.97e-02 ---\n","[2022-04-22 22:04:44,808][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:04:46,707][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 22:04:46,708][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:04:48,561][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 22:04:48,563][experiments.experiment][INFO] - [EMA] Epoch 11.[Train] time:623.1790637969971 seconds, lr:0.0297, train_loss: 1.7802, unlabeled_losses_real_strong:0.8316,corrrect_unlabeled_num:320229.0,pro_above_threshold_num:331295.0,unlabelled_weak_top1_acc:86.45629774034023,unlabelled_weak_top5_acc:99.32643230259418  \n","[2022-04-22 22:04:48,564][experiments.experiment][INFO] - [EMA] Epoch 11. [Validation] raw_testing_loss: 0.6091, raw test Top1 acc:80.14, raw test Top5 acc: 98.78, ema_testing_loss: 0.3984, ema test Top1 acc:87.9, ema test Top5 acc: 99.64\n","[2022-04-22 22:04:48,692][experiments.experiment][INFO] - [Checkpoints] Epoch 11, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-22 22:04:48,702][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 22:15:08,423][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 12: use 619.8253517150879 seconds\n","--- Optimizer learning rate changed from 2.97e-02 to 2.97e-02 ---\n","[2022-04-22 22:15:08,528][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:15:10,344][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 22:15:10,344][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:15:12,152][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 22:15:12,154][experiments.experiment][INFO] - [EMA] Epoch 12.[Train] time:619.8253517150879 seconds, lr:0.0297, train_loss: 1.7691, unlabeled_losses_real_strong:0.8123,corrrect_unlabeled_num:324968.0,pro_above_threshold_num:335856.0,unlabelled_weak_top1_acc:86.92539650946856,unlabelled_weak_top5_acc:99.33449754863977  \n","[2022-04-22 22:15:12,156][experiments.experiment][INFO] - [EMA] Epoch 12. [Validation] raw_testing_loss: 0.6714, raw test Top1 acc:79.78, raw test Top5 acc: 98.76, ema_testing_loss: 0.3857, ema test Top1 acc:88.56, ema test Top5 acc: 99.62\n","[2022-04-22 22:15:12,158][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 22:25:30,438][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 13: use 618.3848106861115 seconds\n","--- Optimizer learning rate changed from 2.97e-02 to 2.96e-02 ---\n","[2022-04-22 22:25:30,542][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:25:32,368][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 22:25:32,369][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:25:34,188][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 22:25:34,190][experiments.experiment][INFO] - [EMA] Epoch 13.[Train] time:618.3848106861115 seconds, lr:0.0296, train_loss: 1.7537, unlabeled_losses_real_strong:0.7901,corrrect_unlabeled_num:329970.0,pro_above_threshold_num:340837.0,unlabelled_weak_top1_acc:87.40321459621191,unlabelled_weak_top5_acc:99.35825790464878  \n","[2022-04-22 22:25:34,192][experiments.experiment][INFO] - [EMA] Epoch 13. [Validation] raw_testing_loss: 0.6396, raw test Top1 acc:80.26, raw test Top5 acc: 98.86, ema_testing_loss: 0.3737, ema test Top1 acc:88.7, ema test Top5 acc: 99.66\n","[2022-04-22 22:25:34,319][experiments.experiment][INFO] - [Checkpoints] Epoch 13, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-22 22:25:34,329][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 22:35:42,482][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 14: use 608.2575957775116 seconds\n","--- Optimizer learning rate changed from 2.96e-02 to 2.96e-02 ---\n","[2022-04-22 22:35:42,586][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:35:44,416][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 22:35:44,416][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:35:46,185][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 22:35:46,187][experiments.experiment][INFO] - [EMA] Epoch 14.[Train] time:608.2575957775116 seconds, lr:0.0296, train_loss: 1.7411, unlabeled_losses_real_strong:0.7749,corrrect_unlabeled_num:334505.0,pro_above_threshold_num:345163.0,unlabelled_weak_top1_acc:87.71187813580036,unlabelled_weak_top5_acc:99.39051941037178  \n","[2022-04-22 22:35:46,191][experiments.experiment][INFO] - [EMA] Epoch 14. [Validation] raw_testing_loss: 0.6980, raw test Top1 acc:77.78, raw test Top5 acc: 98.5, ema_testing_loss: 0.3603, ema test Top1 acc:89.32, ema test Top5 acc: 99.76\n","[2022-04-22 22:35:46,191][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 22:45:59,431][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 15: use 613.3390319347382 seconds\n","--- Optimizer learning rate changed from 2.96e-02 to 2.95e-02 ---\n","[2022-04-22 22:45:59,530][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:46:01,336][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 22:46:01,337][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:46:03,217][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 22:46:03,219][experiments.experiment][INFO] - [EMA] Epoch 15.[Train] time:613.3390319347382 seconds, lr:0.0295, train_loss: 1.7407, unlabeled_losses_real_strong:0.7591,corrrect_unlabeled_num:337602.0,pro_above_threshold_num:348340.0,unlabelled_weak_top1_acc:88.09661754220724,unlabelled_weak_top5_acc:99.44130957126617  \n","[2022-04-22 22:46:03,221][experiments.experiment][INFO] - [EMA] Epoch 15. [Validation] raw_testing_loss: 0.5820, raw test Top1 acc:82.3, raw test Top5 acc: 98.72, ema_testing_loss: 0.3522, ema test Top1 acc:89.68, ema test Top5 acc: 99.76\n","[2022-04-22 22:46:03,340][experiments.experiment][INFO] - [Checkpoints] Epoch 15, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-22 22:46:03,343][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 22:56:18,141][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 16: use 614.9100217819214 seconds\n","--- Optimizer learning rate changed from 2.95e-02 to 2.94e-02 ---\n","[2022-04-22 22:56:18,253][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:56:20,134][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 22:56:20,134][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:56:21,979][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 22:56:21,981][experiments.experiment][INFO] - [EMA] Epoch 16.[Train] time:614.9100217819214 seconds, lr:0.0294, train_loss: 1.7182, unlabeled_losses_real_strong:0.7456,corrrect_unlabeled_num:341144.0,pro_above_threshold_num:351756.0,unlabelled_weak_top1_acc:88.47830528765917,unlabelled_weak_top5_acc:99.46724958717823  \n","[2022-04-22 22:56:21,984][experiments.experiment][INFO] - [EMA] Epoch 16. [Validation] raw_testing_loss: 0.4834, raw test Top1 acc:85.36, raw test Top5 acc: 99.3, ema_testing_loss: 0.3427, ema test Top1 acc:89.68, ema test Top5 acc: 99.7\n","[2022-04-22 22:56:21,985][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 23:06:42,352][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 17: use 620.4731266498566 seconds\n","--- Optimizer learning rate changed from 2.94e-02 to 2.94e-02 ---\n","[2022-04-22 23:06:42,458][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:06:44,337][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 23:06:44,338][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:06:46,177][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 23:06:46,179][experiments.experiment][INFO] - [EMA] Epoch 17.[Train] time:620.4731266498566 seconds, lr:0.0294, train_loss: 1.7150, unlabeled_losses_real_strong:0.7315,corrrect_unlabeled_num:344006.0,pro_above_threshold_num:354318.0,unlabelled_weak_top1_acc:88.6788492128253,unlabelled_weak_top5_acc:99.47204537689686  \n","[2022-04-22 23:06:46,182][experiments.experiment][INFO] - [EMA] Epoch 17. [Validation] raw_testing_loss: 0.9586, raw test Top1 acc:77.22, raw test Top5 acc: 97.74, ema_testing_loss: 0.3355, ema test Top1 acc:90.08, ema test Top5 acc: 99.72\n","[2022-04-22 23:06:46,306][experiments.experiment][INFO] - [Checkpoints] Epoch 17, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-22 23:06:46,308][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 23:17:03,817][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 18: use 617.6145970821381 seconds\n","--- Optimizer learning rate changed from 2.94e-02 to 2.93e-02 ---\n","[2022-04-22 23:17:03,923][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:17:05,804][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 23:17:05,805][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:17:07,652][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 23:17:07,654][experiments.experiment][INFO] - [EMA] Epoch 18.[Train] time:617.6145970821381 seconds, lr:0.0293, train_loss: 1.7185, unlabeled_losses_real_strong:0.7208,corrrect_unlabeled_num:347114.0,pro_above_threshold_num:357611.0,unlabelled_weak_top1_acc:88.97661378979683,unlabelled_weak_top5_acc:99.47269916534424  \n","[2022-04-22 23:17:07,656][experiments.experiment][INFO] - [EMA] Epoch 18. [Validation] raw_testing_loss: 0.5926, raw test Top1 acc:82.46, raw test Top5 acc: 98.9, ema_testing_loss: 0.3300, ema test Top1 acc:90.3, ema test Top5 acc: 99.78\n","[2022-04-22 23:17:07,657][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 23:27:25,577][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 19: use 618.0238616466522 seconds\n","--- Optimizer learning rate changed from 2.93e-02 to 2.92e-02 ---\n","[2022-04-22 23:27:25,681][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:27:27,523][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 23:27:27,524][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:27:29,376][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 23:27:29,378][experiments.experiment][INFO] - [EMA] Epoch 19.[Train] time:618.0238616466522 seconds, lr:0.0292, train_loss: 1.6886, unlabeled_losses_real_strong:0.7075,corrrect_unlabeled_num:348700.0,pro_above_threshold_num:358862.0,unlabelled_weak_top1_acc:89.22402404993773,unlabelled_weak_top5_acc:99.51673194020987  \n","[2022-04-22 23:27:29,381][experiments.experiment][INFO] - [EMA] Epoch 19. [Validation] raw_testing_loss: 0.5363, raw test Top1 acc:84.3, raw test Top5 acc: 99.18, ema_testing_loss: 0.3245, ema test Top1 acc:90.38, ema test Top5 acc: 99.8\n","[2022-04-22 23:27:29,505][experiments.experiment][INFO] - [Checkpoints] Epoch 19, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-22 23:27:29,505][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 23:37:43,895][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 20: use 614.4967670440674 seconds\n","--- Optimizer learning rate changed from 2.92e-02 to 2.91e-02 ---\n","[2022-04-22 23:37:44,002][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:37:45,871][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 23:37:45,872][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:37:47,717][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 23:37:47,720][experiments.experiment][INFO] - [EMA] Epoch 20.[Train] time:614.4967670440674 seconds, lr:0.0291, train_loss: 1.6797, unlabeled_losses_real_strong:0.7041,corrrect_unlabeled_num:350412.0,pro_above_threshold_num:360572.0,unlabelled_weak_top1_acc:89.40473164618015,unlabelled_weak_top5_acc:99.52305334061384  \n","[2022-04-22 23:37:47,724][experiments.experiment][INFO] - [EMA] Epoch 20. [Validation] raw_testing_loss: 0.5424, raw test Top1 acc:84.48, raw test Top5 acc: 99.02, ema_testing_loss: 0.3246, ema test Top1 acc:90.56, ema test Top5 acc: 99.74\n","[2022-04-22 23:37:47,724][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 23:47:59,871][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 21: use 612.2482159137726 seconds\n","--- Optimizer learning rate changed from 2.91e-02 to 2.91e-02 ---\n","[2022-04-22 23:47:59,973][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:48:01,794][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 23:48:01,794][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:48:03,586][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 23:48:03,588][experiments.experiment][INFO] - [EMA] Epoch 21.[Train] time:612.2482159137726 seconds, lr:0.0291, train_loss: 1.6755, unlabeled_losses_real_strong:0.6893,corrrect_unlabeled_num:352993.0,pro_above_threshold_num:362904.0,unlabelled_weak_top1_acc:89.62707413733006,unlabelled_weak_top5_acc:99.53395262360573  \n","[2022-04-22 23:48:03,591][experiments.experiment][INFO] - [EMA] Epoch 21. [Validation] raw_testing_loss: 0.4260, raw test Top1 acc:87.5, raw test Top5 acc: 99.4, ema_testing_loss: 0.3196, ema test Top1 acc:90.56, ema test Top5 acc: 99.74\n","[2022-04-22 23:48:03,717][experiments.experiment][INFO] - [Checkpoints] Epoch 21, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-22 23:48:03,720][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 23:58:17,905][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 22: use 614.2895126342773 seconds\n","--- Optimizer learning rate changed from 2.91e-02 to 2.90e-02 ---\n","[2022-04-22 23:58:18,009][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:58:19,835][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 23:58:19,836][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:58:21,654][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 23:58:21,657][experiments.experiment][INFO] - [EMA] Epoch 22.[Train] time:614.2895126342773 seconds, lr:0.0290, train_loss: 1.6679, unlabeled_losses_real_strong:0.6800,corrrect_unlabeled_num:355144.0,pro_above_threshold_num:364900.0,unlabelled_weak_top1_acc:89.8738305196166,unlabelled_weak_top5_acc:99.5411459878087  \n","[2022-04-22 23:58:21,658][experiments.experiment][INFO] - [EMA] Epoch 22. [Validation] raw_testing_loss: 0.4951, raw test Top1 acc:85.86, raw test Top5 acc: 99.22, ema_testing_loss: 0.3117, ema test Top1 acc:90.98, ema test Top5 acc: 99.8\n","[2022-04-22 23:58:21,660][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 00:08:40,362][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 23: use 618.8104689121246 seconds\n","--- Optimizer learning rate changed from 2.90e-02 to 2.89e-02 ---\n","[2022-04-23 00:08:40,470][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:08:42,311][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 00:08:42,312][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:08:44,139][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 00:08:44,141][experiments.experiment][INFO] - [EMA] Epoch 23.[Train] time:618.8104689121246 seconds, lr:0.0289, train_loss: 1.6656, unlabeled_losses_real_strong:0.6725,corrrect_unlabeled_num:356884.0,pro_above_threshold_num:366582.0,unlabelled_weak_top1_acc:90.01006967574358,unlabelled_weak_top5_acc:99.55117335915565  \n","[2022-04-23 00:08:44,143][experiments.experiment][INFO] - [EMA] Epoch 23. [Validation] raw_testing_loss: 0.4610, raw test Top1 acc:86.96, raw test Top5 acc: 98.98, ema_testing_loss: 0.3067, ema test Top1 acc:91.12, ema test Top5 acc: 99.84\n","[2022-04-23 00:08:44,266][experiments.experiment][INFO] - [Checkpoints] Epoch 23, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 00:08:44,272][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 00:19:03,467][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 24: use 619.300375699997 seconds\n","--- Optimizer learning rate changed from 2.89e-02 to 2.88e-02 ---\n","[2022-04-23 00:19:03,572][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:19:05,417][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 00:19:05,418][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:19:07,238][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 00:19:07,240][experiments.experiment][INFO] - [EMA] Epoch 24.[Train] time:619.300375699997 seconds, lr:0.0288, train_loss: 1.6549, unlabeled_losses_real_strong:0.6674,corrrect_unlabeled_num:358121.0,pro_above_threshold_num:367899.0,unlabelled_weak_top1_acc:90.14064133912325,unlabelled_weak_top5_acc:99.57645946741104  \n","[2022-04-23 00:19:07,243][experiments.experiment][INFO] - [EMA] Epoch 24. [Validation] raw_testing_loss: 0.4664, raw test Top1 acc:86.82, raw test Top5 acc: 99.5, ema_testing_loss: 0.3016, ema test Top1 acc:91.14, ema test Top5 acc: 99.84\n","[2022-04-23 00:19:07,244][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 00:29:21,774][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 25: use 614.6396250724792 seconds\n","--- Optimizer learning rate changed from 2.88e-02 to 2.87e-02 ---\n","[2022-04-23 00:29:21,884][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:29:23,728][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 00:29:23,729][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:29:25,549][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 00:29:25,551][experiments.experiment][INFO] - [EMA] Epoch 25.[Train] time:614.6396250724792 seconds, lr:0.0287, train_loss: 1.6392, unlabeled_losses_real_strong:0.6586,corrrect_unlabeled_num:359761.0,pro_above_threshold_num:369357.0,unlabelled_weak_top1_acc:90.29322921484709,unlabelled_weak_top5_acc:99.57297168672085  \n","[2022-04-23 00:29:25,552][experiments.experiment][INFO] - [EMA] Epoch 25. [Validation] raw_testing_loss: 0.4228, raw test Top1 acc:87.9, raw test Top5 acc: 99.42, ema_testing_loss: 0.2962, ema test Top1 acc:91.22, ema test Top5 acc: 99.84\n","[2022-04-23 00:29:25,676][experiments.experiment][INFO] - [Checkpoints] Epoch 25, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 00:29:25,678][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 00:39:41,399][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 26: use 615.8268187046051 seconds\n","--- Optimizer learning rate changed from 2.87e-02 to 2.86e-02 ---\n","[2022-04-23 00:39:41,505][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:39:43,348][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 00:39:43,349][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:39:45,165][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 00:39:45,167][experiments.experiment][INFO] - [EMA] Epoch 26.[Train] time:615.8268187046051 seconds, lr:0.0286, train_loss: 1.6422, unlabeled_losses_real_strong:0.6528,corrrect_unlabeled_num:361648.0,pro_above_threshold_num:370960.0,unlabelled_weak_top1_acc:90.51491763442755,unlabelled_weak_top5_acc:99.59193634986877  \n","[2022-04-23 00:39:45,171][experiments.experiment][INFO] - [EMA] Epoch 26. [Validation] raw_testing_loss: 0.5129, raw test Top1 acc:85.78, raw test Top5 acc: 99.46, ema_testing_loss: 0.2927, ema test Top1 acc:91.3, ema test Top5 acc: 99.84\n","[2022-04-23 00:39:45,172][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 00:49:56,329][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 27: use 611.267618894577 seconds\n","--- Optimizer learning rate changed from 2.86e-02 to 2.85e-02 ---\n","[2022-04-23 00:49:56,439][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:49:58,239][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 00:49:58,239][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:50:00,083][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 00:50:00,085][experiments.experiment][INFO] - [EMA] Epoch 27.[Train] time:611.267618894577 seconds, lr:0.0285, train_loss: 1.6327, unlabeled_losses_real_strong:0.6477,corrrect_unlabeled_num:362110.0,pro_above_threshold_num:371533.0,unlabelled_weak_top1_acc:90.55219266563654,unlabelled_weak_top5_acc:99.60392531007528  \n","[2022-04-23 00:50:00,087][experiments.experiment][INFO] - [EMA] Epoch 27. [Validation] raw_testing_loss: 0.3984, raw test Top1 acc:87.78, raw test Top5 acc: 99.46, ema_testing_loss: 0.2880, ema test Top1 acc:91.7, ema test Top5 acc: 99.84\n","[2022-04-23 00:50:00,210][experiments.experiment][INFO] - [Checkpoints] Epoch 27, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 00:50:00,213][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 01:00:09,122][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 28: use 609.0118093490601 seconds\n","--- Optimizer learning rate changed from 2.85e-02 to 2.84e-02 ---\n","[2022-04-23 01:00:09,225][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 01:00:11,040][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 01:00:11,040][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 01:00:12,848][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 01:00:12,850][experiments.experiment][INFO] - [EMA] Epoch 28.[Train] time:609.0118093490601 seconds, lr:0.0284, train_loss: 1.6230, unlabeled_losses_real_strong:0.6413,corrrect_unlabeled_num:364036.0,pro_above_threshold_num:373563.0,unlabelled_weak_top1_acc:90.73115641623735,unlabelled_weak_top5_acc:99.60283549129963  \n","[2022-04-23 01:00:12,853][experiments.experiment][INFO] - [EMA] Epoch 28. [Validation] raw_testing_loss: 0.4554, raw test Top1 acc:85.8, raw test Top5 acc: 99.48, ema_testing_loss: 0.2827, ema test Top1 acc:91.9, ema test Top5 acc: 99.82\n","[2022-04-23 01:00:12,854][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 01:10:24,886][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 29: use 612.1321320533752 seconds\n","--- Optimizer learning rate changed from 2.84e-02 to 2.82e-02 ---\n","[2022-04-23 01:10:24,987][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 01:10:26,817][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 01:10:26,819][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 01:10:28,660][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 01:10:28,662][experiments.experiment][INFO] - [EMA] Epoch 29.[Train] time:612.1321320533752 seconds, lr:0.0282, train_loss: 1.6284, unlabeled_losses_real_strong:0.6379,corrrect_unlabeled_num:364980.0,pro_above_threshold_num:374353.0,unlabelled_weak_top1_acc:90.82532499730587,unlabelled_weak_top5_acc:99.6065411195159  \n","[2022-04-23 01:10:28,665][experiments.experiment][INFO] - [EMA] Epoch 29. [Validation] raw_testing_loss: 0.4419, raw test Top1 acc:87.2, raw test Top5 acc: 99.2, ema_testing_loss: 0.2768, ema test Top1 acc:91.8, ema test Top5 acc: 99.78\n","[2022-04-23 01:10:28,788][experiments.experiment][INFO] - [Checkpoints] Epoch 29, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 01:10:28,789][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 01:20:42,321][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 30: use 613.6359882354736 seconds\n","--- Optimizer learning rate changed from 2.82e-02 to 2.81e-02 ---\n","[2022-04-23 01:20:42,425][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 01:20:44,276][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 01:20:44,277][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 01:20:46,108][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 01:20:46,110][experiments.experiment][INFO] - [EMA] Epoch 30.[Train] time:613.6359882354736 seconds, lr:0.0281, train_loss: 1.6210, unlabeled_losses_real_strong:0.6300,corrrect_unlabeled_num:366014.0,pro_above_threshold_num:375311.0,unlabelled_weak_top1_acc:90.9628719612956,unlabelled_weak_top5_acc:99.62310788780451  \n","[2022-04-23 01:20:46,113][experiments.experiment][INFO] - [EMA] Epoch 30. [Validation] raw_testing_loss: 0.4638, raw test Top1 acc:86.54, raw test Top5 acc: 99.22, ema_testing_loss: 0.2765, ema test Top1 acc:92.06, ema test Top5 acc: 99.78\n","[2022-04-23 01:20:46,114][experiments.experiment][INFO] - ***** Running training *****\n"]}]},{"cell_type":"code","source":["!python run.py DATASET.label_num=4000 DATASET.strongaugment='RA' EXPERIMENT.epoch_n=120 EXPERIMENT.batch_size=64 MODEL.name='WideResNet_Lk' MODEL.depth=28 MODEL.widen_factor=2 MODEL.num_classes=10 EXPERIMENT.out_model='./checkpoints/checkpoints_celiali-lambda_unlabled_6/' EXPERIMENT.log_path='./outputs/outputs_lambda_unlabled_6/' EXPERIMENT.save_cfmatrix=False EXPERIMENT.decay_type='cosine' DATASET.cut_type='cutout' EXPERIMENT.lambda_unlabeled=6 EXPERIMENT.resume=True EXPERIMENT.resume_checkpoints='./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0srk2tfZiOLd","executionInfo":{"status":"ok","timestamp":1650727039581,"user_tz":300,"elapsed":9788424,"user":{"displayName":"CM Y","userId":"12660552299343911788"}},"outputId":"ab0cd327-4127-453f-d758-b57fec332fba"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["==> CONFIG is: \n"," DATASET:\n","  project_dir: ./\n","  data_dir: data\n","  loading_data: LOAD_LABEL_UNLABEL\n","  dataset: CIFAR10\n","  strongaugment: RA\n","  cut_type: cutout\n","  label_num: 4000\n","  num_expand_x: 65536\n","  mu: 7\n","  barely: false\n","  add_noisy_label: false\n","  both_strong: false\n","MODEL:\n","  name: WideResNet_Lk\n","  depth: 28\n","  widen_factor: 2\n","  num_classes: 10\n","  dropout: 0.0\n","  cardinality: 4\n","  width: 4\n","  base_width: 4\n","EXPERIMENT:\n","  name: FMExperiment\n","  out_model: ./checkpoints/checkpoints_celiali-lambda_unlabled_6/\n","  log_path: ./outputs/outputs_lambda_unlabled_6/\n","  used_gpu: true\n","  decay_type: cosine\n","  abel_decay: 0.1\n","  optim_lr: 0.03\n","  optim_momentum: 0.9\n","  used_nesterov: true\n","  warmup: 0\n","  wdecay: 0.0005\n","  clip: 1\n","  ema_used: true\n","  ema_decay: 0.999\n","  threshold: 0.95\n","  lambda_unlabeled: 6\n","  batch_size: 64\n","  num_workers: 4\n","  n_imgs_per_epoch: 65536\n","  epoch_n: 120\n","  save_every: 2\n","  save_matrix_every: 20\n","  resume: true\n","  resume_checkpoints: ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","  save_cfmatrix: false\n","  batch_balanced: false\n","  neg_penalty: false\n","  equal_freq: false\n","  eta_negpenalty: 0.05\n","  eta_dynamic: false\n","  use_nlloss: false\n","  q: 0.0001\n","Logging:\n","  name: FM\n","  seed: 1265\n"," \n","\n","2022-04-23 03:52:20,546 - INFO - Train -   {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'cut_type': 'cutout', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-lambda_unlabled_6/', 'log_path': './outputs/outputs_lambda_unlabled_6/', 'used_gpu': True, 'decay_type': 'cosine', 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 6, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': True, 'resume_checkpoints': './checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","[2022-04-23 03:52:20,546][Train][INFO] - {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'cut_type': 'cutout', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-lambda_unlabled_6/', 'log_path': './outputs/outputs_lambda_unlabled_6/', 'used_gpu': True, 'decay_type': 'cosine', 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 6, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': True, 'resume_checkpoints': './checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","2022-04-23 03:52:21,282 - INFO - Train -   [Model] Building model WideResNet_Lk\n","[2022-04-23 03:52:21,282][Train][INFO] - [Model] Building model WideResNet_Lk\n","2022-04-23 03:52:23,869 - INFO - Train -   Total params: 1.47M\n","[2022-04-23 03:52:23,869][Train][INFO] - Total params: 1.47M\n","[2022-04-23 03:52:23,871][experiments.experiment][INFO] - I'm using cosine decay!\n","[2022-04-23 03:52:23,874][experiments.experiment][INFO] - [EMA] initial \n","[2022-04-23 03:52:35,884][datasets.datasets1][INFO] - Dataset: CIFAR10\n","[2022-04-23 03:52:35,932][datasets.datasets1][INFO] - Labeled examples: 65536 Unlabeled examples: 458752Validation examples: 5000\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-23 03:52:35,934][experiments.experiment][INFO] - Loading Labelled Loader\n","[2022-04-23 03:52:35,934][experiments.experiment][INFO] - Loading Unlabelled Loader\n","[2022-04-23 03:52:35,935][experiments.experiment][INFO] - Loading Validation Loader\n","=> loading checkpoint './checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar'\n","[2022-04-23 03:52:37,041][experiments.experiment][INFO] - ==> Resuming from checkpoint..\n","=> loaded checkpoint './checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar' (epoch 29)\n","[2022-04-23 03:52:38,330][experiments.experiment][INFO] - => loaded checkpoint './checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar' (epoch 29)\n","[2022-04-23 03:52:38,331][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:00:05,908][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 29: use 447.68183636665344 seconds\n","--- Optimizer learning rate changed from inf to 2.81e-02 ---\n","[2022-04-23 04:00:06,013][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:00:07,367][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:00:07,367][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:00:08,760][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:00:15,098][experiments.experiment][INFO] - [EMA] Epoch 29.[Train] time:447.68183636665344 seconds, lr:0.0281, train_loss: 1.6201, unlabeled_losses_real_strong:0.6291,corrrect_unlabeled_num:366422.0,pro_above_threshold_num:375802.0,unlabelled_weak_top1_acc:90.9539347216487,unlabelled_weak_top5_acc:99.62528769671917  \n","[2022-04-23 04:00:15,098][experiments.experiment][INFO] - [EMA] Epoch 29. [Validation] raw_testing_loss: 0.5671, raw test Top1 acc:85.68, raw test Top5 acc: 99.36, ema_testing_loss: 0.2778, ema test Top1 acc:92.04, ema test Top5 acc: 99.82\n","[2022-04-23 04:00:15,196][experiments.experiment][INFO] - [Checkpoints] Epoch 29, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 04:00:15,207][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:07:42,856][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 30: use 447.7560143470764 seconds\n","--- Optimizer learning rate changed from 2.81e-02 to 2.80e-02 ---\n","[2022-04-23 04:07:42,963][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:07:44,327][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:07:44,327][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:07:45,713][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:07:45,714][experiments.experiment][INFO] - [EMA] Epoch 30.[Train] time:447.7560143470764 seconds, lr:0.0280, train_loss: 1.6057, unlabeled_losses_real_strong:0.6215,corrrect_unlabeled_num:367142.0,pro_above_threshold_num:376169.0,unlabelled_weak_top1_acc:91.09780322760344,unlabelled_weak_top5_acc:99.6311733648181  \n","[2022-04-23 04:07:45,716][experiments.experiment][INFO] - [EMA] Epoch 30. [Validation] raw_testing_loss: 0.3779, raw test Top1 acc:88.78, raw test Top5 acc: 99.5, ema_testing_loss: 0.2728, ema test Top1 acc:92.14, ema test Top5 acc: 99.78\n","[2022-04-23 04:07:45,716][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:15:17,625][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 31: use 452.0046660900116 seconds\n","--- Optimizer learning rate changed from 2.80e-02 to 2.79e-02 ---\n","[2022-04-23 04:15:17,721][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:15:19,138][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:15:19,138][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:15:20,520][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:15:20,521][experiments.experiment][INFO] - [EMA] Epoch 31.[Train] time:452.0046660900116 seconds, lr:0.0279, train_loss: 1.5982, unlabeled_losses_real_strong:0.6185,corrrect_unlabeled_num:367812.0,pro_above_threshold_num:376995.0,unlabelled_weak_top1_acc:91.14619541913271,unlabelled_weak_top5_acc:99.63945666700602  \n","[2022-04-23 04:15:20,523][experiments.experiment][INFO] - [EMA] Epoch 31. [Validation] raw_testing_loss: 0.4388, raw test Top1 acc:87.86, raw test Top5 acc: 99.44, ema_testing_loss: 0.2703, ema test Top1 acc:92.18, ema test Top5 acc: 99.84\n","[2022-04-23 04:15:20,617][experiments.experiment][INFO] - [Checkpoints] Epoch 31, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 04:15:20,619][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:22:53,264][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 32: use 452.7509055137634 seconds\n","--- Optimizer learning rate changed from 2.79e-02 to 2.78e-02 ---\n","[2022-04-23 04:22:53,370][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:22:54,780][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:22:54,780][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:22:56,166][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:22:56,168][experiments.experiment][INFO] - [EMA] Epoch 32.[Train] time:452.7509055137634 seconds, lr:0.0278, train_loss: 1.6075, unlabeled_losses_real_strong:0.6143,corrrect_unlabeled_num:369505.0,pro_above_threshold_num:378755.0,unlabelled_weak_top1_acc:91.29921942949295,unlabelled_weak_top5_acc:99.65733130276203  \n","[2022-04-23 04:22:56,170][experiments.experiment][INFO] - [EMA] Epoch 32. [Validation] raw_testing_loss: 0.4392, raw test Top1 acc:87.52, raw test Top5 acc: 99.38, ema_testing_loss: 0.2669, ema test Top1 acc:92.14, ema test Top5 acc: 99.84\n","[2022-04-23 04:22:56,171][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:30:27,281][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 33: use 451.21988248825073 seconds\n","--- Optimizer learning rate changed from 2.78e-02 to 2.76e-02 ---\n","[2022-04-23 04:30:27,391][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:30:28,799][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:30:28,800][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:30:30,168][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:30:30,170][experiments.experiment][INFO] - [EMA] Epoch 33.[Train] time:451.21988248825073 seconds, lr:0.0276, train_loss: 1.5988, unlabeled_losses_real_strong:0.6102,corrrect_unlabeled_num:370494.0,pro_above_threshold_num:379786.0,unlabelled_weak_top1_acc:91.35175314545631,unlabelled_weak_top5_acc:99.63553304225206  \n","[2022-04-23 04:30:30,172][experiments.experiment][INFO] - [EMA] Epoch 33. [Validation] raw_testing_loss: 0.3999, raw test Top1 acc:88.22, raw test Top5 acc: 99.6, ema_testing_loss: 0.2646, ema test Top1 acc:92.1, ema test Top5 acc: 99.86\n","[2022-04-23 04:30:30,286][experiments.experiment][INFO] - [Checkpoints] Epoch 33, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 04:30:30,296][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:37:59,257][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 34: use 449.0601313114166 seconds\n","--- Optimizer learning rate changed from 2.76e-02 to 2.75e-02 ---\n","[2022-04-23 04:37:59,357][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:38:00,722][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:38:00,722][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:38:02,032][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:38:02,033][experiments.experiment][INFO] - [EMA] Epoch 34.[Train] time:449.0601313114166 seconds, lr:0.0275, train_loss: 1.5915, unlabeled_losses_real_strong:0.6048,corrrect_unlabeled_num:371106.0,pro_above_threshold_num:380124.0,unlabelled_weak_top1_acc:91.44178006798029,unlabelled_weak_top5_acc:99.66626857221127  \n","[2022-04-23 04:38:02,035][experiments.experiment][INFO] - [EMA] Epoch 34. [Validation] raw_testing_loss: 0.4130, raw test Top1 acc:88.82, raw test Top5 acc: 99.28, ema_testing_loss: 0.2630, ema test Top1 acc:92.46, ema test Top5 acc: 99.82\n","[2022-04-23 04:38:02,036][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:45:27,434][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 35: use 445.5017969608307 seconds\n","--- Optimizer learning rate changed from 2.75e-02 to 2.73e-02 ---\n","[2022-04-23 04:45:27,538][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:45:28,914][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:45:28,914][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:45:30,246][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:45:30,248][experiments.experiment][INFO] - [EMA] Epoch 35.[Train] time:445.5017969608307 seconds, lr:0.0273, train_loss: 1.5847, unlabeled_losses_real_strong:0.6012,corrrect_unlabeled_num:372220.0,pro_above_threshold_num:381260.0,unlabelled_weak_top1_acc:91.50150733441114,unlabelled_weak_top5_acc:99.65209975838661  \n","[2022-04-23 04:45:30,248][experiments.experiment][INFO] - [EMA] Epoch 35. [Validation] raw_testing_loss: 0.4717, raw test Top1 acc:86.78, raw test Top5 acc: 99.36, ema_testing_loss: 0.2571, ema test Top1 acc:92.82, ema test Top5 acc: 99.84\n","[2022-04-23 04:45:30,348][experiments.experiment][INFO] - [Checkpoints] Epoch 35, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 04:45:30,350][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:52:56,690][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 36: use 446.440101146698 seconds\n","--- Optimizer learning rate changed from 2.73e-02 to 2.72e-02 ---\n","[2022-04-23 04:52:56,790][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:52:58,130][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:52:58,130][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:52:59,478][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:52:59,479][experiments.experiment][INFO] - [EMA] Epoch 36.[Train] time:446.440101146698 seconds, lr:0.0272, train_loss: 1.5815, unlabeled_losses_real_strong:0.6000,corrrect_unlabeled_num:373067.0,pro_above_threshold_num:381856.0,unlabelled_weak_top1_acc:91.65671097487211,unlabelled_weak_top5_acc:99.65645931661129  \n","[2022-04-23 04:52:59,481][experiments.experiment][INFO] - [EMA] Epoch 36. [Validation] raw_testing_loss: 0.4422, raw test Top1 acc:87.8, raw test Top5 acc: 99.0, ema_testing_loss: 0.2562, ema test Top1 acc:92.7, ema test Top5 acc: 99.88\n","[2022-04-23 04:52:59,482][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:00:25,780][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 37: use 446.40268111228943 seconds\n","--- Optimizer learning rate changed from 2.72e-02 to 2.71e-02 ---\n","[2022-04-23 05:00:25,885][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:00:27,216][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:00:27,216][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:00:28,552][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:00:28,554][experiments.experiment][INFO] - [EMA] Epoch 37.[Train] time:446.40268111228943 seconds, lr:0.0271, train_loss: 1.5823, unlabeled_losses_real_strong:0.5933,corrrect_unlabeled_num:373911.0,pro_above_threshold_num:382908.0,unlabelled_weak_top1_acc:91.6787274107337,unlabelled_weak_top5_acc:99.66932045668364  \n","[2022-04-23 05:00:28,556][experiments.experiment][INFO] - [EMA] Epoch 37. [Validation] raw_testing_loss: 0.4612, raw test Top1 acc:87.5, raw test Top5 acc: 99.44, ema_testing_loss: 0.2507, ema test Top1 acc:92.88, ema test Top5 acc: 99.84\n","[2022-04-23 05:00:28,661][experiments.experiment][INFO] - [Checkpoints] Epoch 37, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 05:00:28,663][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:07:55,035][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 38: use 446.47678899765015 seconds\n","--- Optimizer learning rate changed from 2.71e-02 to 2.69e-02 ---\n","[2022-04-23 05:07:55,140][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:07:56,513][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:07:56,514][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:07:57,884][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:07:57,885][experiments.experiment][INFO] - [EMA] Epoch 38.[Train] time:446.47678899765015 seconds, lr:0.0269, train_loss: 1.5795, unlabeled_losses_real_strong:0.5877,corrrect_unlabeled_num:374878.0,pro_above_threshold_num:383768.0,unlabelled_weak_top1_acc:91.82935328781605,unlabelled_weak_top5_acc:99.65580554306507  \n","[2022-04-23 05:07:57,886][experiments.experiment][INFO] - [EMA] Epoch 38. [Validation] raw_testing_loss: 0.4303, raw test Top1 acc:87.64, raw test Top5 acc: 99.52, ema_testing_loss: 0.2493, ema test Top1 acc:92.92, ema test Top5 acc: 99.86\n","[2022-04-23 05:07:57,888][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:15:19,337][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 39: use 441.5451908111572 seconds\n","--- Optimizer learning rate changed from 2.69e-02 to 2.68e-02 ---\n","[2022-04-23 05:15:19,433][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:15:20,723][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:15:20,724][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:15:22,021][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:15:22,023][experiments.experiment][INFO] - [EMA] Epoch 39.[Train] time:441.5451908111572 seconds, lr:0.0268, train_loss: 1.5710, unlabeled_losses_real_strong:0.5851,corrrect_unlabeled_num:375480.0,pro_above_threshold_num:384323.0,unlabelled_weak_top1_acc:91.86532048135996,unlabelled_weak_top5_acc:99.66779459267855  \n","[2022-04-23 05:15:22,024][experiments.experiment][INFO] - [EMA] Epoch 39. [Validation] raw_testing_loss: 0.4428, raw test Top1 acc:88.06, raw test Top5 acc: 99.66, ema_testing_loss: 0.2437, ema test Top1 acc:93.12, ema test Top5 acc: 99.8\n","[2022-04-23 05:15:22,119][experiments.experiment][INFO] - [Checkpoints] Epoch 39, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 05:15:22,121][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:22:39,065][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 40: use 437.0442078113556 seconds\n","--- Optimizer learning rate changed from 2.68e-02 to 2.66e-02 ---\n","[2022-04-23 05:22:39,166][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:22:40,490][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:22:40,490][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:22:41,834][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:22:41,836][experiments.experiment][INFO] - [EMA] Epoch 40.[Train] time:437.0442078113556 seconds, lr:0.0266, train_loss: 1.5755, unlabeled_losses_real_strong:0.5835,corrrect_unlabeled_num:376256.0,pro_above_threshold_num:385095.0,unlabelled_weak_top1_acc:91.93507485836744,unlabelled_weak_top5_acc:99.68828498572111  \n","[2022-04-23 05:22:41,836][experiments.experiment][INFO] - [EMA] Epoch 40. [Validation] raw_testing_loss: 0.3337, raw test Top1 acc:89.36, raw test Top5 acc: 99.38, ema_testing_loss: 0.2442, ema test Top1 acc:93.0, ema test Top5 acc: 99.8\n","[2022-04-23 05:22:41,838][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:29:57,737][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 41: use 435.99621081352234 seconds\n","--- Optimizer learning rate changed from 2.66e-02 to 2.64e-02 ---\n","[2022-04-23 05:29:57,834][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:29:59,148][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:29:59,148][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:30:00,488][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:30:00,490][experiments.experiment][INFO] - [EMA] Epoch 41.[Train] time:435.99621081352234 seconds, lr:0.0264, train_loss: 1.5603, unlabeled_losses_real_strong:0.5782,corrrect_unlabeled_num:377087.0,pro_above_threshold_num:385751.0,unlabelled_weak_top1_acc:92.01507463306189,unlabelled_weak_top5_acc:99.68523341417313  \n","[2022-04-23 05:30:00,492][experiments.experiment][INFO] - [EMA] Epoch 41. [Validation] raw_testing_loss: 0.3821, raw test Top1 acc:89.32, raw test Top5 acc: 99.56, ema_testing_loss: 0.2433, ema test Top1 acc:92.98, ema test Top5 acc: 99.84\n","[2022-04-23 05:30:00,588][experiments.experiment][INFO] - [Checkpoints] Epoch 41, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 05:30:00,592][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:37:19,506][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 42: use 439.01874017715454 seconds\n","--- Optimizer learning rate changed from 2.64e-02 to 2.63e-02 ---\n","[2022-04-23 05:37:19,611][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:37:20,997][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:37:20,997][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:37:22,408][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:37:22,409][experiments.experiment][INFO] - [EMA] Epoch 42.[Train] time:439.01874017715454 seconds, lr:0.0263, train_loss: 1.5549, unlabeled_losses_real_strong:0.5707,corrrect_unlabeled_num:378385.0,pro_above_threshold_num:387099.0,unlabelled_weak_top1_acc:92.067172460258,unlabelled_weak_top5_acc:99.6804376244545  \n","[2022-04-23 05:37:22,412][experiments.experiment][INFO] - [EMA] Epoch 42. [Validation] raw_testing_loss: 0.3308, raw test Top1 acc:89.96, raw test Top5 acc: 99.64, ema_testing_loss: 0.2396, ema test Top1 acc:93.08, ema test Top5 acc: 99.82\n","[2022-04-23 05:37:22,412][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:44:40,736][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 43: use 438.42082023620605 seconds\n","--- Optimizer learning rate changed from 2.63e-02 to 2.61e-02 ---\n","[2022-04-23 05:44:40,833][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:44:42,157][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:44:42,157][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:44:43,456][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:44:43,458][experiments.experiment][INFO] - [EMA] Epoch 43.[Train] time:438.42082023620605 seconds, lr:0.0261, train_loss: 1.5532, unlabeled_losses_real_strong:0.5711,corrrect_unlabeled_num:379227.0,pro_above_threshold_num:387932.0,unlabelled_weak_top1_acc:92.16657266020775,unlabelled_weak_top5_acc:99.69417056441307  \n","[2022-04-23 05:44:43,459][experiments.experiment][INFO] - [EMA] Epoch 43. [Validation] raw_testing_loss: 0.3959, raw test Top1 acc:88.74, raw test Top5 acc: 99.52, ema_testing_loss: 0.2364, ema test Top1 acc:93.14, ema test Top5 acc: 99.82\n","[2022-04-23 05:44:43,554][experiments.experiment][INFO] - [Checkpoints] Epoch 43, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 05:44:43,555][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:52:01,707][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 44: use 438.2465856075287 seconds\n","--- Optimizer learning rate changed from 2.61e-02 to 2.59e-02 ---\n","[2022-04-23 05:52:01,802][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:52:03,151][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:52:03,152][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:52:04,489][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:52:04,491][experiments.experiment][INFO] - [EMA] Epoch 44.[Train] time:438.2465856075287 seconds, lr:0.0259, train_loss: 1.5554, unlabeled_losses_real_strong:0.5652,corrrect_unlabeled_num:380239.0,pro_above_threshold_num:388827.0,unlabelled_weak_top1_acc:92.26771663874388,unlabelled_weak_top5_acc:99.68763092160225  \n","[2022-04-23 05:52:04,493][experiments.experiment][INFO] - [EMA] Epoch 44. [Validation] raw_testing_loss: 0.3970, raw test Top1 acc:88.88, raw test Top5 acc: 99.62, ema_testing_loss: 0.2344, ema test Top1 acc:93.24, ema test Top5 acc: 99.86\n","[2022-04-23 05:52:04,494][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:59:26,164][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 45: use 441.76918482780457 seconds\n","--- Optimizer learning rate changed from 2.59e-02 to 2.58e-02 ---\n","[2022-04-23 05:59:26,263][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:59:27,606][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:59:27,606][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:59:28,927][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:59:28,929][experiments.experiment][INFO] - [EMA] Epoch 45.[Train] time:441.76918482780457 seconds, lr:0.0258, train_loss: 1.5487, unlabeled_losses_real_strong:0.5622,corrrect_unlabeled_num:380780.0,pro_above_threshold_num:389424.0,unlabelled_weak_top1_acc:92.39196666330099,unlabelled_weak_top5_acc:99.69962006807327  \n","[2022-04-23 05:59:28,931][experiments.experiment][INFO] - [EMA] Epoch 45. [Validation] raw_testing_loss: 0.3293, raw test Top1 acc:90.24, raw test Top5 acc: 99.56, ema_testing_loss: 0.2360, ema test Top1 acc:93.36, ema test Top5 acc: 99.92\n","[2022-04-23 05:59:29,028][experiments.experiment][INFO] - [Checkpoints] Epoch 45, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 05:59:29,038][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:06:48,881][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 46: use 439.94254326820374 seconds\n","--- Optimizer learning rate changed from 2.58e-02 to 2.56e-02 ---\n","[2022-04-23 06:06:48,980][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:06:50,312][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:06:50,313][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:06:51,658][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:06:51,659][experiments.experiment][INFO] - [EMA] Epoch 46.[Train] time:439.94254326820374 seconds, lr:0.0256, train_loss: 1.5476, unlabeled_losses_real_strong:0.5616,corrrect_unlabeled_num:380574.0,pro_above_threshold_num:389296.0,unlabelled_weak_top1_acc:92.2677164748311,unlabelled_weak_top5_acc:99.68937489390373  \n","[2022-04-23 06:06:51,662][experiments.experiment][INFO] - [EMA] Epoch 46. [Validation] raw_testing_loss: 0.4942, raw test Top1 acc:86.54, raw test Top5 acc: 98.9, ema_testing_loss: 0.2352, ema test Top1 acc:93.36, ema test Top5 acc: 99.9\n","[2022-04-23 06:06:51,663][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:14:10,686][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 47: use 439.12632155418396 seconds\n","--- Optimizer learning rate changed from 2.56e-02 to 2.54e-02 ---\n","[2022-04-23 06:14:10,790][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:14:12,107][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:14:12,107][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:14:13,406][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:14:13,408][experiments.experiment][INFO] - [EMA] Epoch 47.[Train] time:439.12632155418396 seconds, lr:0.0254, train_loss: 1.5470, unlabeled_losses_real_strong:0.5589,corrrect_unlabeled_num:381572.0,pro_above_threshold_num:390231.0,unlabelled_weak_top1_acc:92.4072254896164,unlabelled_weak_top5_acc:99.71618676930666  \n","[2022-04-23 06:14:13,410][experiments.experiment][INFO] - [EMA] Epoch 47. [Validation] raw_testing_loss: 0.3930, raw test Top1 acc:88.38, raw test Top5 acc: 99.52, ema_testing_loss: 0.2340, ema test Top1 acc:93.28, ema test Top5 acc: 99.88\n","[2022-04-23 06:14:13,502][experiments.experiment][INFO] - [Checkpoints] Epoch 47, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 06:14:13,512][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:21:35,275][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 48: use 441.85941648483276 seconds\n","--- Optimizer learning rate changed from 2.54e-02 to 2.52e-02 ---\n","[2022-04-23 06:21:35,371][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:21:36,721][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:21:36,722][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:21:38,040][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:21:38,042][experiments.experiment][INFO] - [EMA] Epoch 48.[Train] time:441.85941648483276 seconds, lr:0.0252, train_loss: 1.5405, unlabeled_losses_real_strong:0.5553,corrrect_unlabeled_num:382045.0,pro_above_threshold_num:390635.0,unlabelled_weak_top1_acc:92.43708910048008,unlabelled_weak_top5_acc:99.70179997384548  \n","[2022-04-23 06:21:38,043][experiments.experiment][INFO] - [EMA] Epoch 48. [Validation] raw_testing_loss: 0.3336, raw test Top1 acc:90.36, raw test Top5 acc: 99.68, ema_testing_loss: 0.2352, ema test Top1 acc:93.52, ema test Top5 acc: 99.88\n","[2022-04-23 06:21:38,044][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:28:55,810][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 49: use 437.8630635738373 seconds\n","--- Optimizer learning rate changed from 2.52e-02 to 2.50e-02 ---\n","[2022-04-23 06:28:55,907][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:28:57,233][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:28:57,233][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:28:58,550][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:28:58,552][experiments.experiment][INFO] - [EMA] Epoch 49.[Train] time:437.8630635738373 seconds, lr:0.0250, train_loss: 1.5310, unlabeled_losses_real_strong:0.5519,corrrect_unlabeled_num:382522.0,pro_above_threshold_num:391052.0,unlabelled_weak_top1_acc:92.47763397544622,unlabelled_weak_top5_acc:99.70703156292439  \n","[2022-04-23 06:28:58,553][experiments.experiment][INFO] - [EMA] Epoch 49. [Validation] raw_testing_loss: 0.3265, raw test Top1 acc:90.26, raw test Top5 acc: 99.6, ema_testing_loss: 0.2313, ema test Top1 acc:93.54, ema test Top5 acc: 99.86\n","[2022-04-23 06:28:58,650][experiments.experiment][INFO] - [Checkpoints] Epoch 49, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 06:28:58,655][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:36:17,065][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 50: use 438.5043807029724 seconds\n","--- Optimizer learning rate changed from 2.50e-02 to 2.48e-02 ---\n","[2022-04-23 06:36:17,159][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:36:18,472][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:36:18,473][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:36:19,773][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:36:19,774][experiments.experiment][INFO] - [EMA] Epoch 50.[Train] time:438.5043807029724 seconds, lr:0.0248, train_loss: 1.5394, unlabeled_losses_real_strong:0.5483,corrrect_unlabeled_num:383247.0,pro_above_threshold_num:391921.0,unlabelled_weak_top1_acc:92.5286417528987,unlabelled_weak_top5_acc:99.72185457497835  \n","[2022-04-23 06:36:19,776][experiments.experiment][INFO] - [EMA] Epoch 50. [Validation] raw_testing_loss: 0.3546, raw test Top1 acc:90.14, raw test Top5 acc: 99.66, ema_testing_loss: 0.2314, ema test Top1 acc:93.62, ema test Top5 acc: 99.92\n","[2022-04-23 06:36:19,777][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:43:38,770][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 51: use 439.093079328537 seconds\n","--- Optimizer learning rate changed from 2.48e-02 to 2.46e-02 ---\n","[2022-04-23 06:43:38,870][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:43:40,215][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:43:40,215][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:43:41,541][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:43:41,542][experiments.experiment][INFO] - [EMA] Epoch 51.[Train] time:439.093079328537 seconds, lr:0.0246, train_loss: 1.5311, unlabeled_losses_real_strong:0.5482,corrrect_unlabeled_num:383774.0,pro_above_threshold_num:392305.0,unlabelled_weak_top1_acc:92.59229274839163,unlabelled_weak_top5_acc:99.71705878525972  \n","[2022-04-23 06:43:41,544][experiments.experiment][INFO] - [EMA] Epoch 51. [Validation] raw_testing_loss: 0.3286, raw test Top1 acc:90.38, raw test Top5 acc: 99.66, ema_testing_loss: 0.2277, ema test Top1 acc:93.58, ema test Top5 acc: 99.9\n","[2022-04-23 06:43:41,640][experiments.experiment][INFO] - [Checkpoints] Epoch 51, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 06:43:41,641][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:51:00,234][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 52: use 438.6908121109009 seconds\n","--- Optimizer learning rate changed from 2.46e-02 to 2.44e-02 ---\n","[2022-04-23 06:51:00,332][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:51:01,665][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:51:01,666][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:51:02,959][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:51:02,961][experiments.experiment][INFO] - [EMA] Epoch 52.[Train] time:438.6908121109009 seconds, lr:0.0244, train_loss: 1.5237, unlabeled_losses_real_strong:0.5456,corrrect_unlabeled_num:383657.0,pro_above_threshold_num:392133.0,unlabelled_weak_top1_acc:92.64133889228106,unlabelled_weak_top5_acc:99.71030137687922  \n","[2022-04-23 06:51:02,962][experiments.experiment][INFO] - [EMA] Epoch 52. [Validation] raw_testing_loss: 0.3575, raw test Top1 acc:89.6, raw test Top5 acc: 99.68, ema_testing_loss: 0.2265, ema test Top1 acc:93.8, ema test Top5 acc: 99.9\n","[2022-04-23 06:51:02,963][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:58:21,514][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 53: use 438.64628052711487 seconds\n","--- Optimizer learning rate changed from 2.44e-02 to 2.42e-02 ---\n","[2022-04-23 06:58:21,610][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:58:22,898][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:58:22,899][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:58:24,225][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:58:24,227][experiments.experiment][INFO] - [EMA] Epoch 53.[Train] time:438.64628052711487 seconds, lr:0.0242, train_loss: 1.5103, unlabeled_losses_real_strong:0.5398,corrrect_unlabeled_num:384918.0,pro_above_threshold_num:393438.0,unlabelled_weak_top1_acc:92.73986710608006,unlabelled_weak_top5_acc:99.73100975900888  \n","[2022-04-23 06:58:24,229][experiments.experiment][INFO] - [EMA] Epoch 53. [Validation] raw_testing_loss: 0.3669, raw test Top1 acc:89.58, raw test Top5 acc: 99.66, ema_testing_loss: 0.2256, ema test Top1 acc:93.54, ema test Top5 acc: 99.9\n","[2022-04-23 06:58:24,325][experiments.experiment][INFO] - [Checkpoints] Epoch 53, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 06:58:24,328][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:05:43,146][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 54: use 438.9148540496826 seconds\n","--- Optimizer learning rate changed from 2.42e-02 to 2.40e-02 ---\n","[2022-04-23 07:05:43,243][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:05:44,566][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:05:44,566][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:05:45,854][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:05:45,856][experiments.experiment][INFO] - [EMA] Epoch 54.[Train] time:438.9148540496826 seconds, lr:0.0240, train_loss: 1.5175, unlabeled_losses_real_strong:0.5375,corrrect_unlabeled_num:385197.0,pro_above_threshold_num:393697.0,unlabelled_weak_top1_acc:92.80112011730671,unlabelled_weak_top5_acc:99.72294443845749  \n","[2022-04-23 07:05:45,858][experiments.experiment][INFO] - [EMA] Epoch 54. [Validation] raw_testing_loss: 0.3515, raw test Top1 acc:89.72, raw test Top5 acc: 99.52, ema_testing_loss: 0.2279, ema test Top1 acc:93.82, ema test Top5 acc: 99.9\n","[2022-04-23 07:05:45,858][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:13:04,410][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 55: use 438.6562032699585 seconds\n","--- Optimizer learning rate changed from 2.40e-02 to 2.38e-02 ---\n","[2022-04-23 07:13:04,515][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:13:05,872][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:13:05,872][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:13:07,185][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:13:07,186][experiments.experiment][INFO] - [EMA] Epoch 55.[Train] time:438.6562032699585 seconds, lr:0.0238, train_loss: 1.5185, unlabeled_losses_real_strong:0.5378,corrrect_unlabeled_num:385522.0,pro_above_threshold_num:394008.0,unlabelled_weak_top1_acc:92.8553979024291,unlabelled_weak_top5_acc:99.72294440120459  \n","[2022-04-23 07:13:07,188][experiments.experiment][INFO] - [EMA] Epoch 55. [Validation] raw_testing_loss: 0.3262, raw test Top1 acc:90.28, raw test Top5 acc: 99.66, ema_testing_loss: 0.2285, ema test Top1 acc:93.68, ema test Top5 acc: 99.88\n","[2022-04-23 07:13:07,284][experiments.experiment][INFO] - [Checkpoints] Epoch 55, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 07:13:07,290][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:20:27,521][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 56: use 440.32798981666565 seconds\n","--- Optimizer learning rate changed from 2.38e-02 to 2.36e-02 ---\n","[2022-04-23 07:20:27,618][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:20:28,940][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:20:28,940][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:20:30,258][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:20:30,260][experiments.experiment][INFO] - [EMA] Epoch 56.[Train] time:440.32798981666565 seconds, lr:0.0236, train_loss: 1.5158, unlabeled_losses_real_strong:0.5355,corrrect_unlabeled_num:386368.0,pro_above_threshold_num:394680.0,unlabelled_weak_top1_acc:92.87610628455877,unlabelled_weak_top5_acc:99.71836676448584  \n","[2022-04-23 07:20:30,260][experiments.experiment][INFO] - [EMA] Epoch 56. [Validation] raw_testing_loss: 0.3483, raw test Top1 acc:90.92, raw test Top5 acc: 99.56, ema_testing_loss: 0.2237, ema test Top1 acc:93.72, ema test Top5 acc: 99.84\n","[2022-04-23 07:20:30,262][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:27:50,672][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 57: use 440.51112484931946 seconds\n","--- Optimizer learning rate changed from 2.36e-02 to 2.34e-02 ---\n","[2022-04-23 07:27:50,773][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:27:52,111][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:27:52,112][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:27:53,449][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:27:53,451][experiments.experiment][INFO] - [EMA] Epoch 57.[Train] time:440.51112484931946 seconds, lr:0.0234, train_loss: 1.5015, unlabeled_losses_real_strong:0.5297,corrrect_unlabeled_num:386838.0,pro_above_threshold_num:395091.0,unlabelled_weak_top1_acc:92.86913076788187,unlabelled_weak_top5_acc:99.72926581650972  \n","[2022-04-23 07:27:53,453][experiments.experiment][INFO] - [EMA] Epoch 57. [Validation] raw_testing_loss: 0.2962, raw test Top1 acc:90.74, raw test Top5 acc: 99.62, ema_testing_loss: 0.2210, ema test Top1 acc:93.94, ema test Top5 acc: 99.84\n","[2022-04-23 07:27:53,548][experiments.experiment][INFO] - [Checkpoints] Epoch 57, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 07:27:53,559][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:35:18,513][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 58: use 445.0529775619507 seconds\n","--- Optimizer learning rate changed from 2.34e-02 to 2.32e-02 ---\n","[2022-04-23 07:35:18,612][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:35:19,947][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:35:19,947][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:35:21,304][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:35:21,306][experiments.experiment][INFO] - [EMA] Epoch 58.[Train] time:445.0529775619507 seconds, lr:0.0232, train_loss: 1.5079, unlabeled_losses_real_strong:0.5316,corrrect_unlabeled_num:387379.0,pro_above_threshold_num:395747.0,unlabelled_weak_top1_acc:92.86695095896721,unlabelled_weak_top5_acc:99.72621393948793  \n","[2022-04-23 07:35:21,307][experiments.experiment][INFO] - [EMA] Epoch 58. [Validation] raw_testing_loss: 0.4073, raw test Top1 acc:88.78, raw test Top5 acc: 99.46, ema_testing_loss: 0.2202, ema test Top1 acc:93.88, ema test Top5 acc: 99.88\n","[2022-04-23 07:35:21,308][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:42:49,825][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 59: use 448.6134374141693 seconds\n","--- Optimizer learning rate changed from 2.32e-02 to 2.30e-02 ---\n","[2022-04-23 07:42:49,922][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:42:51,310][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:42:51,311][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:42:52,615][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:42:52,616][experiments.experiment][INFO] - [EMA] Epoch 59.[Train] time:448.6134374141693 seconds, lr:0.0230, train_loss: 1.4981, unlabeled_losses_real_strong:0.5279,corrrect_unlabeled_num:387245.0,pro_above_threshold_num:395575.0,unlabelled_weak_top1_acc:92.94934837520123,unlabelled_weak_top5_acc:99.73536948114634  \n","[2022-04-23 07:42:52,618][experiments.experiment][INFO] - [EMA] Epoch 59. [Validation] raw_testing_loss: 0.3191, raw test Top1 acc:91.12, raw test Top5 acc: 99.62, ema_testing_loss: 0.2192, ema test Top1 acc:93.74, ema test Top5 acc: 99.88\n","[2022-04-23 07:42:52,715][experiments.experiment][INFO] - [Checkpoints] Epoch 59, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 07:42:52,718][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:50:21,736][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 60: use 449.1224434375763 seconds\n","--- Optimizer learning rate changed from 2.30e-02 to 2.27e-02 ---\n","[2022-04-23 07:50:21,840][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:50:23,270][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:50:23,271][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:50:24,630][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:50:24,632][experiments.experiment][INFO] - [EMA] Epoch 60.[Train] time:449.1224434375763 seconds, lr:0.0227, train_loss: 1.5005, unlabeled_losses_real_strong:0.5246,corrrect_unlabeled_num:388067.0,pro_above_threshold_num:396537.0,unlabelled_weak_top1_acc:93.01583311706781,unlabelled_weak_top5_acc:99.73645929992199  \n","[2022-04-23 07:50:24,634][experiments.experiment][INFO] - [EMA] Epoch 60. [Validation] raw_testing_loss: 0.3454, raw test Top1 acc:90.32, raw test Top5 acc: 99.68, ema_testing_loss: 0.2179, ema test Top1 acc:93.74, ema test Top5 acc: 99.92\n","[2022-04-23 07:50:24,635][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:57:55,390][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 61: use 450.8638355731964 seconds\n","--- Optimizer learning rate changed from 2.27e-02 to 2.25e-02 ---\n","[2022-04-23 07:57:55,499][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:57:56,871][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:57:56,871][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:57:58,289][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:57:58,291][experiments.experiment][INFO] - [EMA] Epoch 61.[Train] time:450.8638355731964 seconds, lr:0.0225, train_loss: 1.4851, unlabeled_losses_real_strong:0.5202,corrrect_unlabeled_num:388619.0,pro_above_threshold_num:396912.0,unlabelled_weak_top1_acc:93.09626880288124,unlabelled_weak_top5_acc:99.74103704094887  \n","[2022-04-23 07:57:58,292][experiments.experiment][INFO] - [EMA] Epoch 61. [Validation] raw_testing_loss: 0.3426, raw test Top1 acc:90.28, raw test Top5 acc: 99.72, ema_testing_loss: 0.2181, ema test Top1 acc:93.86, ema test Top5 acc: 99.88\n","[2022-04-23 07:57:58,392][experiments.experiment][INFO] - [Checkpoints] Epoch 61, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 07:57:58,401][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:05:30,613][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 62: use 452.31156158447266 seconds\n","--- Optimizer learning rate changed from 2.25e-02 to 2.23e-02 ---\n","[2022-04-23 08:05:30,712][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:05:32,032][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:05:32,033][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:05:33,367][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:05:33,368][experiments.experiment][INFO] - [EMA] Epoch 62.[Train] time:452.31156158447266 seconds, lr:0.0223, train_loss: 1.4899, unlabeled_losses_real_strong:0.5201,corrrect_unlabeled_num:389151.0,pro_above_threshold_num:397500.0,unlabelled_weak_top1_acc:93.10259026288986,unlabelled_weak_top5_acc:99.74278078973293  \n","[2022-04-23 08:05:33,370][experiments.experiment][INFO] - [EMA] Epoch 62. [Validation] raw_testing_loss: 0.3335, raw test Top1 acc:90.8, raw test Top5 acc: 99.72, ema_testing_loss: 0.2178, ema test Top1 acc:93.94, ema test Top5 acc: 99.92\n","[2022-04-23 08:05:33,371][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:13:01,699][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 63: use 448.4279043674469 seconds\n","--- Optimizer learning rate changed from 2.23e-02 to 2.21e-02 ---\n","[2022-04-23 08:13:01,799][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:13:03,161][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:13:03,161][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:13:04,516][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:13:04,518][experiments.experiment][INFO] - [EMA] Epoch 63.[Train] time:448.4279043674469 seconds, lr:0.0221, train_loss: 1.4847, unlabeled_losses_real_strong:0.5168,corrrect_unlabeled_num:390130.0,pro_above_threshold_num:398567.0,unlabelled_weak_top1_acc:93.21877500414848,unlabelled_weak_top5_acc:99.75302609801292  \n","[2022-04-23 08:13:04,519][experiments.experiment][INFO] - [EMA] Epoch 63. [Validation] raw_testing_loss: 0.3638, raw test Top1 acc:89.82, raw test Top5 acc: 99.4, ema_testing_loss: 0.2148, ema test Top1 acc:94.04, ema test Top5 acc: 99.9\n","[2022-04-23 08:13:04,618][experiments.experiment][INFO] - [Checkpoints] Epoch 63, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 08:13:04,628][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:20:34,143][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 64: use 449.61810088157654 seconds\n","--- Optimizer learning rate changed from 2.21e-02 to 2.18e-02 ---\n","[2022-04-23 08:20:34,247][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:20:35,649][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:20:35,650][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:20:36,999][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:20:37,001][experiments.experiment][INFO] - [EMA] Epoch 64.[Train] time:449.61810088157654 seconds, lr:0.0218, train_loss: 1.4800, unlabeled_losses_real_strong:0.5149,corrrect_unlabeled_num:390615.0,pro_above_threshold_num:399106.0,unlabelled_weak_top1_acc:93.17823015153408,unlabelled_weak_top5_acc:99.75041024386883  \n","[2022-04-23 08:20:37,002][experiments.experiment][INFO] - [EMA] Epoch 64. [Validation] raw_testing_loss: 0.3320, raw test Top1 acc:90.42, raw test Top5 acc: 99.7, ema_testing_loss: 0.2139, ema test Top1 acc:94.14, ema test Top5 acc: 99.92\n","[2022-04-23 08:20:37,003][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:28:04,785][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 65: use 447.890527009964 seconds\n","--- Optimizer learning rate changed from 2.18e-02 to 2.16e-02 ---\n","[2022-04-23 08:28:04,894][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:28:06,271][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:28:06,271][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:28:07,687][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:28:07,689][experiments.experiment][INFO] - [EMA] Epoch 65.[Train] time:447.890527009964 seconds, lr:0.0216, train_loss: 1.4762, unlabeled_losses_real_strong:0.5107,corrrect_unlabeled_num:390568.0,pro_above_threshold_num:398907.0,unlabelled_weak_top1_acc:93.19000128656626,unlabelled_weak_top5_acc:99.74343483895063  \n","[2022-04-23 08:28:07,691][experiments.experiment][INFO] - [EMA] Epoch 65. [Validation] raw_testing_loss: 0.3315, raw test Top1 acc:90.68, raw test Top5 acc: 99.76, ema_testing_loss: 0.2149, ema test Top1 acc:94.02, ema test Top5 acc: 99.94\n","[2022-04-23 08:28:07,800][experiments.experiment][INFO] - [Checkpoints] Epoch 65, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 08:28:07,810][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:35:35,649][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 66: use 447.9369695186615 seconds\n","--- Optimizer learning rate changed from 2.16e-02 to 2.14e-02 ---\n","[2022-04-23 08:35:35,747][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:35:37,071][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:35:37,071][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:35:38,450][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:35:38,452][experiments.experiment][INFO] - [EMA] Epoch 66.[Train] time:447.9369695186615 seconds, lr:0.0214, train_loss: 1.4674, unlabeled_losses_real_strong:0.5105,corrrect_unlabeled_num:390916.0,pro_above_threshold_num:399088.0,unlabelled_weak_top1_acc:93.31773921102285,unlabelled_weak_top5_acc:99.75673169642687  \n","[2022-04-23 08:35:38,455][experiments.experiment][INFO] - [EMA] Epoch 66. [Validation] raw_testing_loss: 0.3315, raw test Top1 acc:90.48, raw test Top5 acc: 99.76, ema_testing_loss: 0.2137, ema test Top1 acc:94.2, ema test Top5 acc: 99.92\n","[2022-04-23 08:35:38,455][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:43:03,610][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 67: use 445.2555949687958 seconds\n","--- Optimizer learning rate changed from 2.14e-02 to 2.11e-02 ---\n","[2022-04-23 08:43:03,711][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:43:05,061][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:43:05,061][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:43:06,467][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:43:06,469][experiments.experiment][INFO] - [EMA] Epoch 67.[Train] time:445.2555949687958 seconds, lr:0.0211, train_loss: 1.4768, unlabeled_losses_real_strong:0.5062,corrrect_unlabeled_num:391118.0,pro_above_threshold_num:399436.0,unlabelled_weak_top1_acc:93.34280724823475,unlabelled_weak_top5_acc:99.75585982948542  \n","[2022-04-23 08:43:06,472][experiments.experiment][INFO] - [EMA] Epoch 67. [Validation] raw_testing_loss: 0.3335, raw test Top1 acc:91.04, raw test Top5 acc: 99.68, ema_testing_loss: 0.2146, ema test Top1 acc:94.2, ema test Top5 acc: 99.94\n","[2022-04-23 08:43:06,572][experiments.experiment][INFO] - [Checkpoints] Epoch 67, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 08:43:06,573][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:50:35,069][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 68: use 448.6034688949585 seconds\n","--- Optimizer learning rate changed from 2.11e-02 to 2.09e-02 ---\n","[2022-04-23 08:50:35,176][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:50:36,509][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:50:36,509][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:50:37,855][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:50:37,856][experiments.experiment][INFO] - [EMA] Epoch 68.[Train] time:448.6034688949585 seconds, lr:0.0209, train_loss: 1.4639, unlabeled_losses_real_strong:0.5033,corrrect_unlabeled_num:392095.0,pro_above_threshold_num:400347.0,unlabelled_weak_top1_acc:93.38247999548912,unlabelled_weak_top5_acc:99.76610504835844  \n","[2022-04-23 08:50:37,858][experiments.experiment][INFO] - [EMA] Epoch 68. [Validation] raw_testing_loss: 0.3379, raw test Top1 acc:90.54, raw test Top5 acc: 99.68, ema_testing_loss: 0.2125, ema test Top1 acc:94.18, ema test Top5 acc: 99.94\n","[2022-04-23 08:50:37,859][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:58:09,299][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 69: use 451.5458619594574 seconds\n","--- Optimizer learning rate changed from 2.09e-02 to 2.06e-02 ---\n","[2022-04-23 08:58:09,405][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:58:10,744][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:58:10,745][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:58:12,089][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:58:12,090][experiments.experiment][INFO] - [EMA] Epoch 69.[Train] time:451.5458619594574 seconds, lr:0.0206, train_loss: 1.4588, unlabeled_losses_real_strong:0.5016,corrrect_unlabeled_num:393086.0,pro_above_threshold_num:401442.0,unlabelled_weak_top1_acc:93.39098137617111,unlabelled_weak_top5_acc:99.75280802696943  \n","[2022-04-23 08:58:12,093][experiments.experiment][INFO] - [EMA] Epoch 69. [Validation] raw_testing_loss: 0.3040, raw test Top1 acc:91.48, raw test Top5 acc: 99.78, ema_testing_loss: 0.2116, ema test Top1 acc:94.28, ema test Top5 acc: 99.94\n","[2022-04-23 08:58:12,189][experiments.experiment][INFO] - [Checkpoints] Epoch 69, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 08:58:12,200][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:05:46,338][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 70: use 454.2457859516144 seconds\n","--- Optimizer learning rate changed from 2.06e-02 to 2.04e-02 ---\n","[2022-04-23 09:05:46,446][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:05:47,849][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:05:47,849][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:05:49,254][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:05:49,256][experiments.experiment][INFO] - [EMA] Epoch 70.[Train] time:454.2457859516144 seconds, lr:0.0204, train_loss: 1.4493, unlabeled_losses_real_strong:0.4990,corrrect_unlabeled_num:392846.0,pro_above_threshold_num:401068.0,unlabelled_weak_top1_acc:93.43326995521784,unlabelled_weak_top5_acc:99.767412930727  \n","[2022-04-23 09:05:49,258][experiments.experiment][INFO] - [EMA] Epoch 70. [Validation] raw_testing_loss: 0.3552, raw test Top1 acc:89.78, raw test Top5 acc: 99.7, ema_testing_loss: 0.2116, ema test Top1 acc:94.06, ema test Top5 acc: 99.92\n","[2022-04-23 09:05:49,260][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:13:19,520][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 71: use 450.3627293109894 seconds\n","--- Optimizer learning rate changed from 2.04e-02 to 2.01e-02 ---\n","[2022-04-23 09:13:19,622][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:13:20,968][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:13:20,969][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:13:22,343][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:13:22,345][experiments.experiment][INFO] - [EMA] Epoch 71.[Train] time:450.3627293109894 seconds, lr:0.0201, train_loss: 1.4476, unlabeled_losses_real_strong:0.4952,corrrect_unlabeled_num:393328.0,pro_above_threshold_num:401645.0,unlabelled_weak_top1_acc:93.45855606347322,unlabelled_weak_top5_acc:99.77308051288128  \n","[2022-04-23 09:13:22,347][experiments.experiment][INFO] - [EMA] Epoch 71. [Validation] raw_testing_loss: 0.4311, raw test Top1 acc:88.36, raw test Top5 acc: 99.56, ema_testing_loss: 0.2114, ema test Top1 acc:94.18, ema test Top5 acc: 99.94\n","[2022-04-23 09:13:22,450][experiments.experiment][INFO] - [Checkpoints] Epoch 71, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 09:13:22,452][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:20:53,915][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 72: use 451.58062839508057 seconds\n","--- Optimizer learning rate changed from 2.01e-02 to 1.99e-02 ---\n","[2022-04-23 09:20:54,033][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:20:55,479][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:20:55,480][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:20:56,883][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:20:56,885][experiments.experiment][INFO] - [EMA] Epoch 72.[Train] time:451.58062839508057 seconds, lr:0.0199, train_loss: 1.4497, unlabeled_losses_real_strong:0.4950,corrrect_unlabeled_num:393994.0,pro_above_threshold_num:402105.0,unlabelled_weak_top1_acc:93.57059922069311,unlabelled_weak_top5_acc:99.7600014731288  \n","[2022-04-23 09:20:56,887][experiments.experiment][INFO] - [EMA] Epoch 72. [Validation] raw_testing_loss: 0.2999, raw test Top1 acc:91.02, raw test Top5 acc: 99.68, ema_testing_loss: 0.2113, ema test Top1 acc:94.22, ema test Top5 acc: 99.92\n","[2022-04-23 09:20:56,888][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:28:31,477][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 73: use 454.69514179229736 seconds\n","--- Optimizer learning rate changed from 1.99e-02 to 1.96e-02 ---\n","[2022-04-23 09:28:31,583][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:28:32,948][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:28:32,949][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:28:34,327][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:28:34,329][experiments.experiment][INFO] - [EMA] Epoch 73.[Train] time:454.69514179229736 seconds, lr:0.0196, train_loss: 1.4478, unlabeled_losses_real_strong:0.4914,corrrect_unlabeled_num:394548.0,pro_above_threshold_num:402752.0,unlabelled_weak_top1_acc:93.54444132745266,unlabelled_weak_top5_acc:99.7399470359087  \n","[2022-04-23 09:28:34,330][experiments.experiment][INFO] - [EMA] Epoch 73. [Validation] raw_testing_loss: 0.3069, raw test Top1 acc:91.18, raw test Top5 acc: 99.74, ema_testing_loss: 0.2112, ema test Top1 acc:94.5, ema test Top5 acc: 99.9\n","[2022-04-23 09:28:34,436][experiments.experiment][INFO] - [Checkpoints] Epoch 73, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 09:28:34,438][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:36:08,078][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 74: use 453.7467038631439 seconds\n","--- Optimizer learning rate changed from 1.96e-02 to 1.93e-02 ---\n","[2022-04-23 09:36:08,185][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:36:09,616][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:36:09,617][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:36:11,039][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:36:11,040][experiments.experiment][INFO] - [EMA] Epoch 74.[Train] time:453.7467038631439 seconds, lr:0.0193, train_loss: 1.4316, unlabeled_losses_real_strong:0.4907,corrrect_unlabeled_num:394776.0,pro_above_threshold_num:403111.0,unlabelled_weak_top1_acc:93.52089916914701,unlabelled_weak_top5_acc:99.7702467739582  \n","[2022-04-23 09:36:11,042][experiments.experiment][INFO] - [EMA] Epoch 74. [Validation] raw_testing_loss: 0.3282, raw test Top1 acc:90.42, raw test Top5 acc: 99.68, ema_testing_loss: 0.2071, ema test Top1 acc:94.26, ema test Top5 acc: 99.9\n","[2022-04-23 09:36:11,043][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:43:44,015][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 75: use 453.08293533325195 seconds\n","--- Optimizer learning rate changed from 1.93e-02 to 1.91e-02 ---\n","[2022-04-23 09:43:44,126][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:43:45,541][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:43:45,542][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:43:46,929][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:43:46,931][experiments.experiment][INFO] - [EMA] Epoch 75.[Train] time:453.08293533325195 seconds, lr:0.0191, train_loss: 1.4389, unlabeled_losses_real_strong:0.4851,corrrect_unlabeled_num:395815.0,pro_above_threshold_num:404069.0,unlabelled_weak_top1_acc:93.69790110737085,unlabelled_weak_top5_acc:99.766540966928  \n","[2022-04-23 09:43:46,933][experiments.experiment][INFO] - [EMA] Epoch 75. [Validation] raw_testing_loss: 0.2772, raw test Top1 acc:91.54, raw test Top5 acc: 99.8, ema_testing_loss: 0.2093, ema test Top1 acc:94.12, ema test Top5 acc: 99.92\n","[2022-04-23 09:43:47,042][experiments.experiment][INFO] - [Checkpoints] Epoch 75, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 09:43:47,050][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:51:22,454][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 76: use 455.5111036300659 seconds\n","--- Optimizer learning rate changed from 1.91e-02 to 1.88e-02 ---\n","[2022-04-23 09:51:22,561][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:51:23,974][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:51:23,974][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:51:25,390][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:51:25,392][experiments.experiment][INFO] - [EMA] Epoch 76.[Train] time:455.5111036300659 seconds, lr:0.0188, train_loss: 1.4333, unlabeled_losses_real_strong:0.4848,corrrect_unlabeled_num:395878.0,pro_above_threshold_num:403979.0,unlabelled_weak_top1_acc:93.69484932720661,unlabelled_weak_top5_acc:99.77635017037392  \n","[2022-04-23 09:51:25,393][experiments.experiment][INFO] - [EMA] Epoch 76. [Validation] raw_testing_loss: 0.3208, raw test Top1 acc:90.7, raw test Top5 acc: 99.76, ema_testing_loss: 0.2093, ema test Top1 acc:94.02, ema test Top5 acc: 99.9\n","[2022-04-23 09:51:25,394][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:59:05,067][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 77: use 459.7854127883911 seconds\n","--- Optimizer learning rate changed from 1.88e-02 to 1.85e-02 ---\n","[2022-04-23 09:59:05,179][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:59:06,593][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:59:06,593][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:59:08,067][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:59:08,068][experiments.experiment][INFO] - [EMA] Epoch 77.[Train] time:459.7854127883911 seconds, lr:0.0185, train_loss: 1.4248, unlabeled_losses_real_strong:0.4823,corrrect_unlabeled_num:396485.0,pro_above_threshold_num:404688.0,unlabelled_weak_top1_acc:93.71119794249535,unlabelled_weak_top5_acc:99.7669769525528  \n","[2022-04-23 09:59:08,069][experiments.experiment][INFO] - [EMA] Epoch 77. [Validation] raw_testing_loss: 0.2876, raw test Top1 acc:91.56, raw test Top5 acc: 99.78, ema_testing_loss: 0.2088, ema test Top1 acc:94.06, ema test Top5 acc: 99.88\n","[2022-04-23 09:59:08,166][experiments.experiment][INFO] - [Checkpoints] Epoch 77, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 09:59:08,175][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:06:49,853][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 78: use 461.7928903102875 seconds\n","--- Optimizer learning rate changed from 1.85e-02 to 1.83e-02 ---\n","[2022-04-23 10:06:49,968][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:06:51,391][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:06:51,392][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:06:52,781][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:06:52,782][experiments.experiment][INFO] - [EMA] Epoch 78.[Train] time:461.7928903102875 seconds, lr:0.0183, train_loss: 1.4153, unlabeled_losses_real_strong:0.4823,corrrect_unlabeled_num:396556.0,pro_above_threshold_num:404535.0,unlabelled_weak_top1_acc:93.76111608743668,unlabelled_weak_top5_acc:99.78463363647461  \n","[2022-04-23 10:06:52,785][experiments.experiment][INFO] - [EMA] Epoch 78. [Validation] raw_testing_loss: 0.3352, raw test Top1 acc:90.1, raw test Top5 acc: 99.78, ema_testing_loss: 0.2086, ema test Top1 acc:94.38, ema test Top5 acc: 99.92\n","[2022-04-23 10:06:52,786][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:14:33,091][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 79: use 460.40589022636414 seconds\n","--- Optimizer learning rate changed from 1.83e-02 to 1.80e-02 ---\n","[2022-04-23 10:14:33,192][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:14:34,591][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:14:34,591][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:14:36,039][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:14:36,041][experiments.experiment][INFO] - [EMA] Epoch 79.[Train] time:460.40589022636414 seconds, lr:0.0180, train_loss: 1.4065, unlabeled_losses_real_strong:0.4740,corrrect_unlabeled_num:397295.0,pro_above_threshold_num:405197.0,unlabelled_weak_top1_acc:93.8140858784318,unlabelled_weak_top5_acc:99.77417040616274  \n","[2022-04-23 10:14:36,044][experiments.experiment][INFO] - [EMA] Epoch 79. [Validation] raw_testing_loss: 0.2925, raw test Top1 acc:91.62, raw test Top5 acc: 99.84, ema_testing_loss: 0.2072, ema test Top1 acc:94.3, ema test Top5 acc: 99.94\n","[2022-04-23 10:14:36,139][experiments.experiment][INFO] - [Checkpoints] Epoch 79, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 10:14:36,146][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:22:11,860][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 80: use 455.82136726379395 seconds\n","--- Optimizer learning rate changed from 1.80e-02 to 1.77e-02 ---\n","[2022-04-23 10:22:11,967][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:22:13,318][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:22:13,319][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:22:14,757][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:22:14,759][experiments.experiment][INFO] - [EMA] Epoch 80.[Train] time:455.82136726379395 seconds, lr:0.0177, train_loss: 1.4076, unlabeled_losses_real_strong:0.4763,corrrect_unlabeled_num:397369.0,pro_above_threshold_num:405479.0,unlabelled_weak_top1_acc:93.83196038007736,unlabelled_weak_top5_acc:99.76566907763481  \n","[2022-04-23 10:22:14,760][experiments.experiment][INFO] - [EMA] Epoch 80. [Validation] raw_testing_loss: 0.2929, raw test Top1 acc:91.86, raw test Top5 acc: 99.82, ema_testing_loss: 0.2041, ema test Top1 acc:94.54, ema test Top5 acc: 99.94\n","[2022-04-23 10:22:14,762][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:29:50,267][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 81: use 455.60772013664246 seconds\n","--- Optimizer learning rate changed from 1.77e-02 to 1.74e-02 ---\n","[2022-04-23 10:29:50,370][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:29:51,819][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:29:51,820][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:29:53,291][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:29:53,292][experiments.experiment][INFO] - [EMA] Epoch 81.[Train] time:455.60772013664246 seconds, lr:0.0174, train_loss: 1.3976, unlabeled_losses_real_strong:0.4699,corrrect_unlabeled_num:398691.0,pro_above_threshold_num:406630.0,unlabelled_weak_top1_acc:93.95751848816872,unlabelled_weak_top5_acc:99.78201772272587  \n","[2022-04-23 10:29:53,295][experiments.experiment][INFO] - [EMA] Epoch 81. [Validation] raw_testing_loss: 0.3124, raw test Top1 acc:91.24, raw test Top5 acc: 99.74, ema_testing_loss: 0.2038, ema test Top1 acc:94.66, ema test Top5 acc: 99.92\n","[2022-04-23 10:29:53,395][experiments.experiment][INFO] - [Checkpoints] Epoch 81, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 10:29:53,397][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:37:26,871][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 82: use 453.57483530044556 seconds\n","--- Optimizer learning rate changed from 1.74e-02 to 1.72e-02 ---\n","[2022-04-23 10:37:26,972][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:37:28,379][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:37:28,379][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:37:29,794][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:37:29,796][experiments.experiment][INFO] - [EMA] Epoch 82.[Train] time:453.57483530044556 seconds, lr:0.0172, train_loss: 1.4060, unlabeled_losses_real_strong:0.4700,corrrect_unlabeled_num:398590.0,pro_above_threshold_num:406673.0,unlabelled_weak_top1_acc:93.92721889168024,unlabelled_weak_top5_acc:99.78049194067717  \n","[2022-04-23 10:37:29,797][experiments.experiment][INFO] - [EMA] Epoch 82. [Validation] raw_testing_loss: 0.3425, raw test Top1 acc:90.58, raw test Top5 acc: 99.6, ema_testing_loss: 0.1978, ema test Top1 acc:94.76, ema test Top5 acc: 99.88\n","[2022-04-23 10:37:29,799][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:44:59,868][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 83: use 450.17977809906006 seconds\n","--- Optimizer learning rate changed from 1.72e-02 to 1.69e-02 ---\n","[2022-04-23 10:44:59,979][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:45:01,331][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:45:01,331][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:45:02,665][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:45:02,667][experiments.experiment][INFO] - [EMA] Epoch 83.[Train] time:450.17977809906006 seconds, lr:0.0169, train_loss: 1.4007, unlabeled_losses_real_strong:0.4678,corrrect_unlabeled_num:399152.0,pro_above_threshold_num:407219.0,unlabelled_weak_top1_acc:93.97059736400843,unlabelled_weak_top5_acc:99.80294410139322  \n","[2022-04-23 10:45:02,669][experiments.experiment][INFO] - [EMA] Epoch 83. [Validation] raw_testing_loss: 0.3345, raw test Top1 acc:90.42, raw test Top5 acc: 99.74, ema_testing_loss: 0.1990, ema test Top1 acc:94.5, ema test Top5 acc: 99.9\n","[2022-04-23 10:45:02,765][experiments.experiment][INFO] - [Checkpoints] Epoch 83, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 10:45:02,773][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:52:34,177][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 84: use 451.50206685066223 seconds\n","--- Optimizer learning rate changed from 1.69e-02 to 1.66e-02 ---\n","[2022-04-23 10:52:34,276][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:52:35,619][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:52:35,620][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:52:36,944][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:52:36,946][experiments.experiment][INFO] - [EMA] Epoch 84.[Train] time:451.50206685066223 seconds, lr:0.0166, train_loss: 1.3945, unlabeled_losses_real_strong:0.4635,corrrect_unlabeled_num:400060.0,pro_above_threshold_num:408252.0,unlabelled_weak_top1_acc:94.02923476696014,unlabelled_weak_top5_acc:99.78877529501915  \n","[2022-04-23 10:52:36,948][experiments.experiment][INFO] - [EMA] Epoch 84. [Validation] raw_testing_loss: 0.3161, raw test Top1 acc:90.44, raw test Top5 acc: 99.58, ema_testing_loss: 0.1994, ema test Top1 acc:94.38, ema test Top5 acc: 99.94\n","[2022-04-23 10:52:36,949][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:00:06,599][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 85: use 449.7719314098358 seconds\n","--- Optimizer learning rate changed from 1.66e-02 to 1.63e-02 ---\n","[2022-04-23 11:00:06,721][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:00:08,095][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:00:08,095][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:00:09,474][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:00:09,476][experiments.experiment][INFO] - [EMA] Epoch 85.[Train] time:449.7719314098358 seconds, lr:0.0163, train_loss: 1.3751, unlabeled_losses_real_strong:0.4622,corrrect_unlabeled_num:400277.0,pro_above_threshold_num:408283.0,unlabelled_weak_top1_acc:94.06258612126112,unlabelled_weak_top5_acc:99.78768533468246  \n","[2022-04-23 11:00:09,478][experiments.experiment][INFO] - [EMA] Epoch 85. [Validation] raw_testing_loss: 0.3074, raw test Top1 acc:91.1, raw test Top5 acc: 99.68, ema_testing_loss: 0.1996, ema test Top1 acc:94.48, ema test Top5 acc: 99.88\n","[2022-04-23 11:00:09,574][experiments.experiment][INFO] - [Checkpoints] Epoch 85, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 11:00:09,583][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:07:38,779][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 86: use 449.2963571548462 seconds\n","--- Optimizer learning rate changed from 1.63e-02 to 1.60e-02 ---\n","[2022-04-23 11:07:38,879][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:07:40,246][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:07:40,247][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:07:41,602][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:07:41,604][experiments.experiment][INFO] - [EMA] Epoch 86.[Train] time:449.2963571548462 seconds, lr:0.0160, train_loss: 1.3850, unlabeled_losses_real_strong:0.4582,corrrect_unlabeled_num:400551.0,pro_above_threshold_num:408560.0,unlabelled_weak_top1_acc:94.10661859810352,unlabelled_weak_top5_acc:99.79705855250359  \n","[2022-04-23 11:07:41,606][experiments.experiment][INFO] - [EMA] Epoch 86. [Validation] raw_testing_loss: 0.3020, raw test Top1 acc:91.74, raw test Top5 acc: 99.82, ema_testing_loss: 0.2003, ema test Top1 acc:94.46, ema test Top5 acc: 99.88\n","[2022-04-23 11:07:41,607][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:15:11,011][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 87: use 449.5095992088318 seconds\n","--- Optimizer learning rate changed from 1.60e-02 to 1.57e-02 ---\n","[2022-04-23 11:15:11,117][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:15:12,507][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:15:12,507][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:15:13,878][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:15:13,880][experiments.experiment][INFO] - [EMA] Epoch 87.[Train] time:449.5095992088318 seconds, lr:0.0157, train_loss: 1.3691, unlabeled_losses_real_strong:0.4559,corrrect_unlabeled_num:401078.0,pro_above_threshold_num:409007.0,unlabelled_weak_top1_acc:94.20056911557913,unlabelled_weak_top5_acc:99.78768533468246  \n","[2022-04-23 11:15:13,882][experiments.experiment][INFO] - [EMA] Epoch 87. [Validation] raw_testing_loss: 0.3125, raw test Top1 acc:91.68, raw test Top5 acc: 99.6, ema_testing_loss: 0.1944, ema test Top1 acc:94.62, ema test Top5 acc: 99.9\n","[2022-04-23 11:15:13,982][experiments.experiment][INFO] - [Checkpoints] Epoch 87, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 11:15:13,991][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:22:42,756][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 88: use 448.8688151836395 seconds\n","--- Optimizer learning rate changed from 1.57e-02 to 1.54e-02 ---\n","[2022-04-23 11:22:42,860][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:22:44,178][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:22:44,179][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:22:45,522][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:22:45,523][experiments.experiment][INFO] - [EMA] Epoch 88.[Train] time:448.8688151836395 seconds, lr:0.0154, train_loss: 1.3661, unlabeled_losses_real_strong:0.4522,corrrect_unlabeled_num:402156.0,pro_above_threshold_num:410075.0,unlabelled_weak_top1_acc:94.23108675330877,unlabelled_weak_top5_acc:99.7929169088602  \n","[2022-04-23 11:22:45,526][experiments.experiment][INFO] - [EMA] Epoch 88. [Validation] raw_testing_loss: 0.3341, raw test Top1 acc:90.52, raw test Top5 acc: 99.7, ema_testing_loss: 0.1928, ema test Top1 acc:94.72, ema test Top5 acc: 99.92\n","[2022-04-23 11:22:45,526][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:30:12,866][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 89: use 447.45018196105957 seconds\n","--- Optimizer learning rate changed from 1.54e-02 to 1.51e-02 ---\n","[2022-04-23 11:30:12,977][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:30:14,287][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:30:14,288][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:30:15,645][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:30:15,647][experiments.experiment][INFO] - [EMA] Epoch 89.[Train] time:447.45018196105957 seconds, lr:0.0151, train_loss: 1.3608, unlabeled_losses_real_strong:0.4528,corrrect_unlabeled_num:401893.0,pro_above_threshold_num:409800.0,unlabelled_weak_top1_acc:94.24699956923723,unlabelled_weak_top5_acc:99.78310778737068  \n","[2022-04-23 11:30:15,649][experiments.experiment][INFO] - [EMA] Epoch 89. [Validation] raw_testing_loss: 0.3647, raw test Top1 acc:90.54, raw test Top5 acc: 99.72, ema_testing_loss: 0.1914, ema test Top1 acc:94.74, ema test Top5 acc: 99.96\n","[2022-04-23 11:30:15,743][experiments.experiment][INFO] - [Checkpoints] Epoch 89, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 11:30:15,745][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:37:41,918][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 90: use 446.27424907684326 seconds\n","--- Optimizer learning rate changed from 1.51e-02 to 1.48e-02 ---\n","[2022-04-23 11:37:42,019][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:37:43,400][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:37:43,401][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:37:44,733][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:37:44,735][experiments.experiment][INFO] - [EMA] Epoch 90.[Train] time:446.27424907684326 seconds, lr:0.0148, train_loss: 1.3467, unlabeled_losses_real_strong:0.4482,corrrect_unlabeled_num:402214.0,pro_above_threshold_num:410332.0,unlabelled_weak_top1_acc:94.20907047390938,unlabelled_weak_top5_acc:99.79117307811975  \n","[2022-04-23 11:37:44,737][experiments.experiment][INFO] - [EMA] Epoch 90. [Validation] raw_testing_loss: 0.2370, raw test Top1 acc:93.0, raw test Top5 acc: 99.84, ema_testing_loss: 0.1987, ema test Top1 acc:94.56, ema test Top5 acc: 99.94\n","[2022-04-23 11:37:44,737][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:45:13,056][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 91: use 448.4186429977417 seconds\n","--- Optimizer learning rate changed from 1.48e-02 to 1.45e-02 ---\n","[2022-04-23 11:45:13,156][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:45:14,483][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:45:14,484][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:45:15,847][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:45:15,848][experiments.experiment][INFO] - [EMA] Epoch 91.[Train] time:448.4186429977417 seconds, lr:0.0145, train_loss: 1.3488, unlabeled_losses_real_strong:0.4446,corrrect_unlabeled_num:403295.0,pro_above_threshold_num:411273.0,unlabelled_weak_top1_acc:94.36362025141716,unlabelled_weak_top5_acc:99.79553268104792  \n","[2022-04-23 11:45:15,850][experiments.experiment][INFO] - [EMA] Epoch 91. [Validation] raw_testing_loss: 0.2481, raw test Top1 acc:92.2, raw test Top5 acc: 99.82, ema_testing_loss: 0.1971, ema test Top1 acc:94.58, ema test Top5 acc: 99.92\n","[2022-04-23 11:45:15,948][experiments.experiment][INFO] - [Checkpoints] Epoch 91, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 11:45:15,958][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:52:44,881][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 92: use 449.0272614955902 seconds\n","--- Optimizer learning rate changed from 1.45e-02 to 1.42e-02 ---\n","[2022-04-23 11:52:44,985][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:52:46,324][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:52:46,324][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:52:47,659][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:52:47,661][experiments.experiment][INFO] - [EMA] Epoch 92.[Train] time:449.0272614955902 seconds, lr:0.0142, train_loss: 1.3344, unlabeled_losses_real_strong:0.4430,corrrect_unlabeled_num:403391.0,pro_above_threshold_num:411328.0,unlabelled_weak_top1_acc:94.39043214917183,unlabelled_weak_top5_acc:99.8064318522811  \n","[2022-04-23 11:52:47,662][experiments.experiment][INFO] - [EMA] Epoch 92. [Validation] raw_testing_loss: 0.2572, raw test Top1 acc:92.72, raw test Top5 acc: 99.84, ema_testing_loss: 0.1937, ema test Top1 acc:94.8, ema test Top5 acc: 99.9\n","[2022-04-23 11:52:47,663][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:00:17,044][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 93: use 449.48292326927185 seconds\n","--- Optimizer learning rate changed from 1.42e-02 to 1.39e-02 ---\n","[2022-04-23 12:00:17,146][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:00:18,534][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:00:18,535][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:00:19,899][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:00:19,901][experiments.experiment][INFO] - [EMA] Epoch 93.[Train] time:449.48292326927185 seconds, lr:0.0139, train_loss: 1.3365, unlabeled_losses_real_strong:0.4402,corrrect_unlabeled_num:404302.0,pro_above_threshold_num:412280.0,unlabelled_weak_top1_acc:94.41005046665668,unlabelled_weak_top5_acc:99.810791477561  \n","[2022-04-23 12:00:19,904][experiments.experiment][INFO] - [EMA] Epoch 93. [Validation] raw_testing_loss: 0.2703, raw test Top1 acc:92.14, raw test Top5 acc: 99.8, ema_testing_loss: 0.1924, ema test Top1 acc:94.94, ema test Top5 acc: 99.9\n","[2022-04-23 12:00:20,000][experiments.experiment][INFO] - [Checkpoints] Epoch 93, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 12:00:20,005][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:07:48,211][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 94: use 448.3037679195404 seconds\n","--- Optimizer learning rate changed from 1.39e-02 to 1.36e-02 ---\n","[2022-04-23 12:07:48,309][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:07:49,700][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:07:49,701][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:07:51,021][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:07:51,023][experiments.experiment][INFO] - [EMA] Epoch 94.[Train] time:448.3037679195404 seconds, lr:0.0136, train_loss: 1.3292, unlabeled_losses_real_strong:0.4358,corrrect_unlabeled_num:404109.0,pro_above_threshold_num:411906.0,unlabelled_weak_top1_acc:94.4471076503396,unlabelled_weak_top5_acc:99.80730383098125  \n","[2022-04-23 12:07:51,025][experiments.experiment][INFO] - [EMA] Epoch 94. [Validation] raw_testing_loss: 0.2854, raw test Top1 acc:92.0, raw test Top5 acc: 99.78, ema_testing_loss: 0.1918, ema test Top1 acc:95.0, ema test Top5 acc: 99.9\n","[2022-04-23 12:07:51,025][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:15:19,895][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 95: use 448.9701201915741 seconds\n","--- Optimizer learning rate changed from 1.36e-02 to 1.33e-02 ---\n","[2022-04-23 12:15:19,996][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:15:21,368][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:15:21,369][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:15:22,726][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:15:22,727][experiments.experiment][INFO] - [EMA] Epoch 95.[Train] time:448.9701201915741 seconds, lr:0.0133, train_loss: 1.3212, unlabeled_losses_real_strong:0.4368,corrrect_unlabeled_num:404636.0,pro_above_threshold_num:412776.0,unlabelled_weak_top1_acc:94.43969622254372,unlabelled_weak_top5_acc:99.80381605774164  \n","[2022-04-23 12:15:22,729][experiments.experiment][INFO] - [EMA] Epoch 95. [Validation] raw_testing_loss: 0.2432, raw test Top1 acc:93.02, raw test Top5 acc: 99.8, ema_testing_loss: 0.1918, ema test Top1 acc:94.78, ema test Top5 acc: 99.9\n","[2022-04-23 12:15:22,833][experiments.experiment][INFO] - [Checkpoints] Epoch 95, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 12:15:22,835][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:22:51,260][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 96: use 448.52686309814453 seconds\n","--- Optimizer learning rate changed from 1.33e-02 to 1.30e-02 ---\n","[2022-04-23 12:22:51,362][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:22:52,820][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:22:52,820][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:22:54,169][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:22:54,170][experiments.experiment][INFO] - [EMA] Epoch 96.[Train] time:448.52686309814453 seconds, lr:0.0130, train_loss: 1.3106, unlabeled_losses_real_strong:0.4311,corrrect_unlabeled_num:405501.0,pro_above_threshold_num:413452.0,unlabelled_weak_top1_acc:94.49615366011858,unlabelled_weak_top5_acc:99.80643188208342  \n","[2022-04-23 12:22:54,172][experiments.experiment][INFO] - [EMA] Epoch 96. [Validation] raw_testing_loss: 0.2737, raw test Top1 acc:92.52, raw test Top5 acc: 99.8, ema_testing_loss: 0.1883, ema test Top1 acc:94.92, ema test Top5 acc: 99.88\n","[2022-04-23 12:22:54,174][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:30:22,047][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 97: use 447.9739463329315 seconds\n","--- Optimizer learning rate changed from 1.30e-02 to 1.27e-02 ---\n","[2022-04-23 12:30:22,148][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:30:23,484][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:30:23,485][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:30:24,826][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:30:24,827][experiments.experiment][INFO] - [EMA] Epoch 97.[Train] time:447.9739463329315 seconds, lr:0.0127, train_loss: 1.3080, unlabeled_losses_real_strong:0.4313,corrrect_unlabeled_num:405841.0,pro_above_threshold_num:413834.0,unlabelled_weak_top1_acc:94.55195727199316,unlabelled_weak_top5_acc:99.81122748553753  \n","[2022-04-23 12:30:24,829][experiments.experiment][INFO] - [EMA] Epoch 97. [Validation] raw_testing_loss: 0.2389, raw test Top1 acc:92.64, raw test Top5 acc: 99.82, ema_testing_loss: 0.1876, ema test Top1 acc:95.08, ema test Top5 acc: 99.9\n","[2022-04-23 12:30:24,932][experiments.experiment][INFO] - [Checkpoints] Epoch 97, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 12:30:24,934][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:37:55,011][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 98: use 450.18039298057556 seconds\n","--- Optimizer learning rate changed from 1.27e-02 to 1.24e-02 ---\n","[2022-04-23 12:37:55,114][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:37:56,474][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:37:56,474][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:37:57,852][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:37:57,854][experiments.experiment][INFO] - [EMA] Epoch 98.[Train] time:450.18039298057556 seconds, lr:0.0124, train_loss: 1.2983, unlabeled_losses_real_strong:0.4255,corrrect_unlabeled_num:406273.0,pro_above_threshold_num:414102.0,unlabelled_weak_top1_acc:94.62214777618647,unlabelled_weak_top5_acc:99.8179849460721  \n","[2022-04-23 12:37:57,855][experiments.experiment][INFO] - [EMA] Epoch 98. [Validation] raw_testing_loss: 0.2622, raw test Top1 acc:92.46, raw test Top5 acc: 99.84, ema_testing_loss: 0.1826, ema test Top1 acc:94.94, ema test Top5 acc: 99.92\n","[2022-04-23 12:37:57,856][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:45:24,655][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 99: use 446.904748916626 seconds\n","--- Optimizer learning rate changed from 1.24e-02 to 1.21e-02 ---\n","[2022-04-23 12:45:24,761][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:45:26,145][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:45:26,146][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:45:27,488][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:45:27,489][experiments.experiment][INFO] - [EMA] Epoch 99.[Train] time:446.904748916626 seconds, lr:0.0121, train_loss: 1.2882, unlabeled_losses_real_strong:0.4225,corrrect_unlabeled_num:407054.0,pro_above_threshold_num:415055.0,unlabelled_weak_top1_acc:94.62672530114651,unlabelled_weak_top5_acc:99.81362526863813  \n","[2022-04-23 12:45:27,491][experiments.experiment][INFO] - [EMA] Epoch 99. [Validation] raw_testing_loss: 0.2243, raw test Top1 acc:93.3, raw test Top5 acc: 99.94, ema_testing_loss: 0.1854, ema test Top1 acc:94.78, ema test Top5 acc: 99.94\n","[2022-04-23 12:45:27,601][experiments.experiment][INFO] - [Checkpoints] Epoch 99, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 12:45:27,608][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:52:55,017][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 100: use 447.5091242790222 seconds\n","--- Optimizer learning rate changed from 1.21e-02 to 1.18e-02 ---\n","[2022-04-23 12:52:55,117][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:52:56,458][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:52:56,459][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:52:57,775][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:52:57,777][experiments.experiment][INFO] - [EMA] Epoch 100.[Train] time:447.5091242790222 seconds, lr:0.0118, train_loss: 1.2865, unlabeled_losses_real_strong:0.4205,corrrect_unlabeled_num:407492.0,pro_above_threshold_num:415336.0,unlabelled_weak_top1_acc:94.70541699975729,unlabelled_weak_top5_acc:99.81209936738014  \n","[2022-04-23 12:52:57,779][experiments.experiment][INFO] - [EMA] Epoch 100. [Validation] raw_testing_loss: 0.3152, raw test Top1 acc:91.8, raw test Top5 acc: 99.68, ema_testing_loss: 0.1863, ema test Top1 acc:94.84, ema test Top5 acc: 99.96\n","[2022-04-23 12:52:57,780][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:00:24,498][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 101: use 446.81502318382263 seconds\n","--- Optimizer learning rate changed from 1.18e-02 to 1.14e-02 ---\n","[2022-04-23 13:00:24,595][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:00:25,972][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:00:25,973][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:00:27,333][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:00:27,334][experiments.experiment][INFO] - [EMA] Epoch 101.[Train] time:446.81502318382263 seconds, lr:0.0114, train_loss: 1.2783, unlabeled_losses_real_strong:0.4169,corrrect_unlabeled_num:407912.0,pro_above_threshold_num:416008.0,unlabelled_weak_top1_acc:94.71064856648445,unlabelled_weak_top5_acc:99.81929286569357  \n","[2022-04-23 13:00:27,337][experiments.experiment][INFO] - [EMA] Epoch 101. [Validation] raw_testing_loss: 0.2479, raw test Top1 acc:92.76, raw test Top5 acc: 99.72, ema_testing_loss: 0.1894, ema test Top1 acc:95.0, ema test Top5 acc: 99.92\n","[2022-04-23 13:00:27,433][experiments.experiment][INFO] - [Checkpoints] Epoch 101, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 13:00:27,434][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:07:55,063][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 102: use 447.72996258735657 seconds\n","--- Optimizer learning rate changed from 1.14e-02 to 1.11e-02 ---\n","[2022-04-23 13:07:55,164][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:07:56,503][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:07:56,504][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:07:57,878][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:07:57,879][experiments.experiment][INFO] - [EMA] Epoch 102.[Train] time:447.72996258735657 seconds, lr:0.0111, train_loss: 1.2705, unlabeled_losses_real_strong:0.4172,corrrect_unlabeled_num:407873.0,pro_above_threshold_num:415841.0,unlabelled_weak_top1_acc:94.7250354513526,unlabelled_weak_top5_acc:99.82496033608913  \n","[2022-04-23 13:07:57,882][experiments.experiment][INFO] - [EMA] Epoch 102. [Validation] raw_testing_loss: 0.2837, raw test Top1 acc:92.26, raw test Top5 acc: 99.74, ema_testing_loss: 0.1859, ema test Top1 acc:94.76, ema test Top5 acc: 99.92\n","[2022-04-23 13:07:57,882][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:15:25,390][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 103: use 447.6065535545349 seconds\n","--- Optimizer learning rate changed from 1.11e-02 to 1.08e-02 ---\n","[2022-04-23 13:15:25,489][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:15:26,810][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:15:26,811][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:15:28,177][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:15:28,178][experiments.experiment][INFO] - [EMA] Epoch 103.[Train] time:447.6065535545349 seconds, lr:0.0108, train_loss: 1.2607, unlabeled_losses_real_strong:0.4113,corrrect_unlabeled_num:408910.0,pro_above_threshold_num:416804.0,unlabelled_weak_top1_acc:94.83250104635954,unlabelled_weak_top5_acc:99.81929287314415  \n","[2022-04-23 13:15:28,180][experiments.experiment][INFO] - [EMA] Epoch 103. [Validation] raw_testing_loss: 0.2569, raw test Top1 acc:92.46, raw test Top5 acc: 99.82, ema_testing_loss: 0.1809, ema test Top1 acc:94.82, ema test Top5 acc: 99.88\n","[2022-04-23 13:15:28,282][experiments.experiment][INFO] - [Checkpoints] Epoch 103, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 13:15:28,293][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:22:56,921][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 104: use 448.7288146018982 seconds\n","--- Optimizer learning rate changed from 1.08e-02 to 1.05e-02 ---\n","[2022-04-23 13:22:57,022][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:22:58,365][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:22:58,365][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:22:59,702][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:22:59,703][experiments.experiment][INFO] - [EMA] Epoch 104.[Train] time:448.7288146018982 seconds, lr:0.0105, train_loss: 1.2523, unlabeled_losses_real_strong:0.4084,corrrect_unlabeled_num:409830.0,pro_above_threshold_num:417742.0,unlabelled_weak_top1_acc:94.845144033432,unlabelled_weak_top5_acc:99.82975600659847  \n","[2022-04-23 13:22:59,706][experiments.experiment][INFO] - [EMA] Epoch 104. [Validation] raw_testing_loss: 0.2297, raw test Top1 acc:93.3, raw test Top5 acc: 99.86, ema_testing_loss: 0.1781, ema test Top1 acc:95.04, ema test Top5 acc: 99.9\n","[2022-04-23 13:22:59,707][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:30:27,913][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 105: use 448.31692719459534 seconds\n","--- Optimizer learning rate changed from 1.05e-02 to 1.02e-02 ---\n","[2022-04-23 13:30:28,024][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:30:29,350][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:30:29,351][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:30:30,663][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:30:30,665][experiments.experiment][INFO] - [EMA] Epoch 105.[Train] time:448.31692719459534 seconds, lr:0.0102, train_loss: 1.2454, unlabeled_losses_real_strong:0.4059,corrrect_unlabeled_num:410044.0,pro_above_threshold_num:417864.0,unlabelled_weak_top1_acc:94.86672428250313,unlabelled_weak_top5_acc:99.83411566913128  \n","[2022-04-23 13:30:30,667][experiments.experiment][INFO] - [EMA] Epoch 105. [Validation] raw_testing_loss: 0.2502, raw test Top1 acc:93.04, raw test Top5 acc: 99.64, ema_testing_loss: 0.1752, ema test Top1 acc:95.08, ema test Top5 acc: 99.92\n","[2022-04-23 13:30:30,772][experiments.experiment][INFO] - [Checkpoints] Epoch 105, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 13:30:30,781][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:38:08,483][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 106: use 457.8102011680603 seconds\n","--- Optimizer learning rate changed from 1.02e-02 to 9.83e-03 ---\n","[2022-04-23 13:38:08,591][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:38:09,990][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:38:09,991][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:38:11,428][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:38:11,429][experiments.experiment][INFO] - [EMA] Epoch 106.[Train] time:457.8102011680603 seconds, lr:0.0098, train_loss: 1.2304, unlabeled_losses_real_strong:0.4007,corrrect_unlabeled_num:410675.0,pro_above_threshold_num:418646.0,unlabelled_weak_top1_acc:94.9210019633174,unlabelled_weak_top5_acc:99.82496039569378  \n","[2022-04-23 13:38:11,432][experiments.experiment][INFO] - [EMA] Epoch 106. [Validation] raw_testing_loss: 0.2406, raw test Top1 acc:93.38, raw test Top5 acc: 99.82, ema_testing_loss: 0.1762, ema test Top1 acc:95.1, ema test Top5 acc: 99.92\n","[2022-04-23 13:38:11,433][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:45:49,165][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 107: use 457.8410050868988 seconds\n","--- Optimizer learning rate changed from 9.83e-03 to 9.50e-03 ---\n","[2022-04-23 13:45:49,274][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:45:50,684][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:45:50,685][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:45:52,066][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:45:52,067][experiments.experiment][INFO] - [EMA] Epoch 107.[Train] time:457.8410050868988 seconds, lr:0.0095, train_loss: 1.2165, unlabeled_losses_real_strong:0.3986,corrrect_unlabeled_num:410974.0,pro_above_threshold_num:418887.0,unlabelled_weak_top1_acc:94.96852224320173,unlabelled_weak_top5_acc:99.82757615298033  \n","[2022-04-23 13:45:52,068][experiments.experiment][INFO] - [EMA] Epoch 107. [Validation] raw_testing_loss: 0.2716, raw test Top1 acc:92.4, raw test Top5 acc: 99.76, ema_testing_loss: 0.1745, ema test Top1 acc:95.1, ema test Top5 acc: 99.86\n","[2022-04-23 13:45:52,180][experiments.experiment][INFO] - [Checkpoints] Epoch 107, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 13:45:52,182][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:53:27,753][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 108: use 455.6730308532715 seconds\n","--- Optimizer learning rate changed from 9.50e-03 to 9.18e-03 ---\n","[2022-04-23 13:53:27,855][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:53:29,256][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:53:29,257][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:53:30,634][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:53:30,636][experiments.experiment][INFO] - [EMA] Epoch 108.[Train] time:455.6730308532715 seconds, lr:0.0092, train_loss: 1.2147, unlabeled_losses_real_strong:0.3952,corrrect_unlabeled_num:411594.0,pro_above_threshold_num:419399.0,unlabelled_weak_top1_acc:95.03653287142515,unlabelled_weak_top5_acc:99.82430639117956  \n","[2022-04-23 13:53:30,638][experiments.experiment][INFO] - [EMA] Epoch 108. [Validation] raw_testing_loss: 0.2397, raw test Top1 acc:93.04, raw test Top5 acc: 99.82, ema_testing_loss: 0.1743, ema test Top1 acc:95.34, ema test Top5 acc: 99.92\n","[2022-04-23 13:53:30,639][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 14:01:10,119][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 109: use 459.59436440467834 seconds\n","--- Optimizer learning rate changed from 9.18e-03 to 8.85e-03 ---\n","[2022-04-23 14:01:10,234][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:01:11,699][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 14:01:11,700][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:01:13,069][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 14:01:13,070][experiments.experiment][INFO] - [EMA] Epoch 109.[Train] time:459.59436440467834 seconds, lr:0.0088, train_loss: 1.2040, unlabeled_losses_real_strong:0.3914,corrrect_unlabeled_num:412291.0,pro_above_threshold_num:420317.0,unlabelled_weak_top1_acc:95.06465256214142,unlabelled_weak_top5_acc:99.82735824584961  \n","[2022-04-23 14:01:13,072][experiments.experiment][INFO] - [EMA] Epoch 109. [Validation] raw_testing_loss: 0.2209, raw test Top1 acc:93.64, raw test Top5 acc: 99.8, ema_testing_loss: 0.1773, ema test Top1 acc:95.2, ema test Top5 acc: 99.9\n","[2022-04-23 14:01:13,172][experiments.experiment][INFO] - [Checkpoints] Epoch 109, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 14:01:13,174][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 14:08:44,272][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 110: use 451.19680523872375 seconds\n","--- Optimizer learning rate changed from 8.85e-03 to 8.52e-03 ---\n","[2022-04-23 14:08:44,371][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:08:45,697][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 14:08:45,697][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:08:47,095][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 14:08:47,096][experiments.experiment][INFO] - [EMA] Epoch 110.[Train] time:451.19680523872375 seconds, lr:0.0085, train_loss: 1.1870, unlabeled_losses_real_strong:0.3865,corrrect_unlabeled_num:412908.0,pro_above_threshold_num:420839.0,unlabelled_weak_top1_acc:95.08906658738852,unlabelled_weak_top5_acc:99.82779412716627  \n","[2022-04-23 14:08:47,098][experiments.experiment][INFO] - [EMA] Epoch 110. [Validation] raw_testing_loss: 0.2181, raw test Top1 acc:93.74, raw test Top5 acc: 99.82, ema_testing_loss: 0.1782, ema test Top1 acc:95.12, ema test Top5 acc: 99.9\n","[2022-04-23 14:08:47,099][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 14:16:15,406][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 111: use 448.4069359302521 seconds\n","--- Optimizer learning rate changed from 8.52e-03 to 8.19e-03 ---\n","[2022-04-23 14:16:15,506][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:16:16,921][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 14:16:16,921][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:16:18,265][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 14:16:18,267][experiments.experiment][INFO] - [EMA] Epoch 111.[Train] time:448.4069359302521 seconds, lr:0.0082, train_loss: 1.1860, unlabeled_losses_real_strong:0.3854,corrrect_unlabeled_num:413944.0,pro_above_threshold_num:421976.0,unlabelled_weak_top1_acc:95.15947509557009,unlabelled_weak_top5_acc:99.82801212370396  \n","[2022-04-23 14:16:18,269][experiments.experiment][INFO] - [EMA] Epoch 111. [Validation] raw_testing_loss: 0.2268, raw test Top1 acc:93.72, raw test Top5 acc: 99.74, ema_testing_loss: 0.1744, ema test Top1 acc:95.4, ema test Top5 acc: 99.88\n","[2022-04-23 14:16:18,368][experiments.experiment][INFO] - [Checkpoints] Epoch 111, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 14:16:18,369][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 14:23:48,821][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 112: use 450.5562252998352 seconds\n","--- Optimizer learning rate changed from 8.19e-03 to 7.86e-03 ---\n","[2022-04-23 14:23:48,926][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:23:50,307][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 14:23:50,307][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:23:51,695][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 14:23:51,697][experiments.experiment][INFO] - [EMA] Epoch 112.[Train] time:450.5562252998352 seconds, lr:0.0079, train_loss: 1.1709, unlabeled_losses_real_strong:0.3822,corrrect_unlabeled_num:414251.0,pro_above_threshold_num:422233.0,unlabelled_weak_top1_acc:95.17604172229767,unlabelled_weak_top5_acc:99.83346171677113  \n","[2022-04-23 14:23:51,699][experiments.experiment][INFO] - [EMA] Epoch 112. [Validation] raw_testing_loss: 0.2278, raw test Top1 acc:93.48, raw test Top5 acc: 99.84, ema_testing_loss: 0.1754, ema test Top1 acc:95.3, ema test Top5 acc: 99.9\n","[2022-04-23 14:23:51,700][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 14:31:20,434][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 113: use 448.8405272960663 seconds\n","--- Optimizer learning rate changed from 7.86e-03 to 7.53e-03 ---\n","[2022-04-23 14:31:20,541][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:31:21,943][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 14:31:21,943][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:31:23,334][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 14:31:23,336][experiments.experiment][INFO] - [EMA] Epoch 113.[Train] time:448.8405272960663 seconds, lr:0.0075, train_loss: 1.1564, unlabeled_losses_real_strong:0.3804,corrrect_unlabeled_num:414711.0,pro_above_threshold_num:422779.0,unlabelled_weak_top1_acc:95.23140936344862,unlabelled_weak_top5_acc:99.83585945516825  \n","[2022-04-23 14:31:23,338][experiments.experiment][INFO] - [EMA] Epoch 113. [Validation] raw_testing_loss: 0.2352, raw test Top1 acc:93.14, raw test Top5 acc: 99.8, ema_testing_loss: 0.1735, ema test Top1 acc:95.32, ema test Top5 acc: 99.9\n","[2022-04-23 14:31:23,439][experiments.experiment][INFO] - [Checkpoints] Epoch 113, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 14:31:23,450][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 14:38:59,638][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 114: use 456.2904574871063 seconds\n","--- Optimizer learning rate changed from 7.53e-03 to 7.19e-03 ---\n","[2022-04-23 14:38:59,740][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:39:01,113][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 14:39:01,113][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:39:02,519][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 14:39:02,520][experiments.experiment][INFO] - [EMA] Epoch 114.[Train] time:456.2904574871063 seconds, lr:0.0072, train_loss: 1.1545, unlabeled_losses_real_strong:0.3755,corrrect_unlabeled_num:415513.0,pro_above_threshold_num:423699.0,unlabelled_weak_top1_acc:95.24884786456823,unlabelled_weak_top5_acc:99.8286661207676  \n","[2022-04-23 14:39:02,523][experiments.experiment][INFO] - [EMA] Epoch 114. [Validation] raw_testing_loss: 0.2300, raw test Top1 acc:93.28, raw test Top5 acc: 99.9, ema_testing_loss: 0.1758, ema test Top1 acc:95.32, ema test Top5 acc: 99.9\n","[2022-04-23 14:39:02,524][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 14:46:37,395][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 115: use 454.9762797355652 seconds\n","--- Optimizer learning rate changed from 7.19e-03 to 6.86e-03 ---\n","[2022-04-23 14:46:37,500][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:46:38,857][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 14:46:38,858][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:46:40,240][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 14:46:40,241][experiments.experiment][INFO] - [EMA] Epoch 115.[Train] time:454.9762797355652 seconds, lr:0.0069, train_loss: 1.1323, unlabeled_losses_real_strong:0.3715,corrrect_unlabeled_num:415909.0,pro_above_threshold_num:424036.0,unlabelled_weak_top1_acc:95.30159981548786,unlabelled_weak_top5_acc:99.84065519273281  \n","[2022-04-23 14:46:40,244][experiments.experiment][INFO] - [EMA] Epoch 115. [Validation] raw_testing_loss: 0.2227, raw test Top1 acc:93.74, raw test Top5 acc: 99.88, ema_testing_loss: 0.1756, ema test Top1 acc:95.26, ema test Top5 acc: 99.86\n","[2022-04-23 14:46:40,361][experiments.experiment][INFO] - [Checkpoints] Epoch 115, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 14:46:40,361][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 14:54:16,693][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 116: use 456.4343421459198 seconds\n","--- Optimizer learning rate changed from 6.86e-03 to 6.53e-03 ---\n","[2022-04-23 14:54:16,796][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:54:18,167][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 14:54:18,168][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 14:54:19,566][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 14:54:19,568][experiments.experiment][INFO] - [EMA] Epoch 116.[Train] time:456.4343421459198 seconds, lr:0.0065, train_loss: 1.1206, unlabeled_losses_real_strong:0.3672,corrrect_unlabeled_num:416331.0,pro_above_threshold_num:424512.0,unlabelled_weak_top1_acc:95.308793194592,unlabelled_weak_top5_acc:99.82910209149122  \n","[2022-04-23 14:54:19,571][experiments.experiment][INFO] - [EMA] Epoch 116. [Validation] raw_testing_loss: 0.2159, raw test Top1 acc:93.56, raw test Top5 acc: 99.78, ema_testing_loss: 0.1709, ema test Top1 acc:95.26, ema test Top5 acc: 99.9\n","[2022-04-23 14:54:19,571][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 15:01:55,534][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 117: use 456.0703694820404 seconds\n","--- Optimizer learning rate changed from 6.53e-03 to 6.19e-03 ---\n","[2022-04-23 15:01:55,642][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 15:01:57,144][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 15:01:57,144][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 15:01:58,545][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 15:01:58,547][experiments.experiment][INFO] - [EMA] Epoch 117.[Train] time:456.0703694820404 seconds, lr:0.0062, train_loss: 1.1002, unlabeled_losses_real_strong:0.3658,corrrect_unlabeled_num:416642.0,pro_above_threshold_num:424923.0,unlabelled_weak_top1_acc:95.29222650825977,unlabelled_weak_top5_acc:99.82474242895842  \n","[2022-04-23 15:01:58,549][experiments.experiment][INFO] - [EMA] Epoch 117. [Validation] raw_testing_loss: 0.2123, raw test Top1 acc:94.04, raw test Top5 acc: 99.84, ema_testing_loss: 0.1709, ema test Top1 acc:95.24, ema test Top5 acc: 99.88\n","[2022-04-23 15:01:58,652][experiments.experiment][INFO] - [Checkpoints] Epoch 117, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","[2022-04-23 15:01:58,663][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 15:09:34,245][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 118: use 455.69585275650024 seconds\n","--- Optimizer learning rate changed from 6.19e-03 to 5.85e-03 ---\n","[2022-04-23 15:09:34,359][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 15:09:35,816][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 15:09:35,816][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 15:09:37,226][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 15:09:37,228][experiments.experiment][INFO] - [EMA] Epoch 118.[Train] time:455.69585275650024 seconds, lr:0.0059, train_loss: 1.0919, unlabeled_losses_real_strong:0.3625,corrrect_unlabeled_num:417218.0,pro_above_threshold_num:425630.0,unlabelled_weak_top1_acc:95.35631345957518,unlabelled_weak_top5_acc:99.84000118076801  \n","[2022-04-23 15:09:37,230][experiments.experiment][INFO] - [EMA] Epoch 118. [Validation] raw_testing_loss: 0.2111, raw test Top1 acc:93.96, raw test Top5 acc: 99.92, ema_testing_loss: 0.1732, ema test Top1 acc:95.26, ema test Top5 acc: 99.88\n","[2022-04-23 15:09:37,231][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 15:17:12,428][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 119: use 455.30011773109436 seconds\n","--- Optimizer learning rate changed from 5.85e-03 to 5.52e-03 ---\n","[2022-04-23 15:17:12,531][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 15:17:13,914][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 15:17:13,915][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 15:17:15,391][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 15:17:15,392][experiments.experiment][INFO] - [EMA] Epoch 119.[Train] time:455.30011773109436 seconds, lr:0.0055, train_loss: 1.0862, unlabeled_losses_real_strong:0.3573,corrrect_unlabeled_num:418100.0,pro_above_threshold_num:426381.0,unlabelled_weak_top1_acc:95.43304339796305,unlabelled_weak_top5_acc:99.83302573859692  \n","[2022-04-23 15:17:15,396][experiments.experiment][INFO] - [EMA] Epoch 119. [Validation] raw_testing_loss: 0.2005, raw test Top1 acc:94.34, raw test Top5 acc: 99.8, ema_testing_loss: 0.1704, ema test Top1 acc:95.24, ema test Top5 acc: 99.9\n","[2022-04-23 15:17:15,494][experiments.experiment][INFO] - [Checkpoints] Epoch 119, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_6/FMExperiment.pth.tar\n","======= Training done =======\n","2022-04-23 15:17:15,521 - INFO - Train -   ======= Training done =======\n","[2022-04-23 15:17:15,521][Train][INFO] - ======= Training done =======\n","[2022-04-23 15:17:15,522][experiments.experiment][INFO] - Loading Testing Loader\n","[2022-04-23 15:17:15,533][experiments.experiment][INFO] - [Testing with EMA] apply shadow\n","[2022-04-23 15:17:15,536][experiments.experiment][INFO] - ***** Running testing *****\n","[2022-04-23 15:17:18,202][experiments.experiment][INFO] - [Testing(EMA)] testing_loss: 0.1746, test Top1 acc:94.91, test Top5 acc: 99.85\n","[2022-04-23 15:17:18,208][experiments.experiment][INFO] - [EMA] restore \n","======= Testing done =======\n","2022-04-23 15:17:18,208 - INFO - Train -   ======= Testing done =======\n","[2022-04-23 15:17:18,208][Train][INFO] - ======= Testing done =======\n"]}]}]}