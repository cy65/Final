{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"celiali-lambda7.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMUD9IP9pfIOdb9FaLv3WDX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"HB3AiiXKS2pD","executionInfo":{"status":"ok","timestamp":1650816078949,"user_tz":300,"elapsed":135099,"user":{"displayName":"CM Y","userId":"12660552299343911788"}},"outputId":"f0c4103e-33b0-4d60-b42b-c3cb7cfd3463"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/celiali\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 2)) (1.0.0)\n","Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 3)) (1.9)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 4)) (0.29.28)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 5)) (1.21.6)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 7)) (4.64.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 8)) (1.4.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 9)) (7.1.2)\n","Collecting torch==1.8.0\n","  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n","\u001b[K     |████████████████████████████████| 735.5 MB 15 kB/s \n","\u001b[?25hCollecting torchvision==0.9.0\n","  Downloading torchvision-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n","\u001b[K     |████████████████████████████████| 17.3 MB 50.7 MB/s \n","\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 12)) (0.10.0+cu111)\n","Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 13)) (0.11.0)\n","Collecting omegaconf\n","  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\n","\u001b[K     |████████████████████████████████| 74 kB 4.3 MB/s \n","\u001b[?25hCollecting hydra\n","  Downloading Hydra-2.5.tar.gz (82 kB)\n","\u001b[K     |████████████████████████████████| 82 kB 306 kB/s \n","\u001b[?25hCollecting hydra-core\n","  Downloading hydra_core-1.1.2-py3-none-any.whl (147 kB)\n","\u001b[K     |████████████████████████████████| 147 kB 71.0 MB/s \n","\u001b[?25hCollecting ignite\n","  Downloading ignite-1.1.0-py2.py3-none-any.whl (4.5 kB)\n","Collecting pytorch-ignite\n","  Downloading pytorch_ignite-0.4.8-py3-none-any.whl (251 kB)\n","\u001b[K     |████████████████████████████████| 251 kB 57.6 MB/s \n","\u001b[?25hCollecting tensorboardX\n","  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 74.0 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 20)) (1.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 21)) (3.2.2)\n","Collecting abel-pytorch\n","  Downloading abel_pytorch-0.0.1-py3-none-any.whl (4.2 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r google_requirements.txt (line 10)) (4.1.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->-r google_requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (57.4.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.17.3)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.14.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.2.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (13.0.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.1.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.5.3)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.6.3)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.24.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.1.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.1.2)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.3.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.44.0)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 75.6 MB/s \n","\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->-r google_requirements.txt (line 6)) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->-r google_requirements.txt (line 6)) (1.5.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.35.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2.23.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.4.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.6.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.2.0)\n","Collecting torchaudio\n","  Downloading torchaudio-0.11.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 55.9 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 50.3 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 59.0 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 61.0 MB/s \n","\u001b[?25h  Downloading torchaudio-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 58.4 MB/s \n","\u001b[?25h  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 54.2 MB/s \n","\u001b[?25h  Downloading torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 57.4 MB/s \n","\u001b[?25h  Downloading torchaudio-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 57.1 MB/s \n","\u001b[?25hCollecting torchtext\n","  Downloading torchtext-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n","\u001b[K     |████████████████████████████████| 10.4 MB 56.6 MB/s \n","\u001b[?25h  Downloading torchtext-0.11.2-cp37-cp37m-manylinux1_x86_64.whl (8.0 MB)\n","\u001b[K     |████████████████████████████████| 8.0 MB 46.7 MB/s \n","\u001b[?25h  Downloading torchtext-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (8.0 MB)\n","\u001b[K     |████████████████████████████████| 8.0 MB 18.8 MB/s \n","\u001b[?25h  Downloading torchtext-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 52.8 MB/s \n","\u001b[?25h  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 52.7 MB/s \n","\u001b[?25h  Downloading torchtext-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 25.2 MB/s \n","\u001b[?25h  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 35.3 MB/s \n","\u001b[?25hCollecting PyYAML>=5.1.0\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 69.3 MB/s \n","\u001b[?25hCollecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 74.8 MB/s \n","\u001b[?25hCollecting importlib-resources<5.3\n","  Downloading importlib_resources-5.2.3-py3-none-any.whl (27 kB)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r google_requirements.txt (line 20)) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r google_requirements.txt (line 20)) (1.1.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (3.0.8)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (1.4.2)\n","Building wheels for collected packages: antlr4-python3-runtime, hydra\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=157ca161e9e9dc38a098bf9e2b52a6e22ed37cd8b24c6dc3d0d600511f556f42\n","  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n","  Building wheel for hydra (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hydra: filename=Hydra-2.5-cp37-cp37m-linux_x86_64.whl size=220745 sha256=0761a6f9ab69c2743d34fc132ac79fb20b8892ea466a794f2f31b3bd7149ab1c\n","  Stored in directory: /root/.cache/pip/wheels/46/28/7d/3b38a41d900da90c4e17576f442bac9344eb1f5a4e78ee9f83\n","Successfully built antlr4-python3-runtime hydra\n","Installing collected packages: PyYAML, antlr4-python3-runtime, torch, tf-estimator-nightly, omegaconf, importlib-resources, torchvision, torchtext, torchaudio, tensorboardX, pytorch-ignite, ignite, hydra-core, hydra, abel-pytorch\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","  Attempting uninstall: importlib-resources\n","    Found existing installation: importlib-resources 5.7.0\n","    Uninstalling importlib-resources-5.7.0:\n","      Successfully uninstalled importlib-resources-5.7.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.11.1+cu111\n","    Uninstalling torchvision-0.11.1+cu111:\n","      Successfully uninstalled torchvision-0.11.1+cu111\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.11.0\n","    Uninstalling torchtext-0.11.0:\n","      Successfully uninstalled torchtext-0.11.0\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.10.0+cu111\n","    Uninstalling torchaudio-0.10.0+cu111:\n","      Successfully uninstalled torchaudio-0.10.0+cu111\n","Successfully installed PyYAML-6.0 abel-pytorch-0.0.1 antlr4-python3-runtime-4.8 hydra-2.5 hydra-core-1.1.2 ignite-1.1.0 importlib-resources-5.2.3 omegaconf-2.1.2 pytorch-ignite-0.4.8 tensorboardX-2.5 tf-estimator-nightly-2.8.0.dev2021122109 torch-1.8.0 torchaudio-0.8.0 torchtext-0.9.0 torchvision-0.9.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{}}],"source":["# Mount into drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","# Change directory to the package folder\n","%cd '/content/drive/MyDrive/celiali'\n","%pip install -r google_requirements.txt"]},{"cell_type":"code","source":["!python run.py DATASET.label_num=4000 DATASET.strongaugment='RA' EXPERIMENT.epoch_n=120 EXPERIMENT.batch_size=64 MODEL.name='WideResNet_Lk' MODEL.depth=28 MODEL.widen_factor=2 MODEL.num_classes=10 EXPERIMENT.out_model='./checkpoints/checkpoints_celiali-lambda_unlabled_7/' EXPERIMENT.log_path='./outputs/outputs_lambda_unlabled_7/' EXPERIMENT.save_cfmatrix=False EXPERIMENT.decay_type='cosine' DATASET.cut_type='cutout' EXPERIMENT.lambda_unlabeled=7"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kzcKl_ItS5Zd","executionInfo":{"status":"ok","timestamp":1650870661223,"user_tz":300,"elapsed":21552928,"user":{"displayName":"CM Y","userId":"12660552299343911788"}},"outputId":"4fc9f8bb-b675-4afa-8603-35df01b88fba"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["==> CONFIG is: \n"," DATASET:\n","  project_dir: ./\n","  data_dir: data\n","  loading_data: LOAD_LABEL_UNLABEL\n","  dataset: CIFAR10\n","  strongaugment: RA\n","  cut_type: cutout\n","  label_num: 4000\n","  num_expand_x: 65536\n","  mu: 7\n","  barely: false\n","  add_noisy_label: false\n","  both_strong: false\n","MODEL:\n","  name: WideResNet_Lk\n","  depth: 28\n","  widen_factor: 2\n","  num_classes: 10\n","  dropout: 0.0\n","  cardinality: 4\n","  width: 4\n","  base_width: 4\n","EXPERIMENT:\n","  name: FMExperiment\n","  out_model: ./checkpoints/checkpoints_celiali-lambda_unlabled_7/\n","  log_path: ./outputs/outputs_lambda_unlabled_7/\n","  used_gpu: true\n","  decay_type: cosine\n","  abel_decay: 0.1\n","  optim_lr: 0.03\n","  optim_momentum: 0.9\n","  used_nesterov: true\n","  warmup: 0\n","  wdecay: 0.0005\n","  clip: 1\n","  ema_used: true\n","  ema_decay: 0.999\n","  threshold: 0.95\n","  lambda_unlabeled: 7\n","  batch_size: 64\n","  num_workers: 4\n","  n_imgs_per_epoch: 65536\n","  epoch_n: 120\n","  save_every: 2\n","  save_matrix_every: 20\n","  resume: false\n","  resume_checkpoints: ./checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar\n","  save_cfmatrix: false\n","  batch_balanced: false\n","  neg_penalty: false\n","  equal_freq: false\n","  eta_negpenalty: 0.05\n","  eta_dynamic: false\n","  use_nlloss: false\n","  q: 0.0001\n","Logging:\n","  name: FM\n","  seed: 1265\n"," \n","\n","2022-04-24 16:04:13,598 - INFO - Train -   {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'cut_type': 'cutout', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-lambda_unlabled_7/', 'log_path': './outputs/outputs_lambda_unlabled_7/', 'used_gpu': True, 'decay_type': 'cosine', 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 7, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': False, 'resume_checkpoints': './checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","[2022-04-24 16:04:13,598][Train][INFO] - {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'cut_type': 'cutout', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-lambda_unlabled_7/', 'log_path': './outputs/outputs_lambda_unlabled_7/', 'used_gpu': True, 'decay_type': 'cosine', 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 7, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': False, 'resume_checkpoints': './checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","2022-04-24 16:04:14,149 - INFO - Train -   [Model] Building model WideResNet_Lk\n","[2022-04-24 16:04:14,149][Train][INFO] - [Model] Building model WideResNet_Lk\n","2022-04-24 16:04:16,601 - INFO - Train -   Total params: 1.47M\n","[2022-04-24 16:04:16,601][Train][INFO] - Total params: 1.47M\n","[2022-04-24 16:04:16,603][experiments.experiment][INFO] - I'm using cosine decay!\n","[2022-04-24 16:04:16,606][experiments.experiment][INFO] - [EMA] initial \n","[2022-04-24 16:04:25,042][datasets.datasets1][INFO] - Dataset: CIFAR10\n","[2022-04-24 16:04:25,092][datasets.datasets1][INFO] - Labeled examples: 65536 Unlabeled examples: 458752Validation examples: 5000\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-24 16:04:25,093][experiments.experiment][INFO] - Loading Labelled Loader\n","[2022-04-24 16:04:25,094][experiments.experiment][INFO] - Loading Unlabelled Loader\n","[2022-04-24 16:04:25,094][experiments.experiment][INFO] - Loading Validation Loader\n","[2022-04-24 16:04:25,100][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 16:11:52,578][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 0: use 447.5782399177551 seconds\n","--- Optimizer learning rate changed from inf to 3.00e-02 ---\n","[2022-04-24 16:11:52,679][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 16:11:54,027][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 16:11:54,028][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 16:11:55,342][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 16:11:55,402][experiments.experiment][INFO] - [EMA] Epoch 0.[Train] time:447.5782399177551 seconds, lr:0.0300, train_loss: 1.5308, unlabeled_losses_real_strong:2.1771,corrrect_unlabeled_num:26937.0,pro_above_threshold_num:28818.0,unlabelled_weak_top1_acc:50.492422363720834,unlabelled_weak_top5_acc:92.60449973866343  \n","[2022-04-24 16:11:55,403][experiments.experiment][INFO] - [EMA] Epoch 0. [Validation] raw_testing_loss: 2.1290, raw test Top1 acc:39.06, raw test Top5 acc: 87.78, ema_testing_loss: 1.5825, ema test Top1 acc:45.2, ema test Top5 acc: 90.96\n","[2022-04-24 16:11:55,495][experiments.experiment][INFO] - [Checkpoints] Epoch 0, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 16:11:55,496][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 16:19:22,862][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 1: use 447.46762204170227 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-24 16:19:22,964][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 16:19:24,301][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 16:19:24,301][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 16:19:25,632][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 16:19:25,634][experiments.experiment][INFO] - [EMA] Epoch 1.[Train] time:447.46762204170227 seconds, lr:0.0300, train_loss: 1.7989, unlabeled_losses_real_strong:1.9388,corrrect_unlabeled_num:112077.0,pro_above_threshold_num:118757.0,unlabelled_weak_top1_acc:64.33541341871023,unlabelled_weak_top5_acc:96.51467350125313  \n","[2022-04-24 16:19:25,635][experiments.experiment][INFO] - [EMA] Epoch 1. [Validation] raw_testing_loss: 2.7239, raw test Top1 acc:21.68, raw test Top5 acc: 80.36, ema_testing_loss: 1.0902, ema test Top1 acc:61.38, ema test Top5 acc: 95.76\n","[2022-04-24 16:19:25,728][experiments.experiment][INFO] - [Checkpoints] Epoch 1, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 16:19:25,734][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 16:26:55,758][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 2: use 450.1207113265991 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-24 16:26:55,855][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 16:26:57,236][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 16:26:57,236][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 16:26:58,614][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 16:26:58,616][experiments.experiment][INFO] - [EMA] Epoch 2.[Train] time:450.1207113265991 seconds, lr:0.0300, train_loss: 1.9173, unlabeled_losses_real_strong:1.6037,corrrect_unlabeled_num:162632.0,pro_above_threshold_num:171754.0,unlabelled_weak_top1_acc:69.93277310952544,unlabelled_weak_top5_acc:97.50409689545631  \n","[2022-04-24 16:26:58,617][experiments.experiment][INFO] - [EMA] Epoch 2. [Validation] raw_testing_loss: 2.8363, raw test Top1 acc:29.0, raw test Top5 acc: 86.54, ema_testing_loss: 0.8844, ema test Top1 acc:69.18, ema test Top5 acc: 97.48\n","[2022-04-24 16:26:58,618][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 16:34:21,675][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 3: use 443.1569633483887 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-24 16:34:21,775][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 16:34:23,102][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 16:34:23,103][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 16:34:24,403][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 16:34:24,405][experiments.experiment][INFO] - [EMA] Epoch 3.[Train] time:443.1569633483887 seconds, lr:0.0300, train_loss: 2.0538, unlabeled_losses_real_strong:1.3271,corrrect_unlabeled_num:204144.0,pro_above_threshold_num:214838.0,unlabelled_weak_top1_acc:74.64599506556988,unlabelled_weak_top5_acc:98.1887806802988  \n","[2022-04-24 16:34:24,407][experiments.experiment][INFO] - [EMA] Epoch 3. [Validation] raw_testing_loss: 2.0407, raw test Top1 acc:45.18, raw test Top5 acc: 89.78, ema_testing_loss: 0.7698, ema test Top1 acc:73.98, ema test Top5 acc: 98.22\n","[2022-04-24 16:34:24,502][experiments.experiment][INFO] - [Checkpoints] Epoch 3, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 16:34:24,509][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 16:41:48,812][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 4: use 444.40285873413086 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-24 16:41:48,912][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 16:41:50,256][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 16:41:50,257][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 16:41:51,587][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 16:41:51,589][experiments.experiment][INFO] - [EMA] Epoch 4.[Train] time:444.40285873413086 seconds, lr:0.0300, train_loss: 2.1121, unlabeled_losses_real_strong:1.1860,corrrect_unlabeled_num:236328.0,pro_above_threshold_num:247739.0,unlabelled_weak_top1_acc:77.90352844446898,unlabelled_weak_top5_acc:98.59139456599951  \n","[2022-04-24 16:41:51,591][experiments.experiment][INFO] - [EMA] Epoch 4. [Validation] raw_testing_loss: 3.6039, raw test Top1 acc:30.54, raw test Top5 acc: 89.28, ema_testing_loss: 0.6859, ema test Top1 acc:77.66, ema test Top5 acc: 98.76\n","[2022-04-24 16:41:51,592][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 16:49:17,863][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 5: use 446.36635971069336 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 2.99e-02 ---\n","[2022-04-24 16:49:17,959][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 16:49:19,277][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 16:49:19,278][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 16:49:20,660][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 16:49:20,661][experiments.experiment][INFO] - [EMA] Epoch 5.[Train] time:446.36635971069336 seconds, lr:0.0299, train_loss: 2.0850, unlabeled_losses_real_strong:1.0896,corrrect_unlabeled_num:258920.0,pro_above_threshold_num:270676.0,unlabelled_weak_top1_acc:80.2311476841569,unlabelled_weak_top5_acc:98.80283767729998  \n","[2022-04-24 16:49:20,664][experiments.experiment][INFO] - [EMA] Epoch 5. [Validation] raw_testing_loss: 2.2797, raw test Top1 acc:43.74, raw test Top5 acc: 88.72, ema_testing_loss: 0.6180, ema test Top1 acc:80.62, ema test Top5 acc: 99.08\n","[2022-04-24 16:49:20,757][experiments.experiment][INFO] - [Checkpoints] Epoch 5, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 16:49:20,764][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 16:56:46,515][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 6: use 445.8452868461609 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.99e-02 ---\n","[2022-04-24 16:56:46,610][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 16:56:47,927][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 16:56:47,928][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 16:56:49,250][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 16:56:49,252][experiments.experiment][INFO] - [EMA] Epoch 6.[Train] time:445.8452868461609 seconds, lr:0.0299, train_loss: 2.0817, unlabeled_losses_real_strong:1.0181,corrrect_unlabeled_num:274605.0,pro_above_threshold_num:286064.0,unlabelled_weak_top1_acc:81.86710792034864,unlabelled_weak_top5_acc:99.00403555482626  \n","[2022-04-24 16:56:49,254][experiments.experiment][INFO] - [EMA] Epoch 6. [Validation] raw_testing_loss: 1.2912, raw test Top1 acc:66.28, raw test Top5 acc: 95.98, ema_testing_loss: 0.5608, ema test Top1 acc:82.52, ema test Top5 acc: 99.24\n","[2022-04-24 16:56:49,255][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 17:04:16,605][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 7: use 447.4465157985687 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.99e-02 ---\n","[2022-04-24 17:04:16,702][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 17:04:18,031][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 17:04:18,031][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 17:04:19,375][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 17:04:19,377][experiments.experiment][INFO] - [EMA] Epoch 7.[Train] time:447.4465157985687 seconds, lr:0.0299, train_loss: 2.0899, unlabeled_losses_real_strong:0.9664,corrrect_unlabeled_num:288154.0,pro_above_threshold_num:299680.0,unlabelled_weak_top1_acc:83.26219734549522,unlabelled_weak_top5_acc:99.07553384453058  \n","[2022-04-24 17:04:19,378][experiments.experiment][INFO] - [EMA] Epoch 7. [Validation] raw_testing_loss: 0.7730, raw test Top1 acc:75.22, raw test Top5 acc: 97.82, ema_testing_loss: 0.5094, ema test Top1 acc:84.38, ema test Top5 acc: 99.32\n","[2022-04-24 17:04:19,476][experiments.experiment][INFO] - [Checkpoints] Epoch 7, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 17:04:19,486][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 17:11:43,658][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 8: use 444.2682595252991 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.98e-02 ---\n","[2022-04-24 17:11:43,755][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 17:11:45,091][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 17:11:45,091][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 17:11:46,421][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 17:11:46,422][experiments.experiment][INFO] - [EMA] Epoch 8.[Train] time:444.2682595252991 seconds, lr:0.0298, train_loss: 2.0677, unlabeled_losses_real_strong:0.9265,corrrect_unlabeled_num:297030.0,pro_above_threshold_num:308300.0,unlabelled_weak_top1_acc:84.19777894765139,unlabelled_weak_top5_acc:99.16643258929253  \n","[2022-04-24 17:11:46,425][experiments.experiment][INFO] - [EMA] Epoch 8. [Validation] raw_testing_loss: 1.0897, raw test Top1 acc:70.08, raw test Top5 acc: 97.74, ema_testing_loss: 0.4737, ema test Top1 acc:85.78, ema test Top5 acc: 99.32\n","[2022-04-24 17:11:46,425][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 17:19:09,062][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 9: use 442.73431372642517 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.98e-02 ---\n","[2022-04-24 17:19:09,160][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 17:19:10,534][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 17:19:10,534][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 17:19:11,910][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 17:19:11,911][experiments.experiment][INFO] - [EMA] Epoch 9.[Train] time:442.73431372642517 seconds, lr:0.0298, train_loss: 2.0543, unlabeled_losses_real_strong:0.8899,corrrect_unlabeled_num:305524.0,pro_above_threshold_num:316587.0,unlabelled_weak_top1_acc:85.04311589151621,unlabelled_weak_top5_acc:99.20741353183985  \n","[2022-04-24 17:19:11,913][experiments.experiment][INFO] - [EMA] Epoch 9. [Validation] raw_testing_loss: 0.8854, raw test Top1 acc:76.22, raw test Top5 acc: 98.22, ema_testing_loss: 0.4462, ema test Top1 acc:86.86, ema test Top5 acc: 99.44\n","[2022-04-24 17:19:12,009][experiments.experiment][INFO] - [Checkpoints] Epoch 9, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 17:19:12,010][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 17:26:38,537][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 10: use 446.6257109642029 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.98e-02 ---\n","[2022-04-24 17:26:38,636][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 17:26:39,977][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 17:26:39,978][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 17:26:41,310][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 17:26:41,312][experiments.experiment][INFO] - [EMA] Epoch 10.[Train] time:446.6257109642029 seconds, lr:0.0298, train_loss: 2.0483, unlabeled_losses_real_strong:0.8584,corrrect_unlabeled_num:313019.0,pro_above_threshold_num:323878.0,unlabelled_weak_top1_acc:85.80300360918045,unlabelled_weak_top5_acc:99.29460673779249  \n","[2022-04-24 17:26:41,313][experiments.experiment][INFO] - [EMA] Epoch 10. [Validation] raw_testing_loss: 1.1136, raw test Top1 acc:69.62, raw test Top5 acc: 96.36, ema_testing_loss: 0.4207, ema test Top1 acc:87.4, ema test Top5 acc: 99.5\n","[2022-04-24 17:26:41,314][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 17:34:08,844][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 11: use 447.6291534900665 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.97e-02 ---\n","[2022-04-24 17:34:08,943][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 17:34:10,298][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 17:34:10,299][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 17:34:11,642][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 17:34:11,643][experiments.experiment][INFO] - [EMA] Epoch 11.[Train] time:447.6291534900665 seconds, lr:0.0297, train_loss: 2.0390, unlabeled_losses_real_strong:0.8326,corrrect_unlabeled_num:318915.0,pro_above_threshold_num:329825.0,unlabelled_weak_top1_acc:86.37193834781647,unlabelled_weak_top5_acc:99.30615991353989  \n","[2022-04-24 17:34:11,645][experiments.experiment][INFO] - [EMA] Epoch 11. [Validation] raw_testing_loss: 0.6413, raw test Top1 acc:80.04, raw test Top5 acc: 98.9, ema_testing_loss: 0.4011, ema test Top1 acc:88.2, ema test Top5 acc: 99.62\n","[2022-04-24 17:34:11,740][experiments.experiment][INFO] - [Checkpoints] Epoch 11, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 17:34:11,741][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 17:41:36,579][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 12: use 444.94177174568176 seconds\n","--- Optimizer learning rate changed from 2.97e-02 to 2.97e-02 ---\n","[2022-04-24 17:41:36,683][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 17:41:38,042][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 17:41:38,043][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 17:41:39,394][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 17:41:39,396][experiments.experiment][INFO] - [EMA] Epoch 12.[Train] time:444.94177174568176 seconds, lr:0.0297, train_loss: 2.0141, unlabeled_losses_real_strong:0.8129,corrrect_unlabeled_num:324040.0,pro_above_threshold_num:334527.0,unlabelled_weak_top1_acc:86.90229046344757,unlabelled_weak_top5_acc:99.33318974077702  \n","[2022-04-24 17:41:39,398][experiments.experiment][INFO] - [EMA] Epoch 12. [Validation] raw_testing_loss: 0.5709, raw test Top1 acc:82.4, raw test Top5 acc: 99.02, ema_testing_loss: 0.3818, ema test Top1 acc:88.44, ema test Top5 acc: 99.74\n","[2022-04-24 17:41:39,399][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 17:49:06,823][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 13: use 447.5269992351532 seconds\n","--- Optimizer learning rate changed from 2.97e-02 to 2.96e-02 ---\n","[2022-04-24 17:49:06,926][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 17:49:08,319][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 17:49:08,319][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 17:49:09,639][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 17:49:09,640][experiments.experiment][INFO] - [EMA] Epoch 13.[Train] time:447.5269992351532 seconds, lr:0.0296, train_loss: 2.0032, unlabeled_losses_real_strong:0.7921,corrrect_unlabeled_num:328591.0,pro_above_threshold_num:339189.0,unlabelled_weak_top1_acc:87.34348728507757,unlabelled_weak_top5_acc:99.40294446051121  \n","[2022-04-24 17:49:09,641][experiments.experiment][INFO] - [EMA] Epoch 13. [Validation] raw_testing_loss: 0.5994, raw test Top1 acc:81.42, raw test Top5 acc: 98.88, ema_testing_loss: 0.3707, ema test Top1 acc:88.78, ema test Top5 acc: 99.78\n","[2022-04-24 17:49:09,740][experiments.experiment][INFO] - [Checkpoints] Epoch 13, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 17:49:09,748][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 17:56:37,297][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 14: use 447.6436810493469 seconds\n","--- Optimizer learning rate changed from 2.96e-02 to 2.96e-02 ---\n","[2022-04-24 17:56:37,392][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 17:56:38,744][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 17:56:38,745][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 17:56:40,082][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 17:56:40,084][experiments.experiment][INFO] - [EMA] Epoch 14.[Train] time:447.6436810493469 seconds, lr:0.0296, train_loss: 1.9920, unlabeled_losses_real_strong:0.7751,corrrect_unlabeled_num:332609.0,pro_above_threshold_num:343196.0,unlabelled_weak_top1_acc:87.66174208372831,unlabelled_weak_top5_acc:99.39727694541216  \n","[2022-04-24 17:56:40,086][experiments.experiment][INFO] - [EMA] Epoch 14. [Validation] raw_testing_loss: 0.7568, raw test Top1 acc:79.72, raw test Top5 acc: 99.08, ema_testing_loss: 0.3596, ema test Top1 acc:89.56, ema test Top5 acc: 99.72\n","[2022-04-24 17:56:40,087][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 18:04:05,336][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 15: use 445.35440254211426 seconds\n","--- Optimizer learning rate changed from 2.96e-02 to 2.95e-02 ---\n","[2022-04-24 18:04:05,441][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 18:04:06,898][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 18:04:06,899][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 18:04:08,318][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 18:04:08,319][experiments.experiment][INFO] - [EMA] Epoch 15.[Train] time:445.35440254211426 seconds, lr:0.0295, train_loss: 1.9905, unlabeled_losses_real_strong:0.7614,corrrect_unlabeled_num:335933.0,pro_above_threshold_num:346523.0,unlabelled_weak_top1_acc:87.93596439063549,unlabelled_weak_top5_acc:99.4291025698185  \n","[2022-04-24 18:04:08,322][experiments.experiment][INFO] - [EMA] Epoch 15. [Validation] raw_testing_loss: 0.5739, raw test Top1 acc:83.18, raw test Top5 acc: 99.06, ema_testing_loss: 0.3552, ema test Top1 acc:89.88, ema test Top5 acc: 99.8\n","[2022-04-24 18:04:08,426][experiments.experiment][INFO] - [Checkpoints] Epoch 15, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 18:04:08,436][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 18:11:31,497][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 16: use 443.1587326526642 seconds\n","--- Optimizer learning rate changed from 2.95e-02 to 2.94e-02 ---\n","[2022-04-24 18:11:31,595][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 18:11:32,980][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 18:11:32,980][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 18:11:34,300][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 18:11:34,301][experiments.experiment][INFO] - [EMA] Epoch 16.[Train] time:443.1587326526642 seconds, lr:0.0294, train_loss: 1.9780, unlabeled_losses_real_strong:0.7446,corrrect_unlabeled_num:339975.0,pro_above_threshold_num:350153.0,unlabelled_weak_top1_acc:88.40310131013393,unlabelled_weak_top5_acc:99.4541706442833  \n","[2022-04-24 18:11:34,302][experiments.experiment][INFO] - [EMA] Epoch 16. [Validation] raw_testing_loss: 0.4903, raw test Top1 acc:84.62, raw test Top5 acc: 98.84, ema_testing_loss: 0.3418, ema test Top1 acc:90.18, ema test Top5 acc: 99.78\n","[2022-04-24 18:11:34,304][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 18:18:55,694][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 17: use 441.48665976524353 seconds\n","--- Optimizer learning rate changed from 2.94e-02 to 2.94e-02 ---\n","[2022-04-24 18:18:55,791][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 18:18:57,092][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 18:18:57,092][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 18:18:58,396][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 18:18:58,397][experiments.experiment][INFO] - [EMA] Epoch 17.[Train] time:441.48665976524353 seconds, lr:0.0294, train_loss: 1.9693, unlabeled_losses_real_strong:0.7364,corrrect_unlabeled_num:342035.0,pro_above_threshold_num:352195.0,unlabelled_weak_top1_acc:88.59340012818575,unlabelled_weak_top5_acc:99.48032853007317  \n","[2022-04-24 18:18:58,399][experiments.experiment][INFO] - [EMA] Epoch 17. [Validation] raw_testing_loss: 0.5962, raw test Top1 acc:82.64, raw test Top5 acc: 98.94, ema_testing_loss: 0.3322, ema test Top1 acc:90.28, ema test Top5 acc: 99.82\n","[2022-04-24 18:18:58,495][experiments.experiment][INFO] - [Checkpoints] Epoch 17, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 18:18:58,505][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 18:26:20,065][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 18: use 441.6581757068634 seconds\n","--- Optimizer learning rate changed from 2.94e-02 to 2.93e-02 ---\n","[2022-04-24 18:26:20,163][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 18:26:21,490][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 18:26:21,490][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 18:26:22,844][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 18:26:22,846][experiments.experiment][INFO] - [EMA] Epoch 18.[Train] time:441.6581757068634 seconds, lr:0.0293, train_loss: 1.9626, unlabeled_losses_real_strong:0.7255,corrrect_unlabeled_num:344620.0,pro_above_threshold_num:354665.0,unlabelled_weak_top1_acc:88.82010219246149,unlabelled_weak_top5_acc:99.49253565818071  \n","[2022-04-24 18:26:22,847][experiments.experiment][INFO] - [EMA] Epoch 18. [Validation] raw_testing_loss: 0.5135, raw test Top1 acc:84.86, raw test Top5 acc: 99.34, ema_testing_loss: 0.3251, ema test Top1 acc:90.52, ema test Top5 acc: 99.82\n","[2022-04-24 18:26:22,849][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 18:33:44,195][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 19: use 441.4451198577881 seconds\n","--- Optimizer learning rate changed from 2.93e-02 to 2.92e-02 ---\n","[2022-04-24 18:33:44,294][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 18:33:45,668][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 18:33:45,668][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 18:33:46,961][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 18:33:46,962][experiments.experiment][INFO] - [EMA] Epoch 19.[Train] time:441.4451198577881 seconds, lr:0.0292, train_loss: 1.9449, unlabeled_losses_real_strong:0.7096,corrrect_unlabeled_num:347185.0,pro_above_threshold_num:357102.0,unlabelled_weak_top1_acc:89.12266216427088,unlabelled_weak_top5_acc:99.49863941222429  \n","[2022-04-24 18:33:46,964][experiments.experiment][INFO] - [EMA] Epoch 19. [Validation] raw_testing_loss: 0.4985, raw test Top1 acc:85.16, raw test Top5 acc: 99.3, ema_testing_loss: 0.3186, ema test Top1 acc:90.8, ema test Top5 acc: 99.8\n","[2022-04-24 18:33:47,061][experiments.experiment][INFO] - [Checkpoints] Epoch 19, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 18:33:47,067][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 18:41:08,542][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 20: use 441.56930780410767 seconds\n","--- Optimizer learning rate changed from 2.92e-02 to 2.91e-02 ---\n","[2022-04-24 18:41:08,636][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 18:41:09,958][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 18:41:09,959][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 18:41:11,268][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 18:41:11,269][experiments.experiment][INFO] - [EMA] Epoch 20.[Train] time:441.56930780410767 seconds, lr:0.0291, train_loss: 1.9392, unlabeled_losses_real_strong:0.7029,corrrect_unlabeled_num:349282.0,pro_above_threshold_num:359271.0,unlabelled_weak_top1_acc:89.3166668266058,unlabelled_weak_top5_acc:99.51694991439581  \n","[2022-04-24 18:41:11,272][experiments.experiment][INFO] - [EMA] Epoch 20. [Validation] raw_testing_loss: 0.5290, raw test Top1 acc:84.92, raw test Top5 acc: 99.04, ema_testing_loss: 0.3172, ema test Top1 acc:90.66, ema test Top5 acc: 99.82\n","[2022-04-24 18:41:11,273][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 18:48:39,010][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 21: use 447.83200883865356 seconds\n","--- Optimizer learning rate changed from 2.91e-02 to 2.91e-02 ---\n","[2022-04-24 18:48:39,105][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 18:48:40,457][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 18:48:40,457][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 18:48:41,767][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 18:48:41,769][experiments.experiment][INFO] - [EMA] Epoch 21.[Train] time:447.83200883865356 seconds, lr:0.0291, train_loss: 1.9255, unlabeled_losses_real_strong:0.6951,corrrect_unlabeled_num:350948.0,pro_above_threshold_num:360998.0,unlabelled_weak_top1_acc:89.43154353648424,unlabelled_weak_top5_acc:99.52370735257864  \n","[2022-04-24 18:48:41,772][experiments.experiment][INFO] - [EMA] Epoch 21. [Validation] raw_testing_loss: 0.4055, raw test Top1 acc:87.3, raw test Top5 acc: 99.56, ema_testing_loss: 0.3136, ema test Top1 acc:90.74, ema test Top5 acc: 99.82\n","[2022-04-24 18:48:41,887][experiments.experiment][INFO] - [Checkpoints] Epoch 21, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 18:48:41,888][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 18:56:08,165][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 22: use 446.38561940193176 seconds\n","--- Optimizer learning rate changed from 2.91e-02 to 2.90e-02 ---\n","[2022-04-24 18:56:08,273][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 18:56:09,591][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 18:56:09,592][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 18:56:10,905][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 18:56:10,907][experiments.experiment][INFO] - [EMA] Epoch 22.[Train] time:446.38561940193176 seconds, lr:0.0290, train_loss: 1.9210, unlabeled_losses_real_strong:0.6846,corrrect_unlabeled_num:353168.0,pro_above_threshold_num:362853.0,unlabelled_weak_top1_acc:89.76941683143377,unlabelled_weak_top5_acc:99.5258871614933  \n","[2022-04-24 18:56:10,909][experiments.experiment][INFO] - [EMA] Epoch 22. [Validation] raw_testing_loss: 0.5769, raw test Top1 acc:83.9, raw test Top5 acc: 99.24, ema_testing_loss: 0.3053, ema test Top1 acc:91.08, ema test Top5 acc: 99.8\n","[2022-04-24 18:56:10,909][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 19:03:40,035][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 23: use 449.2301404476166 seconds\n","--- Optimizer learning rate changed from 2.90e-02 to 2.89e-02 ---\n","[2022-04-24 19:03:40,140][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 19:03:41,502][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 19:03:41,503][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 19:03:42,807][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 19:03:42,809][experiments.experiment][INFO] - [EMA] Epoch 23.[Train] time:449.2301404476166 seconds, lr:0.0289, train_loss: 1.9034, unlabeled_losses_real_strong:0.6750,corrrect_unlabeled_num:355040.0,pro_above_threshold_num:364736.0,unlabelled_weak_top1_acc:89.90107845515013,unlabelled_weak_top5_acc:99.55008345097303  \n","[2022-04-24 19:03:42,809][experiments.experiment][INFO] - [EMA] Epoch 23. [Validation] raw_testing_loss: 0.5650, raw test Top1 acc:83.24, raw test Top5 acc: 99.04, ema_testing_loss: 0.3000, ema test Top1 acc:91.08, ema test Top5 acc: 99.82\n","[2022-04-24 19:03:42,909][experiments.experiment][INFO] - [Checkpoints] Epoch 23, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 19:03:42,919][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 19:11:11,840][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 24: use 449.0225749015808 seconds\n","--- Optimizer learning rate changed from 2.89e-02 to 2.88e-02 ---\n","[2022-04-24 19:11:11,942][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 19:11:13,251][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 19:11:13,251][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 19:11:14,646][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 19:11:14,648][experiments.experiment][INFO] - [EMA] Epoch 24.[Train] time:449.0225749015808 seconds, lr:0.0288, train_loss: 1.8984, unlabeled_losses_real_strong:0.6676,corrrect_unlabeled_num:356533.0,pro_above_threshold_num:365872.0,unlabelled_weak_top1_acc:90.09617280215025,unlabelled_weak_top5_acc:99.55509704351425  \n","[2022-04-24 19:11:14,651][experiments.experiment][INFO] - [EMA] Epoch 24. [Validation] raw_testing_loss: 0.5062, raw test Top1 acc:85.9, raw test Top5 acc: 99.38, ema_testing_loss: 0.2953, ema test Top1 acc:91.26, ema test Top5 acc: 99.84\n","[2022-04-24 19:11:14,652][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 19:18:42,186][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 25: use 447.6336598396301 seconds\n","--- Optimizer learning rate changed from 2.88e-02 to 2.87e-02 ---\n","[2022-04-24 19:18:42,285][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 19:18:43,609][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 19:18:43,609][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 19:18:44,928][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 19:18:44,929][experiments.experiment][INFO] - [EMA] Epoch 25.[Train] time:447.6336598396301 seconds, lr:0.0287, train_loss: 1.8973, unlabeled_losses_real_strong:0.6600,corrrect_unlabeled_num:358730.0,pro_above_threshold_num:368228.0,unlabelled_weak_top1_acc:90.24919677525759,unlabelled_weak_top5_acc:99.58561471104622  \n","[2022-04-24 19:18:44,930][experiments.experiment][INFO] - [EMA] Epoch 25. [Validation] raw_testing_loss: 0.4618, raw test Top1 acc:87.06, raw test Top5 acc: 99.34, ema_testing_loss: 0.2919, ema test Top1 acc:91.66, ema test Top5 acc: 99.82\n","[2022-04-24 19:18:45,025][experiments.experiment][INFO] - [Checkpoints] Epoch 25, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 19:18:45,028][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 19:26:13,738][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 26: use 448.8044681549072 seconds\n","--- Optimizer learning rate changed from 2.87e-02 to 2.86e-02 ---\n","[2022-04-24 19:26:13,833][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 19:26:15,204][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 19:26:15,204][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 19:26:16,541][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 19:26:16,543][experiments.experiment][INFO] - [EMA] Epoch 26.[Train] time:448.8044681549072 seconds, lr:0.0286, train_loss: 1.8960, unlabeled_losses_real_strong:0.6546,corrrect_unlabeled_num:360110.0,pro_above_threshold_num:369412.0,unlabelled_weak_top1_acc:90.4070163294673,unlabelled_weak_top5_acc:99.57951122522354  \n","[2022-04-24 19:26:16,545][experiments.experiment][INFO] - [EMA] Epoch 26. [Validation] raw_testing_loss: 0.3835, raw test Top1 acc:88.44, raw test Top5 acc: 99.68, ema_testing_loss: 0.2888, ema test Top1 acc:91.58, ema test Top5 acc: 99.8\n","[2022-04-24 19:26:16,546][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 19:33:43,990][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 27: use 447.54348373413086 seconds\n","--- Optimizer learning rate changed from 2.86e-02 to 2.85e-02 ---\n","[2022-04-24 19:33:44,089][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 19:33:45,471][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 19:33:45,471][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 19:33:46,863][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 19:33:46,865][experiments.experiment][INFO] - [EMA] Epoch 27.[Train] time:447.54348373413086 seconds, lr:0.0285, train_loss: 1.8935, unlabeled_losses_real_strong:0.6503,corrrect_unlabeled_num:361360.0,pro_above_threshold_num:370619.0,unlabelled_weak_top1_acc:90.51317374408245,unlabelled_weak_top5_acc:99.57798527926207  \n","[2022-04-24 19:33:46,867][experiments.experiment][INFO] - [EMA] Epoch 27. [Validation] raw_testing_loss: 0.4386, raw test Top1 acc:87.08, raw test Top5 acc: 99.44, ema_testing_loss: 0.2859, ema test Top1 acc:91.94, ema test Top5 acc: 99.84\n","[2022-04-24 19:33:46,961][experiments.experiment][INFO] - [Checkpoints] Epoch 27, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 19:33:46,963][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 19:41:12,599][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 28: use 445.73196482658386 seconds\n","--- Optimizer learning rate changed from 2.85e-02 to 2.84e-02 ---\n","[2022-04-24 19:41:12,695][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 19:41:14,090][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 19:41:14,091][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 19:41:15,454][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 19:41:15,455][experiments.experiment][INFO] - [EMA] Epoch 28.[Train] time:445.73196482658386 seconds, lr:0.0284, train_loss: 1.8652, unlabeled_losses_real_strong:0.6422,corrrect_unlabeled_num:362392.0,pro_above_threshold_num:371771.0,unlabelled_weak_top1_acc:90.61889538913965,unlabelled_weak_top5_acc:99.61177276074886  \n","[2022-04-24 19:41:15,458][experiments.experiment][INFO] - [EMA] Epoch 28. [Validation] raw_testing_loss: 0.4131, raw test Top1 acc:87.94, raw test Top5 acc: 99.46, ema_testing_loss: 0.2772, ema test Top1 acc:91.9, ema test Top5 acc: 99.84\n","[2022-04-24 19:41:15,458][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 19:48:45,435][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 29: use 450.07968759536743 seconds\n","--- Optimizer learning rate changed from 2.84e-02 to 2.82e-02 ---\n","[2022-04-24 19:48:45,538][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 19:48:46,966][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 19:48:46,966][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 19:48:48,374][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 19:48:48,376][experiments.experiment][INFO] - [EMA] Epoch 29.[Train] time:450.07968759536743 seconds, lr:0.0282, train_loss: 1.8866, unlabeled_losses_real_strong:0.6382,corrrect_unlabeled_num:363851.0,pro_above_threshold_num:373182.0,unlabelled_weak_top1_acc:90.82009345293045,unlabelled_weak_top5_acc:99.60872095823288  \n","[2022-04-24 19:48:48,379][experiments.experiment][INFO] - [EMA] Epoch 29. [Validation] raw_testing_loss: 0.4221, raw test Top1 acc:88.24, raw test Top5 acc: 99.38, ema_testing_loss: 0.2786, ema test Top1 acc:91.9, ema test Top5 acc: 99.8\n","[2022-04-24 19:48:48,480][experiments.experiment][INFO] - [Checkpoints] Epoch 29, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 19:48:48,490][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 19:56:16,025][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 30: use 447.6300415992737 seconds\n","--- Optimizer learning rate changed from 2.82e-02 to 2.81e-02 ---\n","[2022-04-24 19:56:16,120][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 19:56:17,455][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 19:56:17,456][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 19:56:18,793][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 19:56:18,795][experiments.experiment][INFO] - [EMA] Epoch 30.[Train] time:447.6300415992737 seconds, lr:0.0281, train_loss: 1.8642, unlabeled_losses_real_strong:0.6311,corrrect_unlabeled_num:364602.0,pro_above_threshold_num:373634.0,unlabelled_weak_top1_acc:90.88854010403156,unlabelled_weak_top5_acc:99.60872092097998  \n","[2022-04-24 19:56:18,797][experiments.experiment][INFO] - [EMA] Epoch 30. [Validation] raw_testing_loss: 0.4063, raw test Top1 acc:88.6, raw test Top5 acc: 99.54, ema_testing_loss: 0.2718, ema test Top1 acc:92.06, ema test Top5 acc: 99.84\n","[2022-04-24 19:56:18,798][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 20:03:46,949][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 31: use 448.2483332157135 seconds\n","--- Optimizer learning rate changed from 2.81e-02 to 2.80e-02 ---\n","[2022-04-24 20:03:47,047][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 20:03:48,402][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 20:03:48,402][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 20:03:49,735][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 20:03:49,737][experiments.experiment][INFO] - [EMA] Epoch 31.[Train] time:448.2483332157135 seconds, lr:0.0280, train_loss: 1.8686, unlabeled_losses_real_strong:0.6246,corrrect_unlabeled_num:366531.0,pro_above_threshold_num:375622.0,unlabelled_weak_top1_acc:90.9776950031519,unlabelled_weak_top5_acc:99.63226323574781  \n","[2022-04-24 20:03:49,738][experiments.experiment][INFO] - [EMA] Epoch 31. [Validation] raw_testing_loss: 0.4602, raw test Top1 acc:87.64, raw test Top5 acc: 99.5, ema_testing_loss: 0.2692, ema test Top1 acc:92.28, ema test Top5 acc: 99.84\n","[2022-04-24 20:03:49,836][experiments.experiment][INFO] - [Checkpoints] Epoch 31, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 20:03:49,846][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 20:11:17,451][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 32: use 447.7069993019104 seconds\n","--- Optimizer learning rate changed from 2.80e-02 to 2.79e-02 ---\n","[2022-04-24 20:11:17,553][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 20:11:18,917][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 20:11:18,917][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 20:11:20,297][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 20:11:20,299][experiments.experiment][INFO] - [EMA] Epoch 32.[Train] time:447.7069993019104 seconds, lr:0.0279, train_loss: 1.8498, unlabeled_losses_real_strong:0.6179,corrrect_unlabeled_num:367430.0,pro_above_threshold_num:376405.0,unlabelled_weak_top1_acc:91.10238105803728,unlabelled_weak_top5_acc:99.6364049166441  \n","[2022-04-24 20:11:20,301][experiments.experiment][INFO] - [EMA] Epoch 32. [Validation] raw_testing_loss: 0.5506, raw test Top1 acc:85.46, raw test Top5 acc: 99.12, ema_testing_loss: 0.2667, ema test Top1 acc:92.34, ema test Top5 acc: 99.82\n","[2022-04-24 20:11:20,302][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 20:18:50,743][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 33: use 450.54358196258545 seconds\n","--- Optimizer learning rate changed from 2.79e-02 to 2.78e-02 ---\n","[2022-04-24 20:18:50,846][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 20:18:52,277][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 20:18:52,277][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 20:18:53,610][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 20:18:53,612][experiments.experiment][INFO] - [EMA] Epoch 33.[Train] time:450.54358196258545 seconds, lr:0.0278, train_loss: 1.8498, unlabeled_losses_real_strong:0.6147,corrrect_unlabeled_num:368138.0,pro_above_threshold_num:377183.0,unlabelled_weak_top1_acc:91.17540529370308,unlabelled_weak_top5_acc:99.64686810225248  \n","[2022-04-24 20:18:53,613][experiments.experiment][INFO] - [EMA] Epoch 33. [Validation] raw_testing_loss: 0.4634, raw test Top1 acc:86.54, raw test Top5 acc: 98.88, ema_testing_loss: 0.2666, ema test Top1 acc:92.3, ema test Top5 acc: 99.8\n","[2022-04-24 20:18:53,708][experiments.experiment][INFO] - [Checkpoints] Epoch 33, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 20:18:53,710][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 20:26:26,424][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 34: use 452.82194328308105 seconds\n","--- Optimizer learning rate changed from 2.78e-02 to 2.76e-02 ---\n","[2022-04-24 20:26:26,532][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 20:26:27,922][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 20:26:27,922][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 20:26:29,350][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 20:26:29,352][experiments.experiment][INFO] - [EMA] Epoch 34.[Train] time:452.82194328308105 seconds, lr:0.0276, train_loss: 1.8430, unlabeled_losses_real_strong:0.6110,corrrect_unlabeled_num:369148.0,pro_above_threshold_num:378280.0,unlabelled_weak_top1_acc:91.25954650342464,unlabelled_weak_top5_acc:99.65188167244196  \n","[2022-04-24 20:26:29,354][experiments.experiment][INFO] - [EMA] Epoch 34. [Validation] raw_testing_loss: 0.3803, raw test Top1 acc:88.3, raw test Top5 acc: 99.42, ema_testing_loss: 0.2650, ema test Top1 acc:92.42, ema test Top5 acc: 99.84\n","[2022-04-24 20:26:29,354][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 20:34:03,034][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 35: use 453.786461353302 seconds\n","--- Optimizer learning rate changed from 2.76e-02 to 2.75e-02 ---\n","[2022-04-24 20:34:03,141][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 20:34:04,504][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 20:34:04,504][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 20:34:05,858][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 20:34:05,859][experiments.experiment][INFO] - [EMA] Epoch 35.[Train] time:453.786461353302 seconds, lr:0.0275, train_loss: 1.8385, unlabeled_losses_real_strong:0.6054,corrrect_unlabeled_num:370269.0,pro_above_threshold_num:379262.0,unlabelled_weak_top1_acc:91.3646143078804,unlabelled_weak_top5_acc:99.65253565460443  \n","[2022-04-24 20:34:05,861][experiments.experiment][INFO] - [EMA] Epoch 35. [Validation] raw_testing_loss: 0.4542, raw test Top1 acc:87.92, raw test Top5 acc: 99.48, ema_testing_loss: 0.2649, ema test Top1 acc:92.54, ema test Top5 acc: 99.78\n","[2022-04-24 20:34:05,959][experiments.experiment][INFO] - [Checkpoints] Epoch 35, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 20:34:05,967][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 20:41:38,813][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 36: use 452.9453821182251 seconds\n","--- Optimizer learning rate changed from 2.75e-02 to 2.73e-02 ---\n","[2022-04-24 20:41:38,912][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 20:41:40,327][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 20:41:40,327][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 20:41:41,687][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 20:41:41,689][experiments.experiment][INFO] - [EMA] Epoch 36.[Train] time:452.9453821182251 seconds, lr:0.0273, train_loss: 1.8287, unlabeled_losses_real_strong:0.6005,corrrect_unlabeled_num:371248.0,pro_above_threshold_num:380113.0,unlabelled_weak_top1_acc:91.52243369817734,unlabelled_weak_top5_acc:99.65951126813889  \n","[2022-04-24 20:41:41,692][experiments.experiment][INFO] - [EMA] Epoch 36. [Validation] raw_testing_loss: 0.4356, raw test Top1 acc:88.1, raw test Top5 acc: 99.38, ema_testing_loss: 0.2621, ema test Top1 acc:92.48, ema test Top5 acc: 99.78\n","[2022-04-24 20:41:41,693][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 20:49:17,063][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 37: use 455.4690833091736 seconds\n","--- Optimizer learning rate changed from 2.73e-02 to 2.72e-02 ---\n","[2022-04-24 20:49:17,162][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 20:49:18,522][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 20:49:18,522][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 20:49:19,944][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 20:49:19,946][experiments.experiment][INFO] - [EMA] Epoch 37.[Train] time:455.4690833091736 seconds, lr:0.0272, train_loss: 1.8205, unlabeled_losses_real_strong:0.5973,corrrect_unlabeled_num:372009.0,pro_above_threshold_num:381023.0,unlabelled_weak_top1_acc:91.51829200983047,unlabelled_weak_top5_acc:99.67978367209435  \n","[2022-04-24 20:49:19,949][experiments.experiment][INFO] - [EMA] Epoch 37. [Validation] raw_testing_loss: 0.4092, raw test Top1 acc:88.66, raw test Top5 acc: 99.56, ema_testing_loss: 0.2609, ema test Top1 acc:92.66, ema test Top5 acc: 99.78\n","[2022-04-24 20:49:20,051][experiments.experiment][INFO] - [Checkpoints] Epoch 37, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 20:49:20,057][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 20:56:50,050][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 38: use 450.1010947227478 seconds\n","--- Optimizer learning rate changed from 2.72e-02 to 2.71e-02 ---\n","[2022-04-24 20:56:50,158][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 20:56:51,535][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 20:56:51,535][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 20:56:52,904][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 20:56:52,906][experiments.experiment][INFO] - [EMA] Epoch 38.[Train] time:450.1010947227478 seconds, lr:0.0271, train_loss: 1.8300, unlabeled_losses_real_strong:0.5926,corrrect_unlabeled_num:372717.0,pro_above_threshold_num:381419.0,unlabelled_weak_top1_acc:91.61551231890917,unlabelled_weak_top5_acc:99.66169103235006  \n","[2022-04-24 20:56:52,908][experiments.experiment][INFO] - [EMA] Epoch 38. [Validation] raw_testing_loss: 0.4422, raw test Top1 acc:87.64, raw test Top5 acc: 99.3, ema_testing_loss: 0.2581, ema test Top1 acc:92.84, ema test Top5 acc: 99.8\n","[2022-04-24 20:56:52,909][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 21:04:19,608][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 39: use 446.7975957393646 seconds\n","--- Optimizer learning rate changed from 2.71e-02 to 2.69e-02 ---\n","[2022-04-24 21:04:19,706][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 21:04:21,054][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 21:04:21,054][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 21:04:22,489][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 21:04:22,490][experiments.experiment][INFO] - [EMA] Epoch 39.[Train] time:446.7975957393646 seconds, lr:0.0269, train_loss: 1.8157, unlabeled_losses_real_strong:0.5911,corrrect_unlabeled_num:373237.0,pro_above_threshold_num:382207.0,unlabelled_weak_top1_acc:91.65474918484688,unlabelled_weak_top5_acc:99.66975634545088  \n","[2022-04-24 21:04:22,493][experiments.experiment][INFO] - [EMA] Epoch 39. [Validation] raw_testing_loss: 0.3990, raw test Top1 acc:88.2, raw test Top5 acc: 99.58, ema_testing_loss: 0.2564, ema test Top1 acc:92.82, ema test Top5 acc: 99.8\n","[2022-04-24 21:04:22,586][experiments.experiment][INFO] - [Checkpoints] Epoch 39, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 21:04:22,587][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 21:11:55,829][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 40: use 453.3422384262085 seconds\n","--- Optimizer learning rate changed from 2.69e-02 to 2.68e-02 ---\n","[2022-04-24 21:11:55,930][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 21:11:57,281][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 21:11:57,282][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 21:11:58,686][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 21:11:58,688][experiments.experiment][INFO] - [EMA] Epoch 40.[Train] time:453.3422384262085 seconds, lr:0.0268, train_loss: 1.8105, unlabeled_losses_real_strong:0.5842,corrrect_unlabeled_num:374523.0,pro_above_threshold_num:383319.0,unlabelled_weak_top1_acc:91.77987140417099,unlabelled_weak_top5_acc:99.66496073454618  \n","[2022-04-24 21:11:58,689][experiments.experiment][INFO] - [EMA] Epoch 40. [Validation] raw_testing_loss: 0.3468, raw test Top1 acc:89.7, raw test Top5 acc: 99.72, ema_testing_loss: 0.2525, ema test Top1 acc:93.0, ema test Top5 acc: 99.84\n","[2022-04-24 21:11:58,690][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 21:19:31,492][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 41: use 452.9080204963684 seconds\n","--- Optimizer learning rate changed from 2.68e-02 to 2.66e-02 ---\n","[2022-04-24 21:19:31,598][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 21:19:33,019][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 21:19:33,019][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 21:19:34,384][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 21:19:34,386][experiments.experiment][INFO] - [EMA] Epoch 41.[Train] time:452.9080204963684 seconds, lr:0.0266, train_loss: 1.8163, unlabeled_losses_real_strong:0.5826,corrrect_unlabeled_num:376145.0,pro_above_threshold_num:384915.0,unlabelled_weak_top1_acc:91.82019799947739,unlabelled_weak_top5_acc:99.69656842201948  \n","[2022-04-24 21:19:34,389][experiments.experiment][INFO] - [EMA] Epoch 41. [Validation] raw_testing_loss: 0.4521, raw test Top1 acc:87.14, raw test Top5 acc: 99.52, ema_testing_loss: 0.2553, ema test Top1 acc:93.0, ema test Top5 acc: 99.8\n","[2022-04-24 21:19:34,483][experiments.experiment][INFO] - [Checkpoints] Epoch 41, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 21:19:34,485][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 21:27:10,551][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 42: use 456.1741850376129 seconds\n","--- Optimizer learning rate changed from 2.66e-02 to 2.64e-02 ---\n","[2022-04-24 21:27:10,659][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 21:27:12,011][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 21:27:12,011][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 21:27:13,347][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 21:27:13,349][experiments.experiment][INFO] - [EMA] Epoch 42.[Train] time:456.1741850376129 seconds, lr:0.0264, train_loss: 1.8002, unlabeled_losses_real_strong:0.5755,corrrect_unlabeled_num:376336.0,pro_above_threshold_num:385141.0,unlabelled_weak_top1_acc:91.93115128576756,unlabelled_weak_top5_acc:99.68566919863224  \n","[2022-04-24 21:27:13,351][experiments.experiment][INFO] - [EMA] Epoch 42. [Validation] raw_testing_loss: 0.3837, raw test Top1 acc:88.84, raw test Top5 acc: 99.6, ema_testing_loss: 0.2502, ema test Top1 acc:93.16, ema test Top5 acc: 99.82\n","[2022-04-24 21:27:13,352][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 21:34:45,070][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 43: use 451.8246383666992 seconds\n","--- Optimizer learning rate changed from 2.64e-02 to 2.63e-02 ---\n","[2022-04-24 21:34:45,177][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 21:34:46,647][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 21:34:46,647][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 21:34:48,073][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 21:34:48,075][experiments.experiment][INFO] - [EMA] Epoch 43.[Train] time:451.8246383666992 seconds, lr:0.0263, train_loss: 1.8069, unlabeled_losses_real_strong:0.5747,corrrect_unlabeled_num:376705.0,pro_above_threshold_num:385266.0,unlabelled_weak_top1_acc:92.06695456057787,unlabelled_weak_top5_acc:99.69635038077831  \n","[2022-04-24 21:34:48,077][experiments.experiment][INFO] - [EMA] Epoch 43. [Validation] raw_testing_loss: 0.5246, raw test Top1 acc:85.62, raw test Top5 acc: 99.04, ema_testing_loss: 0.2471, ema test Top1 acc:93.0, ema test Top5 acc: 99.78\n","[2022-04-24 21:34:48,180][experiments.experiment][INFO] - [Checkpoints] Epoch 43, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 21:34:48,181][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 21:42:20,747][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 44: use 452.6666913032532 seconds\n","--- Optimizer learning rate changed from 2.63e-02 to 2.61e-02 ---\n","[2022-04-24 21:42:20,848][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 21:42:22,183][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 21:42:22,184][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 21:42:23,538][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 21:42:23,540][experiments.experiment][INFO] - [EMA] Epoch 44.[Train] time:452.6666913032532 seconds, lr:0.0261, train_loss: 1.7971, unlabeled_losses_real_strong:0.5719,corrrect_unlabeled_num:377523.0,pro_above_threshold_num:386108.0,unlabelled_weak_top1_acc:92.10531944781542,unlabelled_weak_top5_acc:99.6808735653758  \n","[2022-04-24 21:42:23,542][experiments.experiment][INFO] - [EMA] Epoch 44. [Validation] raw_testing_loss: 0.3895, raw test Top1 acc:88.9, raw test Top5 acc: 99.6, ema_testing_loss: 0.2444, ema test Top1 acc:93.12, ema test Top5 acc: 99.8\n","[2022-04-24 21:42:23,543][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 21:49:55,717][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 45: use 452.2775754928589 seconds\n","--- Optimizer learning rate changed from 2.61e-02 to 2.59e-02 ---\n","[2022-04-24 21:49:55,820][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 21:49:57,226][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 21:49:57,227][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 21:49:58,726][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 21:49:58,728][experiments.experiment][INFO] - [EMA] Epoch 45.[Train] time:452.2775754928589 seconds, lr:0.0259, train_loss: 1.8022, unlabeled_losses_real_strong:0.5681,corrrect_unlabeled_num:378884.0,pro_above_threshold_num:387699.0,unlabelled_weak_top1_acc:92.14063258469105,unlabelled_weak_top5_acc:99.68697702139616  \n","[2022-04-24 21:49:58,730][experiments.experiment][INFO] - [EMA] Epoch 45. [Validation] raw_testing_loss: 0.3507, raw test Top1 acc:89.38, raw test Top5 acc: 99.66, ema_testing_loss: 0.2460, ema test Top1 acc:93.14, ema test Top5 acc: 99.78\n","[2022-04-24 21:49:58,832][experiments.experiment][INFO] - [Checkpoints] Epoch 45, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 21:49:58,834][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 21:57:28,127][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 46: use 449.39322423934937 seconds\n","--- Optimizer learning rate changed from 2.59e-02 to 2.58e-02 ---\n","[2022-04-24 21:57:28,227][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 21:57:29,576][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 21:57:29,577][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 21:57:30,915][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 21:57:30,918][experiments.experiment][INFO] - [EMA] Epoch 46.[Train] time:449.39322423934937 seconds, lr:0.0258, train_loss: 1.7916, unlabeled_losses_real_strong:0.5628,corrrect_unlabeled_num:378811.0,pro_above_threshold_num:387401.0,unlabelled_weak_top1_acc:92.22150428593159,unlabelled_weak_top5_acc:99.68784890323877  \n","[2022-04-24 21:57:30,920][experiments.experiment][INFO] - [EMA] Epoch 46. [Validation] raw_testing_loss: 0.4264, raw test Top1 acc:88.56, raw test Top5 acc: 99.58, ema_testing_loss: 0.2392, ema test Top1 acc:93.14, ema test Top5 acc: 99.84\n","[2022-04-24 21:57:30,921][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 22:04:59,747][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 47: use 448.9463269710541 seconds\n","--- Optimizer learning rate changed from 2.58e-02 to 2.56e-02 ---\n","[2022-04-24 22:04:59,867][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 22:05:01,209][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 22:05:01,209][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 22:05:02,581][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 22:05:02,582][experiments.experiment][INFO] - [EMA] Epoch 47.[Train] time:448.9463269710541 seconds, lr:0.0256, train_loss: 1.7783, unlabeled_losses_real_strong:0.5618,corrrect_unlabeled_num:379903.0,pro_above_threshold_num:388367.0,unlabelled_weak_top1_acc:92.27011427283287,unlabelled_weak_top5_acc:99.68828503787518  \n","[2022-04-24 22:05:02,584][experiments.experiment][INFO] - [EMA] Epoch 47. [Validation] raw_testing_loss: 0.3812, raw test Top1 acc:88.78, raw test Top5 acc: 99.64, ema_testing_loss: 0.2383, ema test Top1 acc:93.38, ema test Top5 acc: 99.86\n","[2022-04-24 22:05:02,681][experiments.experiment][INFO] - [Checkpoints] Epoch 47, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 22:05:02,692][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 22:12:32,952][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 48: use 450.37170243263245 seconds\n","--- Optimizer learning rate changed from 2.56e-02 to 2.54e-02 ---\n","[2022-04-24 22:12:33,064][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 22:12:34,434][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 22:12:34,434][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 22:12:35,770][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 22:12:35,771][experiments.experiment][INFO] - [EMA] Epoch 48.[Train] time:450.37170243263245 seconds, lr:0.0254, train_loss: 1.7846, unlabeled_losses_real_strong:0.5590,corrrect_unlabeled_num:380532.0,pro_above_threshold_num:389065.0,unlabelled_weak_top1_acc:92.32918755710125,unlabelled_weak_top5_acc:99.68610517680645  \n","[2022-04-24 22:12:35,773][experiments.experiment][INFO] - [EMA] Epoch 48. [Validation] raw_testing_loss: 0.3244, raw test Top1 acc:89.86, raw test Top5 acc: 99.66, ema_testing_loss: 0.2393, ema test Top1 acc:93.26, ema test Top5 acc: 99.82\n","[2022-04-24 22:12:35,774][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 22:20:05,199][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 49: use 449.5286569595337 seconds\n","--- Optimizer learning rate changed from 2.54e-02 to 2.52e-02 ---\n","[2022-04-24 22:20:05,303][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 22:20:06,727][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 22:20:06,727][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 22:20:08,118][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 22:20:08,120][experiments.experiment][INFO] - [EMA] Epoch 49.[Train] time:449.5286569595337 seconds, lr:0.0252, train_loss: 1.7807, unlabeled_losses_real_strong:0.5567,corrrect_unlabeled_num:380911.0,pro_above_threshold_num:389529.0,unlabelled_weak_top1_acc:92.34008686244488,unlabelled_weak_top5_acc:99.70724949985743  \n","[2022-04-24 22:20:08,122][experiments.experiment][INFO] - [EMA] Epoch 49. [Validation] raw_testing_loss: 0.3240, raw test Top1 acc:89.98, raw test Top5 acc: 99.7, ema_testing_loss: 0.2396, ema test Top1 acc:93.2, ema test Top5 acc: 99.82\n","[2022-04-24 22:20:08,218][experiments.experiment][INFO] - [Checkpoints] Epoch 49, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 22:20:08,223][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 22:27:37,192][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 50: use 449.07092785835266 seconds\n","--- Optimizer learning rate changed from 2.52e-02 to 2.50e-02 ---\n","[2022-04-24 22:27:37,294][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 22:27:38,637][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 22:27:38,637][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 22:27:39,969][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 22:27:39,970][experiments.experiment][INFO] - [EMA] Epoch 50.[Train] time:449.07092785835266 seconds, lr:0.0250, train_loss: 1.7658, unlabeled_losses_real_strong:0.5527,corrrect_unlabeled_num:381400.0,pro_above_threshold_num:389880.0,unlabelled_weak_top1_acc:92.41441883891821,unlabelled_weak_top5_acc:99.700927965343  \n","[2022-04-24 22:27:39,973][experiments.experiment][INFO] - [EMA] Epoch 50. [Validation] raw_testing_loss: 0.4168, raw test Top1 acc:89.2, raw test Top5 acc: 99.5, ema_testing_loss: 0.2363, ema test Top1 acc:93.4, ema test Top5 acc: 99.78\n","[2022-04-24 22:27:39,974][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 22:35:10,834][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 51: use 450.9641811847687 seconds\n","--- Optimizer learning rate changed from 2.50e-02 to 2.48e-02 ---\n","[2022-04-24 22:35:10,938][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 22:35:12,297][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 22:35:12,298][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 22:35:13,635][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 22:35:13,637][experiments.experiment][INFO] - [EMA] Epoch 51.[Train] time:450.9641811847687 seconds, lr:0.0248, train_loss: 1.7638, unlabeled_losses_real_strong:0.5489,corrrect_unlabeled_num:381876.0,pro_above_threshold_num:390428.0,unlabelled_weak_top1_acc:92.46586290001869,unlabelled_weak_top5_acc:99.71030139178038  \n","[2022-04-24 22:35:13,639][experiments.experiment][INFO] - [EMA] Epoch 51. [Validation] raw_testing_loss: 0.3254, raw test Top1 acc:90.4, raw test Top5 acc: 99.72, ema_testing_loss: 0.2358, ema test Top1 acc:93.4, ema test Top5 acc: 99.8\n","[2022-04-24 22:35:13,735][experiments.experiment][INFO] - [Checkpoints] Epoch 51, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 22:35:13,736][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 22:42:42,615][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 52: use 448.9817216396332 seconds\n","--- Optimizer learning rate changed from 2.48e-02 to 2.46e-02 ---\n","[2022-04-24 22:42:42,718][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 22:42:44,036][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 22:42:44,036][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 22:42:45,391][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 22:42:45,393][experiments.experiment][INFO] - [EMA] Epoch 52.[Train] time:448.9817216396332 seconds, lr:0.0246, train_loss: 1.7606, unlabeled_losses_real_strong:0.5453,corrrect_unlabeled_num:382970.0,pro_above_threshold_num:391345.0,unlabelled_weak_top1_acc:92.61583494395018,unlabelled_weak_top5_acc:99.72534209489822  \n","[2022-04-24 22:42:45,395][experiments.experiment][INFO] - [EMA] Epoch 52. [Validation] raw_testing_loss: 0.3656, raw test Top1 acc:89.38, raw test Top5 acc: 99.48, ema_testing_loss: 0.2335, ema test Top1 acc:93.48, ema test Top5 acc: 99.84\n","[2022-04-24 22:42:45,396][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 22:50:13,183][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 53: use 447.88845348358154 seconds\n","--- Optimizer learning rate changed from 2.46e-02 to 2.44e-02 ---\n","[2022-04-24 22:50:13,284][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 22:50:14,685][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 22:50:14,685][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 22:50:16,033][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 22:50:16,034][experiments.experiment][INFO] - [EMA] Epoch 53.[Train] time:447.88845348358154 seconds, lr:0.0244, train_loss: 1.7707, unlabeled_losses_real_strong:0.5419,corrrect_unlabeled_num:383882.0,pro_above_threshold_num:392247.0,unlabelled_weak_top1_acc:92.65507180988789,unlabelled_weak_top5_acc:99.72120048105717  \n","[2022-04-24 22:50:16,035][experiments.experiment][INFO] - [EMA] Epoch 53. [Validation] raw_testing_loss: 0.3595, raw test Top1 acc:89.72, raw test Top5 acc: 99.52, ema_testing_loss: 0.2317, ema test Top1 acc:93.7, ema test Top5 acc: 99.84\n","[2022-04-24 22:50:16,141][experiments.experiment][INFO] - [Checkpoints] Epoch 53, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 22:50:16,151][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 22:57:46,031][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 54: use 449.9858386516571 seconds\n","--- Optimizer learning rate changed from 2.44e-02 to 2.42e-02 ---\n","[2022-04-24 22:57:46,137][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 22:57:47,491][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 22:57:47,492][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 22:57:48,878][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 22:57:48,879][experiments.experiment][INFO] - [EMA] Epoch 54.[Train] time:449.9858386516571 seconds, lr:0.0242, train_loss: 1.7498, unlabeled_losses_real_strong:0.5409,corrrect_unlabeled_num:383747.0,pro_above_threshold_num:392082.0,unlabelled_weak_top1_acc:92.67076654732227,unlabelled_weak_top5_acc:99.74190886318684  \n","[2022-04-24 22:57:48,880][experiments.experiment][INFO] - [EMA] Epoch 54. [Validation] raw_testing_loss: 0.4055, raw test Top1 acc:89.08, raw test Top5 acc: 99.38, ema_testing_loss: 0.2322, ema test Top1 acc:93.7, ema test Top5 acc: 99.84\n","[2022-04-24 22:57:48,881][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 23:05:18,394][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 55: use 449.62119460105896 seconds\n","--- Optimizer learning rate changed from 2.42e-02 to 2.40e-02 ---\n","[2022-04-24 23:05:18,503][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 23:05:19,843][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 23:05:19,844][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 23:05:21,180][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 23:05:21,182][experiments.experiment][INFO] - [EMA] Epoch 55.[Train] time:449.62119460105896 seconds, lr:0.0240, train_loss: 1.7664, unlabeled_losses_real_strong:0.5401,corrrect_unlabeled_num:384996.0,pro_above_threshold_num:393633.0,unlabelled_weak_top1_acc:92.6668428555131,unlabelled_weak_top5_acc:99.72490628063679  \n","[2022-04-24 23:05:21,184][experiments.experiment][INFO] - [EMA] Epoch 55. [Validation] raw_testing_loss: 0.4451, raw test Top1 acc:88.38, raw test Top5 acc: 99.7, ema_testing_loss: 0.2335, ema test Top1 acc:93.56, ema test Top5 acc: 99.86\n","[2022-04-24 23:05:21,281][experiments.experiment][INFO] - [Checkpoints] Epoch 55, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 23:05:21,284][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 23:12:52,930][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 56: use 451.74682879447937 seconds\n","--- Optimizer learning rate changed from 2.40e-02 to 2.38e-02 ---\n","[2022-04-24 23:12:53,031][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 23:12:54,410][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 23:12:54,411][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 23:12:55,774][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 23:12:55,776][experiments.experiment][INFO] - [EMA] Epoch 56.[Train] time:451.74682879447937 seconds, lr:0.0238, train_loss: 1.7428, unlabeled_losses_real_strong:0.5337,corrrect_unlabeled_num:385200.0,pro_above_threshold_num:393580.0,unlabelled_weak_top1_acc:92.77147454768419,unlabelled_weak_top5_acc:99.73667730391026  \n","[2022-04-24 23:12:55,779][experiments.experiment][INFO] - [EMA] Epoch 56. [Validation] raw_testing_loss: 0.3897, raw test Top1 acc:89.52, raw test Top5 acc: 99.66, ema_testing_loss: 0.2311, ema test Top1 acc:93.46, ema test Top5 acc: 99.82\n","[2022-04-24 23:12:55,779][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 23:20:27,388][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 57: use 451.714049577713 seconds\n","--- Optimizer learning rate changed from 2.38e-02 to 2.36e-02 ---\n","[2022-04-24 23:20:27,493][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 23:20:28,927][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 23:20:28,927][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 23:20:30,291][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 23:20:30,292][experiments.experiment][INFO] - [EMA] Epoch 57.[Train] time:451.714049577713 seconds, lr:0.0236, train_loss: 1.7418, unlabeled_losses_real_strong:0.5320,corrrect_unlabeled_num:385028.0,pro_above_threshold_num:393263.0,unlabelled_weak_top1_acc:92.75599785149097,unlabelled_weak_top5_acc:99.71858458220959  \n","[2022-04-24 23:20:30,294][experiments.experiment][INFO] - [EMA] Epoch 57. [Validation] raw_testing_loss: 0.3629, raw test Top1 acc:90.06, raw test Top5 acc: 99.66, ema_testing_loss: 0.2294, ema test Top1 acc:93.58, ema test Top5 acc: 99.82\n","[2022-04-24 23:20:30,391][experiments.experiment][INFO] - [Checkpoints] Epoch 57, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 23:20:30,399][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 23:28:00,914][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 58: use 450.62533617019653 seconds\n","--- Optimizer learning rate changed from 2.36e-02 to 2.34e-02 ---\n","[2022-04-24 23:28:01,024][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 23:28:02,481][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 23:28:02,481][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 23:28:03,871][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 23:28:03,873][experiments.experiment][INFO] - [EMA] Epoch 58.[Train] time:450.62533617019653 seconds, lr:0.0234, train_loss: 1.7363, unlabeled_losses_real_strong:0.5307,corrrect_unlabeled_num:386074.0,pro_above_threshold_num:394402.0,unlabelled_weak_top1_acc:92.80046612024307,unlabelled_weak_top5_acc:99.72621405869722  \n","[2022-04-24 23:28:03,875][experiments.experiment][INFO] - [EMA] Epoch 58. [Validation] raw_testing_loss: 0.4683, raw test Top1 acc:87.98, raw test Top5 acc: 99.5, ema_testing_loss: 0.2278, ema test Top1 acc:93.74, ema test Top5 acc: 99.84\n","[2022-04-24 23:28:03,876][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 23:35:35,680][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 59: use 451.9037163257599 seconds\n","--- Optimizer learning rate changed from 2.34e-02 to 2.32e-02 ---\n","[2022-04-24 23:35:35,780][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 23:35:37,245][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 23:35:37,245][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 23:35:38,612][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 23:35:38,614][experiments.experiment][INFO] - [EMA] Epoch 59.[Train] time:451.9037163257599 seconds, lr:0.0232, train_loss: 1.7345, unlabeled_losses_real_strong:0.5281,corrrect_unlabeled_num:387042.0,pro_above_threshold_num:395498.0,unlabelled_weak_top1_acc:92.86346323788166,unlabelled_weak_top5_acc:99.722072429955  \n","[2022-04-24 23:35:38,618][experiments.experiment][INFO] - [EMA] Epoch 59. [Validation] raw_testing_loss: 0.3263, raw test Top1 acc:90.74, raw test Top5 acc: 99.72, ema_testing_loss: 0.2281, ema test Top1 acc:93.86, ema test Top5 acc: 99.86\n","[2022-04-24 23:35:38,711][experiments.experiment][INFO] - [Checkpoints] Epoch 59, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 23:35:38,719][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 23:43:08,234][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 60: use 449.6211965084076 seconds\n","--- Optimizer learning rate changed from 2.32e-02 to 2.30e-02 ---\n","[2022-04-24 23:43:08,340][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 23:43:09,746][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 23:43:09,746][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 23:43:11,132][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 23:43:11,134][experiments.experiment][INFO] - [EMA] Epoch 60.[Train] time:449.6211965084076 seconds, lr:0.0230, train_loss: 1.7283, unlabeled_losses_real_strong:0.5269,corrrect_unlabeled_num:386519.0,pro_above_threshold_num:394852.0,unlabelled_weak_top1_acc:92.91163741797209,unlabelled_weak_top5_acc:99.72163647413254  \n","[2022-04-24 23:43:11,137][experiments.experiment][INFO] - [EMA] Epoch 60. [Validation] raw_testing_loss: 0.3480, raw test Top1 acc:90.82, raw test Top5 acc: 99.7, ema_testing_loss: 0.2291, ema test Top1 acc:93.64, ema test Top5 acc: 99.86\n","[2022-04-24 23:43:11,137][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 23:50:42,736][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 61: use 451.70464849472046 seconds\n","--- Optimizer learning rate changed from 2.30e-02 to 2.27e-02 ---\n","[2022-04-24 23:50:42,842][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 23:50:44,204][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 23:50:44,205][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 23:50:45,558][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 23:50:45,560][experiments.experiment][INFO] - [EMA] Epoch 61.[Train] time:451.70464849472046 seconds, lr:0.0227, train_loss: 1.7268, unlabeled_losses_real_strong:0.5241,corrrect_unlabeled_num:387501.0,pro_above_threshold_num:395744.0,unlabelled_weak_top1_acc:92.96460725367069,unlabelled_weak_top5_acc:99.73013785481453  \n","[2022-04-24 23:50:45,562][experiments.experiment][INFO] - [EMA] Epoch 61. [Validation] raw_testing_loss: 0.2986, raw test Top1 acc:91.0, raw test Top5 acc: 99.66, ema_testing_loss: 0.2250, ema test Top1 acc:93.94, ema test Top5 acc: 99.84\n","[2022-04-24 23:50:45,658][experiments.experiment][INFO] - [Checkpoints] Epoch 61, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-24 23:50:45,659][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-24 23:58:16,400][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 62: use 450.84119296073914 seconds\n","--- Optimizer learning rate changed from 2.27e-02 to 2.25e-02 ---\n","[2022-04-24 23:58:16,500][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 23:58:17,853][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-24 23:58:17,854][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-24 23:58:19,251][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-24 23:58:19,252][experiments.experiment][INFO] - [EMA] Epoch 62.[Train] time:450.84119296073914 seconds, lr:0.0225, train_loss: 1.7200, unlabeled_losses_real_strong:0.5207,corrrect_unlabeled_num:388193.0,pro_above_threshold_num:396570.0,unlabelled_weak_top1_acc:93.02128281444311,unlabelled_weak_top5_acc:99.73558728396893  \n","[2022-04-24 23:58:19,253][experiments.experiment][INFO] - [EMA] Epoch 62. [Validation] raw_testing_loss: 0.3384, raw test Top1 acc:90.06, raw test Top5 acc: 99.66, ema_testing_loss: 0.2229, ema test Top1 acc:93.84, ema test Top5 acc: 99.92\n","[2022-04-24 23:58:19,255][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 00:05:48,396][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 63: use 449.24093294143677 seconds\n","--- Optimizer learning rate changed from 2.25e-02 to 2.23e-02 ---\n","[2022-04-25 00:05:48,496][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 00:05:49,948][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 00:05:49,949][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 00:05:51,282][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 00:05:51,283][experiments.experiment][INFO] - [EMA] Epoch 63.[Train] time:449.24093294143677 seconds, lr:0.0223, train_loss: 1.7016, unlabeled_losses_real_strong:0.5162,corrrect_unlabeled_num:388744.0,pro_above_threshold_num:396808.0,unlabelled_weak_top1_acc:93.11196351796389,unlabelled_weak_top5_acc:99.74561457335949  \n","[2022-04-25 00:05:51,284][experiments.experiment][INFO] - [EMA] Epoch 63. [Validation] raw_testing_loss: 0.3529, raw test Top1 acc:89.84, raw test Top5 acc: 99.74, ema_testing_loss: 0.2206, ema test Top1 acc:93.9, ema test Top5 acc: 99.86\n","[2022-04-25 00:05:51,382][experiments.experiment][INFO] - [Checkpoints] Epoch 63, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 00:05:51,391][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 00:13:20,727][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 64: use 449.4372682571411 seconds\n","--- Optimizer learning rate changed from 2.23e-02 to 2.21e-02 ---\n","[2022-04-25 00:13:20,828][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 00:13:22,248][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 00:13:22,249][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 00:13:23,616][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 00:13:23,617][experiments.experiment][INFO] - [EMA] Epoch 64.[Train] time:449.4372682571411 seconds, lr:0.0221, train_loss: 1.7165, unlabeled_losses_real_strong:0.5144,corrrect_unlabeled_num:389559.0,pro_above_threshold_num:397769.0,unlabelled_weak_top1_acc:93.12024690210819,unlabelled_weak_top5_acc:99.74321681261063  \n","[2022-04-25 00:13:23,620][experiments.experiment][INFO] - [EMA] Epoch 64. [Validation] raw_testing_loss: 0.4027, raw test Top1 acc:89.62, raw test Top5 acc: 99.56, ema_testing_loss: 0.2219, ema test Top1 acc:93.88, ema test Top5 acc: 99.88\n","[2022-04-25 00:13:23,621][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 00:20:53,155][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 65: use 449.6370725631714 seconds\n","--- Optimizer learning rate changed from 2.21e-02 to 2.18e-02 ---\n","[2022-04-25 00:20:53,258][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 00:20:54,670][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 00:20:54,671][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 00:20:56,008][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 00:20:56,010][experiments.experiment][INFO] - [EMA] Epoch 65.[Train] time:449.6370725631714 seconds, lr:0.0218, train_loss: 1.7128, unlabeled_losses_real_strong:0.5114,corrrect_unlabeled_num:390470.0,pro_above_threshold_num:398463.0,unlabelled_weak_top1_acc:93.27239879220724,unlabelled_weak_top5_acc:99.75041023641825  \n","[2022-04-25 00:20:56,013][experiments.experiment][INFO] - [EMA] Epoch 65. [Validation] raw_testing_loss: 0.3931, raw test Top1 acc:89.14, raw test Top5 acc: 99.56, ema_testing_loss: 0.2198, ema test Top1 acc:94.04, ema test Top5 acc: 99.88\n","[2022-04-25 00:20:56,107][experiments.experiment][INFO] - [Checkpoints] Epoch 65, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 00:20:56,115][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 00:28:26,855][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 66: use 450.8430378437042 seconds\n","--- Optimizer learning rate changed from 2.18e-02 to 2.16e-02 ---\n","[2022-04-25 00:28:26,959][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 00:28:28,293][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 00:28:28,294][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 00:28:29,649][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 00:28:29,650][experiments.experiment][INFO] - [EMA] Epoch 66.[Train] time:450.8430378437042 seconds, lr:0.0216, train_loss: 1.6987, unlabeled_losses_real_strong:0.5084,corrrect_unlabeled_num:389813.0,pro_above_threshold_num:397967.0,unlabelled_weak_top1_acc:93.19697687774897,unlabelled_weak_top5_acc:99.75280806422234  \n","[2022-04-25 00:28:29,653][experiments.experiment][INFO] - [EMA] Epoch 66. [Validation] raw_testing_loss: 0.2895, raw test Top1 acc:91.72, raw test Top5 acc: 99.82, ema_testing_loss: 0.2253, ema test Top1 acc:93.96, ema test Top5 acc: 99.86\n","[2022-04-25 00:28:29,654][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 00:35:56,510][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 67: use 446.96268129348755 seconds\n","--- Optimizer learning rate changed from 2.16e-02 to 2.14e-02 ---\n","[2022-04-25 00:35:56,616][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 00:35:57,974][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 00:35:57,974][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 00:35:59,344][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 00:35:59,346][experiments.experiment][INFO] - [EMA] Epoch 67.[Train] time:446.96268129348755 seconds, lr:0.0214, train_loss: 1.7007, unlabeled_losses_real_strong:0.5091,corrrect_unlabeled_num:390190.0,pro_above_threshold_num:398482.0,unlabelled_weak_top1_acc:93.19457905739546,unlabelled_weak_top5_acc:99.74212693423033  \n","[2022-04-25 00:35:59,348][experiments.experiment][INFO] - [EMA] Epoch 67. [Validation] raw_testing_loss: 0.3366, raw test Top1 acc:90.52, raw test Top5 acc: 99.62, ema_testing_loss: 0.2220, ema test Top1 acc:94.0, ema test Top5 acc: 99.86\n","[2022-04-25 00:35:59,446][experiments.experiment][INFO] - [Checkpoints] Epoch 67, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 00:35:59,454][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 00:43:28,583][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 68: use 449.23534774780273 seconds\n","--- Optimizer learning rate changed from 2.14e-02 to 2.11e-02 ---\n","[2022-04-25 00:43:28,690][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 00:43:30,024][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 00:43:30,024][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 00:43:31,389][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 00:43:31,390][experiments.experiment][INFO] - [EMA] Epoch 68.[Train] time:449.23534774780273 seconds, lr:0.0211, train_loss: 1.6855, unlabeled_losses_real_strong:0.5052,corrrect_unlabeled_num:391086.0,pro_above_threshold_num:399095.0,unlabelled_weak_top1_acc:93.33866554498672,unlabelled_weak_top5_acc:99.75367990881205  \n","[2022-04-25 00:43:31,392][experiments.experiment][INFO] - [EMA] Epoch 68. [Validation] raw_testing_loss: 0.3336, raw test Top1 acc:90.6, raw test Top5 acc: 99.78, ema_testing_loss: 0.2173, ema test Top1 acc:93.96, ema test Top5 acc: 99.84\n","[2022-04-25 00:43:31,393][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 00:51:01,274][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 69: use 449.9819128513336 seconds\n","--- Optimizer learning rate changed from 2.11e-02 to 2.09e-02 ---\n","[2022-04-25 00:51:01,375][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 00:51:02,741][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 00:51:02,742][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 00:51:04,125][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 00:51:04,127][experiments.experiment][INFO] - [EMA] Epoch 69.[Train] time:449.9819128513336 seconds, lr:0.0209, train_loss: 1.6765, unlabeled_losses_real_strong:0.5018,corrrect_unlabeled_num:391241.0,pro_above_threshold_num:399385.0,unlabelled_weak_top1_acc:93.33561377227306,unlabelled_weak_top5_acc:99.75062814354897  \n","[2022-04-25 00:51:04,129][experiments.experiment][INFO] - [EMA] Epoch 69. [Validation] raw_testing_loss: 0.2953, raw test Top1 acc:90.84, raw test Top5 acc: 99.74, ema_testing_loss: 0.2146, ema test Top1 acc:94.1, ema test Top5 acc: 99.82\n","[2022-04-25 00:51:04,228][experiments.experiment][INFO] - [Checkpoints] Epoch 69, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 00:51:04,229][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 00:58:35,296][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 70: use 451.1742699146271 seconds\n","--- Optimizer learning rate changed from 2.09e-02 to 2.06e-02 ---\n","[2022-04-25 00:58:35,403][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 00:58:36,855][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 00:58:36,855][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 00:58:38,227][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 00:58:38,229][experiments.experiment][INFO] - [EMA] Epoch 70.[Train] time:451.1742699146271 seconds, lr:0.0206, train_loss: 1.6762, unlabeled_losses_real_strong:0.4996,corrrect_unlabeled_num:391318.0,pro_above_threshold_num:399351.0,unlabelled_weak_top1_acc:93.42498672753572,unlabelled_weak_top5_acc:99.75389793515205  \n","[2022-04-25 00:58:38,232][experiments.experiment][INFO] - [EMA] Epoch 70. [Validation] raw_testing_loss: 0.3443, raw test Top1 acc:90.44, raw test Top5 acc: 99.62, ema_testing_loss: 0.2129, ema test Top1 acc:93.96, ema test Top5 acc: 99.84\n","[2022-04-25 00:58:38,232][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 01:06:09,237][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 71: use 451.0995092391968 seconds\n","--- Optimizer learning rate changed from 2.06e-02 to 2.04e-02 ---\n","[2022-04-25 01:06:09,332][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 01:06:10,690][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 01:06:10,691][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 01:06:12,042][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 01:06:12,043][experiments.experiment][INFO] - [EMA] Epoch 71.[Train] time:451.0995092391968 seconds, lr:0.0204, train_loss: 1.6779, unlabeled_losses_real_strong:0.4963,corrrect_unlabeled_num:392793.0,pro_above_threshold_num:400756.0,unlabelled_weak_top1_acc:93.49844692647457,unlabelled_weak_top5_acc:99.75847560167313  \n","[2022-04-25 01:06:12,045][experiments.experiment][INFO] - [EMA] Epoch 71. [Validation] raw_testing_loss: 0.3487, raw test Top1 acc:89.96, raw test Top5 acc: 99.6, ema_testing_loss: 0.2108, ema test Top1 acc:94.14, ema test Top5 acc: 99.84\n","[2022-04-25 01:06:12,148][experiments.experiment][INFO] - [Checkpoints] Epoch 71, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 01:06:12,157][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 01:13:42,076][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 72: use 450.0218839645386 seconds\n","--- Optimizer learning rate changed from 2.04e-02 to 2.01e-02 ---\n","[2022-04-25 01:13:42,179][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 01:13:43,543][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 01:13:43,544][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 01:13:44,925][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 01:13:44,927][experiments.experiment][INFO] - [EMA] Epoch 72.[Train] time:450.0218839645386 seconds, lr:0.0201, train_loss: 1.6758, unlabeled_losses_real_strong:0.4951,corrrect_unlabeled_num:392101.0,pro_above_threshold_num:400128.0,unlabelled_weak_top1_acc:93.44678501039743,unlabelled_weak_top5_acc:99.76784882694483  \n","[2022-04-25 01:13:44,928][experiments.experiment][INFO] - [EMA] Epoch 72. [Validation] raw_testing_loss: 0.3537, raw test Top1 acc:90.02, raw test Top5 acc: 99.62, ema_testing_loss: 0.2108, ema test Top1 acc:94.14, ema test Top5 acc: 99.86\n","[2022-04-25 01:13:44,930][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 01:21:15,460][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 73: use 450.6346879005432 seconds\n","--- Optimizer learning rate changed from 2.01e-02 to 1.99e-02 ---\n","[2022-04-25 01:21:15,565][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 01:21:16,981][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 01:21:16,982][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 01:21:18,401][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 01:21:18,403][experiments.experiment][INFO] - [EMA] Epoch 73.[Train] time:450.6346879005432 seconds, lr:0.0199, train_loss: 1.6759, unlabeled_losses_real_strong:0.4957,corrrect_unlabeled_num:393036.0,pro_above_threshold_num:401162.0,unlabelled_weak_top1_acc:93.4940872117877,unlabelled_weak_top5_acc:99.75259009003639  \n","[2022-04-25 01:21:18,405][experiments.experiment][INFO] - [EMA] Epoch 73. [Validation] raw_testing_loss: 0.2918, raw test Top1 acc:91.78, raw test Top5 acc: 99.72, ema_testing_loss: 0.2163, ema test Top1 acc:93.92, ema test Top5 acc: 99.88\n","[2022-04-25 01:21:18,501][experiments.experiment][INFO] - [Checkpoints] Epoch 73, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 01:21:18,512][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 01:28:50,387][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 74: use 451.981725692749 seconds\n","--- Optimizer learning rate changed from 1.99e-02 to 1.96e-02 ---\n","[2022-04-25 01:28:50,494][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 01:28:51,913][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 01:28:51,913][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 01:28:53,291][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 01:28:53,292][experiments.experiment][INFO] - [EMA] Epoch 74.[Train] time:451.981725692749 seconds, lr:0.0196, train_loss: 1.6632, unlabeled_losses_real_strong:0.4909,corrrect_unlabeled_num:393326.0,pro_above_threshold_num:401419.0,unlabelled_weak_top1_acc:93.5553404763341,unlabelled_weak_top5_acc:99.74714047461748  \n","[2022-04-25 01:28:53,295][experiments.experiment][INFO] - [EMA] Epoch 74. [Validation] raw_testing_loss: 0.3946, raw test Top1 acc:89.32, raw test Top5 acc: 99.68, ema_testing_loss: 0.2126, ema test Top1 acc:94.42, ema test Top5 acc: 99.86\n","[2022-04-25 01:28:53,296][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 01:36:24,730][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 75: use 451.53901195526123 seconds\n","--- Optimizer learning rate changed from 1.96e-02 to 1.93e-02 ---\n","[2022-04-25 01:36:24,835][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 01:36:26,249][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 01:36:26,249][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 01:36:27,655][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 01:36:27,657][experiments.experiment][INFO] - [EMA] Epoch 75.[Train] time:451.53901195526123 seconds, lr:0.0193, train_loss: 1.6556, unlabeled_losses_real_strong:0.4897,corrrect_unlabeled_num:394224.0,pro_above_threshold_num:402401.0,unlabelled_weak_top1_acc:93.55686619132757,unlabelled_weak_top5_acc:99.77896597236395  \n","[2022-04-25 01:36:27,660][experiments.experiment][INFO] - [EMA] Epoch 75. [Validation] raw_testing_loss: 0.3505, raw test Top1 acc:90.2, raw test Top5 acc: 99.78, ema_testing_loss: 0.2181, ema test Top1 acc:94.14, ema test Top5 acc: 99.86\n","[2022-04-25 01:36:27,758][experiments.experiment][INFO] - [Checkpoints] Epoch 75, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 01:36:27,768][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 01:43:59,796][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 76: use 452.12895703315735 seconds\n","--- Optimizer learning rate changed from 1.93e-02 to 1.91e-02 ---\n","[2022-04-25 01:43:59,897][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 01:44:01,278][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 01:44:01,278][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 01:44:02,605][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 01:44:02,606][experiments.experiment][INFO] - [EMA] Epoch 76.[Train] time:452.12895703315735 seconds, lr:0.0191, train_loss: 1.6534, unlabeled_losses_real_strong:0.4878,corrrect_unlabeled_num:394219.0,pro_above_threshold_num:402230.0,unlabelled_weak_top1_acc:93.6052583605051,unlabelled_weak_top5_acc:99.76675894111395  \n","[2022-04-25 01:44:02,608][experiments.experiment][INFO] - [EMA] Epoch 76. [Validation] raw_testing_loss: 0.3155, raw test Top1 acc:91.02, raw test Top5 acc: 99.7, ema_testing_loss: 0.2183, ema test Top1 acc:94.2, ema test Top5 acc: 99.86\n","[2022-04-25 01:44:02,610][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 01:51:33,387][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 77: use 450.88829278945923 seconds\n","--- Optimizer learning rate changed from 1.91e-02 to 1.88e-02 ---\n","[2022-04-25 01:51:33,498][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 01:51:34,962][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 01:51:34,962][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 01:51:36,359][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 01:51:36,361][experiments.experiment][INFO] - [EMA] Epoch 77.[Train] time:450.88829278945923 seconds, lr:0.0188, train_loss: 1.6452, unlabeled_losses_real_strong:0.4827,corrrect_unlabeled_num:395087.0,pro_above_threshold_num:403175.0,unlabelled_weak_top1_acc:93.63316015899181,unlabelled_weak_top5_acc:99.76305314898491  \n","[2022-04-25 01:51:36,363][experiments.experiment][INFO] - [EMA] Epoch 77. [Validation] raw_testing_loss: 0.3186, raw test Top1 acc:90.86, raw test Top5 acc: 99.54, ema_testing_loss: 0.2134, ema test Top1 acc:94.42, ema test Top5 acc: 99.9\n","[2022-04-25 01:51:36,458][experiments.experiment][INFO] - [Checkpoints] Epoch 77, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 01:51:36,460][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 01:59:09,440][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 78: use 453.0787823200226 seconds\n","--- Optimizer learning rate changed from 1.88e-02 to 1.85e-02 ---\n","[2022-04-25 01:59:09,539][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 01:59:10,921][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 01:59:10,921][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 01:59:12,366][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 01:59:12,368][experiments.experiment][INFO] - [EMA] Epoch 78.[Train] time:453.0787823200226 seconds, lr:0.0185, train_loss: 1.6317, unlabeled_losses_real_strong:0.4814,corrrect_unlabeled_num:395256.0,pro_above_threshold_num:403062.0,unlabelled_weak_top1_acc:93.74215156584978,unlabelled_weak_top5_acc:99.77765813469887  \n","[2022-04-25 01:59:12,369][experiments.experiment][INFO] - [EMA] Epoch 78. [Validation] raw_testing_loss: 0.4136, raw test Top1 acc:88.4, raw test Top5 acc: 99.7, ema_testing_loss: 0.2044, ema test Top1 acc:94.58, ema test Top5 acc: 99.86\n","[2022-04-25 01:59:12,371][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 02:06:48,815][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 79: use 456.54352140426636 seconds\n","--- Optimizer learning rate changed from 1.85e-02 to 1.83e-02 ---\n","[2022-04-25 02:06:48,914][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 02:06:50,394][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 02:06:50,394][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 02:06:51,777][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 02:06:51,779][experiments.experiment][INFO] - [EMA] Epoch 79.[Train] time:456.54352140426636 seconds, lr:0.0183, train_loss: 1.6454, unlabeled_losses_real_strong:0.4780,corrrect_unlabeled_num:396180.0,pro_above_threshold_num:404050.0,unlabelled_weak_top1_acc:93.7872738391161,unlabelled_weak_top5_acc:99.77373450249434  \n","[2022-04-25 02:06:51,781][experiments.experiment][INFO] - [EMA] Epoch 79. [Validation] raw_testing_loss: 0.3078, raw test Top1 acc:90.96, raw test Top5 acc: 99.76, ema_testing_loss: 0.2035, ema test Top1 acc:94.4, ema test Top5 acc: 99.84\n","[2022-04-25 02:06:51,883][experiments.experiment][INFO] - [Checkpoints] Epoch 79, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 02:06:51,895][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 02:14:27,692][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 80: use 455.897337436676 seconds\n","--- Optimizer learning rate changed from 1.83e-02 to 1.80e-02 ---\n","[2022-04-25 02:14:27,792][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 02:14:29,159][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 02:14:29,160][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 02:14:30,633][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 02:14:30,635][experiments.experiment][INFO] - [EMA] Epoch 80.[Train] time:455.897337436676 seconds, lr:0.0180, train_loss: 1.6316, unlabeled_losses_real_strong:0.4748,corrrect_unlabeled_num:397016.0,pro_above_threshold_num:404985.0,unlabelled_weak_top1_acc:93.85833621770144,unlabelled_weak_top5_acc:99.77700410783291  \n","[2022-04-25 02:14:30,637][experiments.experiment][INFO] - [EMA] Epoch 80. [Validation] raw_testing_loss: 0.3058, raw test Top1 acc:91.6, raw test Top5 acc: 99.74, ema_testing_loss: 0.2053, ema test Top1 acc:94.48, ema test Top5 acc: 99.86\n","[2022-04-25 02:14:30,638][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 02:22:12,921][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 81: use 462.38791680336 seconds\n","--- Optimizer learning rate changed from 1.80e-02 to 1.77e-02 ---\n","[2022-04-25 02:22:13,026][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 02:22:14,393][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 02:22:14,394][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 02:22:15,816][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 02:22:15,818][experiments.experiment][INFO] - [EMA] Epoch 81.[Train] time:462.38791680336 seconds, lr:0.0177, train_loss: 1.6259, unlabeled_losses_real_strong:0.4716,corrrect_unlabeled_num:397085.0,pro_above_threshold_num:404878.0,unlabelled_weak_top1_acc:93.89822724461555,unlabelled_weak_top5_acc:99.78267172724009  \n","[2022-04-25 02:22:15,820][experiments.experiment][INFO] - [EMA] Epoch 81. [Validation] raw_testing_loss: 0.3167, raw test Top1 acc:91.28, raw test Top5 acc: 99.68, ema_testing_loss: 0.2024, ema test Top1 acc:94.42, ema test Top5 acc: 99.9\n","[2022-04-25 02:22:15,927][experiments.experiment][INFO] - [Checkpoints] Epoch 81, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 02:22:15,936][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 02:29:51,822][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 82: use 455.99500465393066 seconds\n","--- Optimizer learning rate changed from 1.77e-02 to 1.74e-02 ---\n","[2022-04-25 02:29:51,931][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 02:29:53,374][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 02:29:53,374][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 02:29:54,801][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 02:29:54,803][experiments.experiment][INFO] - [EMA] Epoch 82.[Train] time:455.99500465393066 seconds, lr:0.0174, train_loss: 1.6222, unlabeled_losses_real_strong:0.4719,corrrect_unlabeled_num:397256.0,pro_above_threshold_num:405242.0,unlabelled_weak_top1_acc:93.85572046041489,unlabelled_weak_top5_acc:99.77373438328505  \n","[2022-04-25 02:29:54,804][experiments.experiment][INFO] - [EMA] Epoch 82. [Validation] raw_testing_loss: 0.2753, raw test Top1 acc:91.92, raw test Top5 acc: 99.76, ema_testing_loss: 0.2017, ema test Top1 acc:94.34, ema test Top5 acc: 99.9\n","[2022-04-25 02:29:54,806][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 02:37:29,197][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 83: use 454.48960065841675 seconds\n","--- Optimizer learning rate changed from 1.74e-02 to 1.72e-02 ---\n","[2022-04-25 02:37:29,296][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 02:37:30,647][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 02:37:30,648][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 02:37:32,009][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 02:37:32,010][experiments.experiment][INFO] - [EMA] Epoch 83.[Train] time:454.48960065841675 seconds, lr:0.0172, train_loss: 1.6166, unlabeled_losses_real_strong:0.4676,corrrect_unlabeled_num:398018.0,pro_above_threshold_num:406034.0,unlabelled_weak_top1_acc:93.91457587480545,unlabelled_weak_top5_acc:99.78768528997898  \n","[2022-04-25 02:37:32,012][experiments.experiment][INFO] - [EMA] Epoch 83. [Validation] raw_testing_loss: 0.2761, raw test Top1 acc:91.96, raw test Top5 acc: 99.66, ema_testing_loss: 0.2034, ema test Top1 acc:94.66, ema test Top5 acc: 99.88\n","[2022-04-25 02:37:32,110][experiments.experiment][INFO] - [Checkpoints] Epoch 83, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 02:37:32,112][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 02:45:09,670][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 84: use 457.6728460788727 seconds\n","--- Optimizer learning rate changed from 1.72e-02 to 1.69e-02 ---\n","[2022-04-25 02:45:09,785][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 02:45:11,182][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 02:45:11,183][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 02:45:12,565][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 02:45:12,567][experiments.experiment][INFO] - [EMA] Epoch 84.[Train] time:457.6728460788727 seconds, lr:0.0169, train_loss: 1.6120, unlabeled_losses_real_strong:0.4665,corrrect_unlabeled_num:398355.0,pro_above_threshold_num:406364.0,unlabelled_weak_top1_acc:93.99217769503593,unlabelled_weak_top5_acc:99.79269886761904  \n","[2022-04-25 02:45:12,569][experiments.experiment][INFO] - [EMA] Epoch 84. [Validation] raw_testing_loss: 0.2679, raw test Top1 acc:91.8, raw test Top5 acc: 99.76, ema_testing_loss: 0.2068, ema test Top1 acc:94.44, ema test Top5 acc: 99.9\n","[2022-04-25 02:45:12,570][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 02:52:53,981][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 85: use 461.51803970336914 seconds\n","--- Optimizer learning rate changed from 1.69e-02 to 1.66e-02 ---\n","[2022-04-25 02:52:54,088][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 02:52:55,500][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 02:52:55,500][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 02:52:56,904][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 02:52:56,905][experiments.experiment][INFO] - [EMA] Epoch 85.[Train] time:461.51803970336914 seconds, lr:0.0166, train_loss: 1.6044, unlabeled_losses_real_strong:0.4641,corrrect_unlabeled_num:398881.0,pro_above_threshold_num:406763.0,unlabelled_weak_top1_acc:93.98542036116123,unlabelled_weak_top5_acc:99.78354358673096  \n","[2022-04-25 02:52:56,907][experiments.experiment][INFO] - [EMA] Epoch 85. [Validation] raw_testing_loss: 0.3015, raw test Top1 acc:91.38, raw test Top5 acc: 99.74, ema_testing_loss: 0.2014, ema test Top1 acc:94.62, ema test Top5 acc: 99.9\n","[2022-04-25 02:52:57,006][experiments.experiment][INFO] - [Checkpoints] Epoch 85, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 02:52:57,012][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 03:00:32,271][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 86: use 455.3601932525635 seconds\n","--- Optimizer learning rate changed from 1.66e-02 to 1.63e-02 ---\n","[2022-04-25 03:00:32,372][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 03:00:33,752][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 03:00:33,752][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 03:00:35,118][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 03:00:35,120][experiments.experiment][INFO] - [EMA] Epoch 86.[Train] time:455.3601932525635 seconds, lr:0.0163, train_loss: 1.6003, unlabeled_losses_real_strong:0.4617,corrrect_unlabeled_num:399097.0,pro_above_threshold_num:406946.0,unlabelled_weak_top1_acc:94.03512024134398,unlabelled_weak_top5_acc:99.78812135010958  \n","[2022-04-25 03:00:35,121][experiments.experiment][INFO] - [EMA] Epoch 86. [Validation] raw_testing_loss: 0.2904, raw test Top1 acc:91.82, raw test Top5 acc: 99.74, ema_testing_loss: 0.1989, ema test Top1 acc:94.7, ema test Top5 acc: 99.9\n","[2022-04-25 03:00:35,123][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 03:08:08,730][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 87: use 453.7093358039856 seconds\n","--- Optimizer learning rate changed from 1.63e-02 to 1.60e-02 ---\n","[2022-04-25 03:08:08,832][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 03:08:10,305][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 03:08:10,305][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 03:08:11,683][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 03:08:11,685][experiments.experiment][INFO] - [EMA] Epoch 87.[Train] time:453.7093358039856 seconds, lr:0.0160, train_loss: 1.5921, unlabeled_losses_real_strong:0.4577,corrrect_unlabeled_num:399892.0,pro_above_threshold_num:407870.0,unlabelled_weak_top1_acc:94.10182306915522,unlabelled_weak_top5_acc:99.78354377299547  \n","[2022-04-25 03:08:11,686][experiments.experiment][INFO] - [EMA] Epoch 87. [Validation] raw_testing_loss: 0.2513, raw test Top1 acc:92.4, raw test Top5 acc: 99.82, ema_testing_loss: 0.1939, ema test Top1 acc:94.78, ema test Top5 acc: 99.9\n","[2022-04-25 03:08:11,783][experiments.experiment][INFO] - [Checkpoints] Epoch 87, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 03:08:11,794][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 03:15:44,890][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 88: use 453.19648933410645 seconds\n","--- Optimizer learning rate changed from 1.60e-02 to 1.57e-02 ---\n","[2022-04-25 03:15:44,991][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 03:15:46,433][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 03:15:46,434][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 03:15:47,842][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 03:15:47,843][experiments.experiment][INFO] - [EMA] Epoch 88.[Train] time:453.19648933410645 seconds, lr:0.0157, train_loss: 1.5829, unlabeled_losses_real_strong:0.4577,corrrect_unlabeled_num:399539.0,pro_above_threshold_num:407492.0,unlabelled_weak_top1_acc:94.09571950882673,unlabelled_weak_top5_acc:99.77809406071901  \n","[2022-04-25 03:15:47,845][experiments.experiment][INFO] - [EMA] Epoch 88. [Validation] raw_testing_loss: 0.3218, raw test Top1 acc:91.26, raw test Top5 acc: 99.58, ema_testing_loss: 0.1972, ema test Top1 acc:94.6, ema test Top5 acc: 99.88\n","[2022-04-25 03:15:47,847][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 03:23:23,273][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 89: use 455.54002261161804 seconds\n","--- Optimizer learning rate changed from 1.57e-02 to 1.54e-02 ---\n","[2022-04-25 03:23:23,387][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 03:23:24,741][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 03:23:24,741][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 03:23:26,113][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 03:23:26,114][experiments.experiment][INFO] - [EMA] Epoch 89.[Train] time:455.54002261161804 seconds, lr:0.0154, train_loss: 1.5714, unlabeled_losses_real_strong:0.4538,corrrect_unlabeled_num:400395.0,pro_above_threshold_num:408377.0,unlabelled_weak_top1_acc:94.15174094587564,unlabelled_weak_top5_acc:99.79684061557055  \n","[2022-04-25 03:23:26,116][experiments.experiment][INFO] - [EMA] Epoch 89. [Validation] raw_testing_loss: 0.3389, raw test Top1 acc:90.58, raw test Top5 acc: 99.64, ema_testing_loss: 0.1919, ema test Top1 acc:94.7, ema test Top5 acc: 99.9\n","[2022-04-25 03:23:26,213][experiments.experiment][INFO] - [Checkpoints] Epoch 89, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 03:23:26,214][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 03:31:02,084][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 90: use 455.97922921180725 seconds\n","--- Optimizer learning rate changed from 1.54e-02 to 1.51e-02 ---\n","[2022-04-25 03:31:02,194][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 03:31:03,592][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 03:31:03,592][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 03:31:04,964][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 03:31:04,965][experiments.experiment][INFO] - [EMA] Epoch 90.[Train] time:455.97922921180725 seconds, lr:0.0151, train_loss: 1.5742, unlabeled_losses_real_strong:0.4500,corrrect_unlabeled_num:400849.0,pro_above_threshold_num:408527.0,unlabelled_weak_top1_acc:94.20536477863789,unlabelled_weak_top5_acc:99.7868133932352  \n","[2022-04-25 03:31:04,967][experiments.experiment][INFO] - [EMA] Epoch 90. [Validation] raw_testing_loss: 0.3077, raw test Top1 acc:91.6, raw test Top5 acc: 99.64, ema_testing_loss: 0.1883, ema test Top1 acc:94.68, ema test Top5 acc: 99.9\n","[2022-04-25 03:31:04,968][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 03:38:41,669][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 91: use 456.8131422996521 seconds\n","--- Optimizer learning rate changed from 1.51e-02 to 1.48e-02 ---\n","[2022-04-25 03:38:41,781][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 03:38:43,159][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 03:38:43,159][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 03:38:44,573][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 03:38:44,574][experiments.experiment][INFO] - [EMA] Epoch 91.[Train] time:456.8131422996521 seconds, lr:0.0148, train_loss: 1.5467, unlabeled_losses_real_strong:0.4448,corrrect_unlabeled_num:401403.0,pro_above_threshold_num:409109.0,unlabelled_weak_top1_acc:94.22999680787325,unlabelled_weak_top5_acc:99.7937889546156  \n","[2022-04-25 03:38:44,577][experiments.experiment][INFO] - [EMA] Epoch 91. [Validation] raw_testing_loss: 0.2995, raw test Top1 acc:91.42, raw test Top5 acc: 99.76, ema_testing_loss: 0.1902, ema test Top1 acc:94.62, ema test Top5 acc: 99.88\n","[2022-04-25 03:38:44,673][experiments.experiment][INFO] - [Checkpoints] Epoch 91, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 03:38:44,674][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 03:46:17,349][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 92: use 452.77588081359863 seconds\n","--- Optimizer learning rate changed from 1.48e-02 to 1.45e-02 ---\n","[2022-04-25 03:46:17,450][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 03:46:18,797][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 03:46:18,797][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 03:46:20,146][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 03:46:20,147][experiments.experiment][INFO] - [EMA] Epoch 92.[Train] time:452.77588081359863 seconds, lr:0.0145, train_loss: 1.5547, unlabeled_losses_real_strong:0.4453,corrrect_unlabeled_num:402118.0,pro_above_threshold_num:409929.0,unlabelled_weak_top1_acc:94.3320128172636,unlabelled_weak_top5_acc:99.79204497486353  \n","[2022-04-25 03:46:20,149][experiments.experiment][INFO] - [EMA] Epoch 92. [Validation] raw_testing_loss: 0.2516, raw test Top1 acc:92.6, raw test Top5 acc: 99.74, ema_testing_loss: 0.1904, ema test Top1 acc:94.74, ema test Top5 acc: 99.9\n","[2022-04-25 03:46:20,150][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 03:53:52,777][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 93: use 452.737233877182 seconds\n","--- Optimizer learning rate changed from 1.45e-02 to 1.42e-02 ---\n","[2022-04-25 03:53:52,887][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 03:53:54,261][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 03:53:54,261][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 03:53:55,674][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 03:53:55,676][experiments.experiment][INFO] - [EMA] Epoch 93.[Train] time:452.737233877182 seconds, lr:0.0142, train_loss: 1.5566, unlabeled_losses_real_strong:0.4422,corrrect_unlabeled_num:402818.0,pro_above_threshold_num:410500.0,unlabelled_weak_top1_acc:94.40154922753572,unlabelled_weak_top5_acc:99.797930508852  \n","[2022-04-25 03:53:55,677][experiments.experiment][INFO] - [EMA] Epoch 93. [Validation] raw_testing_loss: 0.2656, raw test Top1 acc:92.06, raw test Top5 acc: 99.88, ema_testing_loss: 0.1871, ema test Top1 acc:94.76, ema test Top5 acc: 99.9\n","[2022-04-25 03:53:55,773][experiments.experiment][INFO] - [Checkpoints] Epoch 93, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 03:53:55,781][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 04:01:30,519][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 94: use 454.84064960479736 seconds\n","--- Optimizer learning rate changed from 1.42e-02 to 1.39e-02 ---\n","[2022-04-25 04:01:30,622][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 04:01:31,977][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 04:01:31,977][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 04:01:33,328][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 04:01:33,330][experiments.experiment][INFO] - [EMA] Epoch 94.[Train] time:454.84064960479736 seconds, lr:0.0139, train_loss: 1.5455, unlabeled_losses_real_strong:0.4392,corrrect_unlabeled_num:403131.0,pro_above_threshold_num:410997.0,unlabelled_weak_top1_acc:94.37364748120308,unlabelled_weak_top5_acc:99.79749457538128  \n","[2022-04-25 04:01:33,332][experiments.experiment][INFO] - [EMA] Epoch 94. [Validation] raw_testing_loss: 0.2557, raw test Top1 acc:92.24, raw test Top5 acc: 99.8, ema_testing_loss: 0.1881, ema test Top1 acc:94.76, ema test Top5 acc: 99.92\n","[2022-04-25 04:01:33,333][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 04:09:08,996][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 95: use 455.76780819892883 seconds\n","--- Optimizer learning rate changed from 1.39e-02 to 1.36e-02 ---\n","[2022-04-25 04:09:09,101][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 04:09:10,526][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 04:09:10,526][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 04:09:11,925][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 04:09:11,927][experiments.experiment][INFO] - [EMA] Epoch 95.[Train] time:455.76780819892883 seconds, lr:0.0136, train_loss: 1.5286, unlabeled_losses_real_strong:0.4376,corrrect_unlabeled_num:403804.0,pro_above_threshold_num:411698.0,unlabelled_weak_top1_acc:94.38171271979809,unlabelled_weak_top5_acc:99.80011034756899  \n","[2022-04-25 04:09:11,929][experiments.experiment][INFO] - [EMA] Epoch 95. [Validation] raw_testing_loss: 0.3064, raw test Top1 acc:91.64, raw test Top5 acc: 99.8, ema_testing_loss: 0.1940, ema test Top1 acc:94.64, ema test Top5 acc: 99.88\n","[2022-04-25 04:09:12,026][experiments.experiment][INFO] - [Checkpoints] Epoch 95, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 04:09:12,028][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 04:16:47,079][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 96: use 455.1475257873535 seconds\n","--- Optimizer learning rate changed from 1.36e-02 to 1.33e-02 ---\n","[2022-04-25 04:16:47,176][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 04:16:48,549][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 04:16:48,549][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 04:16:49,924][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 04:16:49,926][experiments.experiment][INFO] - [EMA] Epoch 96.[Train] time:455.1475257873535 seconds, lr:0.0133, train_loss: 1.5284, unlabeled_losses_real_strong:0.4342,corrrect_unlabeled_num:404067.0,pro_above_threshold_num:411629.0,unlabelled_weak_top1_acc:94.47064965963364,unlabelled_weak_top5_acc:99.80076429992914  \n","[2022-04-25 04:16:49,928][experiments.experiment][INFO] - [EMA] Epoch 96. [Validation] raw_testing_loss: 0.2457, raw test Top1 acc:92.9, raw test Top5 acc: 99.78, ema_testing_loss: 0.1906, ema test Top1 acc:94.56, ema test Top5 acc: 99.88\n","[2022-04-25 04:16:49,929][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 04:24:24,991][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 97: use 455.16911458969116 seconds\n","--- Optimizer learning rate changed from 1.33e-02 to 1.30e-02 ---\n","[2022-04-25 04:24:25,099][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 04:24:26,480][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 04:24:26,481][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 04:24:27,853][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 04:24:27,855][experiments.experiment][INFO] - [EMA] Epoch 97.[Train] time:455.16911458969116 seconds, lr:0.0130, train_loss: 1.5147, unlabeled_losses_real_strong:0.4316,corrrect_unlabeled_num:404363.0,pro_above_threshold_num:411964.0,unlabelled_weak_top1_acc:94.49266596883535,unlabelled_weak_top5_acc:99.80076419562101  \n","[2022-04-25 04:24:27,856][experiments.experiment][INFO] - [EMA] Epoch 97. [Validation] raw_testing_loss: 0.2925, raw test Top1 acc:91.78, raw test Top5 acc: 99.78, ema_testing_loss: 0.1884, ema test Top1 acc:94.74, ema test Top5 acc: 99.88\n","[2022-04-25 04:24:27,954][experiments.experiment][INFO] - [Checkpoints] Epoch 97, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 04:24:27,963][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 04:32:02,445][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 98: use 454.5839800834656 seconds\n","--- Optimizer learning rate changed from 1.30e-02 to 1.27e-02 ---\n","[2022-04-25 04:32:02,547][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 04:32:03,952][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 04:32:03,952][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 04:32:05,373][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 04:32:05,374][experiments.experiment][INFO] - [EMA] Epoch 98.[Train] time:454.5839800834656 seconds, lr:0.0127, train_loss: 1.5116, unlabeled_losses_real_strong:0.4274,corrrect_unlabeled_num:405089.0,pro_above_threshold_num:412918.0,unlabelled_weak_top1_acc:94.5772432461381,unlabelled_weak_top5_acc:99.80752174556255  \n","[2022-04-25 04:32:05,376][experiments.experiment][INFO] - [EMA] Epoch 98. [Validation] raw_testing_loss: 0.3615, raw test Top1 acc:90.9, raw test Top5 acc: 99.26, ema_testing_loss: 0.1861, ema test Top1 acc:94.74, ema test Top5 acc: 99.88\n","[2022-04-25 04:32:05,377][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 04:39:41,567][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 99: use 456.2925455570221 seconds\n","--- Optimizer learning rate changed from 1.27e-02 to 1.24e-02 ---\n","[2022-04-25 04:39:41,670][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 04:39:43,083][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 04:39:43,084][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 04:39:44,487][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 04:39:44,488][experiments.experiment][INFO] - [EMA] Epoch 99.[Train] time:456.2925455570221 seconds, lr:0.0124, train_loss: 1.4985, unlabeled_losses_real_strong:0.4269,corrrect_unlabeled_num:405198.0,pro_above_threshold_num:413044.0,unlabelled_weak_top1_acc:94.55522695183754,unlabelled_weak_top5_acc:99.80534195154905  \n","[2022-04-25 04:39:44,491][experiments.experiment][INFO] - [EMA] Epoch 99. [Validation] raw_testing_loss: 0.2759, raw test Top1 acc:92.1, raw test Top5 acc: 99.84, ema_testing_loss: 0.1889, ema test Top1 acc:94.6, ema test Top5 acc: 99.88\n","[2022-04-25 04:39:44,589][experiments.experiment][INFO] - [Checkpoints] Epoch 99, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 04:39:44,600][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 04:47:15,865][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 100: use 451.3678648471832 seconds\n","--- Optimizer learning rate changed from 1.24e-02 to 1.21e-02 ---\n","[2022-04-25 04:47:15,968][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 04:47:17,365][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 04:47:17,366][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 04:47:18,807][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 04:47:18,809][experiments.experiment][INFO] - [EMA] Epoch 100.[Train] time:451.3678648471832 seconds, lr:0.0121, train_loss: 1.4934, unlabeled_losses_real_strong:0.4238,corrrect_unlabeled_num:405731.0,pro_above_threshold_num:413438.0,unlabelled_weak_top1_acc:94.6173520758748,unlabelled_weak_top5_acc:99.81711309403181  \n","[2022-04-25 04:47:18,811][experiments.experiment][INFO] - [EMA] Epoch 100. [Validation] raw_testing_loss: 0.2490, raw test Top1 acc:92.92, raw test Top5 acc: 99.74, ema_testing_loss: 0.1854, ema test Top1 acc:94.7, ema test Top5 acc: 99.86\n","[2022-04-25 04:47:18,812][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 04:54:50,537][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 101: use 451.8359990119934 seconds\n","--- Optimizer learning rate changed from 1.21e-02 to 1.18e-02 ---\n","[2022-04-25 04:54:50,648][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 04:54:52,094][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 04:54:52,094][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 04:54:53,495][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 04:54:53,497][experiments.experiment][INFO] - [EMA] Epoch 101.[Train] time:451.8359990119934 seconds, lr:0.0118, train_loss: 1.4885, unlabeled_losses_real_strong:0.4223,corrrect_unlabeled_num:406039.0,pro_above_threshold_num:413780.0,unlabelled_weak_top1_acc:94.62563524395227,unlabelled_weak_top5_acc:99.80904767662287  \n","[2022-04-25 04:54:53,500][experiments.experiment][INFO] - [EMA] Epoch 101. [Validation] raw_testing_loss: 0.2411, raw test Top1 acc:92.8, raw test Top5 acc: 99.8, ema_testing_loss: 0.1850, ema test Top1 acc:94.7, ema test Top5 acc: 99.88\n","[2022-04-25 04:54:53,604][experiments.experiment][INFO] - [Checkpoints] Epoch 101, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 04:54:53,605][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 05:02:24,057][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 102: use 450.55723786354065 seconds\n","--- Optimizer learning rate changed from 1.18e-02 to 1.14e-02 ---\n","[2022-04-25 05:02:24,163][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 05:02:25,519][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 05:02:25,520][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 05:02:26,902][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 05:02:26,904][experiments.experiment][INFO] - [EMA] Epoch 102.[Train] time:450.55723786354065 seconds, lr:0.0114, train_loss: 1.4767, unlabeled_losses_real_strong:0.4181,corrrect_unlabeled_num:406538.0,pro_above_threshold_num:414332.0,unlabelled_weak_top1_acc:94.63282884657383,unlabelled_weak_top5_acc:99.8190748244524  \n","[2022-04-25 05:02:26,905][experiments.experiment][INFO] - [EMA] Epoch 102. [Validation] raw_testing_loss: 0.2672, raw test Top1 acc:91.86, raw test Top5 acc: 99.72, ema_testing_loss: 0.1826, ema test Top1 acc:94.7, ema test Top5 acc: 99.86\n","[2022-04-25 05:02:26,906][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 05:09:57,943][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 103: use 451.143785238266 seconds\n","--- Optimizer learning rate changed from 1.14e-02 to 1.11e-02 ---\n","[2022-04-25 05:09:58,051][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 05:09:59,408][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 05:09:59,409][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 05:10:00,779][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 05:10:00,780][experiments.experiment][INFO] - [EMA] Epoch 103.[Train] time:451.143785238266 seconds, lr:0.0111, train_loss: 1.4612, unlabeled_losses_real_strong:0.4139,corrrect_unlabeled_num:407290.0,pro_above_threshold_num:415031.0,unlabelled_weak_top1_acc:94.74487199634314,unlabelled_weak_top5_acc:99.80752176046371  \n","[2022-04-25 05:10:00,783][experiments.experiment][INFO] - [EMA] Epoch 103. [Validation] raw_testing_loss: 0.2890, raw test Top1 acc:92.06, raw test Top5 acc: 99.58, ema_testing_loss: 0.1815, ema test Top1 acc:94.78, ema test Top5 acc: 99.84\n","[2022-04-25 05:10:00,883][experiments.experiment][INFO] - [Checkpoints] Epoch 103, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 05:10:00,886][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 05:17:32,582][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 104: use 451.8021717071533 seconds\n","--- Optimizer learning rate changed from 1.11e-02 to 1.08e-02 ---\n","[2022-04-25 05:17:32,689][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 05:17:34,022][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 05:17:34,023][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 05:17:35,382][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 05:17:35,384][experiments.experiment][INFO] - [EMA] Epoch 104.[Train] time:451.8021717071533 seconds, lr:0.0108, train_loss: 1.4558, unlabeled_losses_real_strong:0.4106,corrrect_unlabeled_num:407901.0,pro_above_threshold_num:415586.0,unlabelled_weak_top1_acc:94.83206510543823,unlabelled_weak_top5_acc:99.80730386823416  \n","[2022-04-25 05:17:35,386][experiments.experiment][INFO] - [EMA] Epoch 104. [Validation] raw_testing_loss: 0.2403, raw test Top1 acc:93.0, raw test Top5 acc: 99.82, ema_testing_loss: 0.1830, ema test Top1 acc:94.68, ema test Top5 acc: 99.88\n","[2022-04-25 05:17:35,387][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 05:25:05,686][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 105: use 450.40044808387756 seconds\n","--- Optimizer learning rate changed from 1.08e-02 to 1.05e-02 ---\n","[2022-04-25 05:25:05,787][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 05:25:07,143][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 05:25:07,143][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 05:25:08,462][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 05:25:08,464][experiments.experiment][INFO] - [EMA] Epoch 105.[Train] time:450.40044808387756 seconds, lr:0.0105, train_loss: 1.4382, unlabeled_losses_real_strong:0.4076,corrrect_unlabeled_num:407887.0,pro_above_threshold_num:415505.0,unlabelled_weak_top1_acc:94.8523373529315,unlabelled_weak_top5_acc:99.82931998372078  \n","[2022-04-25 05:25:08,466][experiments.experiment][INFO] - [EMA] Epoch 105. [Validation] raw_testing_loss: 0.2336, raw test Top1 acc:93.14, raw test Top5 acc: 99.86, ema_testing_loss: 0.1814, ema test Top1 acc:94.8, ema test Top5 acc: 99.9\n","[2022-04-25 05:25:08,562][experiments.experiment][INFO] - [Checkpoints] Epoch 105, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 05:25:08,563][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 05:32:39,755][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 106: use 451.2955298423767 seconds\n","--- Optimizer learning rate changed from 1.05e-02 to 1.02e-02 ---\n","[2022-04-25 05:32:39,858][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 05:32:41,190][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 05:32:41,190][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 05:32:42,599][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 05:32:42,601][experiments.experiment][INFO] - [EMA] Epoch 106.[Train] time:451.2955298423767 seconds, lr:0.0102, train_loss: 1.4337, unlabeled_losses_real_strong:0.4043,corrrect_unlabeled_num:408889.0,pro_above_threshold_num:416514.0,unlabelled_weak_top1_acc:94.82269169390202,unlabelled_weak_top5_acc:99.82539638876915  \n","[2022-04-25 05:32:42,603][experiments.experiment][INFO] - [EMA] Epoch 106. [Validation] raw_testing_loss: 0.2543, raw test Top1 acc:92.3, raw test Top5 acc: 99.8, ema_testing_loss: 0.1783, ema test Top1 acc:94.96, ema test Top5 acc: 99.9\n","[2022-04-25 05:32:42,604][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 05:40:13,029][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 107: use 450.5310592651367 seconds\n","--- Optimizer learning rate changed from 1.02e-02 to 9.83e-03 ---\n","[2022-04-25 05:40:13,135][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 05:40:14,557][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 05:40:14,557][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 05:40:15,936][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 05:40:15,937][experiments.experiment][INFO] - [EMA] Epoch 107.[Train] time:450.5310592651367 seconds, lr:0.0098, train_loss: 1.4304, unlabeled_losses_real_strong:0.4018,corrrect_unlabeled_num:409888.0,pro_above_threshold_num:417598.0,unlabelled_weak_top1_acc:94.91141067445278,unlabelled_weak_top5_acc:99.81689505279064  \n","[2022-04-25 05:40:15,939][experiments.experiment][INFO] - [EMA] Epoch 107. [Validation] raw_testing_loss: 0.2235, raw test Top1 acc:93.32, raw test Top5 acc: 99.88, ema_testing_loss: 0.1785, ema test Top1 acc:94.98, ema test Top5 acc: 99.86\n","[2022-04-25 05:40:16,036][experiments.experiment][INFO] - [Checkpoints] Epoch 107, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 05:40:16,041][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 05:47:47,637][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 108: use 451.7025842666626 seconds\n","--- Optimizer learning rate changed from 9.83e-03 to 9.50e-03 ---\n","[2022-04-25 05:47:47,743][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 05:47:49,112][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 05:47:49,112][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 05:47:50,618][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 05:47:50,619][experiments.experiment][INFO] - [EMA] Epoch 108.[Train] time:451.7025842666626 seconds, lr:0.0095, train_loss: 1.4168, unlabeled_losses_real_strong:0.3994,corrrect_unlabeled_num:410308.0,pro_above_threshold_num:417949.0,unlabelled_weak_top1_acc:94.95653307437897,unlabelled_weak_top5_acc:99.811009503901  \n","[2022-04-25 05:47:50,620][experiments.experiment][INFO] - [EMA] Epoch 108. [Validation] raw_testing_loss: 0.2270, raw test Top1 acc:92.96, raw test Top5 acc: 99.86, ema_testing_loss: 0.1791, ema test Top1 acc:94.92, ema test Top5 acc: 99.84\n","[2022-04-25 05:47:50,622][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 05:55:23,063][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 109: use 452.54199838638306 seconds\n","--- Optimizer learning rate changed from 9.50e-03 to 9.18e-03 ---\n","[2022-04-25 05:55:23,164][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 05:55:24,517][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 05:55:24,517][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 05:55:25,927][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 05:55:25,929][experiments.experiment][INFO] - [EMA] Epoch 109.[Train] time:452.54199838638306 seconds, lr:0.0092, train_loss: 1.3943, unlabeled_losses_real_strong:0.3945,corrrect_unlabeled_num:410649.0,pro_above_threshold_num:418501.0,unlabelled_weak_top1_acc:94.97767744213343,unlabelled_weak_top5_acc:99.81863892823458  \n","[2022-04-25 05:55:25,930][experiments.experiment][INFO] - [EMA] Epoch 109. [Validation] raw_testing_loss: 0.2492, raw test Top1 acc:92.42, raw test Top5 acc: 99.86, ema_testing_loss: 0.1820, ema test Top1 acc:94.94, ema test Top5 acc: 99.9\n","[2022-04-25 05:55:26,028][experiments.experiment][INFO] - [Checkpoints] Epoch 109, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 05:55:26,038][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 06:02:57,709][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 110: use 451.7787160873413 seconds\n","--- Optimizer learning rate changed from 9.18e-03 to 8.85e-03 ---\n","[2022-04-25 06:02:57,817][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 06:02:59,219][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 06:02:59,220][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 06:03:00,598][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 06:03:00,599][experiments.experiment][INFO] - [EMA] Epoch 110.[Train] time:451.7787160873413 seconds, lr:0.0088, train_loss: 1.3898, unlabeled_losses_real_strong:0.3920,corrrect_unlabeled_num:411456.0,pro_above_threshold_num:419326.0,unlabelled_weak_top1_acc:95.01756829768419,unlabelled_weak_top5_acc:99.82321648299694  \n","[2022-04-25 06:03:00,601][experiments.experiment][INFO] - [EMA] Epoch 110. [Validation] raw_testing_loss: 0.2827, raw test Top1 acc:92.46, raw test Top5 acc: 99.68, ema_testing_loss: 0.1796, ema test Top1 acc:94.74, ema test Top5 acc: 99.88\n","[2022-04-25 06:03:00,602][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 06:10:31,701][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 111: use 451.20516872406006 seconds\n","--- Optimizer learning rate changed from 8.85e-03 to 8.52e-03 ---\n","[2022-04-25 06:10:31,807][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 06:10:33,171][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 06:10:33,171][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 06:10:34,536][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 06:10:34,538][experiments.experiment][INFO] - [EMA] Epoch 111.[Train] time:451.20516872406006 seconds, lr:0.0085, train_loss: 1.3681, unlabeled_losses_real_strong:0.3864,corrrect_unlabeled_num:412118.0,pro_above_threshold_num:419958.0,unlabelled_weak_top1_acc:95.06770430505276,unlabelled_weak_top5_acc:99.81972882896662  \n","[2022-04-25 06:10:34,541][experiments.experiment][INFO] - [EMA] Epoch 111. [Validation] raw_testing_loss: 0.2124, raw test Top1 acc:93.64, raw test Top5 acc: 99.9, ema_testing_loss: 0.1756, ema test Top1 acc:95.06, ema test Top5 acc: 99.92\n","[2022-04-25 06:10:34,640][experiments.experiment][INFO] - [Checkpoints] Epoch 111, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 06:10:34,642][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 06:18:04,784][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 112: use 450.24457907676697 seconds\n","--- Optimizer learning rate changed from 8.52e-03 to 8.19e-03 ---\n","[2022-04-25 06:18:04,887][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 06:18:06,297][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 06:18:06,297][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 06:18:07,638][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 06:18:07,639][experiments.experiment][INFO] - [EMA] Epoch 112.[Train] time:450.24457907676697 seconds, lr:0.0082, train_loss: 1.3666, unlabeled_losses_real_strong:0.3854,corrrect_unlabeled_num:412394.0,pro_above_threshold_num:420313.0,unlabelled_weak_top1_acc:95.05789524316788,unlabelled_weak_top5_acc:99.82692223787308  \n","[2022-04-25 06:18:07,642][experiments.experiment][INFO] - [EMA] Epoch 112. [Validation] raw_testing_loss: 0.2774, raw test Top1 acc:92.26, raw test Top5 acc: 99.62, ema_testing_loss: 0.1755, ema test Top1 acc:95.12, ema test Top5 acc: 99.86\n","[2022-04-25 06:18:07,643][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 06:25:36,805][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 113: use 449.2617259025574 seconds\n","--- Optimizer learning rate changed from 8.19e-03 to 7.86e-03 ---\n","[2022-04-25 06:25:36,905][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 06:25:38,265][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 06:25:38,266][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 06:25:39,644][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 06:25:39,645][experiments.experiment][INFO] - [EMA] Epoch 113.[Train] time:449.2617259025574 seconds, lr:0.0079, train_loss: 1.3541, unlabeled_losses_real_strong:0.3838,corrrect_unlabeled_num:412895.0,pro_above_threshold_num:420800.0,unlabelled_weak_top1_acc:95.11653243750334,unlabelled_weak_top5_acc:99.8319358676672  \n","[2022-04-25 06:25:39,648][experiments.experiment][INFO] - [EMA] Epoch 113. [Validation] raw_testing_loss: 0.1981, raw test Top1 acc:94.16, raw test Top5 acc: 99.88, ema_testing_loss: 0.1748, ema test Top1 acc:95.2, ema test Top5 acc: 99.86\n","[2022-04-25 06:25:39,743][experiments.experiment][INFO] - [Checkpoints] Epoch 113, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 06:25:39,744][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 06:33:09,765][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 114: use 450.1222848892212 seconds\n","--- Optimizer learning rate changed from 7.86e-03 to 7.53e-03 ---\n","[2022-04-25 06:33:09,866][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 06:33:11,210][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 06:33:11,210][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 06:33:12,559][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 06:33:12,560][experiments.experiment][INFO] - [EMA] Epoch 114.[Train] time:450.1222848892212 seconds, lr:0.0075, train_loss: 1.3434, unlabeled_losses_real_strong:0.3799,corrrect_unlabeled_num:413583.0,pro_above_threshold_num:421610.0,unlabelled_weak_top1_acc:95.14225454628468,unlabelled_weak_top5_acc:99.83520559221506  \n","[2022-04-25 06:33:12,562][experiments.experiment][INFO] - [EMA] Epoch 114. [Validation] raw_testing_loss: 0.2269, raw test Top1 acc:93.58, raw test Top5 acc: 99.84, ema_testing_loss: 0.1735, ema test Top1 acc:95.04, ema test Top5 acc: 99.86\n","[2022-04-25 06:33:12,564][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 06:40:40,146][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 115: use 447.6825988292694 seconds\n","--- Optimizer learning rate changed from 7.53e-03 to 7.19e-03 ---\n","[2022-04-25 06:40:40,246][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 06:40:41,609][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 06:40:41,609][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 06:40:42,943][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 06:40:42,945][experiments.experiment][INFO] - [EMA] Epoch 115.[Train] time:447.6825988292694 seconds, lr:0.0072, train_loss: 1.3138, unlabeled_losses_real_strong:0.3756,corrrect_unlabeled_num:413536.0,pro_above_threshold_num:421557.0,unlabelled_weak_top1_acc:95.15555129945278,unlabelled_weak_top5_acc:99.83869326859713  \n","[2022-04-25 06:40:42,946][experiments.experiment][INFO] - [EMA] Epoch 115. [Validation] raw_testing_loss: 0.2219, raw test Top1 acc:93.48, raw test Top5 acc: 99.84, ema_testing_loss: 0.1742, ema test Top1 acc:95.14, ema test Top5 acc: 99.9\n","[2022-04-25 06:40:43,045][experiments.experiment][INFO] - [Checkpoints] Epoch 115, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 06:40:43,046][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 06:48:10,901][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 116: use 447.9515736103058 seconds\n","--- Optimizer learning rate changed from 7.19e-03 to 6.86e-03 ---\n","[2022-04-25 06:48:10,998][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 06:48:12,430][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 06:48:12,431][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 06:48:13,756][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 06:48:13,758][experiments.experiment][INFO] - [EMA] Epoch 116.[Train] time:447.9515736103058 seconds, lr:0.0069, train_loss: 1.3033, unlabeled_losses_real_strong:0.3734,corrrect_unlabeled_num:414331.0,pro_above_threshold_num:422446.0,unlabelled_weak_top1_acc:95.21418868750334,unlabelled_weak_top5_acc:99.83171784877777  \n","[2022-04-25 06:48:13,761][experiments.experiment][INFO] - [EMA] Epoch 116. [Validation] raw_testing_loss: 0.2169, raw test Top1 acc:93.4, raw test Top5 acc: 99.9, ema_testing_loss: 0.1686, ema test Top1 acc:95.18, ema test Top5 acc: 99.94\n","[2022-04-25 06:48:13,762][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 06:55:44,923][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 117: use 451.2651333808899 seconds\n","--- Optimizer learning rate changed from 6.86e-03 to 6.53e-03 ---\n","[2022-04-25 06:55:45,027][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 06:55:46,435][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 06:55:46,436][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 06:55:47,848][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 06:55:47,849][experiments.experiment][INFO] - [EMA] Epoch 117.[Train] time:451.2651333808899 seconds, lr:0.0065, train_loss: 1.2898, unlabeled_losses_real_strong:0.3701,corrrect_unlabeled_num:415114.0,pro_above_threshold_num:423002.0,unlabelled_weak_top1_acc:95.26476065814495,unlabelled_weak_top5_acc:99.82103667408228  \n","[2022-04-25 06:55:47,851][experiments.experiment][INFO] - [EMA] Epoch 117. [Validation] raw_testing_loss: 0.2092, raw test Top1 acc:93.6, raw test Top5 acc: 99.82, ema_testing_loss: 0.1689, ema test Top1 acc:95.04, ema test Top5 acc: 99.9\n","[2022-04-25 06:55:47,948][experiments.experiment][INFO] - [Checkpoints] Epoch 117, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","[2022-04-25 06:55:47,951][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 07:03:18,521][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 118: use 450.6713602542877 seconds\n","--- Optimizer learning rate changed from 6.53e-03 to 6.19e-03 ---\n","[2022-04-25 07:03:18,622][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 07:03:19,987][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 07:03:19,987][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 07:03:21,424][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 07:03:21,426][experiments.experiment][INFO] - [EMA] Epoch 118.[Train] time:450.6713602542877 seconds, lr:0.0062, train_loss: 1.2683, unlabeled_losses_real_strong:0.3655,corrrect_unlabeled_num:415151.0,pro_above_threshold_num:423241.0,unlabelled_weak_top1_acc:95.28481516242027,unlabelled_weak_top5_acc:99.84632270038128  \n","[2022-04-25 07:03:21,429][experiments.experiment][INFO] - [EMA] Epoch 118. [Validation] raw_testing_loss: 0.2412, raw test Top1 acc:93.14, raw test Top5 acc: 99.84, ema_testing_loss: 0.1699, ema test Top1 acc:94.82, ema test Top5 acc: 99.9\n","[2022-04-25 07:03:21,430][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-25 07:10:54,665][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 119: use 453.33884167671204 seconds\n","--- Optimizer learning rate changed from 6.19e-03 to 5.85e-03 ---\n","[2022-04-25 07:10:54,769][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 07:10:56,171][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-25 07:10:56,171][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-25 07:10:57,558][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-25 07:10:57,560][experiments.experiment][INFO] - [EMA] Epoch 119.[Train] time:453.33884167671204 seconds, lr:0.0059, train_loss: 1.2603, unlabeled_losses_real_strong:0.3610,corrrect_unlabeled_num:416117.0,pro_above_threshold_num:424332.0,unlabelled_weak_top1_acc:95.33582302182913,unlabelled_weak_top5_acc:99.841309055686  \n","[2022-04-25 07:10:57,561][experiments.experiment][INFO] - [EMA] Epoch 119. [Validation] raw_testing_loss: 0.1963, raw test Top1 acc:94.2, raw test Top5 acc: 99.76, ema_testing_loss: 0.1659, ema test Top1 acc:95.12, ema test Top5 acc: 99.88\n","[2022-04-25 07:10:57,660][experiments.experiment][INFO] - [Checkpoints] Epoch 119, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_7/FMExperiment.pth.tar\n","======= Training done =======\n","2022-04-25 07:10:57,757 - INFO - Train -   ======= Training done =======\n","[2022-04-25 07:10:57,757][Train][INFO] - ======= Training done =======\n","[2022-04-25 07:10:57,758][experiments.experiment][INFO] - Loading Testing Loader\n","[2022-04-25 07:10:57,766][experiments.experiment][INFO] - [Testing with EMA] apply shadow\n","[2022-04-25 07:10:57,766][experiments.experiment][INFO] - ***** Running testing *****\n","[2022-04-25 07:11:00,199][experiments.experiment][INFO] - [Testing(EMA)] testing_loss: 0.1756, test Top1 acc:94.95, test Top5 acc: 99.86\n","[2022-04-25 07:11:00,205][experiments.experiment][INFO] - [EMA] restore \n","======= Testing done =======\n","2022-04-25 07:11:00,205 - INFO - Train -   ======= Testing done =======\n","[2022-04-25 07:11:00,205][Train][INFO] - ======= Testing done =======\n"]}]}]}