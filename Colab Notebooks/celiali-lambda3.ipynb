{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"celiali-lambda3.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOr70znpm7vzr41Q/BR/duq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ohZyAmq03Vf2","executionInfo":{"status":"ok","timestamp":1650685963727,"user_tz":300,"elapsed":128003,"user":{"displayName":"CM Y","userId":"12660552299343911788"}},"outputId":"47782fe1-8c18-4c5f-cc18-40220c4532dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/celiali\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 2)) (1.0.0)\n","Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 3)) (1.9)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 4)) (0.29.28)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 5)) (1.21.6)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 7)) (4.64.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 8)) (1.4.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 9)) (7.1.2)\n","Collecting torch==1.8.0\n","  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n","\u001b[K     |████████████████████████████████| 735.5 MB 15 kB/s \n","\u001b[?25hCollecting torchvision==0.9.0\n","  Downloading torchvision-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n","\u001b[K     |████████████████████████████████| 17.3 MB 21.5 MB/s \n","\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 12)) (0.10.0+cu111)\n","Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 13)) (0.11.0)\n","Collecting omegaconf\n","  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\n","\u001b[K     |████████████████████████████████| 74 kB 4.1 MB/s \n","\u001b[?25hCollecting hydra\n","  Downloading Hydra-2.5.tar.gz (82 kB)\n","\u001b[K     |████████████████████████████████| 82 kB 302 kB/s \n","\u001b[?25hCollecting hydra-core\n","  Downloading hydra_core-1.1.2-py3-none-any.whl (147 kB)\n","\u001b[K     |████████████████████████████████| 147 kB 67.9 MB/s \n","\u001b[?25hCollecting ignite\n","  Downloading ignite-1.1.0-py2.py3-none-any.whl (4.5 kB)\n","Collecting pytorch-ignite\n","  Downloading pytorch_ignite-0.4.8-py3-none-any.whl (251 kB)\n","\u001b[K     |████████████████████████████████| 251 kB 68.4 MB/s \n","\u001b[?25hCollecting tensorboardX\n","  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 66.4 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 20)) (1.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 21)) (3.2.2)\n","Collecting abel-pytorch\n","  Downloading abel_pytorch-0.0.1-py3-none-any.whl (4.2 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r google_requirements.txt (line 10)) (4.1.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->-r google_requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.17.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.3.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.1.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.44.0)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 73.3 MB/s \n","\u001b[?25hRequirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (13.0.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.1.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.5.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (57.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.6.3)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.14.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.24.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.1.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.2.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->-r google_requirements.txt (line 6)) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->-r google_requirements.txt (line 6)) (1.5.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.3.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.6.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2.23.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.2.0)\n","Collecting torchaudio\n","  Downloading torchaudio-0.11.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 56.8 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 56.8 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 63.9 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 58.7 MB/s \n","\u001b[?25h  Downloading torchaudio-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 57.8 MB/s \n","\u001b[?25h  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 57.5 MB/s \n","\u001b[?25h  Downloading torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 57.5 MB/s \n","\u001b[?25h  Downloading torchaudio-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 24.4 MB/s \n","\u001b[?25hCollecting torchtext\n","  Downloading torchtext-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n","\u001b[K     |████████████████████████████████| 10.4 MB 27.3 MB/s \n","\u001b[?25h  Downloading torchtext-0.11.2-cp37-cp37m-manylinux1_x86_64.whl (8.0 MB)\n","\u001b[K     |████████████████████████████████| 8.0 MB 27.4 MB/s \n","\u001b[?25h  Downloading torchtext-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (8.0 MB)\n","\u001b[K     |████████████████████████████████| 8.0 MB 31.8 MB/s \n","\u001b[?25h  Downloading torchtext-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 18.2 MB/s \n","\u001b[?25h  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 1.9 MB/s \n","\u001b[?25h  Downloading torchtext-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 29.1 MB/s \n","\u001b[?25h  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 58.4 MB/s \n","\u001b[?25hCollecting PyYAML>=5.1.0\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 51.9 MB/s \n","\u001b[?25hCollecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 66.8 MB/s \n","\u001b[?25hCollecting importlib-resources<5.3\n","  Downloading importlib_resources-5.2.3-py3-none-any.whl (27 kB)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r google_requirements.txt (line 20)) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r google_requirements.txt (line 20)) (1.1.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (1.4.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (3.0.8)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (0.11.0)\n","Building wheels for collected packages: antlr4-python3-runtime, hydra\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=4e3d5480edbccde505f7521b6c5efc24c0d2fdcb756417543a9b516d3d71b7af\n","  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n","  Building wheel for hydra (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hydra: filename=Hydra-2.5-cp37-cp37m-linux_x86_64.whl size=220776 sha256=9e167147b4f582e65002de3cb8aa6e51714dcc2f27462f27e683058d70fb8e17\n","  Stored in directory: /root/.cache/pip/wheels/46/28/7d/3b38a41d900da90c4e17576f442bac9344eb1f5a4e78ee9f83\n","Successfully built antlr4-python3-runtime hydra\n","Installing collected packages: PyYAML, antlr4-python3-runtime, torch, tf-estimator-nightly, omegaconf, importlib-resources, torchvision, torchtext, torchaudio, tensorboardX, pytorch-ignite, ignite, hydra-core, hydra, abel-pytorch\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","  Attempting uninstall: importlib-resources\n","    Found existing installation: importlib-resources 5.7.0\n","    Uninstalling importlib-resources-5.7.0:\n","      Successfully uninstalled importlib-resources-5.7.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.11.1+cu111\n","    Uninstalling torchvision-0.11.1+cu111:\n","      Successfully uninstalled torchvision-0.11.1+cu111\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.11.0\n","    Uninstalling torchtext-0.11.0:\n","      Successfully uninstalled torchtext-0.11.0\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.10.0+cu111\n","    Uninstalling torchaudio-0.10.0+cu111:\n","      Successfully uninstalled torchaudio-0.10.0+cu111\n","Successfully installed PyYAML-6.0 abel-pytorch-0.0.1 antlr4-python3-runtime-4.8 hydra-2.5 hydra-core-1.1.2 ignite-1.1.0 importlib-resources-5.2.3 omegaconf-2.1.2 pytorch-ignite-0.4.8 tensorboardX-2.5 tf-estimator-nightly-2.8.0.dev2021122109 torch-1.8.0 torchaudio-0.8.0 torchtext-0.9.0 torchvision-0.9.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{}}],"source":["# Mount into drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","# Change directory to the package folder\n","%cd '/content/drive/MyDrive/celiali'\n","%pip install -r google_requirements.txt"]},{"cell_type":"code","source":["!python run.py DATASET.label_num=4000 DATASET.strongaugment='RA' EXPERIMENT.epoch_n=120 EXPERIMENT.batch_size=64 MODEL.name='WideResNet_Lk' MODEL.depth=28 MODEL.widen_factor=2 MODEL.num_classes=10 EXPERIMENT.out_model='./checkpoints/checkpoints_celiali-lambda_unlabled_3/' EXPERIMENT.log_path='./outputs/outputs_lambda_unlabled_3/' EXPERIMENT.save_cfmatrix=False EXPERIMENT.decay_type='cosine' DATASET.cut_type='cutout' EXPERIMENT.lambda_unlabeled=3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"knXIkR9Z3ZOe","outputId":"b6bda1dc-15b1-413e-91eb-e70abe982781"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==> CONFIG is: \n"," DATASET:\n","  project_dir: ./\n","  data_dir: data\n","  loading_data: LOAD_LABEL_UNLABEL\n","  dataset: CIFAR10\n","  strongaugment: RA\n","  cut_type: cutout\n","  label_num: 4000\n","  num_expand_x: 65536\n","  mu: 7\n","  barely: false\n","  add_noisy_label: false\n","  both_strong: false\n","MODEL:\n","  name: WideResNet_Lk\n","  depth: 28\n","  widen_factor: 2\n","  num_classes: 10\n","  dropout: 0.0\n","  cardinality: 4\n","  width: 4\n","  base_width: 4\n","EXPERIMENT:\n","  name: FMExperiment\n","  out_model: ./checkpoints/checkpoints_celiali-lambda_unlabled_3/\n","  log_path: ./outputs/outputs_lambda_unlabled_3/\n","  used_gpu: true\n","  decay_type: cosine\n","  abel_decay: 0.1\n","  optim_lr: 0.03\n","  optim_momentum: 0.9\n","  used_nesterov: true\n","  warmup: 0\n","  wdecay: 0.0005\n","  clip: 1\n","  ema_used: true\n","  ema_decay: 0.999\n","  threshold: 0.95\n","  lambda_unlabeled: 3\n","  batch_size: 64\n","  num_workers: 4\n","  n_imgs_per_epoch: 65536\n","  epoch_n: 120\n","  save_every: 2\n","  save_matrix_every: 20\n","  resume: false\n","  resume_checkpoints: ./checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar\n","  save_cfmatrix: false\n","  batch_balanced: false\n","  neg_penalty: false\n","  equal_freq: false\n","  eta_negpenalty: 0.05\n","  eta_dynamic: false\n","  use_nlloss: false\n","  q: 0.0001\n","Logging:\n","  name: FM\n","  seed: 1265\n"," \n","\n","2022-04-22 20:04:45,410 - INFO - Train -   {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'cut_type': 'cutout', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-lambda_unlabled_3/', 'log_path': './outputs/outputs_lambda_unlabled_3/', 'used_gpu': True, 'decay_type': 'cosine', 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 3, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': False, 'resume_checkpoints': './checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","[2022-04-22 20:04:45,410][Train][INFO] - {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'cut_type': 'cutout', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-lambda_unlabled_3/', 'log_path': './outputs/outputs_lambda_unlabled_3/', 'used_gpu': True, 'decay_type': 'cosine', 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 3, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': False, 'resume_checkpoints': './checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","2022-04-22 20:04:45,831 - INFO - Train -   [Model] Building model WideResNet_Lk\n","[2022-04-22 20:04:45,831][Train][INFO] - [Model] Building model WideResNet_Lk\n","2022-04-22 20:04:48,400 - INFO - Train -   Total params: 1.47M\n","[2022-04-22 20:04:48,400][Train][INFO] - Total params: 1.47M\n","[2022-04-22 20:04:48,401][experiments.experiment][INFO] - I'm using cosine decay!\n","[2022-04-22 20:04:48,404][experiments.experiment][INFO] - [EMA] initial \n","[2022-04-22 20:04:56,491][datasets.datasets1][INFO] - Dataset: CIFAR10\n","[2022-04-22 20:04:56,540][datasets.datasets1][INFO] - Labeled examples: 65536 Unlabeled examples: 458752Validation examples: 5000\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-22 20:04:56,541][experiments.experiment][INFO] - Loading Labelled Loader\n","[2022-04-22 20:04:56,542][experiments.experiment][INFO] - Loading Unlabelled Loader\n","[2022-04-22 20:04:56,542][experiments.experiment][INFO] - Loading Validation Loader\n","[2022-04-22 20:04:56,549][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 20:12:21,977][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 0: use 445.53730392456055 seconds\n","--- Optimizer learning rate changed from inf to 3.00e-02 ---\n","[2022-04-22 20:12:22,086][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:12:23,430][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 20:12:23,430][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:12:24,717][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 20:12:24,773][experiments.experiment][INFO] - [EMA] Epoch 0.[Train] time:445.53730392456055 seconds, lr:0.0300, train_loss: 1.3489, unlabeled_losses_real_strong:2.0575,corrrect_unlabeled_num:25616.0,pro_above_threshold_num:27162.0,unlabelled_weak_top1_acc:51.115198944695294,unlabelled_weak_top5_acc:92.78259159252048  \n","[2022-04-22 20:12:24,774][experiments.experiment][INFO] - [EMA] Epoch 0. [Validation] raw_testing_loss: 1.5677, raw test Top1 acc:46.38, raw test Top5 acc: 90.78, ema_testing_loss: 1.5754, ema test Top1 acc:46.58, ema test Top5 acc: 92.02\n","[2022-04-22 20:12:24,864][experiments.experiment][INFO] - [Checkpoints] Epoch 0, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-22 20:12:24,865][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 20:19:51,998][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 1: use 447.2272193431854 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-22 20:19:52,092][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:19:53,405][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 20:19:53,405][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:19:54,717][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 20:19:54,719][experiments.experiment][INFO] - [EMA] Epoch 1.[Train] time:447.2272193431854 seconds, lr:0.0300, train_loss: 1.2153, unlabeled_losses_real_strong:1.8139,corrrect_unlabeled_num:118130.0,pro_above_threshold_num:125176.0,unlabelled_weak_top1_acc:65.42750683054328,unlabelled_weak_top5_acc:96.73047633469105  \n","[2022-04-22 20:19:54,721][experiments.experiment][INFO] - [EMA] Epoch 1. [Validation] raw_testing_loss: 3.7103, raw test Top1 acc:19.98, raw test Top5 acc: 80.22, ema_testing_loss: 1.0509, ema test Top1 acc:63.22, ema test Top5 acc: 96.32\n","[2022-04-22 20:19:54,812][experiments.experiment][INFO] - [Checkpoints] Epoch 1, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-22 20:19:54,814][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 20:27:22,645][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 2: use 447.93629789352417 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-22 20:27:22,750][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:27:24,091][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 20:27:24,091][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:27:25,425][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 20:27:25,426][experiments.experiment][INFO] - [EMA] Epoch 2.[Train] time:447.93629789352417 seconds, lr:0.0300, train_loss: 1.2232, unlabeled_losses_real_strong:1.4983,corrrect_unlabeled_num:181638.0,pro_above_threshold_num:193389.0,unlabelled_weak_top1_acc:71.37451061606407,unlabelled_weak_top5_acc:97.665622189641  \n","[2022-04-22 20:27:25,428][experiments.experiment][INFO] - [EMA] Epoch 2. [Validation] raw_testing_loss: 2.7759, raw test Top1 acc:28.52, raw test Top5 acc: 82.96, ema_testing_loss: 0.8600, ema test Top1 acc:71.04, ema test Top5 acc: 97.6\n","[2022-04-22 20:27:25,429][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 20:34:52,891][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 3: use 447.56113147735596 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-22 20:34:52,990][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:34:54,317][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 20:34:54,318][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:34:55,660][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 20:34:55,662][experiments.experiment][INFO] - [EMA] Epoch 3.[Train] time:447.56113147735596 seconds, lr:0.0300, train_loss: 1.2213, unlabeled_losses_real_strong:1.3056,corrrect_unlabeled_num:225148.0,pro_above_threshold_num:239378.0,unlabelled_weak_top1_acc:75.70844272524118,unlabelled_weak_top5_acc:98.29166855663061  \n","[2022-04-22 20:34:55,663][experiments.experiment][INFO] - [EMA] Epoch 3. [Validation] raw_testing_loss: 1.8003, raw test Top1 acc:42.62, raw test Top5 acc: 94.18, ema_testing_loss: 0.7501, ema test Top1 acc:75.4, ema test Top5 acc: 98.36\n","[2022-04-22 20:34:55,760][experiments.experiment][INFO] - [Checkpoints] Epoch 3, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-22 20:34:55,769][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 20:42:23,204][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 4: use 447.5317277908325 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-22 20:42:23,301][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:42:24,668][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 20:42:24,669][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:42:26,026][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 20:42:26,028][experiments.experiment][INFO] - [EMA] Epoch 4.[Train] time:447.5317277908325 seconds, lr:0.0300, train_loss: 1.2026, unlabeled_losses_real_strong:1.1863,corrrect_unlabeled_num:254806.0,pro_above_threshold_num:269913.0,unlabelled_weak_top1_acc:78.6932798102498,unlabelled_weak_top5_acc:98.60992303490639  \n","[2022-04-22 20:42:26,029][experiments.experiment][INFO] - [EMA] Epoch 4. [Validation] raw_testing_loss: 2.6355, raw test Top1 acc:36.78, raw test Top5 acc: 90.76, ema_testing_loss: 0.6722, ema test Top1 acc:79.34, ema test Top5 acc: 98.66\n","[2022-04-22 20:42:26,031][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 20:49:52,841][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 5: use 446.91231989860535 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 2.99e-02 ---\n","[2022-04-22 20:49:52,943][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:49:54,291][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 20:49:54,291][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:49:55,591][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 20:49:55,593][experiments.experiment][INFO] - [EMA] Epoch 5.[Train] time:446.91231989860535 seconds, lr:0.0299, train_loss: 1.1523, unlabeled_losses_real_strong:1.0920,corrrect_unlabeled_num:274825.0,pro_above_threshold_num:289812.0,unlabelled_weak_top1_acc:80.84149933606386,unlabelled_weak_top5_acc:98.8141727000475  \n","[2022-04-22 20:49:55,595][experiments.experiment][INFO] - [EMA] Epoch 5. [Validation] raw_testing_loss: 1.8217, raw test Top1 acc:46.72, raw test Top5 acc: 94.42, ema_testing_loss: 0.6083, ema test Top1 acc:81.98, ema test Top5 acc: 99.1\n","[2022-04-22 20:49:55,688][experiments.experiment][INFO] - [Checkpoints] Epoch 5, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-22 20:49:55,693][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 20:57:24,324][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 6: use 448.72465562820435 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.99e-02 ---\n","[2022-04-22 20:57:24,418][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:57:25,733][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 20:57:25,734][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 20:57:27,035][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 20:57:27,036][experiments.experiment][INFO] - [EMA] Epoch 6.[Train] time:448.72465562820435 seconds, lr:0.0299, train_loss: 1.1191, unlabeled_losses_real_strong:1.0231,corrrect_unlabeled_num:289655.0,pro_above_threshold_num:304307.0,unlabelled_weak_top1_acc:82.38765068352222,unlabelled_weak_top5_acc:98.99400836974382  \n","[2022-04-22 20:57:27,039][experiments.experiment][INFO] - [EMA] Epoch 6. [Validation] raw_testing_loss: 1.7162, raw test Top1 acc:51.4, raw test Top5 acc: 92.46, ema_testing_loss: 0.5616, ema test Top1 acc:84.5, ema test Top5 acc: 99.22\n","[2022-04-22 20:57:27,039][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 21:04:55,356][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 7: use 448.4154179096222 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.99e-02 ---\n","[2022-04-22 21:04:55,455][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:04:56,812][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 21:04:56,813][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:04:58,136][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 21:04:58,138][experiments.experiment][INFO] - [EMA] Epoch 7.[Train] time:448.4154179096222 seconds, lr:0.0299, train_loss: 1.0892, unlabeled_losses_real_strong:0.9664,corrrect_unlabeled_num:301466.0,pro_above_threshold_num:315435.0,unlabelled_weak_top1_acc:83.71865303069353,unlabelled_weak_top5_acc:99.10190978646278  \n","[2022-04-22 21:04:58,139][experiments.experiment][INFO] - [EMA] Epoch 7. [Validation] raw_testing_loss: 1.4546, raw test Top1 acc:60.34, raw test Top5 acc: 96.26, ema_testing_loss: 0.5226, ema test Top1 acc:85.32, ema test Top5 acc: 99.36\n","[2022-04-22 21:04:58,244][experiments.experiment][INFO] - [Checkpoints] Epoch 7, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-22 21:04:58,245][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 21:12:26,489][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 8: use 448.33899211883545 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.98e-02 ---\n","[2022-04-22 21:12:26,584][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:12:27,916][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 21:12:27,916][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:12:29,235][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 21:12:29,236][experiments.experiment][INFO] - [EMA] Epoch 8.[Train] time:448.33899211883545 seconds, lr:0.0298, train_loss: 1.0596, unlabeled_losses_real_strong:0.9263,corrrect_unlabeled_num:309548.0,pro_above_threshold_num:323190.0,unlabelled_weak_top1_acc:84.55919425189495,unlabelled_weak_top5_acc:99.19259066134691  \n","[2022-04-22 21:12:29,237][experiments.experiment][INFO] - [EMA] Epoch 8. [Validation] raw_testing_loss: 0.6739, raw test Top1 acc:78.38, raw test Top5 acc: 98.72, ema_testing_loss: 0.4866, ema test Top1 acc:86.14, ema test Top5 acc: 99.52\n","[2022-04-22 21:12:29,238][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 21:19:59,328][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 9: use 450.1829173564911 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.98e-02 ---\n","[2022-04-22 21:19:59,421][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:20:00,791][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 21:20:00,792][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:20:02,101][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 21:20:02,102][experiments.experiment][INFO] - [EMA] Epoch 9.[Train] time:450.1829173564911 seconds, lr:0.0298, train_loss: 1.0310, unlabeled_losses_real_strong:0.8897,corrrect_unlabeled_num:316496.0,pro_above_threshold_num:329619.0,unlabelled_weak_top1_acc:85.37728330492973,unlabelled_weak_top5_acc:99.2279040068388  \n","[2022-04-22 21:20:02,104][experiments.experiment][INFO] - [EMA] Epoch 9. [Validation] raw_testing_loss: 1.0009, raw test Top1 acc:72.34, raw test Top5 acc: 98.42, ema_testing_loss: 0.4595, ema test Top1 acc:86.84, ema test Top5 acc: 99.48\n","[2022-04-22 21:20:02,200][experiments.experiment][INFO] - [Checkpoints] Epoch 9, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-22 21:20:02,210][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 21:27:30,539][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 10: use 448.4356961250305 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.98e-02 ---\n","[2022-04-22 21:27:30,646][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:27:32,034][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 21:27:32,035][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:27:33,447][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 21:27:33,448][experiments.experiment][INFO] - [EMA] Epoch 10.[Train] time:448.4356961250305 seconds, lr:0.0298, train_loss: 1.0211, unlabeled_losses_real_strong:0.8600,corrrect_unlabeled_num:323101.0,pro_above_threshold_num:335940.0,unlabelled_weak_top1_acc:86.09597233682871,unlabelled_weak_top5_acc:99.31771292537451  \n","[2022-04-22 21:27:33,451][experiments.experiment][INFO] - [EMA] Epoch 10. [Validation] raw_testing_loss: 0.6470, raw test Top1 acc:79.36, raw test Top5 acc: 98.92, ema_testing_loss: 0.4431, ema test Top1 acc:87.66, ema test Top5 acc: 99.56\n","[2022-04-22 21:27:33,452][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 21:35:02,386][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 11: use 449.0286228656769 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.97e-02 ---\n","[2022-04-22 21:35:02,480][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:35:03,909][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 21:35:03,909][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:35:05,283][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 21:35:05,284][experiments.experiment][INFO] - [EMA] Epoch 11.[Train] time:449.0286228656769 seconds, lr:0.0297, train_loss: 1.0081, unlabeled_losses_real_strong:0.8337,corrrect_unlabeled_num:328648.0,pro_above_threshold_num:341171.0,unlabelled_weak_top1_acc:86.66599711030722,unlabelled_weak_top5_acc:99.32795822620392  \n","[2022-04-22 21:35:05,286][experiments.experiment][INFO] - [EMA] Epoch 11. [Validation] raw_testing_loss: 0.5264, raw test Top1 acc:83.52, raw test Top5 acc: 99.08, ema_testing_loss: 0.4205, ema test Top1 acc:88.18, ema test Top5 acc: 99.58\n","[2022-04-22 21:35:05,389][experiments.experiment][INFO] - [Checkpoints] Epoch 11, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-22 21:35:05,391][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 21:42:34,917][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 12: use 449.62111496925354 seconds\n","--- Optimizer learning rate changed from 2.97e-02 to 2.97e-02 ---\n","[2022-04-22 21:42:35,012][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:42:36,329][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 21:42:36,330][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:42:37,627][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 21:42:37,629][experiments.experiment][INFO] - [EMA] Epoch 12.[Train] time:449.62111496925354 seconds, lr:0.0297, train_loss: 0.9893, unlabeled_losses_real_strong:0.8129,corrrect_unlabeled_num:332859.0,pro_above_threshold_num:345261.0,unlabelled_weak_top1_acc:87.19656705856323,unlabelled_weak_top5_acc:99.3543341010809  \n","[2022-04-22 21:42:37,630][experiments.experiment][INFO] - [EMA] Epoch 12. [Validation] raw_testing_loss: 1.0849, raw test Top1 acc:73.56, raw test Top5 acc: 97.32, ema_testing_loss: 0.4025, ema test Top1 acc:88.78, ema test Top5 acc: 99.64\n","[2022-04-22 21:42:37,632][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 21:50:07,548][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 13: use 450.0088224411011 seconds\n","--- Optimizer learning rate changed from 2.97e-02 to 2.96e-02 ---\n","[2022-04-22 21:50:07,641][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:50:08,960][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 21:50:08,960][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:50:10,283][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 21:50:10,284][experiments.experiment][INFO] - [EMA] Epoch 13.[Train] time:450.0088224411011 seconds, lr:0.0296, train_loss: 0.9748, unlabeled_losses_real_strong:0.7906,corrrect_unlabeled_num:337227.0,pro_above_threshold_num:349300.0,unlabelled_weak_top1_acc:87.63384034484625,unlabelled_weak_top5_acc:99.40425235033035  \n","[2022-04-22 21:50:10,285][experiments.experiment][INFO] - [EMA] Epoch 13. [Validation] raw_testing_loss: 0.6522, raw test Top1 acc:81.22, raw test Top5 acc: 98.48, ema_testing_loss: 0.3860, ema test Top1 acc:89.5, ema test Top5 acc: 99.64\n","[2022-04-22 21:50:10,380][experiments.experiment][INFO] - [Checkpoints] Epoch 13, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-22 21:50:10,382][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 21:57:39,579][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 14: use 449.2941348552704 seconds\n","--- Optimizer learning rate changed from 2.96e-02 to 2.96e-02 ---\n","[2022-04-22 21:57:39,676][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:57:41,040][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 21:57:41,041][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 21:57:42,395][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 21:57:42,397][experiments.experiment][INFO] - [EMA] Epoch 14.[Train] time:449.2941348552704 seconds, lr:0.0296, train_loss: 0.9602, unlabeled_losses_real_strong:0.7762,corrrect_unlabeled_num:340545.0,pro_above_threshold_num:352483.0,unlabelled_weak_top1_acc:87.96473792940378,unlabelled_weak_top5_acc:99.41275370121002  \n","[2022-04-22 21:57:42,399][experiments.experiment][INFO] - [EMA] Epoch 14. [Validation] raw_testing_loss: 0.6045, raw test Top1 acc:82.38, raw test Top5 acc: 99.4, ema_testing_loss: 0.3766, ema test Top1 acc:89.42, ema test Top5 acc: 99.7\n","[2022-04-22 21:57:42,400][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 22:05:12,750][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 15: use 450.44730162620544 seconds\n","--- Optimizer learning rate changed from 2.96e-02 to 2.95e-02 ---\n","[2022-04-22 22:05:12,847][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:05:14,215][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 22:05:14,215][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:05:15,652][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 22:05:15,653][experiments.experiment][INFO] - [EMA] Epoch 15.[Train] time:450.44730162620544 seconds, lr:0.0295, train_loss: 0.9546, unlabeled_losses_real_strong:0.7587,corrrect_unlabeled_num:344022.0,pro_above_threshold_num:355690.0,unlabelled_weak_top1_acc:88.31895987689495,unlabelled_weak_top5_acc:99.4452332034707  \n","[2022-04-22 22:05:15,656][experiments.experiment][INFO] - [EMA] Epoch 15. [Validation] raw_testing_loss: 0.5518, raw test Top1 acc:84.66, raw test Top5 acc: 99.28, ema_testing_loss: 0.3689, ema test Top1 acc:89.8, ema test Top5 acc: 99.76\n","[2022-04-22 22:05:15,765][experiments.experiment][INFO] - [Checkpoints] Epoch 15, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-22 22:05:15,767][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 22:12:47,526][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 16: use 451.8577950000763 seconds\n","--- Optimizer learning rate changed from 2.95e-02 to 2.94e-02 ---\n","[2022-04-22 22:12:47,624][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:12:48,978][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 22:12:48,978][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:12:50,344][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 22:12:50,345][experiments.experiment][INFO] - [EMA] Epoch 16.[Train] time:451.8577950000763 seconds, lr:0.0294, train_loss: 0.9394, unlabeled_losses_real_strong:0.7440,corrrect_unlabeled_num:347160.0,pro_above_threshold_num:358627.0,unlabelled_weak_top1_acc:88.66860412806273,unlabelled_weak_top5_acc:99.45940224826336  \n","[2022-04-22 22:12:50,347][experiments.experiment][INFO] - [EMA] Epoch 16. [Validation] raw_testing_loss: 0.5539, raw test Top1 acc:84.92, raw test Top5 acc: 98.48, ema_testing_loss: 0.3573, ema test Top1 acc:89.94, ema test Top5 acc: 99.7\n","[2022-04-22 22:12:50,348][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 22:20:20,515][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 17: use 450.27174711227417 seconds\n","--- Optimizer learning rate changed from 2.94e-02 to 2.94e-02 ---\n","[2022-04-22 22:20:20,620][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:20:22,045][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 22:20:22,045][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:20:23,442][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 22:20:23,444][experiments.experiment][INFO] - [EMA] Epoch 17.[Train] time:450.27174711227417 seconds, lr:0.0294, train_loss: 0.9390, unlabeled_losses_real_strong:0.7333,corrrect_unlabeled_num:349738.0,pro_above_threshold_num:361297.0,unlabelled_weak_top1_acc:88.83906656503677,unlabelled_weak_top5_acc:99.50016529113054  \n","[2022-04-22 22:20:23,445][experiments.experiment][INFO] - [EMA] Epoch 17. [Validation] raw_testing_loss: 0.7393, raw test Top1 acc:80.68, raw test Top5 acc: 98.64, ema_testing_loss: 0.3455, ema test Top1 acc:90.44, ema test Top5 acc: 99.68\n","[2022-04-22 22:20:23,543][experiments.experiment][INFO] - [Checkpoints] Epoch 17, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-22 22:20:23,544][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 22:27:53,439][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 18: use 449.9901854991913 seconds\n","--- Optimizer learning rate changed from 2.94e-02 to 2.93e-02 ---\n","[2022-04-22 22:27:53,534][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:27:54,851][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 22:27:54,852][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:27:56,164][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 22:27:56,166][experiments.experiment][INFO] - [EMA] Epoch 18.[Train] time:449.9901854991913 seconds, lr:0.0293, train_loss: 0.9316, unlabeled_losses_real_strong:0.7247,corrrect_unlabeled_num:351828.0,pro_above_threshold_num:363345.0,unlabelled_weak_top1_acc:89.07710382342339,unlabelled_weak_top5_acc:99.4920996800065  \n","[2022-04-22 22:27:56,167][experiments.experiment][INFO] - [EMA] Epoch 18. [Validation] raw_testing_loss: 0.6771, raw test Top1 acc:81.2, raw test Top5 acc: 99.08, ema_testing_loss: 0.3348, ema test Top1 acc:90.58, ema test Top5 acc: 99.68\n","[2022-04-22 22:27:56,169][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 22:35:24,839][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 19: use 448.764719247818 seconds\n","--- Optimizer learning rate changed from 2.93e-02 to 2.92e-02 ---\n","[2022-04-22 22:35:24,934][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:35:26,339][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 22:35:26,339][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:35:27,677][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 22:35:27,678][experiments.experiment][INFO] - [EMA] Epoch 19.[Train] time:448.764719247818 seconds, lr:0.0292, train_loss: 0.9150, unlabeled_losses_real_strong:0.7119,corrrect_unlabeled_num:353651.0,pro_above_threshold_num:364678.0,unlabelled_weak_top1_acc:89.34544034302235,unlabelled_weak_top5_acc:99.49907523393631  \n","[2022-04-22 22:35:27,680][experiments.experiment][INFO] - [EMA] Epoch 19. [Validation] raw_testing_loss: 0.8511, raw test Top1 acc:78.62, raw test Top5 acc: 98.94, ema_testing_loss: 0.3264, ema test Top1 acc:90.76, ema test Top5 acc: 99.68\n","[2022-04-22 22:35:27,783][experiments.experiment][INFO] - [Checkpoints] Epoch 19, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-22 22:35:27,786][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 22:42:56,206][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 20: use 448.51953387260437 seconds\n","--- Optimizer learning rate changed from 2.92e-02 to 2.91e-02 ---\n","[2022-04-22 22:42:56,305][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:42:57,640][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 22:42:57,641][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:42:58,958][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 22:42:58,960][experiments.experiment][INFO] - [EMA] Epoch 20.[Train] time:448.51953387260437 seconds, lr:0.0291, train_loss: 0.9082, unlabeled_losses_real_strong:0.7034,corrrect_unlabeled_num:356584.0,pro_above_threshold_num:367632.0,unlabelled_weak_top1_acc:89.54271487891674,unlabelled_weak_top5_acc:99.51825775206089  \n","[2022-04-22 22:42:58,961][experiments.experiment][INFO] - [EMA] Epoch 20. [Validation] raw_testing_loss: 0.6201, raw test Top1 acc:84.0, raw test Top5 acc: 98.6, ema_testing_loss: 0.3213, ema test Top1 acc:91.14, ema test Top5 acc: 99.72\n","[2022-04-22 22:42:58,962][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 22:50:28,928][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 21: use 450.06828689575195 seconds\n","--- Optimizer learning rate changed from 2.91e-02 to 2.91e-02 ---\n","[2022-04-22 22:50:29,031][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:50:30,370][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 22:50:30,370][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:50:31,755][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 22:50:31,757][experiments.experiment][INFO] - [EMA] Epoch 21.[Train] time:450.06828689575195 seconds, lr:0.0291, train_loss: 0.9108, unlabeled_losses_real_strong:0.6921,corrrect_unlabeled_num:358507.0,pro_above_threshold_num:369485.0,unlabelled_weak_top1_acc:89.77159658074379,unlabelled_weak_top5_acc:99.51368012279272  \n","[2022-04-22 22:50:31,759][experiments.experiment][INFO] - [EMA] Epoch 21. [Validation] raw_testing_loss: 0.4649, raw test Top1 acc:86.44, raw test Top5 acc: 99.3, ema_testing_loss: 0.3125, ema test Top1 acc:91.22, ema test Top5 acc: 99.66\n","[2022-04-22 22:50:31,853][experiments.experiment][INFO] - [Checkpoints] Epoch 21, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-22 22:50:31,854][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 22:58:01,690][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 22: use 449.93855905532837 seconds\n","--- Optimizer learning rate changed from 2.91e-02 to 2.90e-02 ---\n","[2022-04-22 22:58:01,792][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:58:03,193][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 22:58:03,193][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 22:58:04,515][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 22:58:04,517][experiments.experiment][INFO] - [EMA] Epoch 22.[Train] time:449.93855905532837 seconds, lr:0.0290, train_loss: 0.9017, unlabeled_losses_real_strong:0.6864,corrrect_unlabeled_num:359458.0,pro_above_threshold_num:370299.0,unlabelled_weak_top1_acc:89.87448438256979,unlabelled_weak_top5_acc:99.54092801362276  \n","[2022-04-22 22:58:04,519][experiments.experiment][INFO] - [EMA] Epoch 22. [Validation] raw_testing_loss: 0.4905, raw test Top1 acc:85.48, raw test Top5 acc: 99.36, ema_testing_loss: 0.3108, ema test Top1 acc:91.12, ema test Top5 acc: 99.68\n","[2022-04-22 22:58:04,520][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 23:05:35,403][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 23: use 450.9817388057709 seconds\n","--- Optimizer learning rate changed from 2.90e-02 to 2.89e-02 ---\n","[2022-04-22 23:05:35,502][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:05:36,825][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 23:05:36,825][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:05:38,150][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 23:05:38,156][experiments.experiment][INFO] - [EMA] Epoch 23.[Train] time:450.9817388057709 seconds, lr:0.0289, train_loss: 0.8956, unlabeled_losses_real_strong:0.6767,corrrect_unlabeled_num:361281.0,pro_above_threshold_num:371898.0,unlabelled_weak_top1_acc:90.0700149834156,unlabelled_weak_top5_acc:99.5441978648305  \n","[2022-04-22 23:05:38,159][experiments.experiment][INFO] - [EMA] Epoch 23. [Validation] raw_testing_loss: 0.4037, raw test Top1 acc:88.14, raw test Top5 acc: 99.62, ema_testing_loss: 0.3049, ema test Top1 acc:91.18, ema test Top5 acc: 99.66\n","[2022-04-22 23:05:38,255][experiments.experiment][INFO] - [Checkpoints] Epoch 23, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-22 23:05:38,264][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 23:13:07,752][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 24: use 449.58323645591736 seconds\n","--- Optimizer learning rate changed from 2.89e-02 to 2.88e-02 ---\n","[2022-04-22 23:13:07,847][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:13:09,216][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 23:13:09,216][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:13:10,568][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 23:13:10,570][experiments.experiment][INFO] - [EMA] Epoch 24.[Train] time:449.58323645591736 seconds, lr:0.0288, train_loss: 0.8888, unlabeled_losses_real_strong:0.6692,corrrect_unlabeled_num:362634.0,pro_above_threshold_num:373418.0,unlabelled_weak_top1_acc:90.23720767349005,unlabelled_weak_top5_acc:99.55705884099007  \n","[2022-04-22 23:13:10,571][experiments.experiment][INFO] - [EMA] Epoch 24. [Validation] raw_testing_loss: 0.4696, raw test Top1 acc:86.18, raw test Top5 acc: 99.56, ema_testing_loss: 0.3019, ema test Top1 acc:91.34, ema test Top5 acc: 99.76\n","[2022-04-22 23:13:10,573][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 23:20:41,956][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 25: use 451.48125076293945 seconds\n","--- Optimizer learning rate changed from 2.88e-02 to 2.87e-02 ---\n","[2022-04-22 23:20:42,054][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:20:43,436][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 23:20:43,436][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:20:44,792][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 23:20:44,794][experiments.experiment][INFO] - [EMA] Epoch 25.[Train] time:451.48125076293945 seconds, lr:0.0287, train_loss: 0.8868, unlabeled_losses_real_strong:0.6619,corrrect_unlabeled_num:364240.0,pro_above_threshold_num:374667.0,unlabelled_weak_top1_acc:90.41965913027525,unlabelled_weak_top5_acc:99.56534234434366  \n","[2022-04-22 23:20:44,796][experiments.experiment][INFO] - [EMA] Epoch 25. [Validation] raw_testing_loss: 0.4721, raw test Top1 acc:86.78, raw test Top5 acc: 99.5, ema_testing_loss: 0.2979, ema test Top1 acc:91.54, ema test Top5 acc: 99.72\n","[2022-04-22 23:20:44,899][experiments.experiment][INFO] - [Checkpoints] Epoch 25, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-22 23:20:44,902][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 23:28:15,591][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 26: use 450.78666615486145 seconds\n","--- Optimizer learning rate changed from 2.87e-02 to 2.86e-02 ---\n","[2022-04-22 23:28:15,689][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:28:17,080][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 23:28:17,081][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:28:18,443][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 23:28:18,445][experiments.experiment][INFO] - [EMA] Epoch 26.[Train] time:450.78666615486145 seconds, lr:0.0286, train_loss: 0.8908, unlabeled_losses_real_strong:0.6556,corrrect_unlabeled_num:366795.0,pro_above_threshold_num:377132.0,unlabelled_weak_top1_acc:90.60472644120455,unlabelled_weak_top5_acc:99.58932036906481  \n","[2022-04-22 23:28:18,447][experiments.experiment][INFO] - [EMA] Epoch 26. [Validation] raw_testing_loss: 0.4241, raw test Top1 acc:88.56, raw test Top5 acc: 99.5, ema_testing_loss: 0.2905, ema test Top1 acc:91.84, ema test Top5 acc: 99.7\n","[2022-04-22 23:28:18,447][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 23:35:47,577][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 27: use 449.23631024360657 seconds\n","--- Optimizer learning rate changed from 2.86e-02 to 2.85e-02 ---\n","[2022-04-22 23:35:47,684][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:35:49,134][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 23:35:49,135][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:35:50,446][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 23:35:50,448][experiments.experiment][INFO] - [EMA] Epoch 27.[Train] time:449.23631024360657 seconds, lr:0.0285, train_loss: 0.8777, unlabeled_losses_real_strong:0.6500,corrrect_unlabeled_num:367769.0,pro_above_threshold_num:377928.0,unlabelled_weak_top1_acc:90.75055695325136,unlabelled_weak_top5_acc:99.59062840044498  \n","[2022-04-22 23:35:50,450][experiments.experiment][INFO] - [EMA] Epoch 27. [Validation] raw_testing_loss: 0.4735, raw test Top1 acc:87.26, raw test Top5 acc: 99.42, ema_testing_loss: 0.2874, ema test Top1 acc:91.92, ema test Top5 acc: 99.72\n","[2022-04-22 23:35:50,545][experiments.experiment][INFO] - [Checkpoints] Epoch 27, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-22 23:35:50,555][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 23:43:20,135][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 28: use 449.67711663246155 seconds\n","--- Optimizer learning rate changed from 2.85e-02 to 2.84e-02 ---\n","[2022-04-22 23:43:20,232][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:43:21,567][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 23:43:21,568][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:43:22,899][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 23:43:22,900][experiments.experiment][INFO] - [EMA] Epoch 28.[Train] time:449.67711663246155 seconds, lr:0.0284, train_loss: 0.8734, unlabeled_losses_real_strong:0.6397,corrrect_unlabeled_num:369310.0,pro_above_threshold_num:379442.0,unlabelled_weak_top1_acc:90.8961693122983,unlabelled_weak_top5_acc:99.59825773537159  \n","[2022-04-22 23:43:22,901][experiments.experiment][INFO] - [EMA] Epoch 28. [Validation] raw_testing_loss: 0.4200, raw test Top1 acc:87.94, raw test Top5 acc: 99.46, ema_testing_loss: 0.2843, ema test Top1 acc:91.9, ema test Top5 acc: 99.72\n","[2022-04-22 23:43:22,902][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 23:50:52,794][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 29: use 449.9965190887451 seconds\n","--- Optimizer learning rate changed from 2.84e-02 to 2.82e-02 ---\n","[2022-04-22 23:50:52,899][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:50:54,246][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 23:50:54,247][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:50:55,674][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 23:50:55,676][experiments.experiment][INFO] - [EMA] Epoch 29.[Train] time:449.9965190887451 seconds, lr:0.0282, train_loss: 0.8792, unlabeled_losses_real_strong:0.6372,corrrect_unlabeled_num:370592.0,pro_above_threshold_num:380855.0,unlabelled_weak_top1_acc:90.99883925169706,unlabelled_weak_top5_acc:99.6063232049346  \n","[2022-04-22 23:50:55,678][experiments.experiment][INFO] - [EMA] Epoch 29. [Validation] raw_testing_loss: 0.4948, raw test Top1 acc:86.96, raw test Top5 acc: 99.2, ema_testing_loss: 0.2779, ema test Top1 acc:92.14, ema test Top5 acc: 99.82\n","[2022-04-22 23:50:55,772][experiments.experiment][INFO] - [Checkpoints] Epoch 29, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-22 23:50:55,773][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 23:58:26,237][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 30: use 450.5692548751831 seconds\n","--- Optimizer learning rate changed from 2.82e-02 to 2.81e-02 ---\n","[2022-04-22 23:58:26,342][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:58:27,734][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 23:58:27,734][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 23:58:29,045][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 23:58:29,046][experiments.experiment][INFO] - [EMA] Epoch 30.[Train] time:450.5692548751831 seconds, lr:0.0281, train_loss: 0.8693, unlabeled_losses_real_strong:0.6306,corrrect_unlabeled_num:370842.0,pro_above_threshold_num:380717.0,unlabelled_weak_top1_acc:91.10521474480629,unlabelled_weak_top5_acc:99.62441582977772  \n","[2022-04-22 23:58:29,048][experiments.experiment][INFO] - [EMA] Epoch 30. [Validation] raw_testing_loss: 0.3981, raw test Top1 acc:89.02, raw test Top5 acc: 99.4, ema_testing_loss: 0.2715, ema test Top1 acc:92.46, ema test Top5 acc: 99.82\n","[2022-04-22 23:58:29,050][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 00:05:59,318][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 31: use 450.36776757240295 seconds\n","--- Optimizer learning rate changed from 2.81e-02 to 2.80e-02 ---\n","[2022-04-23 00:05:59,418][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:06:00,746][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 00:06:00,746][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:06:02,048][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 00:06:02,050][experiments.experiment][INFO] - [EMA] Epoch 31.[Train] time:450.36776757240295 seconds, lr:0.0280, train_loss: 0.8647, unlabeled_losses_real_strong:0.6242,corrrect_unlabeled_num:371867.0,pro_above_threshold_num:381903.0,unlabelled_weak_top1_acc:91.13987398147583,unlabelled_weak_top5_acc:99.62921145558357  \n","[2022-04-23 00:06:02,052][experiments.experiment][INFO] - [EMA] Epoch 31. [Validation] raw_testing_loss: 0.5078, raw test Top1 acc:86.08, raw test Top5 acc: 99.12, ema_testing_loss: 0.2725, ema test Top1 acc:92.28, ema test Top5 acc: 99.76\n","[2022-04-23 00:06:02,149][experiments.experiment][INFO] - [Checkpoints] Epoch 31, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 00:06:02,150][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 00:13:33,217][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 32: use 451.1650538444519 seconds\n","--- Optimizer learning rate changed from 2.80e-02 to 2.79e-02 ---\n","[2022-04-23 00:13:33,315][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:13:34,636][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 00:13:34,637][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:13:35,965][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 00:13:35,967][experiments.experiment][INFO] - [EMA] Epoch 32.[Train] time:451.1650538444519 seconds, lr:0.0279, train_loss: 0.8575, unlabeled_losses_real_strong:0.6197,corrrect_unlabeled_num:373107.0,pro_above_threshold_num:382908.0,unlabelled_weak_top1_acc:91.31556817889214,unlabelled_weak_top5_acc:99.63989254832268  \n","[2022-04-23 00:13:35,968][experiments.experiment][INFO] - [EMA] Epoch 32. [Validation] raw_testing_loss: 0.4811, raw test Top1 acc:87.2, raw test Top5 acc: 99.6, ema_testing_loss: 0.2753, ema test Top1 acc:92.5, ema test Top5 acc: 99.74\n","[2022-04-23 00:13:35,970][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 00:21:07,543][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 33: use 451.67174553871155 seconds\n","--- Optimizer learning rate changed from 2.79e-02 to 2.78e-02 ---\n","[2022-04-23 00:21:07,641][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:21:08,975][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 00:21:08,975][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:21:10,299][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 00:21:10,301][experiments.experiment][INFO] - [EMA] Epoch 33.[Train] time:451.67174553871155 seconds, lr:0.0278, train_loss: 0.8608, unlabeled_losses_real_strong:0.6132,corrrect_unlabeled_num:374138.0,pro_above_threshold_num:383907.0,unlabelled_weak_top1_acc:91.39404191821814,unlabelled_weak_top5_acc:99.6564593911171  \n","[2022-04-23 00:21:10,303][experiments.experiment][INFO] - [EMA] Epoch 33. [Validation] raw_testing_loss: 0.3892, raw test Top1 acc:89.26, raw test Top5 acc: 99.32, ema_testing_loss: 0.2690, ema test Top1 acc:92.62, ema test Top5 acc: 99.76\n","[2022-04-23 00:21:10,402][experiments.experiment][INFO] - [Checkpoints] Epoch 33, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 00:21:10,404][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 00:28:38,093][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 34: use 447.7866380214691 seconds\n","--- Optimizer learning rate changed from 2.78e-02 to 2.76e-02 ---\n","[2022-04-23 00:28:38,191][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:28:39,612][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 00:28:39,612][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:28:40,925][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 00:28:40,927][experiments.experiment][INFO] - [EMA] Epoch 34.[Train] time:447.7866380214691 seconds, lr:0.0276, train_loss: 0.8521, unlabeled_losses_real_strong:0.6124,corrrect_unlabeled_num:374439.0,pro_above_threshold_num:384282.0,unlabelled_weak_top1_acc:91.41191647201777,unlabelled_weak_top5_acc:99.62724956125021  \n","[2022-04-23 00:28:40,928][experiments.experiment][INFO] - [EMA] Epoch 34. [Validation] raw_testing_loss: 0.4965, raw test Top1 acc:87.1, raw test Top5 acc: 99.34, ema_testing_loss: 0.2644, ema test Top1 acc:92.74, ema test Top5 acc: 99.78\n","[2022-04-23 00:28:40,929][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 00:36:12,571][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 35: use 451.7581956386566 seconds\n","--- Optimizer learning rate changed from 2.76e-02 to 2.75e-02 ---\n","[2022-04-23 00:36:12,688][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:36:14,020][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 00:36:14,020][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:36:15,416][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 00:36:15,417][experiments.experiment][INFO] - [EMA] Epoch 35.[Train] time:451.7581956386566 seconds, lr:0.0275, train_loss: 0.8454, unlabeled_losses_real_strong:0.6083,corrrect_unlabeled_num:375068.0,pro_above_threshold_num:384859.0,unlabelled_weak_top1_acc:91.52395960688591,unlabelled_weak_top5_acc:99.63378907740116  \n","[2022-04-23 00:36:15,418][experiments.experiment][INFO] - [EMA] Epoch 35. [Validation] raw_testing_loss: 0.4892, raw test Top1 acc:87.16, raw test Top5 acc: 99.42, ema_testing_loss: 0.2639, ema test Top1 acc:93.18, ema test Top5 acc: 99.78\n","[2022-04-23 00:36:15,517][experiments.experiment][INFO] - [Checkpoints] Epoch 35, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 00:36:15,517][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 00:43:45,826][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 36: use 450.4164137840271 seconds\n","--- Optimizer learning rate changed from 2.75e-02 to 2.73e-02 ---\n","[2022-04-23 00:43:45,934][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:43:47,332][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 00:43:47,332][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:43:48,701][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 00:43:48,703][experiments.experiment][INFO] - [EMA] Epoch 36.[Train] time:450.4164137840271 seconds, lr:0.0273, train_loss: 0.8443, unlabeled_losses_real_strong:0.6008,corrrect_unlabeled_num:376644.0,pro_above_threshold_num:386281.0,unlabelled_weak_top1_acc:91.63992641121149,unlabelled_weak_top5_acc:99.65297173708677  \n","[2022-04-23 00:43:48,704][experiments.experiment][INFO] - [EMA] Epoch 36. [Validation] raw_testing_loss: 0.4311, raw test Top1 acc:88.44, raw test Top5 acc: 99.52, ema_testing_loss: 0.2635, ema test Top1 acc:93.2, ema test Top5 acc: 99.8\n","[2022-04-23 00:43:48,706][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 00:51:18,135][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 37: use 449.5268590450287 seconds\n","--- Optimizer learning rate changed from 2.73e-02 to 2.72e-02 ---\n","[2022-04-23 00:51:18,232][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:51:19,606][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 00:51:19,606][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:51:20,970][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 00:51:20,972][experiments.experiment][INFO] - [EMA] Epoch 37.[Train] time:449.5268590450287 seconds, lr:0.0272, train_loss: 0.8439, unlabeled_losses_real_strong:0.5965,corrrect_unlabeled_num:377581.0,pro_above_threshold_num:387102.0,unlabelled_weak_top1_acc:91.75872707366943,unlabelled_weak_top5_acc:99.65602335333824  \n","[2022-04-23 00:51:20,973][experiments.experiment][INFO] - [EMA] Epoch 37. [Validation] raw_testing_loss: 0.3747, raw test Top1 acc:89.12, raw test Top5 acc: 99.56, ema_testing_loss: 0.2639, ema test Top1 acc:93.1, ema test Top5 acc: 99.8\n","[2022-04-23 00:51:21,071][experiments.experiment][INFO] - [Checkpoints] Epoch 37, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 00:51:21,081][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 00:58:51,824][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 38: use 450.84254336357117 seconds\n","--- Optimizer learning rate changed from 2.72e-02 to 2.71e-02 ---\n","[2022-04-23 00:58:51,924][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:58:53,259][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 00:58:53,260][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 00:58:54,592][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 00:58:54,594][experiments.experiment][INFO] - [EMA] Epoch 38.[Train] time:450.84254336357117 seconds, lr:0.0271, train_loss: 0.8453, unlabeled_losses_real_strong:0.5940,corrrect_unlabeled_num:377975.0,pro_above_threshold_num:387551.0,unlabelled_weak_top1_acc:91.81409446895123,unlabelled_weak_top5_acc:99.65536952763796  \n","[2022-04-23 00:58:54,596][experiments.experiment][INFO] - [EMA] Epoch 38. [Validation] raw_testing_loss: 0.4229, raw test Top1 acc:87.82, raw test Top5 acc: 99.22, ema_testing_loss: 0.2623, ema test Top1 acc:92.76, ema test Top5 acc: 99.78\n","[2022-04-23 00:58:54,597][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 01:06:26,182][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 39: use 451.6855573654175 seconds\n","--- Optimizer learning rate changed from 2.71e-02 to 2.69e-02 ---\n","[2022-04-23 01:06:26,283][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 01:06:27,691][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 01:06:27,691][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 01:06:29,035][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 01:06:29,037][experiments.experiment][INFO] - [EMA] Epoch 39.[Train] time:451.6855573654175 seconds, lr:0.0269, train_loss: 0.8377, unlabeled_losses_real_strong:0.5876,corrrect_unlabeled_num:379162.0,pro_above_threshold_num:388676.0,unlabelled_weak_top1_acc:91.91829020529985,unlabelled_weak_top5_acc:99.67673188447952  \n","[2022-04-23 01:06:29,038][experiments.experiment][INFO] - [EMA] Epoch 39. [Validation] raw_testing_loss: 0.3701, raw test Top1 acc:89.54, raw test Top5 acc: 99.46, ema_testing_loss: 0.2543, ema test Top1 acc:93.08, ema test Top5 acc: 99.8\n","[2022-04-23 01:06:29,133][experiments.experiment][INFO] - [Checkpoints] Epoch 39, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 01:06:29,135][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 01:14:02,104][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 40: use 453.075430393219 seconds\n","--- Optimizer learning rate changed from 2.69e-02 to 2.68e-02 ---\n","[2022-04-23 01:14:02,211][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 01:14:03,585][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 01:14:03,585][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 01:14:04,962][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 01:14:04,964][experiments.experiment][INFO] - [EMA] Epoch 40.[Train] time:453.075430393219 seconds, lr:0.0268, train_loss: 0.8374, unlabeled_losses_real_strong:0.5844,corrrect_unlabeled_num:379921.0,pro_above_threshold_num:389373.0,unlabelled_weak_top1_acc:91.93660079687834,unlabelled_weak_top5_acc:99.6847972497344  \n","[2022-04-23 01:14:04,965][experiments.experiment][INFO] - [EMA] Epoch 40. [Validation] raw_testing_loss: 0.4376, raw test Top1 acc:87.58, raw test Top5 acc: 99.34, ema_testing_loss: 0.2543, ema test Top1 acc:93.16, ema test Top5 acc: 99.78\n","[2022-04-23 01:14:04,967][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 01:21:37,986][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 41: use 453.1155860424042 seconds\n","--- Optimizer learning rate changed from 2.68e-02 to 2.66e-02 ---\n","[2022-04-23 01:21:38,082][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 01:21:39,477][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 01:21:39,477][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 01:21:40,873][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 01:21:40,874][experiments.experiment][INFO] - [EMA] Epoch 41.[Train] time:453.1155860424042 seconds, lr:0.0266, train_loss: 0.8351, unlabeled_losses_real_strong:0.5792,corrrect_unlabeled_num:381103.0,pro_above_threshold_num:390429.0,unlabelled_weak_top1_acc:92.07545585930347,unlabelled_weak_top5_acc:99.68675918877125  \n","[2022-04-23 01:21:40,876][experiments.experiment][INFO] - [EMA] Epoch 41. [Validation] raw_testing_loss: 0.4428, raw test Top1 acc:87.12, raw test Top5 acc: 99.5, ema_testing_loss: 0.2511, ema test Top1 acc:93.16, ema test Top5 acc: 99.82\n","[2022-04-23 01:21:40,975][experiments.experiment][INFO] - [Checkpoints] Epoch 41, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 01:21:40,975][experiments.experiment][INFO] - ***** Running training *****\n"]}]},{"cell_type":"code","source":["!python run.py DATASET.label_num=4000 DATASET.strongaugment='RA' EXPERIMENT.epoch_n=120 EXPERIMENT.batch_size=64 MODEL.name='WideResNet_Lk' MODEL.depth=28 MODEL.widen_factor=2 MODEL.num_classes=10 EXPERIMENT.out_model='./checkpoints/checkpoints_celiali-lambda_unlabled_3/' EXPERIMENT.log_path='./outputs/outputs_lambda_unlabled_3/' EXPERIMENT.save_cfmatrix=False EXPERIMENT.decay_type='cosine' DATASET.cut_type='cutout' EXPERIMENT.lambda_unlabeled=3 EXPERIMENT.resume=True EXPERIMENT.resume_checkpoints='./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cVKW7J6pi0lD","executionInfo":{"status":"ok","timestamp":1650721666599,"user_tz":300,"elapsed":4417317,"user":{"displayName":"CM Y","userId":"12660552299343911788"}},"outputId":"349ddb3a-d473-4abc-e611-ad8a7423b6d1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["==> CONFIG is: \n"," DATASET:\n","  project_dir: ./\n","  data_dir: data\n","  loading_data: LOAD_LABEL_UNLABEL\n","  dataset: CIFAR10\n","  strongaugment: RA\n","  cut_type: cutout\n","  label_num: 4000\n","  num_expand_x: 65536\n","  mu: 7\n","  barely: false\n","  add_noisy_label: false\n","  both_strong: false\n","MODEL:\n","  name: WideResNet_Lk\n","  depth: 28\n","  widen_factor: 2\n","  num_classes: 10\n","  dropout: 0.0\n","  cardinality: 4\n","  width: 4\n","  base_width: 4\n","EXPERIMENT:\n","  name: FMExperiment\n","  out_model: ./checkpoints/checkpoints_celiali-lambda_unlabled_3/\n","  log_path: ./outputs/outputs_lambda_unlabled_3/\n","  used_gpu: true\n","  decay_type: cosine\n","  abel_decay: 0.1\n","  optim_lr: 0.03\n","  optim_momentum: 0.9\n","  used_nesterov: true\n","  warmup: 0\n","  wdecay: 0.0005\n","  clip: 1\n","  ema_used: true\n","  ema_decay: 0.999\n","  threshold: 0.95\n","  lambda_unlabeled: 3\n","  batch_size: 64\n","  num_workers: 4\n","  n_imgs_per_epoch: 65536\n","  epoch_n: 120\n","  save_every: 2\n","  save_matrix_every: 20\n","  resume: true\n","  resume_checkpoints: ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","  save_cfmatrix: false\n","  batch_balanced: false\n","  neg_penalty: false\n","  equal_freq: false\n","  eta_negpenalty: 0.05\n","  eta_dynamic: false\n","  use_nlloss: false\n","  q: 0.0001\n","Logging:\n","  name: FM\n","  seed: 1265\n"," \n","\n","2022-04-23 03:52:58,568 - INFO - Train -   {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'cut_type': 'cutout', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-lambda_unlabled_3/', 'log_path': './outputs/outputs_lambda_unlabled_3/', 'used_gpu': True, 'decay_type': 'cosine', 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 3, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': True, 'resume_checkpoints': './checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","[2022-04-23 03:52:58,568][Train][INFO] - {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'cut_type': 'cutout', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-lambda_unlabled_3/', 'log_path': './outputs/outputs_lambda_unlabled_3/', 'used_gpu': True, 'decay_type': 'cosine', 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 3, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': True, 'resume_checkpoints': './checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","2022-04-23 03:52:58,886 - INFO - Train -   [Model] Building model WideResNet_Lk\n","[2022-04-23 03:52:58,886][Train][INFO] - [Model] Building model WideResNet_Lk\n","2022-04-23 03:53:01,461 - INFO - Train -   Total params: 1.47M\n","[2022-04-23 03:53:01,461][Train][INFO] - Total params: 1.47M\n","[2022-04-23 03:53:01,462][experiments.experiment][INFO] - I'm using cosine decay!\n","[2022-04-23 03:53:01,466][experiments.experiment][INFO] - [EMA] initial \n","[2022-04-23 03:53:07,455][datasets.datasets1][INFO] - Dataset: CIFAR10\n","[2022-04-23 03:53:07,504][datasets.datasets1][INFO] - Labeled examples: 65536 Unlabeled examples: 458752Validation examples: 5000\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-23 03:53:07,506][experiments.experiment][INFO] - Loading Labelled Loader\n","[2022-04-23 03:53:07,506][experiments.experiment][INFO] - Loading Unlabelled Loader\n","[2022-04-23 03:53:07,507][experiments.experiment][INFO] - Loading Validation Loader\n","=> loading checkpoint './checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar'\n","[2022-04-23 03:53:08,496][experiments.experiment][INFO] - ==> Resuming from checkpoint..\n","=> loaded checkpoint './checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar' (epoch 41)\n","[2022-04-23 03:53:09,091][experiments.experiment][INFO] - => loaded checkpoint './checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar' (epoch 41)\n","[2022-04-23 03:53:09,092][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:00:36,375][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 41: use 447.37891387939453 seconds\n","--- Optimizer learning rate changed from inf to 2.64e-02 ---\n","[2022-04-23 04:00:36,471][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:00:37,785][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:00:37,785][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:00:39,235][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:00:44,239][experiments.experiment][INFO] - [EMA] Epoch 41.[Train] time:447.37891387939453 seconds, lr:0.0264, train_loss: 0.8316, unlabeled_losses_real_strong:0.5792,corrrect_unlabeled_num:381365.0,pro_above_threshold_num:390720.0,unlabelled_weak_top1_acc:92.10510148108006,unlabelled_weak_top5_acc:99.6695383861661  \n","[2022-04-23 04:00:44,239][experiments.experiment][INFO] - [EMA] Epoch 41. [Validation] raw_testing_loss: 0.4389, raw test Top1 acc:88.04, raw test Top5 acc: 99.54, ema_testing_loss: 0.2541, ema test Top1 acc:93.12, ema test Top5 acc: 99.82\n","[2022-04-23 04:00:44,330][experiments.experiment][INFO] - [Checkpoints] Epoch 41, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 04:00:44,340][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:08:11,096][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 42: use 446.851637840271 seconds\n","--- Optimizer learning rate changed from 2.64e-02 to 2.63e-02 ---\n","[2022-04-23 04:08:11,192][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:08:12,543][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:08:12,543][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:08:13,884][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:08:13,888][experiments.experiment][INFO] - [EMA] Epoch 42.[Train] time:446.851637840271 seconds, lr:0.0263, train_loss: 0.8268, unlabeled_losses_real_strong:0.5736,corrrect_unlabeled_num:382589.0,pro_above_threshold_num:391764.0,unlabelled_weak_top1_acc:92.2023216560483,unlabelled_weak_top5_acc:99.66539675742388  \n","[2022-04-23 04:08:13,890][experiments.experiment][INFO] - [EMA] Epoch 42. [Validation] raw_testing_loss: 0.4971, raw test Top1 acc:87.3, raw test Top5 acc: 99.44, ema_testing_loss: 0.2510, ema test Top1 acc:92.88, ema test Top5 acc: 99.8\n","[2022-04-23 04:08:13,892][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:15:39,207][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 43: use 445.4154534339905 seconds\n","--- Optimizer learning rate changed from 2.63e-02 to 2.61e-02 ---\n","[2022-04-23 04:15:39,307][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:15:40,622][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:15:40,623][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:15:42,003][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:15:42,005][experiments.experiment][INFO] - [EMA] Epoch 43.[Train] time:445.4154534339905 seconds, lr:0.0261, train_loss: 0.8196, unlabeled_losses_real_strong:0.5675,corrrect_unlabeled_num:382645.0,pro_above_threshold_num:391664.0,unlabelled_weak_top1_acc:92.29038677364588,unlabelled_weak_top5_acc:99.68828497081995  \n","[2022-04-23 04:15:42,006][experiments.experiment][INFO] - [EMA] Epoch 43. [Validation] raw_testing_loss: 0.3468, raw test Top1 acc:90.72, raw test Top5 acc: 99.64, ema_testing_loss: 0.2478, ema test Top1 acc:93.54, ema test Top5 acc: 99.8\n","[2022-04-23 04:15:42,101][experiments.experiment][INFO] - [Checkpoints] Epoch 43, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 04:15:42,103][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:23:06,977][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 44: use 444.97290301322937 seconds\n","--- Optimizer learning rate changed from 2.61e-02 to 2.59e-02 ---\n","[2022-04-23 04:23:07,076][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:23:08,391][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:23:08,392][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:23:09,734][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:23:09,735][experiments.experiment][INFO] - [EMA] Epoch 44.[Train] time:444.97290301322937 seconds, lr:0.0259, train_loss: 0.8252, unlabeled_losses_real_strong:0.5675,corrrect_unlabeled_num:383661.0,pro_above_threshold_num:393005.0,unlabelled_weak_top1_acc:92.26771654188633,unlabelled_weak_top5_acc:99.67825774103403  \n","[2022-04-23 04:23:09,737][experiments.experiment][INFO] - [EMA] Epoch 44. [Validation] raw_testing_loss: 0.3687, raw test Top1 acc:90.14, raw test Top5 acc: 99.52, ema_testing_loss: 0.2478, ema test Top1 acc:93.44, ema test Top5 acc: 99.84\n","[2022-04-23 04:23:09,738][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:30:35,474][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 45: use 445.8310179710388 seconds\n","--- Optimizer learning rate changed from 2.59e-02 to 2.58e-02 ---\n","[2022-04-23 04:30:35,570][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:30:36,926][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:30:36,926][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:30:38,269][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:30:38,270][experiments.experiment][INFO] - [EMA] Epoch 45.[Train] time:445.8310179710388 seconds, lr:0.0258, train_loss: 0.8193, unlabeled_losses_real_strong:0.5669,corrrect_unlabeled_num:383746.0,pro_above_threshold_num:392891.0,unlabelled_weak_top1_acc:92.3514219224453,unlabelled_weak_top5_acc:99.69155469536781  \n","[2022-04-23 04:30:38,272][experiments.experiment][INFO] - [EMA] Epoch 45. [Validation] raw_testing_loss: 0.3677, raw test Top1 acc:89.76, raw test Top5 acc: 99.62, ema_testing_loss: 0.2487, ema test Top1 acc:93.32, ema test Top5 acc: 99.78\n","[2022-04-23 04:30:38,371][experiments.experiment][INFO] - [Checkpoints] Epoch 45, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 04:30:38,381][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:38:06,532][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 46: use 448.2495324611664 seconds\n","--- Optimizer learning rate changed from 2.58e-02 to 2.56e-02 ---\n","[2022-04-23 04:38:06,630][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:38:08,039][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:38:08,040][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:38:09,401][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:38:09,402][experiments.experiment][INFO] - [EMA] Epoch 46.[Train] time:448.2495324611664 seconds, lr:0.0256, train_loss: 0.8151, unlabeled_losses_real_strong:0.5572,corrrect_unlabeled_num:384885.0,pro_above_threshold_num:393853.0,unlabelled_weak_top1_acc:92.50749746710062,unlabelled_weak_top5_acc:99.71575088053942  \n","[2022-04-23 04:38:09,403][experiments.experiment][INFO] - [EMA] Epoch 46. [Validation] raw_testing_loss: 0.4311, raw test Top1 acc:89.3, raw test Top5 acc: 99.58, ema_testing_loss: 0.2446, ema test Top1 acc:93.54, ema test Top5 acc: 99.8\n","[2022-04-23 04:38:09,404][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:45:35,203][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 47: use 445.89402437210083 seconds\n","--- Optimizer learning rate changed from 2.56e-02 to 2.54e-02 ---\n","[2022-04-23 04:45:35,298][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:45:36,621][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:45:36,622][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:45:37,954][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:45:37,956][experiments.experiment][INFO] - [EMA] Epoch 47.[Train] time:445.89402437210083 seconds, lr:0.0254, train_loss: 0.8126, unlabeled_losses_real_strong:0.5578,corrrect_unlabeled_num:384951.0,pro_above_threshold_num:394069.0,unlabelled_weak_top1_acc:92.48504534363747,unlabelled_weak_top5_acc:99.69155479222536  \n","[2022-04-23 04:45:37,957][experiments.experiment][INFO] - [EMA] Epoch 47. [Validation] raw_testing_loss: 0.3929, raw test Top1 acc:89.48, raw test Top5 acc: 99.6, ema_testing_loss: 0.2461, ema test Top1 acc:93.46, ema test Top5 acc: 99.82\n","[2022-04-23 04:45:38,057][experiments.experiment][INFO] - [Checkpoints] Epoch 47, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 04:45:38,069][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 04:53:06,246][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 48: use 448.27003359794617 seconds\n","--- Optimizer learning rate changed from 2.54e-02 to 2.52e-02 ---\n","[2022-04-23 04:53:06,339][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:53:07,704][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 04:53:07,705][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 04:53:09,029][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 04:53:09,030][experiments.experiment][INFO] - [EMA] Epoch 48.[Train] time:448.27003359794617 seconds, lr:0.0252, train_loss: 0.8172, unlabeled_losses_real_strong:0.5565,corrrect_unlabeled_num:386021.0,pro_above_threshold_num:395103.0,unlabelled_weak_top1_acc:92.55741552263498,unlabelled_weak_top5_acc:99.69635032117367  \n","[2022-04-23 04:53:09,033][experiments.experiment][INFO] - [EMA] Epoch 48. [Validation] raw_testing_loss: 0.4855, raw test Top1 acc:87.32, raw test Top5 acc: 98.82, ema_testing_loss: 0.2487, ema test Top1 acc:93.48, ema test Top5 acc: 99.82\n","[2022-04-23 04:53:09,034][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:00:36,206][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 49: use 447.2702052593231 seconds\n","--- Optimizer learning rate changed from 2.52e-02 to 2.50e-02 ---\n","[2022-04-23 05:00:36,304][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:00:37,682][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:00:37,683][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:00:39,049][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:00:39,050][experiments.experiment][INFO] - [EMA] Epoch 49.[Train] time:447.2702052593231 seconds, lr:0.0250, train_loss: 0.8106, unlabeled_losses_real_strong:0.5509,corrrect_unlabeled_num:386301.0,pro_above_threshold_num:395343.0,unlabelled_weak_top1_acc:92.60580772906542,unlabelled_weak_top5_acc:99.70049208402634  \n","[2022-04-23 05:00:39,051][experiments.experiment][INFO] - [EMA] Epoch 49. [Validation] raw_testing_loss: 0.5469, raw test Top1 acc:87.08, raw test Top5 acc: 99.26, ema_testing_loss: 0.2432, ema test Top1 acc:93.3, ema test Top5 acc: 99.84\n","[2022-04-23 05:00:39,147][experiments.experiment][INFO] - [Checkpoints] Epoch 49, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 05:00:39,158][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:08:07,851][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 50: use 448.7948884963989 seconds\n","--- Optimizer learning rate changed from 2.50e-02 to 2.48e-02 ---\n","[2022-04-23 05:08:07,953][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:08:09,331][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:08:09,331][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:08:10,703][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:08:10,705][experiments.experiment][INFO] - [EMA] Epoch 50.[Train] time:448.7948884963989 seconds, lr:0.0248, train_loss: 0.8082, unlabeled_losses_real_strong:0.5461,corrrect_unlabeled_num:387188.0,pro_above_threshold_num:396206.0,unlabelled_weak_top1_acc:92.67708794772625,unlabelled_weak_top5_acc:99.72032859176397  \n","[2022-04-23 05:08:10,706][experiments.experiment][INFO] - [EMA] Epoch 50. [Validation] raw_testing_loss: 0.3971, raw test Top1 acc:88.44, raw test Top5 acc: 99.58, ema_testing_loss: 0.2396, ema test Top1 acc:93.72, ema test Top5 acc: 99.8\n","[2022-04-23 05:08:10,708][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:15:37,278][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 51: use 446.66862201690674 seconds\n","--- Optimizer learning rate changed from 2.48e-02 to 2.46e-02 ---\n","[2022-04-23 05:15:37,376][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:15:38,683][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:15:38,684][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:15:40,011][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:15:40,012][experiments.experiment][INFO] - [EMA] Epoch 51.[Train] time:446.66862201690674 seconds, lr:0.0246, train_loss: 0.8047, unlabeled_losses_real_strong:0.5445,corrrect_unlabeled_num:387826.0,pro_above_threshold_num:396780.0,unlabelled_weak_top1_acc:92.74836837500334,unlabelled_weak_top5_acc:99.70921149849892  \n","[2022-04-23 05:15:40,013][experiments.experiment][INFO] - [EMA] Epoch 51. [Validation] raw_testing_loss: 0.3635, raw test Top1 acc:90.34, raw test Top5 acc: 99.62, ema_testing_loss: 0.2369, ema test Top1 acc:93.58, ema test Top5 acc: 99.9\n","[2022-04-23 05:15:40,110][experiments.experiment][INFO] - [Checkpoints] Epoch 51, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 05:15:40,119][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:23:04,665][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 52: use 444.6504032611847 seconds\n","--- Optimizer learning rate changed from 2.46e-02 to 2.44e-02 ---\n","[2022-04-23 05:23:04,769][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:23:06,164][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:23:06,165][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:23:07,484][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:23:07,485][experiments.experiment][INFO] - [EMA] Epoch 52.[Train] time:444.6504032611847 seconds, lr:0.0244, train_loss: 0.8036, unlabeled_losses_real_strong:0.5410,corrrect_unlabeled_num:388433.0,pro_above_threshold_num:397421.0,unlabelled_weak_top1_acc:92.76755077391863,unlabelled_weak_top5_acc:99.71335303038359  \n","[2022-04-23 05:23:07,486][experiments.experiment][INFO] - [EMA] Epoch 52. [Validation] raw_testing_loss: 0.4897, raw test Top1 acc:87.46, raw test Top5 acc: 99.34, ema_testing_loss: 0.2360, ema test Top1 acc:93.52, ema test Top5 acc: 99.86\n","[2022-04-23 05:23:07,488][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:30:32,958][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 53: use 445.56855487823486 seconds\n","--- Optimizer learning rate changed from 2.44e-02 to 2.42e-02 ---\n","[2022-04-23 05:30:33,057][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:30:34,353][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:30:34,353][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:30:35,686][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:30:35,687][experiments.experiment][INFO] - [EMA] Epoch 53.[Train] time:445.56855487823486 seconds, lr:0.0242, train_loss: 0.8008, unlabeled_losses_real_strong:0.5394,corrrect_unlabeled_num:388533.0,pro_above_threshold_num:397418.0,unlabelled_weak_top1_acc:92.79349094629288,unlabelled_weak_top5_acc:99.71771277487278  \n","[2022-04-23 05:30:35,689][experiments.experiment][INFO] - [EMA] Epoch 53. [Validation] raw_testing_loss: 0.3399, raw test Top1 acc:90.22, raw test Top5 acc: 99.74, ema_testing_loss: 0.2374, ema test Top1 acc:93.56, ema test Top5 acc: 99.84\n","[2022-04-23 05:30:35,807][experiments.experiment][INFO] - [Checkpoints] Epoch 53, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 05:30:35,808][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:38:02,751][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 54: use 447.0475788116455 seconds\n","--- Optimizer learning rate changed from 2.42e-02 to 2.40e-02 ---\n","[2022-04-23 05:38:02,855][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:38:04,203][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:38:04,203][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:38:05,522][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:38:05,524][experiments.experiment][INFO] - [EMA] Epoch 54.[Train] time:447.0475788116455 seconds, lr:0.0240, train_loss: 0.7960, unlabeled_losses_real_strong:0.5345,corrrect_unlabeled_num:389809.0,pro_above_threshold_num:398610.0,unlabelled_weak_top1_acc:92.95501589030027,unlabelled_weak_top5_acc:99.7164049744606  \n","[2022-04-23 05:38:05,525][experiments.experiment][INFO] - [EMA] Epoch 54. [Validation] raw_testing_loss: 0.3623, raw test Top1 acc:89.9, raw test Top5 acc: 99.58, ema_testing_loss: 0.2354, ema test Top1 acc:93.6, ema test Top5 acc: 99.86\n","[2022-04-23 05:38:05,526][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:45:30,768][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 55: use 445.34087920188904 seconds\n","--- Optimizer learning rate changed from 2.40e-02 to 2.38e-02 ---\n","[2022-04-23 05:45:30,867][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:45:32,235][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:45:32,235][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:45:33,677][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:45:33,679][experiments.experiment][INFO] - [EMA] Epoch 55.[Train] time:445.34087920188904 seconds, lr:0.0238, train_loss: 0.7943, unlabeled_losses_real_strong:0.5332,corrrect_unlabeled_num:390475.0,pro_above_threshold_num:399406.0,unlabelled_weak_top1_acc:92.94368078559637,unlabelled_weak_top5_acc:99.73297169059515  \n","[2022-04-23 05:45:33,680][experiments.experiment][INFO] - [EMA] Epoch 55. [Validation] raw_testing_loss: 0.3646, raw test Top1 acc:89.98, raw test Top5 acc: 99.64, ema_testing_loss: 0.2361, ema test Top1 acc:93.72, ema test Top5 acc: 99.86\n","[2022-04-23 05:45:33,774][experiments.experiment][INFO] - [Checkpoints] Epoch 55, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 05:45:33,780][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 05:53:01,792][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 56: use 448.1088125705719 seconds\n","--- Optimizer learning rate changed from 2.38e-02 to 2.36e-02 ---\n","[2022-04-23 05:53:01,889][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:53:03,216][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 05:53:03,216][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 05:53:04,617][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 05:53:04,618][experiments.experiment][INFO] - [EMA] Epoch 56.[Train] time:448.1088125705719 seconds, lr:0.0236, train_loss: 0.7941, unlabeled_losses_real_strong:0.5312,corrrect_unlabeled_num:390309.0,pro_above_threshold_num:399159.0,unlabelled_weak_top1_acc:93.01801308989525,unlabelled_weak_top5_acc:99.71030135452747  \n","[2022-04-23 05:53:04,619][experiments.experiment][INFO] - [EMA] Epoch 56. [Validation] raw_testing_loss: 0.3072, raw test Top1 acc:90.72, raw test Top5 acc: 99.72, ema_testing_loss: 0.2386, ema test Top1 acc:93.64, ema test Top5 acc: 99.88\n","[2022-04-23 05:53:04,621][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:00:30,756][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 57: use 446.23265075683594 seconds\n","--- Optimizer learning rate changed from 2.36e-02 to 2.34e-02 ---\n","[2022-04-23 06:00:30,854][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:00:32,231][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:00:32,231][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:00:33,618][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:00:33,619][experiments.experiment][INFO] - [EMA] Epoch 57.[Train] time:446.23265075683594 seconds, lr:0.0234, train_loss: 0.7887, unlabeled_losses_real_strong:0.5284,corrrect_unlabeled_num:391176.0,pro_above_threshold_num:400040.0,unlabelled_weak_top1_acc:93.05899381637573,unlabelled_weak_top5_acc:99.73209961503744  \n","[2022-04-23 06:00:33,621][experiments.experiment][INFO] - [EMA] Epoch 57. [Validation] raw_testing_loss: 0.3403, raw test Top1 acc:91.18, raw test Top5 acc: 99.72, ema_testing_loss: 0.2382, ema test Top1 acc:93.76, ema test Top5 acc: 99.88\n","[2022-04-23 06:00:33,717][experiments.experiment][INFO] - [Checkpoints] Epoch 57, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 06:00:33,719][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:08:01,137][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 58: use 447.5192151069641 seconds\n","--- Optimizer learning rate changed from 2.34e-02 to 2.32e-02 ---\n","[2022-04-23 06:08:01,239][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:08:02,605][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:08:02,605][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:08:03,946][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:08:03,947][experiments.experiment][INFO] - [EMA] Epoch 58.[Train] time:447.5192151069641 seconds, lr:0.0232, train_loss: 0.7916, unlabeled_losses_real_strong:0.5289,corrrect_unlabeled_num:391602.0,pro_above_threshold_num:400464.0,unlabelled_weak_top1_acc:93.0929991826415,unlabelled_weak_top5_acc:99.72904785722494  \n","[2022-04-23 06:08:03,949][experiments.experiment][INFO] - [EMA] Epoch 58. [Validation] raw_testing_loss: 0.4092, raw test Top1 acc:89.36, raw test Top5 acc: 99.42, ema_testing_loss: 0.2372, ema test Top1 acc:93.76, ema test Top5 acc: 99.84\n","[2022-04-23 06:08:03,950][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:15:30,765][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 59: use 446.91510820388794 seconds\n","--- Optimizer learning rate changed from 2.32e-02 to 2.30e-02 ---\n","[2022-04-23 06:15:30,865][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:15:32,181][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:15:32,181][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:15:33,574][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:15:33,575][experiments.experiment][INFO] - [EMA] Epoch 59.[Train] time:446.91510820388794 seconds, lr:0.0230, train_loss: 0.7874, unlabeled_losses_real_strong:0.5245,corrrect_unlabeled_num:392085.0,pro_above_threshold_num:401050.0,unlabelled_weak_top1_acc:93.08427964895964,unlabelled_weak_top5_acc:99.73057383298874  \n","[2022-04-23 06:15:33,576][experiments.experiment][INFO] - [EMA] Epoch 59. [Validation] raw_testing_loss: 0.2899, raw test Top1 acc:91.32, raw test Top5 acc: 99.72, ema_testing_loss: 0.2351, ema test Top1 acc:93.7, ema test Top5 acc: 99.84\n","[2022-04-23 06:15:33,678][experiments.experiment][INFO] - [Checkpoints] Epoch 59, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 06:15:33,679][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:23:00,651][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 60: use 447.0689060688019 seconds\n","--- Optimizer learning rate changed from 2.30e-02 to 2.27e-02 ---\n","[2022-04-23 06:23:00,748][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:23:02,079][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:23:02,080][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:23:03,438][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:23:03,440][experiments.experiment][INFO] - [EMA] Epoch 60.[Train] time:447.0689060688019 seconds, lr:0.0227, train_loss: 0.7826, unlabeled_losses_real_strong:0.5219,corrrect_unlabeled_num:392220.0,pro_above_threshold_num:401072.0,unlabelled_weak_top1_acc:93.1692930161953,unlabelled_weak_top5_acc:99.74365278333426  \n","[2022-04-23 06:23:03,442][experiments.experiment][INFO] - [EMA] Epoch 60. [Validation] raw_testing_loss: 0.3481, raw test Top1 acc:90.44, raw test Top5 acc: 99.7, ema_testing_loss: 0.2340, ema test Top1 acc:93.9, ema test Top5 acc: 99.88\n","[2022-04-23 06:23:03,443][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:30:29,515][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 61: use 446.1709363460541 seconds\n","--- Optimizer learning rate changed from 2.27e-02 to 2.25e-02 ---\n","[2022-04-23 06:30:29,614][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:30:30,965][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:30:30,966][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:30:32,322][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:30:32,324][experiments.experiment][INFO] - [EMA] Epoch 61.[Train] time:446.1709363460541 seconds, lr:0.0225, train_loss: 0.7826, unlabeled_losses_real_strong:0.5223,corrrect_unlabeled_num:392333.0,pro_above_threshold_num:401195.0,unlabelled_weak_top1_acc:93.14684080332518,unlabelled_weak_top5_acc:99.73318955302238  \n","[2022-04-23 06:30:32,326][experiments.experiment][INFO] - [EMA] Epoch 61. [Validation] raw_testing_loss: 0.3396, raw test Top1 acc:90.68, raw test Top5 acc: 99.58, ema_testing_loss: 0.2328, ema test Top1 acc:93.96, ema test Top5 acc: 99.82\n","[2022-04-23 06:30:32,421][experiments.experiment][INFO] - [Checkpoints] Epoch 61, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 06:30:32,424][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:37:56,145][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 62: use 443.82072591781616 seconds\n","--- Optimizer learning rate changed from 2.25e-02 to 2.23e-02 ---\n","[2022-04-23 06:37:56,244][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:37:57,607][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:37:57,608][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:37:58,952][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:37:58,953][experiments.experiment][INFO] - [EMA] Epoch 62.[Train] time:443.82072591781616 seconds, lr:0.0223, train_loss: 0.7784, unlabeled_losses_real_strong:0.5154,corrrect_unlabeled_num:393324.0,pro_above_threshold_num:402240.0,unlabelled_weak_top1_acc:93.24929258227348,unlabelled_weak_top5_acc:99.73035575449467  \n","[2022-04-23 06:37:58,956][experiments.experiment][INFO] - [EMA] Epoch 62. [Validation] raw_testing_loss: 0.3426, raw test Top1 acc:90.4, raw test Top5 acc: 99.76, ema_testing_loss: 0.2246, ema test Top1 acc:94.26, ema test Top5 acc: 99.84\n","[2022-04-23 06:37:58,956][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:45:27,291][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 63: use 448.43460607528687 seconds\n","--- Optimizer learning rate changed from 2.23e-02 to 2.21e-02 ---\n","[2022-04-23 06:45:27,391][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:45:28,713][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:45:28,714][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:45:30,040][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:45:30,042][experiments.experiment][INFO] - [EMA] Epoch 63.[Train] time:448.43460607528687 seconds, lr:0.0221, train_loss: 0.7786, unlabeled_losses_real_strong:0.5142,corrrect_unlabeled_num:393925.0,pro_above_threshold_num:402651.0,unlabelled_weak_top1_acc:93.29419706761837,unlabelled_weak_top5_acc:99.72512426227331  \n","[2022-04-23 06:45:30,044][experiments.experiment][INFO] - [EMA] Epoch 63. [Validation] raw_testing_loss: 0.3719, raw test Top1 acc:90.14, raw test Top5 acc: 99.5, ema_testing_loss: 0.2250, ema test Top1 acc:94.22, ema test Top5 acc: 99.88\n","[2022-04-23 06:45:30,139][experiments.experiment][INFO] - [Checkpoints] Epoch 63, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 06:45:30,141][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 06:52:58,926][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 64: use 448.88472151756287 seconds\n","--- Optimizer learning rate changed from 2.21e-02 to 2.18e-02 ---\n","[2022-04-23 06:52:59,026][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:53:00,366][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 06:53:00,366][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 06:53:01,697][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 06:53:01,699][experiments.experiment][INFO] - [EMA] Epoch 64.[Train] time:448.88472151756287 seconds, lr:0.0218, train_loss: 0.7740, unlabeled_losses_real_strong:0.5096,corrrect_unlabeled_num:394369.0,pro_above_threshold_num:403070.0,unlabelled_weak_top1_acc:93.36155375093222,unlabelled_weak_top5_acc:99.74408864974976  \n","[2022-04-23 06:53:01,701][experiments.experiment][INFO] - [EMA] Epoch 64. [Validation] raw_testing_loss: 0.3478, raw test Top1 acc:90.46, raw test Top5 acc: 99.68, ema_testing_loss: 0.2243, ema test Top1 acc:94.26, ema test Top5 acc: 99.88\n","[2022-04-23 06:53:01,702][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:00:31,570][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 65: use 449.9644389152527 seconds\n","--- Optimizer learning rate changed from 2.18e-02 to 2.16e-02 ---\n","[2022-04-23 07:00:31,667][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:00:33,003][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:00:33,003][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:00:34,410][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:00:34,411][experiments.experiment][INFO] - [EMA] Epoch 65.[Train] time:449.9644389152527 seconds, lr:0.0216, train_loss: 0.7721, unlabeled_losses_real_strong:0.5089,corrrect_unlabeled_num:395068.0,pro_above_threshold_num:403798.0,unlabelled_weak_top1_acc:93.37703043967485,unlabelled_weak_top5_acc:99.73253560066223  \n","[2022-04-23 07:00:34,412][experiments.experiment][INFO] - [EMA] Epoch 65. [Validation] raw_testing_loss: 0.3226, raw test Top1 acc:90.96, raw test Top5 acc: 99.72, ema_testing_loss: 0.2250, ema test Top1 acc:94.2, ema test Top5 acc: 99.82\n","[2022-04-23 07:00:34,509][experiments.experiment][INFO] - [Checkpoints] Epoch 65, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 07:00:34,510][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:08:06,041][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 66: use 451.6278657913208 seconds\n","--- Optimizer learning rate changed from 2.16e-02 to 2.14e-02 ---\n","[2022-04-23 07:08:06,138][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:08:07,497][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:08:07,498][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:08:08,842][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:08:08,843][experiments.experiment][INFO] - [EMA] Epoch 66.[Train] time:451.6278657913208 seconds, lr:0.0214, train_loss: 0.7735, unlabeled_losses_real_strong:0.5066,corrrect_unlabeled_num:395222.0,pro_above_threshold_num:403946.0,unlabelled_weak_top1_acc:93.45397827774286,unlabelled_weak_top5_acc:99.75106424838305  \n","[2022-04-23 07:08:08,845][experiments.experiment][INFO] - [EMA] Epoch 66. [Validation] raw_testing_loss: 0.3312, raw test Top1 acc:90.84, raw test Top5 acc: 99.74, ema_testing_loss: 0.2243, ema test Top1 acc:94.3, ema test Top5 acc: 99.88\n","[2022-04-23 07:08:08,847][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:15:32,069][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 67: use 443.31975841522217 seconds\n","--- Optimizer learning rate changed from 2.14e-02 to 2.11e-02 ---\n","[2022-04-23 07:15:32,167][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:15:33,542][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:15:33,543][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:15:34,940][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:15:34,942][experiments.experiment][INFO] - [EMA] Epoch 67.[Train] time:443.31975841522217 seconds, lr:0.0211, train_loss: 0.7691, unlabeled_losses_real_strong:0.5050,corrrect_unlabeled_num:395610.0,pro_above_threshold_num:404385.0,unlabelled_weak_top1_acc:93.45049063116312,unlabelled_weak_top5_acc:99.74256285279989  \n","[2022-04-23 07:15:34,944][experiments.experiment][INFO] - [EMA] Epoch 67. [Validation] raw_testing_loss: 0.3980, raw test Top1 acc:89.18, raw test Top5 acc: 99.64, ema_testing_loss: 0.2277, ema test Top1 acc:94.08, ema test Top5 acc: 99.88\n","[2022-04-23 07:15:35,039][experiments.experiment][INFO] - [Checkpoints] Epoch 67, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 07:15:35,048][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:22:59,415][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 68: use 444.4653890132904 seconds\n","--- Optimizer learning rate changed from 2.11e-02 to 2.09e-02 ---\n","[2022-04-23 07:22:59,514][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:23:00,832][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:23:00,832][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:23:02,137][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:23:02,138][experiments.experiment][INFO] - [EMA] Epoch 68.[Train] time:444.4653890132904 seconds, lr:0.0209, train_loss: 0.7644, unlabeled_losses_real_strong:0.5035,corrrect_unlabeled_num:396101.0,pro_above_threshold_num:405002.0,unlabelled_weak_top1_acc:93.4866759032011,unlabelled_weak_top5_acc:99.7486662864685  \n","[2022-04-23 07:23:02,140][experiments.experiment][INFO] - [EMA] Epoch 68. [Validation] raw_testing_loss: 0.3556, raw test Top1 acc:90.78, raw test Top5 acc: 99.64, ema_testing_loss: 0.2237, ema test Top1 acc:94.2, ema test Top5 acc: 99.88\n","[2022-04-23 07:23:02,141][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:30:25,126][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 69: use 443.0821216106415 seconds\n","--- Optimizer learning rate changed from 2.09e-02 to 2.06e-02 ---\n","[2022-04-23 07:30:25,223][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:30:26,536][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:30:26,536][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:30:27,853][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:30:27,855][experiments.experiment][INFO] - [EMA] Epoch 69.[Train] time:443.0821216106415 seconds, lr:0.0206, train_loss: 0.7553, unlabeled_losses_real_strong:0.4997,corrrect_unlabeled_num:396263.0,pro_above_threshold_num:404950.0,unlabelled_weak_top1_acc:93.49190742522478,unlabelled_weak_top5_acc:99.75782159715891  \n","[2022-04-23 07:30:27,856][experiments.experiment][INFO] - [EMA] Epoch 69. [Validation] raw_testing_loss: 0.4375, raw test Top1 acc:88.4, raw test Top5 acc: 99.32, ema_testing_loss: 0.2271, ema test Top1 acc:94.2, ema test Top5 acc: 99.86\n","[2022-04-23 07:30:27,949][experiments.experiment][INFO] - [Checkpoints] Epoch 69, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 07:30:27,952][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:37:50,605][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 70: use 442.74749851226807 seconds\n","--- Optimizer learning rate changed from 2.06e-02 to 2.04e-02 ---\n","[2022-04-23 07:37:50,699][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:37:52,008][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:37:52,009][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:37:53,350][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:37:53,351][experiments.experiment][INFO] - [EMA] Epoch 70.[Train] time:442.74749851226807 seconds, lr:0.0204, train_loss: 0.7627, unlabeled_losses_real_strong:0.4990,corrrect_unlabeled_num:396625.0,pro_above_threshold_num:405208.0,unlabelled_weak_top1_acc:93.57038122415543,unlabelled_weak_top5_acc:99.76545107364655  \n","[2022-04-23 07:37:53,354][experiments.experiment][INFO] - [EMA] Epoch 70. [Validation] raw_testing_loss: 0.3254, raw test Top1 acc:91.22, raw test Top5 acc: 99.72, ema_testing_loss: 0.2246, ema test Top1 acc:94.28, ema test Top5 acc: 99.88\n","[2022-04-23 07:37:53,354][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:45:15,329][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 71: use 442.06860280036926 seconds\n","--- Optimizer learning rate changed from 2.04e-02 to 2.01e-02 ---\n","[2022-04-23 07:45:15,423][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:45:16,756][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:45:16,757][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:45:18,036][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:45:18,038][experiments.experiment][INFO] - [EMA] Epoch 71.[Train] time:442.06860280036926 seconds, lr:0.0201, train_loss: 0.7575, unlabeled_losses_real_strong:0.4954,corrrect_unlabeled_num:396842.0,pro_above_threshold_num:405303.0,unlabelled_weak_top1_acc:93.6410074904561,unlabelled_weak_top5_acc:99.76937472075224  \n","[2022-04-23 07:45:18,040][experiments.experiment][INFO] - [EMA] Epoch 71. [Validation] raw_testing_loss: 0.3247, raw test Top1 acc:90.84, raw test Top5 acc: 99.54, ema_testing_loss: 0.2232, ema test Top1 acc:94.26, ema test Top5 acc: 99.9\n","[2022-04-23 07:45:18,133][experiments.experiment][INFO] - [Checkpoints] Epoch 71, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 07:45:18,135][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 07:52:40,287][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 72: use 442.2598731517792 seconds\n","--- Optimizer learning rate changed from 2.01e-02 to 1.99e-02 ---\n","[2022-04-23 07:52:40,395][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:52:41,702][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 07:52:41,702][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 07:52:42,986][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 07:52:42,987][experiments.experiment][INFO] - [EMA] Epoch 72.[Train] time:442.2598731517792 seconds, lr:0.0199, train_loss: 0.7546, unlabeled_losses_real_strong:0.4937,corrrect_unlabeled_num:397386.0,pro_above_threshold_num:406158.0,unlabelled_weak_top1_acc:93.6353400349617,unlabelled_weak_top5_acc:99.76000149548054  \n","[2022-04-23 07:52:42,990][experiments.experiment][INFO] - [EMA] Epoch 72. [Validation] raw_testing_loss: 0.3767, raw test Top1 acc:90.26, raw test Top5 acc: 99.6, ema_testing_loss: 0.2228, ema test Top1 acc:94.16, ema test Top5 acc: 99.9\n","[2022-04-23 07:52:42,991][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:00:04,237][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 73: use 441.34370398521423 seconds\n","--- Optimizer learning rate changed from 1.99e-02 to 1.96e-02 ---\n","[2022-04-23 08:00:04,334][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:00:05,658][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:00:05,659][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:00:06,997][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:00:06,998][experiments.experiment][INFO] - [EMA] Epoch 73.[Train] time:441.34370398521423 seconds, lr:0.0196, train_loss: 0.7471, unlabeled_losses_real_strong:0.4879,corrrect_unlabeled_num:398441.0,pro_above_threshold_num:406958.0,unlabelled_weak_top1_acc:93.73343224823475,unlabelled_weak_top5_acc:99.76327128708363  \n","[2022-04-23 08:00:07,000][experiments.experiment][INFO] - [EMA] Epoch 73. [Validation] raw_testing_loss: 0.3448, raw test Top1 acc:90.8, raw test Top5 acc: 99.7, ema_testing_loss: 0.2220, ema test Top1 acc:94.14, ema test Top5 acc: 99.88\n","[2022-04-23 08:00:07,093][experiments.experiment][INFO] - [Checkpoints] Epoch 73, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 08:00:07,102][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:07:28,919][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 74: use 441.91359543800354 seconds\n","--- Optimizer learning rate changed from 1.96e-02 to 1.93e-02 ---\n","[2022-04-23 08:07:29,015][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:07:30,374][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:07:30,374][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:07:31,739][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:07:31,740][experiments.experiment][INFO] - [EMA] Epoch 74.[Train] time:441.91359543800354 seconds, lr:0.0193, train_loss: 0.7506, unlabeled_losses_real_strong:0.4864,corrrect_unlabeled_num:398528.0,pro_above_threshold_num:407201.0,unlabelled_weak_top1_acc:93.73495806008577,unlabelled_weak_top5_acc:99.77896600216627  \n","[2022-04-23 08:07:31,743][experiments.experiment][INFO] - [EMA] Epoch 74. [Validation] raw_testing_loss: 0.2722, raw test Top1 acc:92.08, raw test Top5 acc: 99.72, ema_testing_loss: 0.2189, ema test Top1 acc:94.18, ema test Top5 acc: 99.9\n","[2022-04-23 08:07:31,743][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:14:53,643][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 75: use 441.9938259124756 seconds\n","--- Optimizer learning rate changed from 1.93e-02 to 1.91e-02 ---\n","[2022-04-23 08:14:53,737][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:14:55,065][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:14:55,066][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:14:56,371][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:14:56,373][experiments.experiment][INFO] - [EMA] Epoch 75.[Train] time:441.9938259124756 seconds, lr:0.0191, train_loss: 0.7439, unlabeled_losses_real_strong:0.4843,corrrect_unlabeled_num:399385.0,pro_above_threshold_num:407969.0,unlabelled_weak_top1_acc:93.81081610172987,unlabelled_weak_top5_acc:99.76348922401667  \n","[2022-04-23 08:14:56,374][experiments.experiment][INFO] - [EMA] Epoch 75. [Validation] raw_testing_loss: 0.2985, raw test Top1 acc:91.68, raw test Top5 acc: 99.78, ema_testing_loss: 0.2130, ema test Top1 acc:94.3, ema test Top5 acc: 99.88\n","[2022-04-23 08:14:56,468][experiments.experiment][INFO] - [Checkpoints] Epoch 75, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 08:14:56,470][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:22:18,611][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 76: use 442.2374827861786 seconds\n","--- Optimizer learning rate changed from 1.91e-02 to 1.88e-02 ---\n","[2022-04-23 08:22:18,708][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:22:20,010][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:22:20,010][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:22:21,324][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:22:21,326][experiments.experiment][INFO] - [EMA] Epoch 76.[Train] time:442.2374827861786 seconds, lr:0.0188, train_loss: 0.7439, unlabeled_losses_real_strong:0.4819,corrrect_unlabeled_num:399889.0,pro_above_threshold_num:408353.0,unlabelled_weak_top1_acc:93.87141527235508,unlabelled_weak_top5_acc:99.7713365405798  \n","[2022-04-23 08:22:21,328][experiments.experiment][INFO] - [EMA] Epoch 76. [Validation] raw_testing_loss: 0.2866, raw test Top1 acc:91.78, raw test Top5 acc: 99.74, ema_testing_loss: 0.2140, ema test Top1 acc:94.46, ema test Top5 acc: 99.9\n","[2022-04-23 08:22:21,329][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:29:42,293][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 77: use 441.06433367729187 seconds\n","--- Optimizer learning rate changed from 1.88e-02 to 1.85e-02 ---\n","[2022-04-23 08:29:42,393][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:29:43,703][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:29:43,703][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:29:45,029][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:29:45,031][experiments.experiment][INFO] - [EMA] Epoch 77.[Train] time:441.06433367729187 seconds, lr:0.0185, train_loss: 0.7404, unlabeled_losses_real_strong:0.4787,corrrect_unlabeled_num:400357.0,pro_above_threshold_num:408803.0,unlabelled_weak_top1_acc:93.91522977501154,unlabelled_weak_top5_acc:99.78746733814478  \n","[2022-04-23 08:29:45,032][experiments.experiment][INFO] - [EMA] Epoch 77. [Validation] raw_testing_loss: 0.3570, raw test Top1 acc:90.3, raw test Top5 acc: 99.7, ema_testing_loss: 0.2154, ema test Top1 acc:94.36, ema test Top5 acc: 99.9\n","[2022-04-23 08:29:45,128][experiments.experiment][INFO] - [Checkpoints] Epoch 77, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 08:29:45,130][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:37:08,133][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 78: use 443.1025800704956 seconds\n","--- Optimizer learning rate changed from 1.85e-02 to 1.83e-02 ---\n","[2022-04-23 08:37:08,233][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:37:09,643][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:37:09,644][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:37:10,943][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:37:10,945][experiments.experiment][INFO] - [EMA] Epoch 78.[Train] time:443.1025800704956 seconds, lr:0.0183, train_loss: 0.7361, unlabeled_losses_real_strong:0.4740,corrrect_unlabeled_num:400982.0,pro_above_threshold_num:409333.0,unlabelled_weak_top1_acc:93.95969834178686,unlabelled_weak_top5_acc:99.77504232525826  \n","[2022-04-23 08:37:10,947][experiments.experiment][INFO] - [EMA] Epoch 78. [Validation] raw_testing_loss: 0.3215, raw test Top1 acc:91.34, raw test Top5 acc: 99.72, ema_testing_loss: 0.2100, ema test Top1 acc:94.6, ema test Top5 acc: 99.9\n","[2022-04-23 08:37:10,948][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:44:33,901][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 79: use 443.05420327186584 seconds\n","--- Optimizer learning rate changed from 1.83e-02 to 1.80e-02 ---\n","[2022-04-23 08:44:34,002][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:44:35,365][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:44:35,365][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:44:36,731][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:44:36,733][experiments.experiment][INFO] - [EMA] Epoch 79.[Train] time:443.05420327186584 seconds, lr:0.0180, train_loss: 0.7385, unlabeled_losses_real_strong:0.4725,corrrect_unlabeled_num:401245.0,pro_above_threshold_num:409490.0,unlabelled_weak_top1_acc:94.0037306919694,unlabelled_weak_top5_acc:99.78463353961706  \n","[2022-04-23 08:44:36,735][experiments.experiment][INFO] - [EMA] Epoch 79. [Validation] raw_testing_loss: 0.3629, raw test Top1 acc:90.3, raw test Top5 acc: 99.68, ema_testing_loss: 0.2108, ema test Top1 acc:94.56, ema test Top5 acc: 99.92\n","[2022-04-23 08:44:36,834][experiments.experiment][INFO] - [Checkpoints] Epoch 79, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 08:44:36,836][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:52:02,254][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 80: use 445.5185933113098 seconds\n","--- Optimizer learning rate changed from 1.80e-02 to 1.77e-02 ---\n","[2022-04-23 08:52:02,354][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:52:03,713][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:52:03,713][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:52:05,039][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:52:05,041][experiments.experiment][INFO] - [EMA] Epoch 80.[Train] time:445.5185933113098 seconds, lr:0.0177, train_loss: 0.7285, unlabeled_losses_real_strong:0.4709,corrrect_unlabeled_num:401180.0,pro_above_threshold_num:409422.0,unlabelled_weak_top1_acc:94.01702772825956,unlabelled_weak_top5_acc:99.77504229545593  \n","[2022-04-23 08:52:05,043][experiments.experiment][INFO] - [EMA] Epoch 80. [Validation] raw_testing_loss: 0.3618, raw test Top1 acc:90.24, raw test Top5 acc: 99.6, ema_testing_loss: 0.2127, ema test Top1 acc:94.38, ema test Top5 acc: 99.9\n","[2022-04-23 08:52:05,044][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 08:59:33,859][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 81: use 448.9124267101288 seconds\n","--- Optimizer learning rate changed from 1.77e-02 to 1.74e-02 ---\n","[2022-04-23 08:59:33,957][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:59:35,407][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 08:59:35,407][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 08:59:36,743][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 08:59:36,745][experiments.experiment][INFO] - [EMA] Epoch 81.[Train] time:448.9124267101288 seconds, lr:0.0174, train_loss: 0.7223, unlabeled_losses_real_strong:0.4680,corrrect_unlabeled_num:401540.0,pro_above_threshold_num:409994.0,unlabelled_weak_top1_acc:94.01833567768335,unlabelled_weak_top5_acc:99.78179978579283  \n","[2022-04-23 08:59:36,747][experiments.experiment][INFO] - [EMA] Epoch 81. [Validation] raw_testing_loss: 0.3212, raw test Top1 acc:91.16, raw test Top5 acc: 99.9, ema_testing_loss: 0.2127, ema test Top1 acc:94.3, ema test Top5 acc: 99.9\n","[2022-04-23 08:59:36,848][experiments.experiment][INFO] - [Checkpoints] Epoch 81, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 08:59:36,850][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:07:05,076][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 82: use 448.3332109451294 seconds\n","--- Optimizer learning rate changed from 1.74e-02 to 1.72e-02 ---\n","[2022-04-23 09:07:05,183][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:07:06,574][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:07:06,575][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:07:07,964][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:07:07,966][experiments.experiment][INFO] - [EMA] Epoch 82.[Train] time:448.3332109451294 seconds, lr:0.0172, train_loss: 0.7253, unlabeled_losses_real_strong:0.4681,corrrect_unlabeled_num:402360.0,pro_above_threshold_num:410907.0,unlabelled_weak_top1_acc:94.00242289155722,unlabelled_weak_top5_acc:99.78637746721506  \n","[2022-04-23 09:07:07,967][experiments.experiment][INFO] - [EMA] Epoch 82. [Validation] raw_testing_loss: 0.3292, raw test Top1 acc:90.82, raw test Top5 acc: 99.68, ema_testing_loss: 0.2126, ema test Top1 acc:94.28, ema test Top5 acc: 99.88\n","[2022-04-23 09:07:07,968][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:14:36,431][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 83: use 448.5618793964386 seconds\n","--- Optimizer learning rate changed from 1.72e-02 to 1.69e-02 ---\n","[2022-04-23 09:14:36,530][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:14:37,855][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:14:37,855][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:14:39,186][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:14:39,187][experiments.experiment][INFO] - [EMA] Epoch 83.[Train] time:448.5618793964386 seconds, lr:0.0169, train_loss: 0.7216, unlabeled_losses_real_strong:0.4627,corrrect_unlabeled_num:403014.0,pro_above_threshold_num:411473.0,unlabelled_weak_top1_acc:94.12492909282446,unlabelled_weak_top5_acc:99.78070989251137  \n","[2022-04-23 09:14:39,189][experiments.experiment][INFO] - [EMA] Epoch 83. [Validation] raw_testing_loss: 0.3264, raw test Top1 acc:91.06, raw test Top5 acc: 99.64, ema_testing_loss: 0.2062, ema test Top1 acc:94.5, ema test Top5 acc: 99.9\n","[2022-04-23 09:14:39,287][experiments.experiment][INFO] - [Checkpoints] Epoch 83, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 09:14:39,292][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:22:06,220][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 84: use 447.02638721466064 seconds\n","--- Optimizer learning rate changed from 1.69e-02 to 1.66e-02 ---\n","[2022-04-23 09:22:06,318][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:22:07,655][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:22:07,656][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:22:08,967][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:22:08,968][experiments.experiment][INFO] - [EMA] Epoch 84.[Train] time:447.02638721466064 seconds, lr:0.0166, train_loss: 0.7202, unlabeled_losses_real_strong:0.4615,corrrect_unlabeled_num:403231.0,pro_above_threshold_num:411582.0,unlabelled_weak_top1_acc:94.1685256883502,unlabelled_weak_top5_acc:99.79095513373613  \n","[2022-04-23 09:22:08,970][experiments.experiment][INFO] - [EMA] Epoch 84. [Validation] raw_testing_loss: 0.2826, raw test Top1 acc:92.04, raw test Top5 acc: 99.68, ema_testing_loss: 0.2089, ema test Top1 acc:94.62, ema test Top5 acc: 99.9\n","[2022-04-23 09:22:08,971][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:29:37,237][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 85: use 448.37061047554016 seconds\n","--- Optimizer learning rate changed from 1.66e-02 to 1.63e-02 ---\n","[2022-04-23 09:29:37,342][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:29:38,683][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:29:38,684][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:29:40,049][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:29:40,051][experiments.experiment][INFO] - [EMA] Epoch 85.[Train] time:448.37061047554016 seconds, lr:0.0163, train_loss: 0.7220, unlabeled_losses_real_strong:0.4609,corrrect_unlabeled_num:404025.0,pro_above_threshold_num:412557.0,unlabelled_weak_top1_acc:94.20492888242006,unlabelled_weak_top5_acc:99.79248096048832  \n","[2022-04-23 09:29:40,053][experiments.experiment][INFO] - [EMA] Epoch 85. [Validation] raw_testing_loss: 0.4028, raw test Top1 acc:89.06, raw test Top5 acc: 99.76, ema_testing_loss: 0.2090, ema test Top1 acc:94.76, ema test Top5 acc: 99.88\n","[2022-04-23 09:29:40,153][experiments.experiment][INFO] - [Checkpoints] Epoch 85, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 09:29:40,163][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:37:09,367][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 86: use 449.30526781082153 seconds\n","--- Optimizer learning rate changed from 1.63e-02 to 1.60e-02 ---\n","[2022-04-23 09:37:09,468][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:37:10,771][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:37:10,771][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:37:12,155][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:37:12,157][experiments.experiment][INFO] - [EMA] Epoch 86.[Train] time:449.30526781082153 seconds, lr:0.0160, train_loss: 0.7180, unlabeled_losses_real_strong:0.4561,corrrect_unlabeled_num:404762.0,pro_above_threshold_num:413164.0,unlabelled_weak_top1_acc:94.2212774977088,unlabelled_weak_top5_acc:99.79596875607967  \n","[2022-04-23 09:37:12,159][experiments.experiment][INFO] - [EMA] Epoch 86. [Validation] raw_testing_loss: 0.2456, raw test Top1 acc:92.78, raw test Top5 acc: 99.84, ema_testing_loss: 0.2043, ema test Top1 acc:94.74, ema test Top5 acc: 99.88\n","[2022-04-23 09:37:12,160][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:44:40,170][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 87: use 448.106009721756 seconds\n","--- Optimizer learning rate changed from 1.60e-02 to 1.57e-02 ---\n","[2022-04-23 09:44:40,266][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:44:41,595][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:44:41,595][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:44:42,905][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:44:42,907][experiments.experiment][INFO] - [EMA] Epoch 87.[Train] time:448.106009721756 seconds, lr:0.0157, train_loss: 0.7092, unlabeled_losses_real_strong:0.4510,corrrect_unlabeled_num:405343.0,pro_above_threshold_num:413655.0,unlabelled_weak_top1_acc:94.2792608588934,unlabelled_weak_top5_acc:99.78942918032408  \n","[2022-04-23 09:44:42,908][experiments.experiment][INFO] - [EMA] Epoch 87. [Validation] raw_testing_loss: 0.2812, raw test Top1 acc:92.16, raw test Top5 acc: 99.68, ema_testing_loss: 0.2031, ema test Top1 acc:95.0, ema test Top5 acc: 99.9\n","[2022-04-23 09:44:43,009][experiments.experiment][INFO] - [Checkpoints] Epoch 87, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 09:44:43,010][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:52:12,132][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 88: use 449.2190520763397 seconds\n","--- Optimizer learning rate changed from 1.57e-02 to 1.54e-02 ---\n","[2022-04-23 09:52:12,229][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:52:13,623][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:52:13,623][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:52:15,050][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:52:15,052][experiments.experiment][INFO] - [EMA] Epoch 88.[Train] time:449.2190520763397 seconds, lr:0.0154, train_loss: 0.7079, unlabeled_losses_real_strong:0.4509,corrrect_unlabeled_num:405385.0,pro_above_threshold_num:413715.0,unlabelled_weak_top1_acc:94.3400779813528,unlabelled_weak_top5_acc:99.7940069064498  \n","[2022-04-23 09:52:15,053][experiments.experiment][INFO] - [EMA] Epoch 88. [Validation] raw_testing_loss: 0.2890, raw test Top1 acc:92.26, raw test Top5 acc: 99.86, ema_testing_loss: 0.2054, ema test Top1 acc:94.68, ema test Top5 acc: 99.86\n","[2022-04-23 09:52:15,055][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 09:59:43,993][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 89: use 449.037216424942 seconds\n","--- Optimizer learning rate changed from 1.54e-02 to 1.51e-02 ---\n","[2022-04-23 09:59:44,092][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:59:45,413][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 09:59:45,414][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 09:59:46,741][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 09:59:46,742][experiments.experiment][INFO] - [EMA] Epoch 89.[Train] time:449.037216424942 seconds, lr:0.0151, train_loss: 0.7070, unlabeled_losses_real_strong:0.4479,corrrect_unlabeled_num:405722.0,pro_above_threshold_num:414146.0,unlabelled_weak_top1_acc:94.35032334923744,unlabelled_weak_top5_acc:99.80316217243671  \n","[2022-04-23 09:59:46,744][experiments.experiment][INFO] - [EMA] Epoch 89. [Validation] raw_testing_loss: 0.2903, raw test Top1 acc:91.82, raw test Top5 acc: 99.64, ema_testing_loss: 0.2076, ema test Top1 acc:94.52, ema test Top5 acc: 99.86\n","[2022-04-23 09:59:46,848][experiments.experiment][INFO] - [Checkpoints] Epoch 89, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 09:59:46,860][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:07:14,562][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 90: use 447.8091244697571 seconds\n","--- Optimizer learning rate changed from 1.51e-02 to 1.48e-02 ---\n","[2022-04-23 10:07:14,669][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:07:16,080][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:07:16,081][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:07:17,468][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:07:17,470][experiments.experiment][INFO] - [EMA] Epoch 90.[Train] time:447.8091244697571 seconds, lr:0.0148, train_loss: 0.7019, unlabeled_losses_real_strong:0.4459,corrrect_unlabeled_num:406380.0,pro_above_threshold_num:414622.0,unlabelled_weak_top1_acc:94.41201232373714,unlabelled_weak_top5_acc:99.7885573208332  \n","[2022-04-23 10:07:17,471][experiments.experiment][INFO] - [EMA] Epoch 90. [Validation] raw_testing_loss: 0.2988, raw test Top1 acc:91.74, raw test Top5 acc: 99.82, ema_testing_loss: 0.2090, ema test Top1 acc:94.68, ema test Top5 acc: 99.9\n","[2022-04-23 10:07:17,473][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:14:45,414][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 91: use 448.04086542129517 seconds\n","--- Optimizer learning rate changed from 1.48e-02 to 1.45e-02 ---\n","[2022-04-23 10:14:45,514][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:14:46,827][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:14:46,827][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:14:48,131][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:14:48,132][experiments.experiment][INFO] - [EMA] Epoch 91.[Train] time:448.04086542129517 seconds, lr:0.0145, train_loss: 0.6955, unlabeled_losses_real_strong:0.4407,corrrect_unlabeled_num:406908.0,pro_above_threshold_num:415235.0,unlabelled_weak_top1_acc:94.42530936002731,unlabelled_weak_top5_acc:99.80970160663128  \n","[2022-04-23 10:14:48,135][experiments.experiment][INFO] - [EMA] Epoch 91. [Validation] raw_testing_loss: 0.2768, raw test Top1 acc:92.14, raw test Top5 acc: 99.8, ema_testing_loss: 0.2050, ema test Top1 acc:94.56, ema test Top5 acc: 99.88\n","[2022-04-23 10:14:48,229][experiments.experiment][INFO] - [Checkpoints] Epoch 91, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 10:14:48,237][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:22:15,483][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 92: use 447.34341621398926 seconds\n","--- Optimizer learning rate changed from 1.45e-02 to 1.42e-02 ---\n","[2022-04-23 10:22:15,581][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:22:16,966][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:22:16,966][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:22:18,288][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:22:18,290][experiments.experiment][INFO] - [EMA] Epoch 92.[Train] time:447.34341621398926 seconds, lr:0.0142, train_loss: 0.6934, unlabeled_losses_real_strong:0.4403,corrrect_unlabeled_num:407062.0,pro_above_threshold_num:415463.0,unlabelled_weak_top1_acc:94.47195764631033,unlabelled_weak_top5_acc:99.81079161167145  \n","[2022-04-23 10:22:18,292][experiments.experiment][INFO] - [EMA] Epoch 92. [Validation] raw_testing_loss: 0.2678, raw test Top1 acc:93.0, raw test Top5 acc: 99.78, ema_testing_loss: 0.2084, ema test Top1 acc:94.92, ema test Top5 acc: 99.92\n","[2022-04-23 10:22:18,293][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:29:43,948][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 93: use 445.7523853778839 seconds\n","--- Optimizer learning rate changed from 1.42e-02 to 1.39e-02 ---\n","[2022-04-23 10:29:44,046][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:29:45,378][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:29:45,378][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:29:46,705][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:29:46,707][experiments.experiment][INFO] - [EMA] Epoch 93.[Train] time:445.7523853778839 seconds, lr:0.0139, train_loss: 0.6900, unlabeled_losses_real_strong:0.4358,corrrect_unlabeled_num:408244.0,pro_above_threshold_num:416535.0,unlabelled_weak_top1_acc:94.54127610474825,unlabelled_weak_top5_acc:99.81645904481411  \n","[2022-04-23 10:29:46,709][experiments.experiment][INFO] - [EMA] Epoch 93. [Validation] raw_testing_loss: 0.3052, raw test Top1 acc:91.34, raw test Top5 acc: 99.78, ema_testing_loss: 0.2079, ema test Top1 acc:94.78, ema test Top5 acc: 99.92\n","[2022-04-23 10:29:46,817][experiments.experiment][INFO] - [Checkpoints] Epoch 93, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 10:29:46,825][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:37:14,019][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 94: use 447.29055547714233 seconds\n","--- Optimizer learning rate changed from 1.39e-02 to 1.36e-02 ---\n","[2022-04-23 10:37:14,116][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:37:15,480][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:37:15,480][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:37:16,825][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:37:16,827][experiments.experiment][INFO] - [EMA] Epoch 94.[Train] time:447.29055547714233 seconds, lr:0.0136, train_loss: 0.6901, unlabeled_losses_real_strong:0.4339,corrrect_unlabeled_num:408331.0,pro_above_threshold_num:416762.0,unlabelled_weak_top1_acc:94.56678003072739,unlabelled_weak_top5_acc:99.80621385574341  \n","[2022-04-23 10:37:16,828][experiments.experiment][INFO] - [EMA] Epoch 94. [Validation] raw_testing_loss: 0.3377, raw test Top1 acc:90.58, raw test Top5 acc: 99.58, ema_testing_loss: 0.2060, ema test Top1 acc:94.84, ema test Top5 acc: 99.9\n","[2022-04-23 10:37:16,829][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:44:42,798][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 95: use 446.06815671920776 seconds\n","--- Optimizer learning rate changed from 1.36e-02 to 1.33e-02 ---\n","[2022-04-23 10:44:42,897][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:44:44,254][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:44:44,255][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:44:45,614][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:44:45,616][experiments.experiment][INFO] - [EMA] Epoch 95.[Train] time:446.06815671920776 seconds, lr:0.0133, train_loss: 0.6864, unlabeled_losses_real_strong:0.4320,corrrect_unlabeled_num:408675.0,pro_above_threshold_num:417040.0,unlabelled_weak_top1_acc:94.6236735060811,unlabelled_weak_top5_acc:99.80708581209183  \n","[2022-04-23 10:44:45,618][experiments.experiment][INFO] - [EMA] Epoch 95. [Validation] raw_testing_loss: 0.2547, raw test Top1 acc:92.96, raw test Top5 acc: 99.82, ema_testing_loss: 0.2041, ema test Top1 acc:94.86, ema test Top5 acc: 99.88\n","[2022-04-23 10:44:45,716][experiments.experiment][INFO] - [Checkpoints] Epoch 95, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 10:44:45,717][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:52:13,799][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 96: use 448.18690824508667 seconds\n","--- Optimizer learning rate changed from 1.33e-02 to 1.30e-02 ---\n","[2022-04-23 10:52:13,904][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:52:15,246][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:52:15,246][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:52:16,579][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:52:16,581][experiments.experiment][INFO] - [EMA] Epoch 96.[Train] time:448.18690824508667 seconds, lr:0.0130, train_loss: 0.6873, unlabeled_losses_real_strong:0.4275,corrrect_unlabeled_num:409897.0,pro_above_threshold_num:418292.0,unlabelled_weak_top1_acc:94.71304662525654,unlabelled_weak_top5_acc:99.81558708846569  \n","[2022-04-23 10:52:16,584][experiments.experiment][INFO] - [EMA] Epoch 96. [Validation] raw_testing_loss: 0.2771, raw test Top1 acc:91.92, raw test Top5 acc: 99.84, ema_testing_loss: 0.2011, ema test Top1 acc:94.72, ema test Top5 acc: 99.88\n","[2022-04-23 10:52:16,584][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 10:59:43,159][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 97: use 446.67140889167786 seconds\n","--- Optimizer learning rate changed from 1.30e-02 to 1.27e-02 ---\n","[2022-04-23 10:59:43,256][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:59:44,556][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 10:59:44,557][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 10:59:45,877][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 10:59:45,879][experiments.experiment][INFO] - [EMA] Epoch 97.[Train] time:446.67140889167786 seconds, lr:0.0127, train_loss: 0.6800, unlabeled_losses_real_strong:0.4260,corrrect_unlabeled_num:409617.0,pro_above_threshold_num:418034.0,unlabelled_weak_top1_acc:94.68470883369446,unlabelled_weak_top5_acc:99.80686785280704  \n","[2022-04-23 10:59:45,881][experiments.experiment][INFO] - [EMA] Epoch 97. [Validation] raw_testing_loss: 0.3434, raw test Top1 acc:90.74, raw test Top5 acc: 99.62, ema_testing_loss: 0.2013, ema test Top1 acc:94.94, ema test Top5 acc: 99.9\n","[2022-04-23 10:59:45,977][experiments.experiment][INFO] - [Checkpoints] Epoch 97, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 10:59:45,985][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:07:14,705][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 98: use 448.81824111938477 seconds\n","--- Optimizer learning rate changed from 1.27e-02 to 1.24e-02 ---\n","[2022-04-23 11:07:14,803][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:07:16,106][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:07:16,107][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:07:17,492][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:07:17,494][experiments.experiment][INFO] - [EMA] Epoch 98.[Train] time:448.81824111938477 seconds, lr:0.0124, train_loss: 0.6696, unlabeled_losses_real_strong:0.4213,corrrect_unlabeled_num:409915.0,pro_above_threshold_num:418280.0,unlabelled_weak_top1_acc:94.71217455714941,unlabelled_weak_top5_acc:99.81122749298811  \n","[2022-04-23 11:07:17,497][experiments.experiment][INFO] - [EMA] Epoch 98. [Validation] raw_testing_loss: 0.2850, raw test Top1 acc:92.4, raw test Top5 acc: 99.9, ema_testing_loss: 0.2024, ema test Top1 acc:94.8, ema test Top5 acc: 99.88\n","[2022-04-23 11:07:17,497][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:14:46,119][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 99: use 448.72075033187866 seconds\n","--- Optimizer learning rate changed from 1.24e-02 to 1.21e-02 ---\n","[2022-04-23 11:14:46,218][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:14:47,576][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:14:47,576][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:14:48,937][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:14:48,938][experiments.experiment][INFO] - [EMA] Epoch 99.[Train] time:448.72075033187866 seconds, lr:0.0121, train_loss: 0.6666, unlabeled_losses_real_strong:0.4202,corrrect_unlabeled_num:410201.0,pro_above_threshold_num:418667.0,unlabelled_weak_top1_acc:94.71588020771742,unlabelled_weak_top5_acc:99.81122746318579  \n","[2022-04-23 11:14:48,940][experiments.experiment][INFO] - [EMA] Epoch 99. [Validation] raw_testing_loss: 0.2575, raw test Top1 acc:93.02, raw test Top5 acc: 99.78, ema_testing_loss: 0.2036, ema test Top1 acc:94.88, ema test Top5 acc: 99.9\n","[2022-04-23 11:14:49,034][experiments.experiment][INFO] - [Checkpoints] Epoch 99, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 11:14:49,042][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:22:18,110][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 100: use 449.17473554611206 seconds\n","--- Optimizer learning rate changed from 1.21e-02 to 1.18e-02 ---\n","[2022-04-23 11:22:18,217][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:22:19,573][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:22:19,574][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:22:20,914][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:22:20,915][experiments.experiment][INFO] - [EMA] Epoch 100.[Train] time:449.17473554611206 seconds, lr:0.0118, train_loss: 0.6589, unlabeled_losses_real_strong:0.4173,corrrect_unlabeled_num:411153.0,pro_above_threshold_num:419540.0,unlabelled_weak_top1_acc:94.79522602260113,unlabelled_weak_top5_acc:99.8147151619196  \n","[2022-04-23 11:22:20,918][experiments.experiment][INFO] - [EMA] Epoch 100. [Validation] raw_testing_loss: 0.2638, raw test Top1 acc:92.18, raw test Top5 acc: 99.72, ema_testing_loss: 0.2021, ema test Top1 acc:94.78, ema test Top5 acc: 99.88\n","[2022-04-23 11:22:20,918][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:29:51,872][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 101: use 451.053288936615 seconds\n","--- Optimizer learning rate changed from 1.18e-02 to 1.14e-02 ---\n","[2022-04-23 11:29:51,972][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:29:53,470][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:29:53,470][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:29:54,786][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:29:54,787][experiments.experiment][INFO] - [EMA] Epoch 101.[Train] time:451.053288936615 seconds, lr:0.0114, train_loss: 0.6608, unlabeled_losses_real_strong:0.4160,corrrect_unlabeled_num:411782.0,pro_above_threshold_num:420220.0,unlabelled_weak_top1_acc:94.84470804035664,unlabelled_weak_top5_acc:99.80577798932791  \n","[2022-04-23 11:29:54,790][experiments.experiment][INFO] - [EMA] Epoch 101. [Validation] raw_testing_loss: 0.3339, raw test Top1 acc:91.24, raw test Top5 acc: 99.76, ema_testing_loss: 0.2022, ema test Top1 acc:94.62, ema test Top5 acc: 99.9\n","[2022-04-23 11:29:54,897][experiments.experiment][INFO] - [Checkpoints] Epoch 101, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 11:29:54,899][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:37:26,296][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 102: use 451.50229597091675 seconds\n","--- Optimizer learning rate changed from 1.14e-02 to 1.11e-02 ---\n","[2022-04-23 11:37:26,401][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:37:27,799][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:37:27,799][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:37:29,210][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:37:29,211][experiments.experiment][INFO] - [EMA] Epoch 102.[Train] time:451.50229597091675 seconds, lr:0.0111, train_loss: 0.6554, unlabeled_losses_real_strong:0.4103,corrrect_unlabeled_num:412180.0,pro_above_threshold_num:420585.0,unlabelled_weak_top1_acc:94.92100198566914,unlabelled_weak_top5_acc:99.82125470042229  \n","[2022-04-23 11:37:29,214][experiments.experiment][INFO] - [EMA] Epoch 102. [Validation] raw_testing_loss: 0.2455, raw test Top1 acc:92.88, raw test Top5 acc: 99.74, ema_testing_loss: 0.2011, ema test Top1 acc:94.88, ema test Top5 acc: 99.88\n","[2022-04-23 11:37:29,215][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:45:00,263][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 103: use 451.15051460266113 seconds\n","--- Optimizer learning rate changed from 1.11e-02 to 1.08e-02 ---\n","[2022-04-23 11:45:00,365][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:45:01,732][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:45:01,732][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:45:03,150][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:45:03,151][experiments.experiment][INFO] - [EMA] Epoch 103.[Train] time:451.15051460266113 seconds, lr:0.0108, train_loss: 0.6550, unlabeled_losses_real_strong:0.4082,corrrect_unlabeled_num:413099.0,pro_above_threshold_num:421458.0,unlabelled_weak_top1_acc:94.93887642771006,unlabelled_weak_top5_acc:99.81188140809536  \n","[2022-04-23 11:45:03,153][experiments.experiment][INFO] - [EMA] Epoch 103. [Validation] raw_testing_loss: 0.2303, raw test Top1 acc:93.24, raw test Top5 acc: 99.8, ema_testing_loss: 0.1945, ema test Top1 acc:95.04, ema test Top5 acc: 99.84\n","[2022-04-23 11:45:03,267][experiments.experiment][INFO] - [Checkpoints] Epoch 103, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 11:45:03,275][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 11:52:37,016][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 104: use 453.848251581192 seconds\n","--- Optimizer learning rate changed from 1.08e-02 to 1.05e-02 ---\n","[2022-04-23 11:52:37,123][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:52:38,537][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 11:52:38,538][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 11:52:39,857][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 11:52:39,858][experiments.experiment][INFO] - [EMA] Epoch 104.[Train] time:453.848251581192 seconds, lr:0.0105, train_loss: 0.6382, unlabeled_losses_real_strong:0.4024,corrrect_unlabeled_num:413635.0,pro_above_threshold_num:422008.0,unlabelled_weak_top1_acc:94.98814072459936,unlabelled_weak_top5_acc:99.82605025172234  \n","[2022-04-23 11:52:39,861][experiments.experiment][INFO] - [EMA] Epoch 104. [Validation] raw_testing_loss: 0.2690, raw test Top1 acc:93.02, raw test Top5 acc: 99.78, ema_testing_loss: 0.1932, ema test Top1 acc:95.2, ema test Top5 acc: 99.86\n","[2022-04-23 11:52:39,861][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:00:08,547][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 105: use 448.78236293792725 seconds\n","--- Optimizer learning rate changed from 1.05e-02 to 1.02e-02 ---\n","[2022-04-23 12:00:08,644][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:00:10,002][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:00:10,002][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:00:11,316][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:00:11,318][experiments.experiment][INFO] - [EMA] Epoch 105.[Train] time:448.78236293792725 seconds, lr:0.0102, train_loss: 0.6419, unlabeled_losses_real_strong:0.4015,corrrect_unlabeled_num:414216.0,pro_above_threshold_num:422602.0,unlabelled_weak_top1_acc:95.01582447439432,unlabelled_weak_top5_acc:99.8236525580287  \n","[2022-04-23 12:00:11,321][experiments.experiment][INFO] - [EMA] Epoch 105. [Validation] raw_testing_loss: 0.2676, raw test Top1 acc:92.58, raw test Top5 acc: 99.58, ema_testing_loss: 0.1940, ema test Top1 acc:95.02, ema test Top5 acc: 99.82\n","[2022-04-23 12:00:11,419][experiments.experiment][INFO] - [Checkpoints] Epoch 105, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 12:00:11,421][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:07:47,006][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 106: use 455.69083166122437 seconds\n","--- Optimizer learning rate changed from 1.02e-02 to 9.83e-03 ---\n","[2022-04-23 12:07:47,111][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:07:48,552][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:07:48,552][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:07:50,029][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:07:50,030][experiments.experiment][INFO] - [EMA] Epoch 106.[Train] time:455.69083166122437 seconds, lr:0.0098, train_loss: 0.6379, unlabeled_losses_real_strong:0.3971,corrrect_unlabeled_num:414777.0,pro_above_threshold_num:423151.0,unlabelled_weak_top1_acc:95.0679222419858,unlabelled_weak_top5_acc:99.81885689496994  \n","[2022-04-23 12:07:50,032][experiments.experiment][INFO] - [EMA] Epoch 106. [Validation] raw_testing_loss: 0.2414, raw test Top1 acc:93.52, raw test Top5 acc: 99.76, ema_testing_loss: 0.1932, ema test Top1 acc:95.04, ema test Top5 acc: 99.82\n","[2022-04-23 12:07:50,033][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:15:15,932][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 107: use 446.0004720687866 seconds\n","--- Optimizer learning rate changed from 9.83e-03 to 9.50e-03 ---\n","[2022-04-23 12:15:16,034][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:15:17,383][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:15:17,383][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:15:18,736][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:15:18,737][experiments.experiment][INFO] - [EMA] Epoch 107.[Train] time:446.0004720687866 seconds, lr:0.0095, train_loss: 0.6334, unlabeled_losses_real_strong:0.3950,corrrect_unlabeled_num:414985.0,pro_above_threshold_num:423363.0,unlabelled_weak_top1_acc:95.12895753979683,unlabelled_weak_top5_acc:99.81253544986248  \n","[2022-04-23 12:15:18,738][experiments.experiment][INFO] - [EMA] Epoch 107. [Validation] raw_testing_loss: 0.2418, raw test Top1 acc:93.24, raw test Top5 acc: 99.88, ema_testing_loss: 0.1932, ema test Top1 acc:95.12, ema test Top5 acc: 99.86\n","[2022-04-23 12:15:18,836][experiments.experiment][INFO] - [Checkpoints] Epoch 107, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 12:15:18,837][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:22:45,405][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 108: use 446.6685540676117 seconds\n","--- Optimizer learning rate changed from 9.50e-03 to 9.18e-03 ---\n","[2022-04-23 12:22:45,506][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:22:46,878][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:22:46,878][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:22:48,250][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:22:48,252][experiments.experiment][INFO] - [EMA] Epoch 108.[Train] time:446.6685540676117 seconds, lr:0.0092, train_loss: 0.6224, unlabeled_losses_real_strong:0.3902,corrrect_unlabeled_num:415443.0,pro_above_threshold_num:423861.0,unlabelled_weak_top1_acc:95.11718652397394,unlabelled_weak_top5_acc:99.81733100861311  \n","[2022-04-23 12:22:48,254][experiments.experiment][INFO] - [EMA] Epoch 108. [Validation] raw_testing_loss: 0.2133, raw test Top1 acc:93.8, raw test Top5 acc: 99.88, ema_testing_loss: 0.1882, ema test Top1 acc:95.1, ema test Top5 acc: 99.88\n","[2022-04-23 12:22:48,255][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:30:15,268][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 109: use 447.11553144454956 seconds\n","--- Optimizer learning rate changed from 9.18e-03 to 8.85e-03 ---\n","[2022-04-23 12:30:15,371][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:30:16,719][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:30:16,719][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:30:18,066][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:30:18,069][experiments.experiment][INFO] - [EMA] Epoch 109.[Train] time:447.11553144454956 seconds, lr:0.0088, train_loss: 0.6201, unlabeled_losses_real_strong:0.3894,corrrect_unlabeled_num:416263.0,pro_above_threshold_num:424827.0,unlabelled_weak_top1_acc:95.17495183646679,unlabelled_weak_top5_acc:99.81820291280746  \n","[2022-04-23 12:30:18,072][experiments.experiment][INFO] - [EMA] Epoch 109. [Validation] raw_testing_loss: 0.2403, raw test Top1 acc:93.4, raw test Top5 acc: 99.78, ema_testing_loss: 0.1913, ema test Top1 acc:95.06, ema test Top5 acc: 99.86\n","[2022-04-23 12:30:18,169][experiments.experiment][INFO] - [Checkpoints] Epoch 109, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 12:30:18,177][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:37:48,855][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 110: use 450.78786301612854 seconds\n","--- Optimizer learning rate changed from 8.85e-03 to 8.52e-03 ---\n","[2022-04-23 12:37:48,965][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:37:50,343][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:37:50,343][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:37:51,755][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:37:51,757][experiments.experiment][INFO] - [EMA] Epoch 110.[Train] time:450.78786301612854 seconds, lr:0.0085, train_loss: 0.6174, unlabeled_losses_real_strong:0.3843,corrrect_unlabeled_num:416879.0,pro_above_threshold_num:425382.0,unlabelled_weak_top1_acc:95.23751275986433,unlabelled_weak_top5_acc:99.83411563932896  \n","[2022-04-23 12:37:51,759][experiments.experiment][INFO] - [EMA] Epoch 110. [Validation] raw_testing_loss: 0.2128, raw test Top1 acc:93.72, raw test Top5 acc: 99.82, ema_testing_loss: 0.1884, ema test Top1 acc:95.18, ema test Top5 acc: 99.86\n","[2022-04-23 12:37:51,760][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:45:19,850][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 111: use 448.1997175216675 seconds\n","--- Optimizer learning rate changed from 8.52e-03 to 8.19e-03 ---\n","[2022-04-23 12:45:19,960][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:45:21,297][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:45:21,297][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:45:22,638][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:45:22,639][experiments.experiment][INFO] - [EMA] Epoch 111.[Train] time:448.1997175216675 seconds, lr:0.0082, train_loss: 0.6065, unlabeled_losses_real_strong:0.3802,corrrect_unlabeled_num:417292.0,pro_above_threshold_num:425837.0,unlabelled_weak_top1_acc:95.26694045960903,unlabelled_weak_top5_acc:99.8173309341073  \n","[2022-04-23 12:45:22,642][experiments.experiment][INFO] - [EMA] Epoch 111. [Validation] raw_testing_loss: 0.2384, raw test Top1 acc:93.38, raw test Top5 acc: 99.86, ema_testing_loss: 0.1894, ema test Top1 acc:95.18, ema test Top5 acc: 99.88\n","[2022-04-23 12:45:22,751][experiments.experiment][INFO] - [Checkpoints] Epoch 111, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 12:45:22,752][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 12:53:01,787][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 112: use 459.13982701301575 seconds\n","--- Optimizer learning rate changed from 8.19e-03 to 7.86e-03 ---\n","[2022-04-23 12:53:01,892][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:53:03,331][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 12:53:03,331][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 12:53:04,707][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 12:53:04,708][experiments.experiment][INFO] - [EMA] Epoch 112.[Train] time:459.13982701301575 seconds, lr:0.0079, train_loss: 0.6035, unlabeled_losses_real_strong:0.3780,corrrect_unlabeled_num:417787.0,pro_above_threshold_num:426382.0,unlabelled_weak_top1_acc:95.28939283639193,unlabelled_weak_top5_acc:99.81951081752777  \n","[2022-04-23 12:53:04,710][experiments.experiment][INFO] - [EMA] Epoch 112. [Validation] raw_testing_loss: 0.2519, raw test Top1 acc:93.3, raw test Top5 acc: 99.8, ema_testing_loss: 0.1896, ema test Top1 acc:95.24, ema test Top5 acc: 99.82\n","[2022-04-23 12:53:04,711][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:00:51,228][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 113: use 466.61543703079224 seconds\n","--- Optimizer learning rate changed from 7.86e-03 to 7.53e-03 ---\n","[2022-04-23 13:00:51,327][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:00:52,719][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:00:52,720][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:00:54,156][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:00:54,158][experiments.experiment][INFO] - [EMA] Epoch 113.[Train] time:466.61543703079224 seconds, lr:0.0075, train_loss: 0.5968, unlabeled_losses_real_strong:0.3730,corrrect_unlabeled_num:418111.0,pro_above_threshold_num:426756.0,unlabelled_weak_top1_acc:95.31271694600582,unlabelled_weak_top5_acc:99.82997401058674  \n","[2022-04-23 13:00:54,159][experiments.experiment][INFO] - [EMA] Epoch 113. [Validation] raw_testing_loss: 0.2308, raw test Top1 acc:93.82, raw test Top5 acc: 99.78, ema_testing_loss: 0.1873, ema test Top1 acc:95.18, ema test Top5 acc: 99.88\n","[2022-04-23 13:00:54,256][experiments.experiment][INFO] - [Checkpoints] Epoch 113, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 13:00:54,258][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:08:42,664][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 114: use 468.50618290901184 seconds\n","--- Optimizer learning rate changed from 7.53e-03 to 7.19e-03 ---\n","[2022-04-23 13:08:42,765][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:08:44,204][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:08:44,204][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:08:45,597][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:08:45,599][experiments.experiment][INFO] - [EMA] Epoch 114.[Train] time:468.50618290901184 seconds, lr:0.0072, train_loss: 0.5914, unlabeled_losses_real_strong:0.3722,corrrect_unlabeled_num:418694.0,pro_above_threshold_num:427325.0,unlabelled_weak_top1_acc:95.34170860052109,unlabelled_weak_top5_acc:99.83629552274942  \n","[2022-04-23 13:08:45,601][experiments.experiment][INFO] - [EMA] Epoch 114. [Validation] raw_testing_loss: 0.2374, raw test Top1 acc:93.24, raw test Top5 acc: 99.8, ema_testing_loss: 0.1865, ema test Top1 acc:95.22, ema test Top5 acc: 99.88\n","[2022-04-23 13:08:45,602][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:16:31,341][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 115: use 465.85232281684875 seconds\n","--- Optimizer learning rate changed from 7.19e-03 to 6.86e-03 ---\n","[2022-04-23 13:16:31,454][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:16:32,931][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:16:32,932][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:16:34,328][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:16:34,329][experiments.experiment][INFO] - [EMA] Epoch 115.[Train] time:465.85232281684875 seconds, lr:0.0069, train_loss: 0.5873, unlabeled_losses_real_strong:0.3669,corrrect_unlabeled_num:419400.0,pro_above_threshold_num:428131.0,unlabelled_weak_top1_acc:95.37353409826756,unlabelled_weak_top5_acc:99.82365255057812  \n","[2022-04-23 13:16:34,333][experiments.experiment][INFO] - [EMA] Epoch 115. [Validation] raw_testing_loss: 0.2137, raw test Top1 acc:94.02, raw test Top5 acc: 99.8, ema_testing_loss: 0.1863, ema test Top1 acc:95.02, ema test Top5 acc: 99.9\n","[2022-04-23 13:16:34,433][experiments.experiment][INFO] - [Checkpoints] Epoch 115, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 13:16:34,435][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:24:21,891][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 116: use 467.55931401252747 seconds\n","--- Optimizer learning rate changed from 6.86e-03 to 6.53e-03 ---\n","[2022-04-23 13:24:21,995][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:24:23,432][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:24:23,433][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:24:24,818][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:24:24,819][experiments.experiment][INFO] - [EMA] Epoch 116.[Train] time:467.55931401252747 seconds, lr:0.0065, train_loss: 0.5752, unlabeled_losses_real_strong:0.3645,corrrect_unlabeled_num:420024.0,pro_above_threshold_num:428868.0,unlabelled_weak_top1_acc:95.42846565693617,unlabelled_weak_top5_acc:99.8319358304143  \n","[2022-04-23 13:24:24,821][experiments.experiment][INFO] - [EMA] Epoch 116. [Validation] raw_testing_loss: 0.2186, raw test Top1 acc:93.98, raw test Top5 acc: 99.78, ema_testing_loss: 0.1853, ema test Top1 acc:95.26, ema test Top5 acc: 99.88\n","[2022-04-23 13:24:24,823][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:32:12,142][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 117: use 467.4345803260803 seconds\n","--- Optimizer learning rate changed from 6.53e-03 to 6.19e-03 ---\n","[2022-04-23 13:32:12,257][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:32:13,649][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:32:13,649][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:32:15,052][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:32:15,053][experiments.experiment][INFO] - [EMA] Epoch 117.[Train] time:467.4345803260803 seconds, lr:0.0062, train_loss: 0.5726, unlabeled_losses_real_strong:0.3613,corrrect_unlabeled_num:420951.0,pro_above_threshold_num:429733.0,unlabelled_weak_top1_acc:95.47620389610529,unlabelled_weak_top5_acc:99.83367968350649  \n","[2022-04-23 13:32:15,056][experiments.experiment][INFO] - [EMA] Epoch 117. [Validation] raw_testing_loss: 0.2213, raw test Top1 acc:93.9, raw test Top5 acc: 99.86, ema_testing_loss: 0.1889, ema test Top1 acc:95.18, ema test Top5 acc: 99.9\n","[2022-04-23 13:32:15,153][experiments.experiment][INFO] - [Checkpoints] Epoch 117, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","[2022-04-23 13:32:15,154][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:40:04,136][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 118: use 469.10605359077454 seconds\n","--- Optimizer learning rate changed from 6.19e-03 to 5.85e-03 ---\n","[2022-04-23 13:40:04,260][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:40:05,680][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:40:05,680][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:40:07,058][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:40:07,059][experiments.experiment][INFO] - [EMA] Epoch 118.[Train] time:469.10605359077454 seconds, lr:0.0059, train_loss: 0.5647, unlabeled_losses_real_strong:0.3563,corrrect_unlabeled_num:421175.0,pro_above_threshold_num:430066.0,unlabelled_weak_top1_acc:95.48405136168003,unlabelled_weak_top5_acc:99.8382573723793  \n","[2022-04-23 13:40:07,061][experiments.experiment][INFO] - [EMA] Epoch 118. [Validation] raw_testing_loss: 0.2228, raw test Top1 acc:94.02, raw test Top5 acc: 99.82, ema_testing_loss: 0.1848, ema test Top1 acc:94.98, ema test Top5 acc: 99.9\n","[2022-04-23 13:40:07,062][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-23 13:47:40,357][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 119: use 453.3916656970978 seconds\n","--- Optimizer learning rate changed from 5.85e-03 to 5.52e-03 ---\n","[2022-04-23 13:47:40,454][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:47:41,803][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-23 13:47:41,803][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-23 13:47:43,124][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-23 13:47:43,126][experiments.experiment][INFO] - [EMA] Epoch 119.[Train] time:453.3916656970978 seconds, lr:0.0055, train_loss: 0.5567, unlabeled_losses_real_strong:0.3538,corrrect_unlabeled_num:421683.0,pro_above_threshold_num:430614.0,unlabelled_weak_top1_acc:95.52067239582539,unlabelled_weak_top5_acc:99.83171778917313  \n","[2022-04-23 13:47:43,128][experiments.experiment][INFO] - [EMA] Epoch 119. [Validation] raw_testing_loss: 0.2139, raw test Top1 acc:94.08, raw test Top5 acc: 99.8, ema_testing_loss: 0.1867, ema test Top1 acc:94.86, ema test Top5 acc: 99.9\n","[2022-04-23 13:47:43,223][experiments.experiment][INFO] - [Checkpoints] Epoch 119, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_3/FMExperiment.pth.tar\n","======= Training done =======\n","2022-04-23 13:47:43,323 - INFO - Train -   ======= Training done =======\n","[2022-04-23 13:47:43,323][Train][INFO] - ======= Training done =======\n","[2022-04-23 13:47:43,323][experiments.experiment][INFO] - Loading Testing Loader\n","[2022-04-23 13:47:43,331][experiments.experiment][INFO] - [Testing with EMA] apply shadow\n","[2022-04-23 13:47:43,331][experiments.experiment][INFO] - ***** Running testing *****\n","[2022-04-23 13:47:45,742][experiments.experiment][INFO] - [Testing(EMA)] testing_loss: 0.1768, test Top1 acc:95.02, test Top5 acc: 99.85\n","[2022-04-23 13:47:45,747][experiments.experiment][INFO] - [EMA] restore \n","======= Testing done =======\n","2022-04-23 13:47:45,747 - INFO - Train -   ======= Testing done =======\n","[2022-04-23 13:47:45,747][Train][INFO] - ======= Testing done =======\n"]}]}]}