{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":148370,"status":"ok","timestamp":1650253020946,"user":{"displayName":"CM Y","userId":"12660552299343911788"},"user_tz":300},"id":"DA5HLOU_67zp","outputId":"4cf37211-e98a-4d90-c068-be8915045b9b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/celiali\n","augmentations  datasets\t\t\tLICENSE    requirements.txt   run.py\n","checkpoints    experiments\t\tmodels\t   run_load_temp.log  utils\n","config\t       google_requirements.txt\toutputs    run_load_temp.py\n","data\t       __init__.py\t\tREADME.md  run.log\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 2)) (1.0.0)\n","Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 3)) (1.9)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 4)) (0.29.28)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 5)) (1.21.5)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 7)) (4.64.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 8)) (1.4.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 9)) (7.1.2)\n","Collecting torch==1.8.0\n","  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n","\u001b[K     |████████████████████████████████| 735.5 MB 14 kB/s \n","\u001b[?25hCollecting torchvision==0.9.0\n","  Downloading torchvision-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n","\u001b[K     |████████████████████████████████| 17.3 MB 184 kB/s \n","\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 12)) (0.10.0+cu111)\n","Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 13)) (0.11.0)\n","Collecting omegaconf\n","  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\n","\u001b[K     |████████████████████████████████| 74 kB 4.2 MB/s \n","\u001b[?25hCollecting hydra\n","  Downloading Hydra-2.5.tar.gz (82 kB)\n","\u001b[K     |████████████████████████████████| 82 kB 297 kB/s \n","\u001b[?25hCollecting hydra-core\n","  Downloading hydra_core-1.1.2-py3-none-any.whl (147 kB)\n","\u001b[K     |████████████████████████████████| 147 kB 66.4 MB/s \n","\u001b[?25hCollecting ignite\n","  Downloading ignite-1.1.0-py2.py3-none-any.whl (4.5 kB)\n","Collecting pytorch-ignite\n","  Downloading pytorch_ignite-0.4.8-py3-none-any.whl (251 kB)\n","\u001b[K     |████████████████████████████████| 251 kB 71.4 MB/s \n","\u001b[?25hCollecting tensorboardX\n","  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 73.3 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 20)) (1.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 21)) (3.2.2)\n","Collecting abel-pytorch\n","  Downloading abel_pytorch-0.0.1-py3-none-any.whl (4.2 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r google_requirements.txt (line 10)) (4.1.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->-r google_requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.1.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.2.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.17.3)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.24.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (57.4.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.44.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.6.3)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.1.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.5.3)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (13.0.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.14.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.3.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.1.2)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 69.3 MB/s \n","\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->-r google_requirements.txt (line 6)) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->-r google_requirements.txt (line 6)) (1.5.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.35.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2.23.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.3.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.4.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.2.0)\n","Collecting torchaudio\n","  Downloading torchaudio-0.11.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 52.0 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 49.6 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 53.0 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 58.7 MB/s \n","\u001b[?25h  Downloading torchaudio-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 47.5 MB/s \n","\u001b[?25h  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 6.3 MB/s \n","\u001b[?25h  Downloading torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 55.4 MB/s \n","\u001b[?25h  Downloading torchaudio-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 57.5 MB/s \n","\u001b[?25hCollecting torchtext\n","  Downloading torchtext-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n","\u001b[K     |████████████████████████████████| 10.4 MB 21.6 MB/s \n","\u001b[?25h  Downloading torchtext-0.11.2-cp37-cp37m-manylinux1_x86_64.whl (8.0 MB)\n","\u001b[K     |████████████████████████████████| 8.0 MB 23.4 MB/s \n","\u001b[?25h  Downloading torchtext-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (8.0 MB)\n","\u001b[K     |████████████████████████████████| 8.0 MB 32.7 MB/s \n","\u001b[?25h  Downloading torchtext-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 21.7 MB/s \n","\u001b[?25h  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 38.5 MB/s \n","\u001b[?25h  Downloading torchtext-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 21.1 MB/s \n","\u001b[?25h  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 28.3 MB/s \n","\u001b[?25hCollecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 72.4 MB/s \n","\u001b[?25hCollecting PyYAML>=5.1.0\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 63.0 MB/s \n","\u001b[?25hCollecting importlib-resources<5.3\n","  Downloading importlib_resources-5.2.3-py3-none-any.whl (27 kB)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r google_requirements.txt (line 20)) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r google_requirements.txt (line 20)) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (1.4.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (3.0.8)\n","Building wheels for collected packages: antlr4-python3-runtime, hydra\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=b71c90ce86e076485577b429f20466994caa4bae11bf9d7c5d387d53fe26a0f0\n","  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n","  Building wheel for hydra (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hydra: filename=Hydra-2.5-cp37-cp37m-linux_x86_64.whl size=220751 sha256=bbc1d886dca95cbf039ea439f3b9f20bd3bb88a3d8ee66530448ede3817625ee\n","  Stored in directory: /root/.cache/pip/wheels/46/28/7d/3b38a41d900da90c4e17576f442bac9344eb1f5a4e78ee9f83\n","Successfully built antlr4-python3-runtime hydra\n","Installing collected packages: PyYAML, antlr4-python3-runtime, torch, tf-estimator-nightly, omegaconf, importlib-resources, torchvision, torchtext, torchaudio, tensorboardX, pytorch-ignite, ignite, hydra-core, hydra, abel-pytorch\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","  Attempting uninstall: importlib-resources\n","    Found existing installation: importlib-resources 5.6.0\n","    Uninstalling importlib-resources-5.6.0:\n","      Successfully uninstalled importlib-resources-5.6.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.11.1+cu111\n","    Uninstalling torchvision-0.11.1+cu111:\n","      Successfully uninstalled torchvision-0.11.1+cu111\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.11.0\n","    Uninstalling torchtext-0.11.0:\n","      Successfully uninstalled torchtext-0.11.0\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.10.0+cu111\n","    Uninstalling torchaudio-0.10.0+cu111:\n","      Successfully uninstalled torchaudio-0.10.0+cu111\n","Successfully installed PyYAML-6.0 abel-pytorch-0.0.1 antlr4-python3-runtime-4.8 hydra-2.5 hydra-core-1.1.2 ignite-1.1.0 importlib-resources-5.2.3 omegaconf-2.1.2 pytorch-ignite-0.4.8 tensorboardX-2.5 tf-estimator-nightly-2.8.0.dev2021122109 torch-1.8.0 torchaudio-0.8.0 torchtext-0.9.0 torchvision-0.9.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{}}],"source":["# Mount into drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","# Change directory to the package folder\n","%cd '/content/drive/MyDrive/celiali'\n","# Verify the contents of the current folder\n","!ls\n","requirements = \"\"\"\n","absl-py\n","easydict\n","cython\n","numpy\n","tensorflow\n","tqdm\n","scipy\n","pillow\n","torch==1.8.0\n","torchvision==0.9.0\n","torchaudio\n","torchtext\n","omegaconf\n","hydra\n","hydra-core\n","ignite\n","pytorch-ignite\n","tensorboardX\n","scikit-learn\n","matplotlib\n","abel-pytorch\n","\"\"\"\n","\n","with open(\"google_requirements.txt\", 'w') as txt_file:\n","  txt_file.write(requirements)\n","%pip install -r google_requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16644508,"status":"ok","timestamp":1650227065139,"user":{"displayName":"CM Y","userId":"12660552299343911788"},"user_tz":300},"id":"gJQTcU_u6_YC","outputId":"763af8bf-0af0-48bc-d294-1fd72a0e0a09"},"outputs":[{"name":"stdout","output_type":"stream","text":["==> CONFIG is: \n"," DATASET:\n","  project_dir: ./\n","  data_dir: data\n","  loading_data: LOAD_LABEL_UNLABEL\n","  dataset: CIFAR10\n","  strongaugment: RA\n","  label_num: 4000\n","  num_expand_x: 65536\n","  mu: 7\n","  barely: false\n","  add_noisy_label: false\n","  both_strong: false\n","MODEL:\n","  name: CifarResNeXt\n","  depth: 28\n","  widen_factor: 4\n","  num_classes: 10\n","  dropout: 0.0\n","  cardinality: 4\n","  width: 4\n","  base_width: 4\n","EXPERIMENT:\n","  name: FMExperiment\n","  out_model: ./checkpoints_celiali-resnext-120epochs-32batch/\n","  log_path: ./outputs_celiali-resnext-120epochs-32batch/\n","  used_gpu: true\n","  optim_lr: 0.03\n","  optim_momentum: 0.9\n","  used_nesterov: true\n","  warmup: 0\n","  wdecay: 0.0005\n","  clip: 1\n","  ema_used: true\n","  ema_decay: 0.999\n","  threshold: 0.95\n","  lambda_unlabeled: 1\n","  batch_size: 32\n","  num_workers: 4\n","  n_imgs_per_epoch: 65536\n","  epoch_n: 120\n","  save_every: 64\n","  save_matrix_every: 100\n","  resume: false\n","  resume_checkpoints: ./checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar\n","  save_cfmatrix: true\n","  batch_balanced: false\n","  neg_penalty: false\n","  equal_freq: false\n","  eta_negpenalty: 0.05\n","  eta_dynamic: false\n","  use_nlloss: false\n","  q: 0.0001\n","Logging:\n","  name: FM\n","  seed: 1265\n"," \n","\n","2022-04-16 22:05:34,132 - INFO - Train -   {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'CifarResNeXt', 'depth': 28, 'widen_factor': 4, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints_celiali-resnext-120epochs-32batch/', 'log_path': './outputs_celiali-resnext-120epochs-32batch/', 'used_gpu': True, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 1, 'batch_size': 32, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 64, 'save_matrix_every': 100, 'resume': False, 'resume_checkpoints': './checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar', 'save_cfmatrix': True, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","[2022-04-16 22:05:34,132][Train][INFO] - {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'CifarResNeXt', 'depth': 28, 'widen_factor': 4, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints_celiali-resnext-120epochs-32batch/', 'log_path': './outputs_celiali-resnext-120epochs-32batch/', 'used_gpu': True, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 1, 'batch_size': 32, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 64, 'save_matrix_every': 100, 'resume': False, 'resume_checkpoints': './checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar', 'save_cfmatrix': True, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","2022-04-16 22:05:34,269 - INFO - Train -   [Model] Building model CifarResNeXt\n","[2022-04-16 22:05:34,269][Train][INFO] - [Model] Building model CifarResNeXt\n","2022-04-16 22:05:36,767 - INFO - Train -   Total params: 1.02M\n","[2022-04-16 22:05:36,767][Train][INFO] - Total params: 1.02M\n","[2022-04-16 22:05:36,771][experiments.experiment][INFO] - [EMA] initial \n","[2022-04-16 22:05:38,220][datasets.datasets1][INFO] - Dataset: CIFAR10\n","[2022-04-16 22:05:38,259][datasets.datasets1][INFO] - Labeled examples: 65536 Unlabeled examples: 458752Validation examples: 5000\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-16 22:05:38,260][experiments.experiment][INFO] - Loading Labelled Loader\n","[2022-04-16 22:05:38,260][experiments.experiment][INFO] - Loading Unlabelled Loader\n","[2022-04-16 22:05:38,261][experiments.experiment][INFO] - Loading Validation Loader\n","[2022-04-16 22:05:38,266][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 22:16:42,269][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 0: use 664.1002511978149 seconds\n","--- Optimizer learning rate changed from inf to 3.00e-02 ---\n","[2022-04-16 22:16:42,366][experiments.experiment][INFO] - ***** Running validation *****\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-16 22:16:44,099][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 22:16:44,099][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 22:16:45,859][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 22:16:45,917][experiments.experiment][INFO] - [EMA] Epoch 0.[Train] time:664.1002511978149 seconds, lr:0.0300, train_loss: 1.2536, unlabeled_losses_real_strong:2.2740,corrrect_unlabeled_num:32628.0,pro_above_threshold_num:35586.0,unlabelled_weak_top1_acc:50.30343140102923,unlabelled_weak_top5_acc:92.69561659172177  \n","[2022-04-16 22:16:45,918][experiments.experiment][INFO] - [EMA] Epoch 0. [Validation] raw_testing_loss: 2.7905, raw test Top1 acc:10.0, raw test Top5 acc: 58.1, ema_testing_loss: 2.7043, ema test Top1 acc:10.04, ema test Top5 acc: 54.8\n","[2022-04-16 22:16:45,984][experiments.experiment][INFO] - [Checkpoints] Epoch 0, saving to ./checkpoints_celiali-resnext-120epochs-32batch/FMExperiment_epoch_0.pth.tar\n","[2022-04-16 22:16:45,985][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 22:27:50,157][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 1: use 664.2675275802612 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-16 22:27:50,253][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 22:27:52,026][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 22:27:52,027][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 22:27:53,840][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 22:27:53,841][experiments.experiment][INFO] - [EMA] Epoch 1.[Train] time:664.2675275802612 seconds, lr:0.0300, train_loss: 0.8548, unlabeled_losses_real_strong:2.0083,corrrect_unlabeled_num:107509.0,pro_above_threshold_num:116627.0,unlabelled_weak_top1_acc:63.00462923012674,unlabelled_weak_top5_acc:96.38715364784002  \n","[2022-04-16 22:27:53,844][experiments.experiment][INFO] - [EMA] Epoch 1. [Validation] raw_testing_loss: 3.0307, raw test Top1 acc:20.6, raw test Top5 acc: 64.78, ema_testing_loss: 1.8372, ema test Top1 acc:41.24, ema test Top5 acc: 83.3\n","[2022-04-16 22:27:53,844][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 22:38:58,511][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 2: use 664.7630801200867 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-16 22:38:58,607][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 22:39:00,318][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 22:39:00,318][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 22:39:02,037][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 22:39:02,039][experiments.experiment][INFO] - [EMA] Epoch 2.[Train] time:664.7630801200867 seconds, lr:0.0300, train_loss: 0.7393, unlabeled_losses_real_strong:1.7396,corrrect_unlabeled_num:156099.0,pro_above_threshold_num:170491.0,unlabelled_weak_top1_acc:67.68776934035122,unlabelled_weak_top5_acc:97.08273637667298  \n","[2022-04-16 22:39:02,040][experiments.experiment][INFO] - [EMA] Epoch 2. [Validation] raw_testing_loss: 2.0025, raw test Top1 acc:40.36, raw test Top5 acc: 85.02, ema_testing_loss: 0.8810, ema test Top1 acc:70.72, ema test Top5 acc: 97.74\n","[2022-04-16 22:39:02,041][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 22:50:05,626][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 3: use 663.6805708408356 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-16 22:50:05,722][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 22:50:07,493][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 22:50:07,493][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 22:50:09,253][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 22:50:09,255][experiments.experiment][INFO] - [EMA] Epoch 3.[Train] time:663.6805708408356 seconds, lr:0.0300, train_loss: 0.6877, unlabeled_losses_real_strong:1.6136,corrrect_unlabeled_num:185215.0,pro_above_threshold_num:202054.0,unlabelled_weak_top1_acc:70.26628658175468,unlabelled_weak_top5_acc:97.46180829405785  \n","[2022-04-16 22:50:09,257][experiments.experiment][INFO] - [EMA] Epoch 3. [Validation] raw_testing_loss: 1.7086, raw test Top1 acc:49.76, raw test Top5 acc: 94.14, ema_testing_loss: 0.8222, ema test Top1 acc:75.46, ema test Top5 acc: 98.3\n","[2022-04-16 22:50:09,258][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 23:01:13,746][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 4: use 664.5851082801819 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-16 23:01:13,843][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:01:15,609][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 23:01:15,609][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:01:17,376][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 23:01:17,378][experiments.experiment][INFO] - [EMA] Epoch 4.[Train] time:664.5851082801819 seconds, lr:0.0300, train_loss: 0.6499, unlabeled_losses_real_strong:1.5173,corrrect_unlabeled_num:205936.0,pro_above_threshold_num:223788.0,unlabelled_weak_top1_acc:72.39074593782425,unlabelled_weak_top5_acc:97.78551252558827  \n","[2022-04-16 23:01:17,379][experiments.experiment][INFO] - [EMA] Epoch 4. [Validation] raw_testing_loss: 1.2972, raw test Top1 acc:57.56, raw test Top5 acc: 94.84, ema_testing_loss: 0.7920, ema test Top1 acc:77.2, ema test Top5 acc: 98.54\n","[2022-04-16 23:01:17,380][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 23:12:20,305][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 5: use 663.0240886211395 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 2.99e-02 ---\n","[2022-04-16 23:12:20,404][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:12:22,130][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 23:12:22,130][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:12:23,878][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 23:12:23,879][experiments.experiment][INFO] - [EMA] Epoch 5.[Train] time:663.0240886211395 seconds, lr:0.0299, train_loss: 0.6319, unlabeled_losses_real_strong:1.4483,corrrect_unlabeled_num:220696.0,pro_above_threshold_num:239033.0,unlabelled_weak_top1_acc:73.94474469311535,unlabelled_weak_top5_acc:98.00109733641148  \n","[2022-04-16 23:12:23,881][experiments.experiment][INFO] - [EMA] Epoch 5. [Validation] raw_testing_loss: 1.3527, raw test Top1 acc:62.12, raw test Top5 acc: 95.56, ema_testing_loss: 0.7555, ema test Top1 acc:78.98, ema test Top5 acc: 98.78\n","[2022-04-16 23:12:23,882][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 23:23:26,440][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 6: use 662.6516559123993 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.99e-02 ---\n","[2022-04-16 23:23:26,534][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:23:28,290][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 23:23:28,290][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:23:30,034][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 23:23:30,037][experiments.experiment][INFO] - [EMA] Epoch 6.[Train] time:662.6516559123993 seconds, lr:0.0299, train_loss: 0.6106, unlabeled_losses_real_strong:1.3936,corrrect_unlabeled_num:231507.0,pro_above_threshold_num:250236.0,unlabelled_weak_top1_acc:75.22125137224793,unlabelled_weak_top5_acc:98.16611036658287  \n","[2022-04-16 23:23:30,038][experiments.experiment][INFO] - [EMA] Epoch 6. [Validation] raw_testing_loss: 1.2442, raw test Top1 acc:65.86, raw test Top5 acc: 96.02, ema_testing_loss: 0.7307, ema test Top1 acc:80.04, ema test Top5 acc: 98.98\n","[2022-04-16 23:23:30,039][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 23:34:33,844][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 7: use 663.9068443775177 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.99e-02 ---\n","[2022-04-16 23:34:33,946][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:34:35,677][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 23:34:35,678][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:34:37,435][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 23:34:37,437][experiments.experiment][INFO] - [EMA] Epoch 7.[Train] time:663.9068443775177 seconds, lr:0.0299, train_loss: 0.5945, unlabeled_losses_real_strong:1.3430,corrrect_unlabeled_num:241006.0,pro_above_threshold_num:259468.0,unlabelled_weak_top1_acc:76.26277269795537,unlabelled_weak_top5_acc:98.33526497334242  \n","[2022-04-16 23:34:37,438][experiments.experiment][INFO] - [EMA] Epoch 7. [Validation] raw_testing_loss: 1.2848, raw test Top1 acc:68.78, raw test Top5 acc: 97.22, ema_testing_loss: 0.7039, ema test Top1 acc:81.06, ema test Top5 acc: 99.16\n","[2022-04-16 23:34:37,439][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 23:45:40,994][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 8: use 663.6539418697357 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.98e-02 ---\n","[2022-04-16 23:45:41,093][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:45:42,842][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 23:45:42,843][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:45:44,572][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 23:45:44,573][experiments.experiment][INFO] - [EMA] Epoch 8.[Train] time:663.6539418697357 seconds, lr:0.0298, train_loss: 0.5731, unlabeled_losses_real_strong:1.3070,corrrect_unlabeled_num:249336.0,pro_above_threshold_num:268188.0,unlabelled_weak_top1_acc:77.04990823566914,unlabelled_weak_top5_acc:98.41025106981397  \n","[2022-04-16 23:45:44,575][experiments.experiment][INFO] - [EMA] Epoch 8. [Validation] raw_testing_loss: 0.9699, raw test Top1 acc:72.86, raw test Top5 acc: 98.32, ema_testing_loss: 0.6791, ema test Top1 acc:81.26, ema test Top5 acc: 99.24\n","[2022-04-16 23:45:44,576][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-16 23:56:48,039][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 9: use 663.5612018108368 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.98e-02 ---\n","[2022-04-16 23:56:48,138][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:56:49,893][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-16 23:56:49,894][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-16 23:56:51,746][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-16 23:56:51,748][experiments.experiment][INFO] - [EMA] Epoch 9.[Train] time:663.5612018108368 seconds, lr:0.0298, train_loss: 0.5662, unlabeled_losses_real_strong:1.2746,corrrect_unlabeled_num:255134.0,pro_above_threshold_num:273922.0,unlabelled_weak_top1_acc:77.77818844467402,unlabelled_weak_top5_acc:98.4826212823391  \n","[2022-04-16 23:56:51,749][experiments.experiment][INFO] - [EMA] Epoch 9. [Validation] raw_testing_loss: 0.8603, raw test Top1 acc:75.94, raw test Top5 acc: 97.96, ema_testing_loss: 0.6529, ema test Top1 acc:82.5, ema test Top5 acc: 99.16\n","[2022-04-16 23:56:51,750][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 00:07:55,122][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 10: use 663.4732747077942 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.98e-02 ---\n","[2022-04-17 00:07:55,224][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:07:56,948][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 00:07:56,949][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:07:58,697][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 00:07:58,699][experiments.experiment][INFO] - [EMA] Epoch 10.[Train] time:663.4732747077942 seconds, lr:0.0298, train_loss: 0.5491, unlabeled_losses_real_strong:1.2357,corrrect_unlabeled_num:261913.0,pro_above_threshold_num:280553.0,unlabelled_weak_top1_acc:78.53742221742868,unlabelled_weak_top5_acc:98.57286609336734  \n","[2022-04-17 00:07:58,701][experiments.experiment][INFO] - [EMA] Epoch 10. [Validation] raw_testing_loss: 0.9780, raw test Top1 acc:73.62, raw test Top5 acc: 98.14, ema_testing_loss: 0.6404, ema test Top1 acc:82.76, ema test Top5 acc: 99.24\n","[2022-04-17 00:07:58,702][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 00:19:03,337][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 11: use 664.7338931560516 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.97e-02 ---\n","[2022-04-17 00:19:03,436][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:19:05,185][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 00:19:05,185][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:19:06,945][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 00:19:06,947][experiments.experiment][INFO] - [EMA] Epoch 11.[Train] time:664.7338931560516 seconds, lr:0.0297, train_loss: 0.5372, unlabeled_losses_real_strong:1.2074,corrrect_unlabeled_num:267593.0,pro_above_threshold_num:285921.0,unlabelled_weak_top1_acc:79.30101554095745,unlabelled_weak_top5_acc:98.66725280880928  \n","[2022-04-17 00:19:06,949][experiments.experiment][INFO] - [EMA] Epoch 11. [Validation] raw_testing_loss: 1.0362, raw test Top1 acc:75.2, raw test Top5 acc: 98.34, ema_testing_loss: 0.6203, ema test Top1 acc:83.68, ema test Top5 acc: 99.24\n","[2022-04-17 00:19:06,950][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 00:30:11,294][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 12: use 664.4525060653687 seconds\n","--- Optimizer learning rate changed from 2.97e-02 to 2.97e-02 ---\n","[2022-04-17 00:30:11,403][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:30:13,177][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 00:30:13,177][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:30:14,928][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 00:30:14,930][experiments.experiment][INFO] - [EMA] Epoch 12.[Train] time:664.4525060653687 seconds, lr:0.0297, train_loss: 0.5284, unlabeled_losses_real_strong:1.1792,corrrect_unlabeled_num:273708.0,pro_above_threshold_num:292151.0,unlabelled_weak_top1_acc:79.81262098252773,unlabelled_weak_top5_acc:98.7252361997962  \n","[2022-04-17 00:30:14,931][experiments.experiment][INFO] - [EMA] Epoch 12. [Validation] raw_testing_loss: 0.8948, raw test Top1 acc:77.32, raw test Top5 acc: 98.52, ema_testing_loss: 0.6181, ema test Top1 acc:84.0, ema test Top5 acc: 99.22\n","[2022-04-17 00:30:14,933][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 00:41:20,648][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 13: use 665.8253543376923 seconds\n","--- Optimizer learning rate changed from 2.97e-02 to 2.96e-02 ---\n","[2022-04-17 00:41:20,758][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:41:22,553][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 00:41:22,553][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:41:24,378][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 00:41:24,379][experiments.experiment][INFO] - [EMA] Epoch 13.[Train] time:665.8253543376923 seconds, lr:0.0296, train_loss: 0.5155, unlabeled_losses_real_strong:1.1582,corrrect_unlabeled_num:277358.0,pro_above_threshold_num:295819.0,unlabelled_weak_top1_acc:80.19430876523256,unlabelled_weak_top5_acc:98.75030422583222  \n","[2022-04-17 00:41:24,381][experiments.experiment][INFO] - [EMA] Epoch 13. [Validation] raw_testing_loss: 1.0334, raw test Top1 acc:74.46, raw test Top5 acc: 98.46, ema_testing_loss: 0.6112, ema test Top1 acc:84.04, ema test Top5 acc: 99.28\n","[2022-04-17 00:41:24,383][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 00:52:29,752][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 14: use 665.4699151515961 seconds\n","--- Optimizer learning rate changed from 2.96e-02 to 2.96e-02 ---\n","[2022-04-17 00:52:29,853][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:52:31,618][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 00:52:31,619][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 00:52:33,370][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 00:52:33,372][experiments.experiment][INFO] - [EMA] Epoch 14.[Train] time:665.4699151515961 seconds, lr:0.0296, train_loss: 0.5070, unlabeled_losses_real_strong:1.1380,corrrect_unlabeled_num:281977.0,pro_above_threshold_num:300185.0,unlabelled_weak_top1_acc:80.59408895298839,unlabelled_weak_top5_acc:98.77123058959842  \n","[2022-04-17 00:52:33,373][experiments.experiment][INFO] - [EMA] Epoch 14. [Validation] raw_testing_loss: 1.1333, raw test Top1 acc:74.7, raw test Top5 acc: 98.54, ema_testing_loss: 0.6047, ema test Top1 acc:84.48, ema test Top5 acc: 99.26\n","[2022-04-17 00:52:33,375][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 01:03:39,101][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 15: use 665.8218491077423 seconds\n","--- Optimizer learning rate changed from 2.96e-02 to 2.95e-02 ---\n","[2022-04-17 01:03:39,197][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:03:40,950][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 01:03:40,951][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:03:42,784][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 01:03:42,786][experiments.experiment][INFO] - [EMA] Epoch 15.[Train] time:665.8218491077423 seconds, lr:0.0295, train_loss: 0.4955, unlabeled_losses_real_strong:1.1214,corrrect_unlabeled_num:287203.0,pro_above_threshold_num:305271.0,unlabelled_weak_top1_acc:81.17196105793118,unlabelled_weak_top5_acc:98.83444565162063  \n","[2022-04-17 01:03:42,788][experiments.experiment][INFO] - [EMA] Epoch 15. [Validation] raw_testing_loss: 0.8996, raw test Top1 acc:77.6, raw test Top5 acc: 98.54, ema_testing_loss: 0.5968, ema test Top1 acc:84.92, ema test Top5 acc: 99.36\n","[2022-04-17 01:03:42,789][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 01:14:48,028][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 16: use 665.3401916027069 seconds\n","--- Optimizer learning rate changed from 2.95e-02 to 2.94e-02 ---\n","[2022-04-17 01:14:48,129][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:14:49,909][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 01:14:49,909][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:14:51,701][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 01:14:51,703][experiments.experiment][INFO] - [EMA] Epoch 16.[Train] time:665.3401916027069 seconds, lr:0.0294, train_loss: 0.4866, unlabeled_losses_real_strong:1.0990,corrrect_unlabeled_num:290195.0,pro_above_threshold_num:307894.0,unlabelled_weak_top1_acc:81.61904357746243,unlabelled_weak_top5_acc:98.88043996691704  \n","[2022-04-17 01:14:51,704][experiments.experiment][INFO] - [EMA] Epoch 16. [Validation] raw_testing_loss: 0.7983, raw test Top1 acc:79.82, raw test Top5 acc: 98.94, ema_testing_loss: 0.5888, ema test Top1 acc:85.0, ema test Top5 acc: 99.32\n","[2022-04-17 01:14:51,706][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 01:25:56,891][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 17: use 665.2836647033691 seconds\n","--- Optimizer learning rate changed from 2.94e-02 to 2.94e-02 ---\n","[2022-04-17 01:25:56,989][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:25:58,716][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 01:25:58,716][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:26:00,443][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 01:26:00,444][experiments.experiment][INFO] - [EMA] Epoch 17.[Train] time:665.2836647033691 seconds, lr:0.0294, train_loss: 0.4795, unlabeled_losses_real_strong:1.0812,corrrect_unlabeled_num:293972.0,pro_above_threshold_num:311812.0,unlabelled_weak_top1_acc:81.95124921947718,unlabelled_weak_top5_acc:98.89766062796116  \n","[2022-04-17 01:26:00,447][experiments.experiment][INFO] - [EMA] Epoch 17. [Validation] raw_testing_loss: 0.9558, raw test Top1 acc:77.3, raw test Top5 acc: 98.14, ema_testing_loss: 0.5798, ema test Top1 acc:85.12, ema test Top5 acc: 99.42\n","[2022-04-17 01:26:00,447][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 01:37:04,775][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 18: use 664.4293389320374 seconds\n","--- Optimizer learning rate changed from 2.94e-02 to 2.93e-02 ---\n","[2022-04-17 01:37:04,877][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:37:06,595][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 01:37:06,595][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:37:08,365][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 01:37:08,367][experiments.experiment][INFO] - [EMA] Epoch 18.[Train] time:664.4293389320374 seconds, lr:0.0293, train_loss: 0.4749, unlabeled_losses_real_strong:1.0677,corrrect_unlabeled_num:296057.0,pro_above_threshold_num:313932.0,unlabelled_weak_top1_acc:82.20345523580909,unlabelled_weak_top5_acc:98.90529016032815  \n","[2022-04-17 01:37:08,368][experiments.experiment][INFO] - [EMA] Epoch 18. [Validation] raw_testing_loss: 0.8544, raw test Top1 acc:78.2, raw test Top5 acc: 98.74, ema_testing_loss: 0.5777, ema test Top1 acc:85.78, ema test Top5 acc: 99.38\n","[2022-04-17 01:37:08,369][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 01:48:13,680][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 19: use 665.4184582233429 seconds\n","--- Optimizer learning rate changed from 2.93e-02 to 2.92e-02 ---\n","[2022-04-17 01:48:13,788][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:48:15,527][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 01:48:15,527][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:48:17,242][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 01:48:17,243][experiments.experiment][INFO] - [EMA] Epoch 19.[Train] time:665.4184582233429 seconds, lr:0.0292, train_loss: 0.4722, unlabeled_losses_real_strong:1.0556,corrrect_unlabeled_num:298448.0,pro_above_threshold_num:315866.0,unlabelled_weak_top1_acc:82.50579724833369,unlabelled_weak_top5_acc:98.96022178977728  \n","[2022-04-17 01:48:17,244][experiments.experiment][INFO] - [EMA] Epoch 19. [Validation] raw_testing_loss: 0.7551, raw test Top1 acc:80.78, raw test Top5 acc: 98.88, ema_testing_loss: 0.5665, ema test Top1 acc:85.76, ema test Top5 acc: 99.44\n","[2022-04-17 01:48:17,246][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 01:59:22,522][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 20: use 665.3844318389893 seconds\n","--- Optimizer learning rate changed from 2.92e-02 to 2.91e-02 ---\n","[2022-04-17 01:59:22,631][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:59:24,447][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 01:59:24,447][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 01:59:26,185][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 01:59:26,186][experiments.experiment][INFO] - [EMA] Epoch 20.[Train] time:665.3844318389893 seconds, lr:0.0291, train_loss: 0.4623, unlabeled_losses_real_strong:1.0390,corrrect_unlabeled_num:301795.0,pro_above_threshold_num:319276.0,unlabelled_weak_top1_acc:82.79876605048776,unlabelled_weak_top5_acc:98.95193839818239  \n","[2022-04-17 01:59:26,189][experiments.experiment][INFO] - [EMA] Epoch 20. [Validation] raw_testing_loss: 0.7762, raw test Top1 acc:80.34, raw test Top5 acc: 98.76, ema_testing_loss: 0.5656, ema test Top1 acc:86.08, ema test Top5 acc: 99.3\n","[2022-04-17 01:59:26,190][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 02:10:31,745][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 21: use 665.6527404785156 seconds\n","--- Optimizer learning rate changed from 2.91e-02 to 2.91e-02 ---\n","[2022-04-17 02:10:31,842][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:10:33,580][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 02:10:33,581][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:10:35,321][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 02:10:35,323][experiments.experiment][INFO] - [EMA] Epoch 21.[Train] time:665.6527404785156 seconds, lr:0.0291, train_loss: 0.4598, unlabeled_losses_real_strong:1.0251,corrrect_unlabeled_num:304318.0,pro_above_threshold_num:321637.0,unlabelled_weak_top1_acc:83.10960929095745,unlabelled_weak_top5_acc:98.99902272224426  \n","[2022-04-17 02:10:35,325][experiments.experiment][INFO] - [EMA] Epoch 21. [Validation] raw_testing_loss: 0.8894, raw test Top1 acc:79.48, raw test Top5 acc: 98.42, ema_testing_loss: 0.5616, ema test Top1 acc:86.14, ema test Top5 acc: 99.44\n","[2022-04-17 02:10:35,326][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 02:21:41,162][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 22: use 665.9413948059082 seconds\n","--- Optimizer learning rate changed from 2.91e-02 to 2.90e-02 ---\n","[2022-04-17 02:21:41,267][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:21:43,050][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 02:21:43,051][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:21:44,813][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 02:21:44,815][experiments.experiment][INFO] - [EMA] Epoch 22.[Train] time:665.9413948059082 seconds, lr:0.0290, train_loss: 0.4538, unlabeled_losses_real_strong:1.0122,corrrect_unlabeled_num:306847.0,pro_above_threshold_num:323666.0,unlabelled_weak_top1_acc:83.4766921326518,unlabelled_weak_top5_acc:99.06049395352602  \n","[2022-04-17 02:21:44,817][experiments.experiment][INFO] - [EMA] Epoch 22. [Validation] raw_testing_loss: 0.8576, raw test Top1 acc:80.52, raw test Top5 acc: 98.48, ema_testing_loss: 0.5513, ema test Top1 acc:86.24, ema test Top5 acc: 99.44\n","[2022-04-17 02:21:44,818][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 02:32:51,491][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 23: use 666.7723984718323 seconds\n","--- Optimizer learning rate changed from 2.90e-02 to 2.89e-02 ---\n","[2022-04-17 02:32:51,590][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:32:53,393][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 02:32:53,394][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:32:55,113][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 02:32:55,115][experiments.experiment][INFO] - [EMA] Epoch 23.[Train] time:666.7723984718323 seconds, lr:0.0289, train_loss: 0.4508, unlabeled_losses_real_strong:1.0076,corrrect_unlabeled_num:308779.0,pro_above_threshold_num:325852.0,unlabelled_weak_top1_acc:83.59941648319364,unlabelled_weak_top5_acc:99.02757858112454  \n","[2022-04-17 02:32:55,117][experiments.experiment][INFO] - [EMA] Epoch 23. [Validation] raw_testing_loss: 0.8315, raw test Top1 acc:80.02, raw test Top5 acc: 98.44, ema_testing_loss: 0.5472, ema test Top1 acc:86.4, ema test Top5 acc: 99.46\n","[2022-04-17 02:32:55,117][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 02:44:01,430][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 24: use 666.4104516506195 seconds\n","--- Optimizer learning rate changed from 2.89e-02 to 2.88e-02 ---\n","[2022-04-17 02:44:01,528][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:44:03,362][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 02:44:03,362][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:44:05,134][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 02:44:05,136][experiments.experiment][INFO] - [EMA] Epoch 24.[Train] time:666.4104516506195 seconds, lr:0.0288, train_loss: 0.4449, unlabeled_losses_real_strong:0.9981,corrrect_unlabeled_num:310997.0,pro_above_threshold_num:327735.0,unlabelled_weak_top1_acc:83.82677240297198,unlabelled_weak_top5_acc:99.04981270805001  \n","[2022-04-17 02:44:05,137][experiments.experiment][INFO] - [EMA] Epoch 24. [Validation] raw_testing_loss: 0.8389, raw test Top1 acc:80.98, raw test Top5 acc: 98.94, ema_testing_loss: 0.5450, ema test Top1 acc:86.24, ema test Top5 acc: 99.36\n","[2022-04-17 02:44:05,138][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 02:55:11,112][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 25: use 666.0782918930054 seconds\n","--- Optimizer learning rate changed from 2.88e-02 to 2.87e-02 ---\n","[2022-04-17 02:55:11,217][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:55:13,020][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 02:55:13,021][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 02:55:14,808][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 02:55:14,809][experiments.experiment][INFO] - [EMA] Epoch 25.[Train] time:666.0782918930054 seconds, lr:0.0287, train_loss: 0.4402, unlabeled_losses_real_strong:0.9803,corrrect_unlabeled_num:313683.0,pro_above_threshold_num:330672.0,unlabelled_weak_top1_acc:84.08573590964079,unlabelled_weak_top5_acc:99.07248301431537  \n","[2022-04-17 02:55:14,812][experiments.experiment][INFO] - [EMA] Epoch 25. [Validation] raw_testing_loss: 0.9392, raw test Top1 acc:78.2, raw test Top5 acc: 98.12, ema_testing_loss: 0.5435, ema test Top1 acc:86.54, ema test Top5 acc: 99.48\n","[2022-04-17 02:55:14,813][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 03:06:20,073][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 26: use 665.355838060379 seconds\n","--- Optimizer learning rate changed from 2.87e-02 to 2.86e-02 ---\n","[2022-04-17 03:06:20,168][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:06:21,924][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 03:06:21,924][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:06:23,661][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 03:06:23,663][experiments.experiment][INFO] - [EMA] Epoch 26.[Train] time:665.355838060379 seconds, lr:0.0286, train_loss: 0.4378, unlabeled_losses_real_strong:0.9754,corrrect_unlabeled_num:315245.0,pro_above_threshold_num:332068.0,unlabelled_weak_top1_acc:84.29805102571845,unlabelled_weak_top5_acc:99.10169268026948  \n","[2022-04-17 03:06:23,666][experiments.experiment][INFO] - [EMA] Epoch 26. [Validation] raw_testing_loss: 0.8205, raw test Top1 acc:80.54, raw test Top5 acc: 98.94, ema_testing_loss: 0.5365, ema test Top1 acc:86.76, ema test Top5 acc: 99.48\n","[2022-04-17 03:06:23,666][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 03:17:29,321][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 27: use 665.7526733875275 seconds\n","--- Optimizer learning rate changed from 2.86e-02 to 2.85e-02 ---\n","[2022-04-17 03:17:29,419][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:17:31,298][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 03:17:31,299][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:17:33,143][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 03:17:33,145][experiments.experiment][INFO] - [EMA] Epoch 27.[Train] time:665.7526733875275 seconds, lr:0.0285, train_loss: 0.4338, unlabeled_losses_real_strong:0.9613,corrrect_unlabeled_num:316947.0,pro_above_threshold_num:333476.0,unlabelled_weak_top1_acc:84.51014825701714,unlabelled_weak_top5_acc:99.11891336739063  \n","[2022-04-17 03:17:33,147][experiments.experiment][INFO] - [EMA] Epoch 27. [Validation] raw_testing_loss: 0.7653, raw test Top1 acc:80.52, raw test Top5 acc: 98.8, ema_testing_loss: 0.5301, ema test Top1 acc:86.72, ema test Top5 acc: 99.52\n","[2022-04-17 03:17:33,148][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 03:28:38,438][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 28: use 665.3931238651276 seconds\n","--- Optimizer learning rate changed from 2.85e-02 to 2.84e-02 ---\n","[2022-04-17 03:28:38,541][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:28:40,274][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 03:28:40,274][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:28:42,042][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 03:28:42,044][experiments.experiment][INFO] - [EMA] Epoch 28.[Train] time:665.3931238651276 seconds, lr:0.0284, train_loss: 0.4322, unlabeled_losses_real_strong:0.9570,corrrect_unlabeled_num:318005.0,pro_above_threshold_num:334517.0,unlabelled_weak_top1_acc:84.61892153695226,unlabelled_weak_top5_acc:99.14092963933945  \n","[2022-04-17 03:28:42,046][experiments.experiment][INFO] - [EMA] Epoch 28. [Validation] raw_testing_loss: 1.0524, raw test Top1 acc:77.58, raw test Top5 acc: 98.88, ema_testing_loss: 0.5282, ema test Top1 acc:86.92, ema test Top5 acc: 99.46\n","[2022-04-17 03:28:42,047][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 03:39:48,199][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 29: use 666.2543742656708 seconds\n","--- Optimizer learning rate changed from 2.84e-02 to 2.82e-02 ---\n","[2022-04-17 03:39:48,301][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:39:50,113][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 03:39:50,113][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:39:51,978][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 03:39:51,979][experiments.experiment][INFO] - [EMA] Epoch 29.[Train] time:666.2543742656708 seconds, lr:0.0282, train_loss: 0.4290, unlabeled_losses_real_strong:0.9475,corrrect_unlabeled_num:319227.0,pro_above_threshold_num:335601.0,unlabelled_weak_top1_acc:84.73379845544696,unlabelled_weak_top5_acc:99.16098422184587  \n","[2022-04-17 03:39:51,980][experiments.experiment][INFO] - [EMA] Epoch 29. [Validation] raw_testing_loss: 0.8302, raw test Top1 acc:80.24, raw test Top5 acc: 98.78, ema_testing_loss: 0.5162, ema test Top1 acc:87.22, ema test Top5 acc: 99.52\n","[2022-04-17 03:39:51,982][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 03:50:58,326][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 30: use 666.4414117336273 seconds\n","--- Optimizer learning rate changed from 2.82e-02 to 2.81e-02 ---\n","[2022-04-17 03:50:58,424][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:51:00,165][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 03:51:00,166][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 03:51:01,939][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 03:51:01,941][experiments.experiment][INFO] - [EMA] Epoch 30.[Train] time:666.4414117336273 seconds, lr:0.0281, train_loss: 0.4243, unlabeled_losses_real_strong:0.9342,corrrect_unlabeled_num:321819.0,pro_above_threshold_num:337958.0,unlabelled_weak_top1_acc:84.96747593209147,unlabelled_weak_top5_acc:99.14398143813014  \n","[2022-04-17 03:51:01,942][experiments.experiment][INFO] - [EMA] Epoch 30. [Validation] raw_testing_loss: 0.9522, raw test Top1 acc:78.5, raw test Top5 acc: 98.82, ema_testing_loss: 0.5125, ema test Top1 acc:87.5, ema test Top5 acc: 99.44\n","[2022-04-17 03:51:01,944][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 04:02:06,460][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 31: use 664.6179053783417 seconds\n","--- Optimizer learning rate changed from 2.81e-02 to 2.80e-02 ---\n","[2022-04-17 04:02:06,562][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:02:08,304][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 04:02:08,304][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:02:10,037][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 04:02:10,039][experiments.experiment][INFO] - [EMA] Epoch 31.[Train] time:664.6179053783417 seconds, lr:0.0280, train_loss: 0.4218, unlabeled_losses_real_strong:0.9296,corrrect_unlabeled_num:323361.0,pro_above_threshold_num:339605.0,unlabelled_weak_top1_acc:85.22425954043865,unlabelled_weak_top5_acc:99.15379063040018  \n","[2022-04-17 04:02:10,040][experiments.experiment][INFO] - [EMA] Epoch 31. [Validation] raw_testing_loss: 0.9529, raw test Top1 acc:77.6, raw test Top5 acc: 98.82, ema_testing_loss: 0.5145, ema test Top1 acc:87.58, ema test Top5 acc: 99.52\n","[2022-04-17 04:02:10,042][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 04:13:13,201][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 32: use 663.2582490444183 seconds\n","--- Optimizer learning rate changed from 2.80e-02 to 2.79e-02 ---\n","[2022-04-17 04:13:13,300][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:13:15,056][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 04:13:15,057][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:13:16,800][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 04:13:16,802][experiments.experiment][INFO] - [EMA] Epoch 32.[Train] time:663.2582490444183 seconds, lr:0.0279, train_loss: 0.4205, unlabeled_losses_real_strong:0.9214,corrrect_unlabeled_num:325129.0,pro_above_threshold_num:340989.0,unlabelled_weak_top1_acc:85.44224224239588,unlabelled_weak_top5_acc:99.1849622130394  \n","[2022-04-17 04:13:16,804][experiments.experiment][INFO] - [EMA] Epoch 32. [Validation] raw_testing_loss: 0.7378, raw test Top1 acc:81.9, raw test Top5 acc: 98.88, ema_testing_loss: 0.5030, ema test Top1 acc:87.96, ema test Top5 acc: 99.52\n","[2022-04-17 04:13:16,805][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 04:24:21,536][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 33: use 664.8316962718964 seconds\n","--- Optimizer learning rate changed from 2.79e-02 to 2.78e-02 ---\n","[2022-04-17 04:24:21,637][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:24:23,395][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 04:24:23,396][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:24:25,152][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 04:24:25,154][experiments.experiment][INFO] - [EMA] Epoch 33.[Train] time:664.8316962718964 seconds, lr:0.0278, train_loss: 0.4161, unlabeled_losses_real_strong:0.9125,corrrect_unlabeled_num:326851.0,pro_above_threshold_num:342778.0,unlabelled_weak_top1_acc:85.57891736552119,unlabelled_weak_top5_acc:99.21286396682262  \n","[2022-04-17 04:24:25,155][experiments.experiment][INFO] - [EMA] Epoch 33. [Validation] raw_testing_loss: 0.8350, raw test Top1 acc:81.18, raw test Top5 acc: 99.0, ema_testing_loss: 0.5090, ema test Top1 acc:87.82, ema test Top5 acc: 99.52\n","[2022-04-17 04:24:25,157][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 04:35:29,470][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 34: use 664.4118583202362 seconds\n","--- Optimizer learning rate changed from 2.78e-02 to 2.76e-02 ---\n","[2022-04-17 04:35:29,569][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:35:31,340][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 04:35:31,341][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:35:33,065][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 04:35:33,066][experiments.experiment][INFO] - [EMA] Epoch 34.[Train] time:664.4118583202362 seconds, lr:0.0276, train_loss: 0.4130, unlabeled_losses_real_strong:0.9065,corrrect_unlabeled_num:327236.0,pro_above_threshold_num:343073.0,unlabelled_weak_top1_acc:85.7310692705214,unlabelled_weak_top5_acc:99.26256414502859  \n","[2022-04-17 04:35:33,068][experiments.experiment][INFO] - [EMA] Epoch 34. [Validation] raw_testing_loss: 1.1426, raw test Top1 acc:77.78, raw test Top5 acc: 98.28, ema_testing_loss: 0.5043, ema test Top1 acc:88.04, ema test Top5 acc: 99.48\n","[2022-04-17 04:35:33,069][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 04:46:37,545][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 35: use 664.5732507705688 seconds\n","--- Optimizer learning rate changed from 2.76e-02 to 2.75e-02 ---\n","[2022-04-17 04:46:37,642][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:46:39,386][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 04:46:39,386][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:46:41,132][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 04:46:41,133][experiments.experiment][INFO] - [EMA] Epoch 35.[Train] time:664.5732507705688 seconds, lr:0.0275, train_loss: 0.4111, unlabeled_losses_real_strong:0.8987,corrrect_unlabeled_num:329040.0,pro_above_threshold_num:344620.0,unlabelled_weak_top1_acc:85.91570059210062,unlabelled_weak_top5_acc:99.25428085401654  \n","[2022-04-17 04:46:41,135][experiments.experiment][INFO] - [EMA] Epoch 35. [Validation] raw_testing_loss: 0.6642, raw test Top1 acc:82.62, raw test Top5 acc: 99.06, ema_testing_loss: 0.4829, ema test Top1 acc:88.48, ema test Top5 acc: 99.54\n","[2022-04-17 04:46:41,136][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 04:57:45,432][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 36: use 664.4059162139893 seconds\n","--- Optimizer learning rate changed from 2.75e-02 to 2.73e-02 ---\n","[2022-04-17 04:57:45,542][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:57:47,304][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 04:57:47,305][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 04:57:49,094][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 04:57:49,096][experiments.experiment][INFO] - [EMA] Epoch 36.[Train] time:664.4059162139893 seconds, lr:0.0273, train_loss: 0.4096, unlabeled_losses_real_strong:0.8905,corrrect_unlabeled_num:330762.0,pro_above_threshold_num:346335.0,unlabelled_weak_top1_acc:86.04322042688727,unlabelled_weak_top5_acc:99.26757776737213  \n","[2022-04-17 04:57:49,098][experiments.experiment][INFO] - [EMA] Epoch 36. [Validation] raw_testing_loss: 0.8304, raw test Top1 acc:79.94, raw test Top5 acc: 98.58, ema_testing_loss: 0.4874, ema test Top1 acc:88.18, ema test Top5 acc: 99.62\n","[2022-04-17 04:57:49,100][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 05:08:54,250][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 37: use 665.2520279884338 seconds\n","--- Optimizer learning rate changed from 2.73e-02 to 2.72e-02 ---\n","[2022-04-17 05:08:54,352][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:08:56,129][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 05:08:56,129][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:08:57,873][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 05:08:57,875][experiments.experiment][INFO] - [EMA] Epoch 37.[Train] time:665.2520279884338 seconds, lr:0.0272, train_loss: 0.4070, unlabeled_losses_real_strong:0.8880,corrrect_unlabeled_num:330445.0,pro_above_threshold_num:346087.0,unlabelled_weak_top1_acc:86.04627226665616,unlabelled_weak_top5_acc:99.25144698098302  \n","[2022-04-17 05:08:57,876][experiments.experiment][INFO] - [EMA] Epoch 37. [Validation] raw_testing_loss: 0.7449, raw test Top1 acc:81.58, raw test Top5 acc: 99.46, ema_testing_loss: 0.4796, ema test Top1 acc:88.18, ema test Top5 acc: 99.64\n","[2022-04-17 05:08:57,878][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 05:20:03,142][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 38: use 665.3662710189819 seconds\n","--- Optimizer learning rate changed from 2.72e-02 to 2.71e-02 ---\n","[2022-04-17 05:20:03,244][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:20:05,062][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 05:20:05,062][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:20:06,834][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 05:20:06,836][experiments.experiment][INFO] - [EMA] Epoch 38.[Train] time:665.3662710189819 seconds, lr:0.0271, train_loss: 0.4050, unlabeled_losses_real_strong:0.8767,corrrect_unlabeled_num:332511.0,pro_above_threshold_num:347701.0,unlabelled_weak_top1_acc:86.28496335446835,unlabelled_weak_top5_acc:99.2728094086051  \n","[2022-04-17 05:20:06,838][experiments.experiment][INFO] - [EMA] Epoch 38. [Validation] raw_testing_loss: 0.6838, raw test Top1 acc:82.12, raw test Top5 acc: 99.22, ema_testing_loss: 0.4823, ema test Top1 acc:88.56, ema test Top5 acc: 99.56\n","[2022-04-17 05:20:06,839][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 05:31:13,285][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 39: use 666.553521156311 seconds\n","--- Optimizer learning rate changed from 2.71e-02 to 2.69e-02 ---\n","[2022-04-17 05:31:13,393][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:31:15,172][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 05:31:15,173][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:31:16,953][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 05:31:16,955][experiments.experiment][INFO] - [EMA] Epoch 39.[Train] time:666.553521156311 seconds, lr:0.0269, train_loss: 0.3994, unlabeled_losses_real_strong:0.8698,corrrect_unlabeled_num:333516.0,pro_above_threshold_num:348645.0,unlabelled_weak_top1_acc:86.38109368830919,unlabelled_weak_top5_acc:99.26605192944407  \n","[2022-04-17 05:31:16,957][experiments.experiment][INFO] - [EMA] Epoch 39. [Validation] raw_testing_loss: 0.9973, raw test Top1 acc:78.56, raw test Top5 acc: 97.98, ema_testing_loss: 0.4861, ema test Top1 acc:88.46, ema test Top5 acc: 99.6\n","[2022-04-17 05:31:16,959][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 05:42:22,690][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 40: use 665.8265187740326 seconds\n","--- Optimizer learning rate changed from 2.69e-02 to 2.68e-02 ---\n","[2022-04-17 05:42:22,785][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:42:24,559][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 05:42:24,559][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:42:26,340][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 05:42:26,342][experiments.experiment][INFO] - [EMA] Epoch 40.[Train] time:665.8265187740326 seconds, lr:0.0268, train_loss: 0.3989, unlabeled_losses_real_strong:0.8692,corrrect_unlabeled_num:334376.0,pro_above_threshold_num:349359.0,unlabelled_weak_top1_acc:86.44692448526621,unlabelled_weak_top5_acc:99.28632436692715  \n","[2022-04-17 05:42:26,345][experiments.experiment][INFO] - [EMA] Epoch 40. [Validation] raw_testing_loss: 0.7204, raw test Top1 acc:82.78, raw test Top5 acc: 99.16, ema_testing_loss: 0.4788, ema test Top1 acc:88.44, ema test Top5 acc: 99.56\n","[2022-04-17 05:42:26,346][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 05:53:32,865][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 41: use 666.6213819980621 seconds\n","--- Optimizer learning rate changed from 2.68e-02 to 2.66e-02 ---\n","[2022-04-17 05:53:32,967][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:53:34,739][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 05:53:34,739][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 05:53:36,585][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 05:53:36,587][experiments.experiment][INFO] - [EMA] Epoch 41.[Train] time:666.6213819980621 seconds, lr:0.0266, train_loss: 0.3975, unlabeled_losses_real_strong:0.8616,corrrect_unlabeled_num:335298.0,pro_above_threshold_num:350267.0,unlabelled_weak_top1_acc:86.63308169320226,unlabelled_weak_top5_acc:99.29046596586704  \n","[2022-04-17 05:53:36,589][experiments.experiment][INFO] - [EMA] Epoch 41. [Validation] raw_testing_loss: 0.8908, raw test Top1 acc:79.74, raw test Top5 acc: 98.62, ema_testing_loss: 0.4728, ema test Top1 acc:88.46, ema test Top5 acc: 99.52\n","[2022-04-17 05:53:36,590][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 06:04:43,371][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 42: use 666.881942987442 seconds\n","--- Optimizer learning rate changed from 2.66e-02 to 2.64e-02 ---\n","[2022-04-17 06:04:43,472][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:04:45,219][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 06:04:45,220][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:04:46,971][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 06:04:46,973][experiments.experiment][INFO] - [EMA] Epoch 42.[Train] time:666.881942987442 seconds, lr:0.0264, train_loss: 0.3971, unlabeled_losses_real_strong:0.8579,corrrect_unlabeled_num:336729.0,pro_above_threshold_num:351559.0,unlabelled_weak_top1_acc:86.78370768204331,unlabelled_weak_top5_acc:99.32250948622823  \n","[2022-04-17 06:04:46,975][experiments.experiment][INFO] - [EMA] Epoch 42. [Validation] raw_testing_loss: 0.7218, raw test Top1 acc:82.1, raw test Top5 acc: 98.64, ema_testing_loss: 0.4663, ema test Top1 acc:88.52, ema test Top5 acc: 99.54\n","[2022-04-17 06:04:46,976][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 06:15:53,212][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 43: use 666.337890625 seconds\n","--- Optimizer learning rate changed from 2.64e-02 to 2.63e-02 ---\n","[2022-04-17 06:15:53,314][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:15:55,100][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 06:15:55,100][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:15:56,841][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 06:15:56,843][experiments.experiment][INFO] - [EMA] Epoch 43.[Train] time:666.337890625 seconds, lr:0.0263, train_loss: 0.3941, unlabeled_losses_real_strong:0.8522,corrrect_unlabeled_num:337773.0,pro_above_threshold_num:352282.0,unlabelled_weak_top1_acc:86.88158196210861,unlabelled_weak_top5_acc:99.3445258103311  \n","[2022-04-17 06:15:56,844][experiments.experiment][INFO] - [EMA] Epoch 43. [Validation] raw_testing_loss: 0.7272, raw test Top1 acc:82.3, raw test Top5 acc: 99.0, ema_testing_loss: 0.4554, ema test Top1 acc:88.84, ema test Top5 acc: 99.54\n","[2022-04-17 06:15:56,846][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 06:27:02,550][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 44: use 665.8010394573212 seconds\n","--- Optimizer learning rate changed from 2.63e-02 to 2.61e-02 ---\n","[2022-04-17 06:27:02,647][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:27:04,383][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 06:27:04,383][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:27:06,134][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 06:27:06,135][experiments.experiment][INFO] - [EMA] Epoch 44.[Train] time:665.8010394573212 seconds, lr:0.0261, train_loss: 0.3921, unlabeled_losses_real_strong:0.8406,corrrect_unlabeled_num:338791.0,pro_above_threshold_num:353421.0,unlabelled_weak_top1_acc:87.0753684937954,unlabelled_weak_top5_acc:99.32883106917143  \n","[2022-04-17 06:27:06,137][experiments.experiment][INFO] - [EMA] Epoch 44. [Validation] raw_testing_loss: 0.6472, raw test Top1 acc:84.66, raw test Top5 acc: 99.04, ema_testing_loss: 0.4516, ema test Top1 acc:89.18, ema test Top5 acc: 99.56\n","[2022-04-17 06:27:06,138][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 06:38:12,171][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 45: use 666.1312091350555 seconds\n","--- Optimizer learning rate changed from 2.61e-02 to 2.59e-02 ---\n","[2022-04-17 06:38:12,269][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:38:14,016][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 06:38:14,016][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:38:15,734][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 06:38:15,735][experiments.experiment][INFO] - [EMA] Epoch 45.[Train] time:666.1312091350555 seconds, lr:0.0259, train_loss: 0.3881, unlabeled_losses_real_strong:0.8387,corrrect_unlabeled_num:339000.0,pro_above_threshold_num:353615.0,unlabelled_weak_top1_acc:87.04267124831676,unlabelled_weak_top5_acc:99.36719611287117  \n","[2022-04-17 06:38:15,738][experiments.experiment][INFO] - [EMA] Epoch 45. [Validation] raw_testing_loss: 0.6543, raw test Top1 acc:84.34, raw test Top5 acc: 99.16, ema_testing_loss: 0.4479, ema test Top1 acc:88.92, ema test Top5 acc: 99.56\n","[2022-04-17 06:38:15,739][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 06:49:22,097][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 46: use 666.456250667572 seconds\n","--- Optimizer learning rate changed from 2.59e-02 to 2.58e-02 ---\n","[2022-04-17 06:49:22,195][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:49:23,973][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 06:49:23,974][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 06:49:25,714][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 06:49:25,715][experiments.experiment][INFO] - [EMA] Epoch 46.[Train] time:666.456250667572 seconds, lr:0.0258, train_loss: 0.3870, unlabeled_losses_real_strong:0.8348,corrrect_unlabeled_num:340564.0,pro_above_threshold_num:354852.0,unlabelled_weak_top1_acc:87.31754733994603,unlabelled_weak_top5_acc:99.36501624062657  \n","[2022-04-17 06:49:25,717][experiments.experiment][INFO] - [EMA] Epoch 46. [Validation] raw_testing_loss: 0.7852, raw test Top1 acc:82.86, raw test Top5 acc: 98.48, ema_testing_loss: 0.4494, ema test Top1 acc:89.16, ema test Top5 acc: 99.54\n","[2022-04-17 06:49:25,719][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 07:00:32,837][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 47: use 667.220383644104 seconds\n","--- Optimizer learning rate changed from 2.58e-02 to 2.56e-02 ---\n","[2022-04-17 07:00:32,939][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:00:34,718][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 07:00:34,719][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:00:36,494][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 07:00:36,496][experiments.experiment][INFO] - [EMA] Epoch 47.[Train] time:667.220383644104 seconds, lr:0.0256, train_loss: 0.3837, unlabeled_losses_real_strong:0.8286,corrrect_unlabeled_num:341431.0,pro_above_threshold_num:355841.0,unlabelled_weak_top1_acc:87.2859398983419,unlabelled_weak_top5_acc:99.37395353987813  \n","[2022-04-17 07:00:36,499][experiments.experiment][INFO] - [EMA] Epoch 47. [Validation] raw_testing_loss: 0.7140, raw test Top1 acc:82.46, raw test Top5 acc: 99.18, ema_testing_loss: 0.4472, ema test Top1 acc:89.34, ema test Top5 acc: 99.54\n","[2022-04-17 07:00:36,499][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 07:11:42,407][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 48: use 666.0066094398499 seconds\n","--- Optimizer learning rate changed from 2.56e-02 to 2.54e-02 ---\n","[2022-04-17 07:11:42,506][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:11:44,291][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 07:11:44,291][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:11:46,028][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 07:11:46,030][experiments.experiment][INFO] - [EMA] Epoch 48.[Train] time:666.0066094398499 seconds, lr:0.0254, train_loss: 0.3824, unlabeled_losses_real_strong:0.8259,corrrect_unlabeled_num:341608.0,pro_above_threshold_num:355901.0,unlabelled_weak_top1_acc:87.43678382411599,unlabelled_weak_top5_acc:99.37656923010945  \n","[2022-04-17 07:11:46,032][experiments.experiment][INFO] - [EMA] Epoch 48. [Validation] raw_testing_loss: 0.8392, raw test Top1 acc:81.8, raw test Top5 acc: 98.78, ema_testing_loss: 0.4433, ema test Top1 acc:89.12, ema test Top5 acc: 99.44\n","[2022-04-17 07:11:46,033][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 07:22:52,280][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 49: use 666.3464004993439 seconds\n","--- Optimizer learning rate changed from 2.54e-02 to 2.52e-02 ---\n","[2022-04-17 07:22:52,380][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:22:54,159][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 07:22:54,159][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:22:55,999][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 07:22:56,001][experiments.experiment][INFO] - [EMA] Epoch 49.[Train] time:666.3464004993439 seconds, lr:0.0252, train_loss: 0.3828, unlabeled_losses_real_strong:0.8224,corrrect_unlabeled_num:342796.0,pro_above_threshold_num:356937.0,unlabelled_weak_top1_acc:87.53836392238736,unlabelled_weak_top5_acc:99.38572456687689  \n","[2022-04-17 07:22:56,004][experiments.experiment][INFO] - [EMA] Epoch 49. [Validation] raw_testing_loss: 0.8012, raw test Top1 acc:80.22, raw test Top5 acc: 98.7, ema_testing_loss: 0.4397, ema test Top1 acc:89.16, ema test Top5 acc: 99.58\n","[2022-04-17 07:22:56,004][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 07:34:02,326][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 50: use 666.4186661243439 seconds\n","--- Optimizer learning rate changed from 2.52e-02 to 2.50e-02 ---\n","[2022-04-17 07:34:02,423][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:34:04,203][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 07:34:04,203][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:34:06,002][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 07:34:06,004][experiments.experiment][INFO] - [EMA] Epoch 50.[Train] time:666.4186661243439 seconds, lr:0.0250, train_loss: 0.3800, unlabeled_losses_real_strong:0.8184,corrrect_unlabeled_num:343131.0,pro_above_threshold_num:357259.0,unlabelled_weak_top1_acc:87.55798229202628,unlabelled_weak_top5_acc:99.36959388107061  \n","[2022-04-17 07:34:06,006][experiments.experiment][INFO] - [EMA] Epoch 50. [Validation] raw_testing_loss: 0.6185, raw test Top1 acc:83.82, raw test Top5 acc: 99.14, ema_testing_loss: 0.4355, ema test Top1 acc:89.34, ema test Top5 acc: 99.46\n","[2022-04-17 07:34:06,007][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 07:45:12,177][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 51: use 666.2685215473175 seconds\n","--- Optimizer learning rate changed from 2.50e-02 to 2.48e-02 ---\n","[2022-04-17 07:45:12,276][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:45:14,056][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 07:45:14,056][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:45:15,781][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 07:45:15,783][experiments.experiment][INFO] - [EMA] Epoch 51.[Train] time:666.2685215473175 seconds, lr:0.0248, train_loss: 0.3763, unlabeled_losses_real_strong:0.8127,corrrect_unlabeled_num:343987.0,pro_above_threshold_num:357768.0,unlabelled_weak_top1_acc:87.72234128043056,unlabelled_weak_top5_acc:99.39052024111152  \n","[2022-04-17 07:45:15,784][experiments.experiment][INFO] - [EMA] Epoch 51. [Validation] raw_testing_loss: 0.7045, raw test Top1 acc:81.82, raw test Top5 acc: 98.96, ema_testing_loss: 0.4322, ema test Top1 acc:89.26, ema test Top5 acc: 99.44\n","[2022-04-17 07:45:15,786][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 07:56:22,620][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 52: use 666.9487130641937 seconds\n","--- Optimizer learning rate changed from 2.48e-02 to 2.46e-02 ---\n","[2022-04-17 07:56:22,734][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:56:24,464][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 07:56:24,464][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 07:56:26,201][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 07:56:26,203][experiments.experiment][INFO] - [EMA] Epoch 52.[Train] time:666.9487130641937 seconds, lr:0.0246, train_loss: 0.3748, unlabeled_losses_real_strong:0.8080,corrrect_unlabeled_num:344778.0,pro_above_threshold_num:358860.0,unlabelled_weak_top1_acc:87.72713689506054,unlabelled_weak_top5_acc:99.40054738149047  \n","[2022-04-17 07:56:26,205][experiments.experiment][INFO] - [EMA] Epoch 52. [Validation] raw_testing_loss: 0.7372, raw test Top1 acc:83.18, raw test Top5 acc: 98.84, ema_testing_loss: 0.4376, ema test Top1 acc:89.36, ema test Top5 acc: 99.58\n","[2022-04-17 07:56:26,206][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 08:07:32,669][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 53: use 666.5692172050476 seconds\n","--- Optimizer learning rate changed from 2.46e-02 to 2.44e-02 ---\n","[2022-04-17 08:07:32,775][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:07:34,528][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 08:07:34,528][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:07:36,297][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 08:07:36,299][experiments.experiment][INFO] - [EMA] Epoch 53.[Train] time:666.5692172050476 seconds, lr:0.0244, train_loss: 0.3743, unlabeled_losses_real_strong:0.8047,corrrect_unlabeled_num:346413.0,pro_above_threshold_num:360272.0,unlabelled_weak_top1_acc:87.89149587973952,unlabelled_weak_top5_acc:99.39400798454881  \n","[2022-04-17 08:07:36,302][experiments.experiment][INFO] - [EMA] Epoch 53. [Validation] raw_testing_loss: 1.0414, raw test Top1 acc:78.58, raw test Top5 acc: 98.78, ema_testing_loss: 0.4224, ema test Top1 acc:89.26, ema test Top5 acc: 99.56\n","[2022-04-17 08:07:36,302][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 08:18:43,237][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 54: use 667.0397493839264 seconds\n","--- Optimizer learning rate changed from 2.44e-02 to 2.42e-02 ---\n","[2022-04-17 08:18:43,342][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:18:45,077][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 08:18:45,078][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:18:46,977][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 08:18:46,979][experiments.experiment][INFO] - [EMA] Epoch 54.[Train] time:667.0397493839264 seconds, lr:0.0242, train_loss: 0.3721, unlabeled_losses_real_strong:0.8030,corrrect_unlabeled_num:346165.0,pro_above_threshold_num:359847.0,unlabelled_weak_top1_acc:87.88582833483815,unlabelled_weak_top5_acc:99.40577909722924  \n","[2022-04-17 08:18:46,981][experiments.experiment][INFO] - [EMA] Epoch 54. [Validation] raw_testing_loss: 0.7573, raw test Top1 acc:82.28, raw test Top5 acc: 98.92, ema_testing_loss: 0.4270, ema test Top1 acc:89.52, ema test Top5 acc: 99.6\n","[2022-04-17 08:18:46,982][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 08:29:53,708][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 55: use 666.8251647949219 seconds\n","--- Optimizer learning rate changed from 2.42e-02 to 2.40e-02 ---\n","[2022-04-17 08:29:53,807][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:29:55,562][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 08:29:55,563][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:29:57,376][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 08:29:57,378][experiments.experiment][INFO] - [EMA] Epoch 55.[Train] time:666.8251647949219 seconds, lr:0.0240, train_loss: 0.3709, unlabeled_losses_real_strong:0.7960,corrrect_unlabeled_num:347812.0,pro_above_threshold_num:361430.0,unlabelled_weak_top1_acc:88.03165876865387,unlabelled_weak_top5_acc:99.39684173464775  \n","[2022-04-17 08:29:57,379][experiments.experiment][INFO] - [EMA] Epoch 55. [Validation] raw_testing_loss: 0.8155, raw test Top1 acc:81.72, raw test Top5 acc: 99.14, ema_testing_loss: 0.4316, ema test Top1 acc:89.4, ema test Top5 acc: 99.62\n","[2022-04-17 08:29:57,380][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 08:41:02,903][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 56: use 665.6198358535767 seconds\n","--- Optimizer learning rate changed from 2.40e-02 to 2.38e-02 ---\n","[2022-04-17 08:41:03,000][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:41:04,725][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 08:41:04,725][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:41:06,532][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 08:41:06,534][experiments.experiment][INFO] - [EMA] Epoch 56.[Train] time:665.6198358535767 seconds, lr:0.0238, train_loss: 0.3710, unlabeled_losses_real_strong:0.7898,corrrect_unlabeled_num:348240.0,pro_above_threshold_num:361700.0,unlabelled_weak_top1_acc:88.21803390607238,unlabelled_weak_top5_acc:99.4376045577228  \n","[2022-04-17 08:41:06,536][experiments.experiment][INFO] - [EMA] Epoch 56. [Validation] raw_testing_loss: 0.7259, raw test Top1 acc:82.18, raw test Top5 acc: 99.04, ema_testing_loss: 0.4274, ema test Top1 acc:89.56, ema test Top5 acc: 99.58\n","[2022-04-17 08:41:06,537][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 08:52:13,842][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 57: use 667.416077375412 seconds\n","--- Optimizer learning rate changed from 2.38e-02 to 2.36e-02 ---\n","[2022-04-17 08:52:13,953][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:52:15,677][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 08:52:15,677][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 08:52:17,426][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 08:52:17,427][experiments.experiment][INFO] - [EMA] Epoch 57.[Train] time:667.416077375412 seconds, lr:0.0236, train_loss: 0.3642, unlabeled_losses_real_strong:0.7852,corrrect_unlabeled_num:348654.0,pro_above_threshold_num:362063.0,unlabelled_weak_top1_acc:88.26119446009398,unlabelled_weak_top5_acc:99.44196416065097  \n","[2022-04-17 08:52:17,429][experiments.experiment][INFO] - [EMA] Epoch 57. [Validation] raw_testing_loss: 0.6690, raw test Top1 acc:83.52, raw test Top5 acc: 99.22, ema_testing_loss: 0.4189, ema test Top1 acc:89.68, ema test Top5 acc: 99.58\n","[2022-04-17 08:52:17,430][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 09:03:23,232][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 58: use 665.899820804596 seconds\n","--- Optimizer learning rate changed from 2.36e-02 to 2.34e-02 ---\n","[2022-04-17 09:03:23,330][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:03:25,099][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 09:03:25,099][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:03:26,883][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 09:03:26,884][experiments.experiment][INFO] - [EMA] Epoch 58.[Train] time:665.899820804596 seconds, lr:0.0234, train_loss: 0.3651, unlabeled_losses_real_strong:0.7794,corrrect_unlabeled_num:350097.0,pro_above_threshold_num:363508.0,unlabelled_weak_top1_acc:88.32135775312781,unlabelled_weak_top5_acc:99.43978437036276  \n","[2022-04-17 09:03:26,885][experiments.experiment][INFO] - [EMA] Epoch 58. [Validation] raw_testing_loss: 0.6812, raw test Top1 acc:82.24, raw test Top5 acc: 98.58, ema_testing_loss: 0.4208, ema test Top1 acc:89.54, ema test Top5 acc: 99.52\n","[2022-04-17 09:03:26,887][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 09:14:33,291][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 59: use 666.5062131881714 seconds\n","--- Optimizer learning rate changed from 2.34e-02 to 2.32e-02 ---\n","[2022-04-17 09:14:33,393][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:14:35,129][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 09:14:35,129][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:14:36,987][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 09:14:36,989][experiments.experiment][INFO] - [EMA] Epoch 59.[Train] time:666.5062131881714 seconds, lr:0.0232, train_loss: 0.3627, unlabeled_losses_real_strong:0.7769,corrrect_unlabeled_num:350536.0,pro_above_threshold_num:364135.0,unlabelled_weak_top1_acc:88.36451834067702,unlabelled_weak_top5_acc:99.44654189422727  \n","[2022-04-17 09:14:36,990][experiments.experiment][INFO] - [EMA] Epoch 59. [Validation] raw_testing_loss: 0.7609, raw test Top1 acc:82.48, raw test Top5 acc: 98.56, ema_testing_loss: 0.4227, ema test Top1 acc:89.84, ema test Top5 acc: 99.6\n","[2022-04-17 09:14:36,992][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 09:25:42,919][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 60: use 666.0288829803467 seconds\n","--- Optimizer learning rate changed from 2.32e-02 to 2.30e-02 ---\n","[2022-04-17 09:25:43,021][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:25:44,799][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 09:25:44,799][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:25:46,578][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 09:25:46,580][experiments.experiment][INFO] - [EMA] Epoch 60.[Train] time:666.0288829803467 seconds, lr:0.0230, train_loss: 0.3637, unlabeled_losses_real_strong:0.7740,corrrect_unlabeled_num:350776.0,pro_above_threshold_num:364046.0,unlabelled_weak_top1_acc:88.4469156935811,unlabelled_weak_top5_acc:99.43716860935092  \n","[2022-04-17 09:25:46,581][experiments.experiment][INFO] - [EMA] Epoch 60. [Validation] raw_testing_loss: 1.2087, raw test Top1 acc:76.0, raw test Top5 acc: 98.6, ema_testing_loss: 0.4172, ema test Top1 acc:89.6, ema test Top5 acc: 99.62\n","[2022-04-17 09:25:46,583][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 09:36:53,270][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 61: use 666.7953231334686 seconds\n","--- Optimizer learning rate changed from 2.30e-02 to 2.27e-02 ---\n","[2022-04-17 09:36:53,378][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:36:55,168][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 09:36:55,169][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:36:56,937][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 09:36:56,939][experiments.experiment][INFO] - [EMA] Epoch 61.[Train] time:666.7953231334686 seconds, lr:0.0227, train_loss: 0.3620, unlabeled_losses_real_strong:0.7706,corrrect_unlabeled_num:351880.0,pro_above_threshold_num:364862.0,unlabelled_weak_top1_acc:88.5968878865242,unlabelled_weak_top5_acc:99.43280893191695  \n","[2022-04-17 09:36:56,940][experiments.experiment][INFO] - [EMA] Epoch 61. [Validation] raw_testing_loss: 0.7001, raw test Top1 acc:84.52, raw test Top5 acc: 99.32, ema_testing_loss: 0.4157, ema test Top1 acc:90.12, ema test Top5 acc: 99.56\n","[2022-04-17 09:36:56,941][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 09:48:03,345][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 62: use 666.5008676052094 seconds\n","--- Optimizer learning rate changed from 2.27e-02 to 2.25e-02 ---\n","[2022-04-17 09:48:03,442][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:48:05,203][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 09:48:05,203][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:48:06,940][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 09:48:06,942][experiments.experiment][INFO] - [EMA] Epoch 62.[Train] time:666.5008676052094 seconds, lr:0.0225, train_loss: 0.3586, unlabeled_losses_real_strong:0.7676,corrrect_unlabeled_num:352668.0,pro_above_threshold_num:365741.0,unlabelled_weak_top1_acc:88.67928528040648,unlabelled_weak_top5_acc:99.47139193117619  \n","[2022-04-17 09:48:06,944][experiments.experiment][INFO] - [EMA] Epoch 62. [Validation] raw_testing_loss: 0.5655, raw test Top1 acc:85.48, raw test Top5 acc: 99.3, ema_testing_loss: 0.4036, ema test Top1 acc:90.44, ema test Top5 acc: 99.68\n","[2022-04-17 09:48:06,945][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 09:59:13,742][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 63: use 666.9042930603027 seconds\n","--- Optimizer learning rate changed from 2.25e-02 to 2.23e-02 ---\n","[2022-04-17 09:59:13,849][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:59:15,645][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 09:59:15,646][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 09:59:17,419][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 09:59:17,421][experiments.experiment][INFO] - [EMA] Epoch 63.[Train] time:666.9042930603027 seconds, lr:0.0223, train_loss: 0.3578, unlabeled_losses_real_strong:0.7637,corrrect_unlabeled_num:352902.0,pro_above_threshold_num:366132.0,unlabelled_weak_top1_acc:88.70849503576756,unlabelled_weak_top5_acc:99.47596960514784  \n","[2022-04-17 09:59:17,422][experiments.experiment][INFO] - [EMA] Epoch 63. [Validation] raw_testing_loss: 0.5389, raw test Top1 acc:86.2, raw test Top5 acc: 99.22, ema_testing_loss: 0.4094, ema test Top1 acc:90.02, ema test Top5 acc: 99.6\n","[2022-04-17 09:59:17,490][experiments.experiment][INFO] - [Checkpoints] Epoch 63, saving to ./checkpoints_celiali-resnext-120epochs-32batch/FMExperiment_epoch_63.pth.tar\n","[2022-04-17 09:59:17,490][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 10:10:24,039][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 64: use 666.64697432518 seconds\n","--- Optimizer learning rate changed from 2.23e-02 to 2.21e-02 ---\n","[2022-04-17 10:10:24,137][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:10:25,903][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 10:10:25,904][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:10:27,703][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 10:10:27,704][experiments.experiment][INFO] - [EMA] Epoch 64.[Train] time:666.64697432518 seconds, lr:0.0221, train_loss: 0.3569, unlabeled_losses_real_strong:0.7574,corrrect_unlabeled_num:353615.0,pro_above_threshold_num:366613.0,unlabelled_weak_top1_acc:88.81334467977285,unlabelled_weak_top5_acc:99.46267259120941  \n","[2022-04-17 10:10:27,706][experiments.experiment][INFO] - [EMA] Epoch 64. [Validation] raw_testing_loss: 0.7504, raw test Top1 acc:81.7, raw test Top5 acc: 98.56, ema_testing_loss: 0.4060, ema test Top1 acc:90.4, ema test Top5 acc: 99.64\n","[2022-04-17 10:10:27,707][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 10:21:35,241][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 65: use 667.6319613456726 seconds\n","--- Optimizer learning rate changed from 2.21e-02 to 2.18e-02 ---\n","[2022-04-17 10:21:35,339][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:21:37,147][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 10:21:37,148][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:21:38,933][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 10:21:38,935][experiments.experiment][INFO] - [EMA] Epoch 65.[Train] time:667.6319613456726 seconds, lr:0.0218, train_loss: 0.3545, unlabeled_losses_real_strong:0.7567,corrrect_unlabeled_num:353598.0,pro_above_threshold_num:366451.0,unlabelled_weak_top1_acc:88.79939375817776,unlabelled_weak_top5_acc:99.47858536243439  \n","[2022-04-17 10:21:38,937][experiments.experiment][INFO] - [EMA] Epoch 65. [Validation] raw_testing_loss: 0.9660, raw test Top1 acc:80.08, raw test Top5 acc: 98.76, ema_testing_loss: 0.3973, ema test Top1 acc:90.58, ema test Top5 acc: 99.68\n","[2022-04-17 10:21:38,939][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 10:32:45,492][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 66: use 666.6643972396851 seconds\n","--- Optimizer learning rate changed from 2.18e-02 to 2.16e-02 ---\n","[2022-04-17 10:32:45,603][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:32:47,372][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 10:32:47,372][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:32:49,212][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 10:32:49,214][experiments.experiment][INFO] - [EMA] Epoch 66.[Train] time:666.6643972396851 seconds, lr:0.0216, train_loss: 0.3540, unlabeled_losses_real_strong:0.7515,corrrect_unlabeled_num:354290.0,pro_above_threshold_num:367167.0,unlabelled_weak_top1_acc:88.84560605883598,unlabelled_weak_top5_acc:99.47204587608576  \n","[2022-04-17 10:32:49,216][experiments.experiment][INFO] - [EMA] Epoch 66. [Validation] raw_testing_loss: 0.6050, raw test Top1 acc:86.32, raw test Top5 acc: 99.12, ema_testing_loss: 0.3993, ema test Top1 acc:90.22, ema test Top5 acc: 99.66\n","[2022-04-17 10:32:49,217][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 10:43:55,812][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 67: use 666.6955285072327 seconds\n","--- Optimizer learning rate changed from 2.16e-02 to 2.14e-02 ---\n","[2022-04-17 10:43:55,913][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:43:57,680][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 10:43:57,681][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:43:59,491][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 10:43:59,493][experiments.experiment][INFO] - [EMA] Epoch 67.[Train] time:666.6955285072327 seconds, lr:0.0214, train_loss: 0.3519, unlabeled_losses_real_strong:0.7452,corrrect_unlabeled_num:355250.0,pro_above_threshold_num:368026.0,unlabelled_weak_top1_acc:88.98206340149045,unlabelled_weak_top5_acc:99.49602398276329  \n","[2022-04-17 10:43:59,495][experiments.experiment][INFO] - [EMA] Epoch 67. [Validation] raw_testing_loss: 0.5946, raw test Top1 acc:84.9, raw test Top5 acc: 99.24, ema_testing_loss: 0.3907, ema test Top1 acc:90.38, ema test Top5 acc: 99.74\n","[2022-04-17 10:43:59,497][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 10:55:05,481][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 68: use 666.0925214290619 seconds\n","--- Optimizer learning rate changed from 2.14e-02 to 2.11e-02 ---\n","[2022-04-17 10:55:05,589][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:55:07,318][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 10:55:07,318][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 10:55:09,103][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 10:55:09,105][experiments.experiment][INFO] - [EMA] Epoch 68.[Train] time:666.0925214290619 seconds, lr:0.0211, train_loss: 0.3491, unlabeled_losses_real_strong:0.7401,corrrect_unlabeled_num:357099.0,pro_above_threshold_num:369906.0,unlabelled_weak_top1_acc:89.130509596318,unlabelled_weak_top5_acc:99.48120118677616  \n","[2022-04-17 10:55:09,106][experiments.experiment][INFO] - [EMA] Epoch 68. [Validation] raw_testing_loss: 0.5959, raw test Top1 acc:85.22, raw test Top5 acc: 99.38, ema_testing_loss: 0.3961, ema test Top1 acc:90.4, ema test Top5 acc: 99.62\n","[2022-04-17 10:55:09,108][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 11:06:15,123][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 69: use 666.111659526825 seconds\n","--- Optimizer learning rate changed from 2.11e-02 to 2.09e-02 ---\n","[2022-04-17 11:06:15,220][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:06:16,988][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 11:06:16,989][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:06:18,717][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 11:06:18,719][experiments.experiment][INFO] - [EMA] Epoch 69.[Train] time:666.111659526825 seconds, lr:0.0209, train_loss: 0.3485, unlabeled_losses_real_strong:0.7395,corrrect_unlabeled_num:356994.0,pro_above_threshold_num:369682.0,unlabelled_weak_top1_acc:89.12745779752731,unlabelled_weak_top5_acc:99.49624195694923  \n","[2022-04-17 11:06:18,720][experiments.experiment][INFO] - [EMA] Epoch 69. [Validation] raw_testing_loss: 0.6738, raw test Top1 acc:84.14, raw test Top5 acc: 99.24, ema_testing_loss: 0.3943, ema test Top1 acc:90.72, ema test Top5 acc: 99.66\n","[2022-04-17 11:06:18,721][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 11:17:24,783][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 70: use 666.1677103042603 seconds\n","--- Optimizer learning rate changed from 2.09e-02 to 2.06e-02 ---\n","[2022-04-17 11:17:24,889][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:17:26,705][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 11:17:26,705][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:17:28,458][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 11:17:28,459][experiments.experiment][INFO] - [EMA] Epoch 70.[Train] time:666.1677103042603 seconds, lr:0.0206, train_loss: 0.3453, unlabeled_losses_real_strong:0.7352,corrrect_unlabeled_num:357596.0,pro_above_threshold_num:370386.0,unlabelled_weak_top1_acc:89.18892890959978,unlabelled_weak_top5_acc:99.49754989892244  \n","[2022-04-17 11:17:28,462][experiments.experiment][INFO] - [EMA] Epoch 70. [Validation] raw_testing_loss: 0.6217, raw test Top1 acc:84.52, raw test Top5 acc: 98.8, ema_testing_loss: 0.3997, ema test Top1 acc:90.44, ema test Top5 acc: 99.66\n","[2022-04-17 11:17:28,463][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 11:28:35,564][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 71: use 667.201176404953 seconds\n","--- Optimizer learning rate changed from 2.06e-02 to 2.04e-02 ---\n","[2022-04-17 11:28:35,664][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:28:37,484][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 11:28:37,484][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:28:39,334][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 11:28:39,336][experiments.experiment][INFO] - [EMA] Epoch 71.[Train] time:667.201176404953 seconds, lr:0.0204, train_loss: 0.3452, unlabeled_losses_real_strong:0.7303,corrrect_unlabeled_num:358339.0,pro_above_threshold_num:370827.0,unlabelled_weak_top1_acc:89.34042682498693,unlabelled_weak_top5_acc:99.50648722425103  \n","[2022-04-17 11:28:39,338][experiments.experiment][INFO] - [EMA] Epoch 71. [Validation] raw_testing_loss: 0.5565, raw test Top1 acc:85.74, raw test Top5 acc: 99.38, ema_testing_loss: 0.3962, ema test Top1 acc:90.44, ema test Top5 acc: 99.64\n","[2022-04-17 11:28:39,339][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 11:39:45,235][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 72: use 665.9937081336975 seconds\n","--- Optimizer learning rate changed from 2.04e-02 to 2.01e-02 ---\n","[2022-04-17 11:39:45,333][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:39:47,093][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 11:39:47,093][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:39:48,833][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 11:39:48,835][experiments.experiment][INFO] - [EMA] Epoch 72.[Train] time:665.9937081336975 seconds, lr:0.0201, train_loss: 0.3438, unlabeled_losses_real_strong:0.7291,corrrect_unlabeled_num:358805.0,pro_above_threshold_num:371231.0,unlabelled_weak_top1_acc:89.38903698325157,unlabelled_weak_top5_acc:99.51215472817421  \n","[2022-04-17 11:39:48,837][experiments.experiment][INFO] - [EMA] Epoch 72. [Validation] raw_testing_loss: 0.7006, raw test Top1 acc:83.14, raw test Top5 acc: 99.14, ema_testing_loss: 0.3906, ema test Top1 acc:90.46, ema test Top5 acc: 99.7\n","[2022-04-17 11:39:48,838][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 11:50:55,752][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 73: use 667.0146751403809 seconds\n","--- Optimizer learning rate changed from 2.01e-02 to 1.99e-02 ---\n","[2022-04-17 11:50:55,853][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:50:57,586][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 11:50:57,586][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 11:50:59,323][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 11:50:59,324][experiments.experiment][INFO] - [EMA] Epoch 73.[Train] time:667.0146751403809 seconds, lr:0.0199, train_loss: 0.3418, unlabeled_losses_real_strong:0.7262,corrrect_unlabeled_num:358972.0,pro_above_threshold_num:371438.0,unlabelled_weak_top1_acc:89.34783827513456,unlabelled_weak_top5_acc:99.52719552069902  \n","[2022-04-17 11:50:59,327][experiments.experiment][INFO] - [EMA] Epoch 73. [Validation] raw_testing_loss: 0.4847, raw test Top1 acc:87.3, raw test Top5 acc: 99.44, ema_testing_loss: 0.3889, ema test Top1 acc:90.68, ema test Top5 acc: 99.66\n","[2022-04-17 11:50:59,328][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 12:02:05,851][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 74: use 666.6213083267212 seconds\n","--- Optimizer learning rate changed from 1.99e-02 to 1.96e-02 ---\n","[2022-04-17 12:02:05,950][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:02:07,790][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 12:02:07,790][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:02:09,585][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 12:02:09,586][experiments.experiment][INFO] - [EMA] Epoch 74.[Train] time:666.6213083267212 seconds, lr:0.0196, train_loss: 0.3399, unlabeled_losses_real_strong:0.7246,corrrect_unlabeled_num:359623.0,pro_above_threshold_num:372083.0,unlabelled_weak_top1_acc:89.41911861300468,unlabelled_weak_top5_acc:99.49689592421055  \n","[2022-04-17 12:02:09,587][experiments.experiment][INFO] - [EMA] Epoch 74. [Validation] raw_testing_loss: 0.6658, raw test Top1 acc:85.04, raw test Top5 acc: 98.96, ema_testing_loss: 0.3900, ema test Top1 acc:90.6, ema test Top5 acc: 99.62\n","[2022-04-17 12:02:09,589][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 12:13:16,406][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 75: use 666.9211130142212 seconds\n","--- Optimizer learning rate changed from 1.96e-02 to 1.93e-02 ---\n","[2022-04-17 12:13:16,510][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:13:18,247][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 12:13:18,248][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:13:20,058][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 12:13:20,059][experiments.experiment][INFO] - [EMA] Epoch 75.[Train] time:666.9211130142212 seconds, lr:0.0193, train_loss: 0.3385, unlabeled_losses_real_strong:0.7182,corrrect_unlabeled_num:360745.0,pro_above_threshold_num:373173.0,unlabelled_weak_top1_acc:89.57432233542204,unlabelled_weak_top5_acc:99.52501571550965  \n","[2022-04-17 12:13:20,062][experiments.experiment][INFO] - [EMA] Epoch 75. [Validation] raw_testing_loss: 0.5962, raw test Top1 acc:85.68, raw test Top5 acc: 99.24, ema_testing_loss: 0.3850, ema test Top1 acc:90.56, ema test Top5 acc: 99.72\n","[2022-04-17 12:13:20,062][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 12:24:27,000][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 76: use 667.0487906932831 seconds\n","--- Optimizer learning rate changed from 1.93e-02 to 1.91e-02 ---\n","[2022-04-17 12:24:27,111][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:24:28,906][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 12:24:28,906][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:24:30,725][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 12:24:30,727][experiments.experiment][INFO] - [EMA] Epoch 76.[Train] time:667.0487906932831 seconds, lr:0.0191, train_loss: 0.3393, unlabeled_losses_real_strong:0.7140,corrrect_unlabeled_num:360967.0,pro_above_threshold_num:373388.0,unlabelled_weak_top1_acc:89.60919948667288,unlabelled_weak_top5_acc:99.53591493144631  \n","[2022-04-17 12:24:30,728][experiments.experiment][INFO] - [EMA] Epoch 76. [Validation] raw_testing_loss: 0.5441, raw test Top1 acc:85.8, raw test Top5 acc: 98.98, ema_testing_loss: 0.3808, ema test Top1 acc:90.68, ema test Top5 acc: 99.66\n","[2022-04-17 12:24:30,729][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 12:35:37,770][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 77: use 667.1393513679504 seconds\n","--- Optimizer learning rate changed from 1.91e-02 to 1.88e-02 ---\n","[2022-04-17 12:35:37,868][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:35:39,728][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 12:35:39,729][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:35:41,526][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 12:35:41,528][experiments.experiment][INFO] - [EMA] Epoch 77.[Train] time:667.1393513679504 seconds, lr:0.0188, train_loss: 0.3355, unlabeled_losses_real_strong:0.7103,corrrect_unlabeled_num:362121.0,pro_above_threshold_num:374588.0,unlabelled_weak_top1_acc:89.70968956872821,unlabelled_weak_top5_acc:99.5476860255003  \n","[2022-04-17 12:35:41,530][experiments.experiment][INFO] - [EMA] Epoch 77. [Validation] raw_testing_loss: 0.5426, raw test Top1 acc:86.46, raw test Top5 acc: 99.5, ema_testing_loss: 0.3889, ema test Top1 acc:90.94, ema test Top5 acc: 99.64\n","[2022-04-17 12:35:41,532][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 12:46:48,321][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 78: use 666.8863089084625 seconds\n","--- Optimizer learning rate changed from 1.88e-02 to 1.85e-02 ---\n","[2022-04-17 12:46:48,418][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:46:50,190][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 12:46:50,190][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:46:52,000][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 12:46:52,002][experiments.experiment][INFO] - [EMA] Epoch 78.[Train] time:666.8863089084625 seconds, lr:0.0185, train_loss: 0.3352, unlabeled_losses_real_strong:0.7106,corrrect_unlabeled_num:362860.0,pro_above_threshold_num:375140.0,unlabelled_weak_top1_acc:89.76592912524939,unlabelled_weak_top5_acc:99.54332636296749  \n","[2022-04-17 12:46:52,005][experiments.experiment][INFO] - [EMA] Epoch 78. [Validation] raw_testing_loss: 0.5771, raw test Top1 acc:85.38, raw test Top5 acc: 99.2, ema_testing_loss: 0.3823, ema test Top1 acc:91.14, ema test Top5 acc: 99.66\n","[2022-04-17 12:46:52,006][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 12:57:58,764][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 79: use 666.8580901622772 seconds\n","--- Optimizer learning rate changed from 1.85e-02 to 1.83e-02 ---\n","[2022-04-17 12:57:58,864][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:58:00,612][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 12:58:00,612][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 12:58:02,409][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 12:58:02,411][experiments.experiment][INFO] - [EMA] Epoch 79.[Train] time:666.8580901622772 seconds, lr:0.0183, train_loss: 0.3337, unlabeled_losses_real_strong:0.7036,corrrect_unlabeled_num:363201.0,pro_above_threshold_num:375181.0,unlabelled_weak_top1_acc:89.88516563177109,unlabelled_weak_top5_acc:99.54899398237467  \n","[2022-04-17 12:58:02,414][experiments.experiment][INFO] - [EMA] Epoch 79. [Validation] raw_testing_loss: 0.5546, raw test Top1 acc:85.74, raw test Top5 acc: 99.36, ema_testing_loss: 0.3797, ema test Top1 acc:91.1, ema test Top5 acc: 99.66\n","[2022-04-17 12:58:02,415][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 13:09:08,728][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 80: use 666.4076225757599 seconds\n","--- Optimizer learning rate changed from 1.83e-02 to 1.80e-02 ---\n","[2022-04-17 13:09:08,823][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 13:09:10,613][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 13:09:10,613][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 13:09:12,344][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 13:09:12,345][experiments.experiment][INFO] - [EMA] Epoch 80.[Train] time:666.4076225757599 seconds, lr:0.0180, train_loss: 0.3321, unlabeled_losses_real_strong:0.6971,corrrect_unlabeled_num:364473.0,pro_above_threshold_num:376814.0,unlabelled_weak_top1_acc:89.89410288259387,unlabelled_weak_top5_acc:99.54572420939803  \n","[2022-04-17 13:09:12,347][experiments.experiment][INFO] - [EMA] Epoch 80. [Validation] raw_testing_loss: 0.4965, raw test Top1 acc:87.58, raw test Top5 acc: 99.18, ema_testing_loss: 0.3723, ema test Top1 acc:90.94, ema test Top5 acc: 99.7\n","[2022-04-17 13:09:12,348][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 13:20:18,934][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 81: use 666.6849889755249 seconds\n","--- Optimizer learning rate changed from 1.80e-02 to 1.77e-02 ---\n","[2022-04-17 13:20:19,033][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 13:20:20,774][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 13:20:20,774][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 13:20:22,627][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 13:20:22,629][experiments.experiment][INFO] - [EMA] Epoch 81.[Train] time:666.6849889755249 seconds, lr:0.0177, train_loss: 0.3301, unlabeled_losses_real_strong:0.6950,corrrect_unlabeled_num:364977.0,pro_above_threshold_num:376965.0,unlabelled_weak_top1_acc:89.97388454899192,unlabelled_weak_top5_acc:99.55248161405325  \n","[2022-04-17 13:20:22,630][experiments.experiment][INFO] - [EMA] Epoch 81. [Validation] raw_testing_loss: 0.5056, raw test Top1 acc:87.24, raw test Top5 acc: 99.46, ema_testing_loss: 0.3778, ema test Top1 acc:90.8, ema test Top5 acc: 99.68\n","[2022-04-17 13:20:22,632][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 13:31:29,199][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 82: use 666.6785476207733 seconds\n","--- Optimizer learning rate changed from 1.77e-02 to 1.74e-02 ---\n","[2022-04-17 13:31:29,311][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 13:31:31,051][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 13:31:31,052][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 13:31:32,811][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 13:31:32,813][experiments.experiment][INFO] - [EMA] Epoch 82.[Train] time:666.6785476207733 seconds, lr:0.0174, train_loss: 0.3274, unlabeled_losses_real_strong:0.6908,corrrect_unlabeled_num:365654.0,pro_above_threshold_num:377715.0,unlabelled_weak_top1_acc:90.07066896185279,unlabelled_weak_top5_acc:99.53504291176796  \n","[2022-04-17 13:31:32,816][experiments.experiment][INFO] - [EMA] Epoch 82. [Validation] raw_testing_loss: 0.6348, raw test Top1 acc:85.2, raw test Top5 acc: 98.96, ema_testing_loss: 0.3661, ema test Top1 acc:91.02, ema test Top5 acc: 99.74\n","[2022-04-17 13:31:32,816][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 13:42:39,725][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 83: use 667.0082948207855 seconds\n","--- Optimizer learning rate changed from 1.74e-02 to 1.72e-02 ---\n","[2022-04-17 13:42:39,825][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 13:42:41,611][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 13:42:41,612][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 13:42:43,403][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 13:42:43,405][experiments.experiment][INFO] - [EMA] Epoch 83.[Train] time:667.0082948207855 seconds, lr:0.0172, train_loss: 0.3274, unlabeled_losses_real_strong:0.6901,corrrect_unlabeled_num:365697.0,pro_above_threshold_num:377739.0,unlabelled_weak_top1_acc:90.06827119365335,unlabelled_weak_top5_acc:99.55684123560786  \n","[2022-04-17 13:42:43,406][experiments.experiment][INFO] - [EMA] Epoch 83. [Validation] raw_testing_loss: 0.6487, raw test Top1 acc:84.76, raw test Top5 acc: 98.86, ema_testing_loss: 0.3600, ema test Top1 acc:90.96, ema test Top5 acc: 99.68\n","[2022-04-17 13:42:43,408][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 13:53:49,076][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 84: use 665.7664408683777 seconds\n","--- Optimizer learning rate changed from 1.72e-02 to 1.69e-02 ---\n","[2022-04-17 13:53:49,174][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 13:53:50,943][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 13:53:50,943][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 13:53:52,704][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 13:53:52,706][experiments.experiment][INFO] - [EMA] Epoch 84.[Train] time:665.7664408683777 seconds, lr:0.0169, train_loss: 0.3258, unlabeled_losses_real_strong:0.6859,corrrect_unlabeled_num:366299.0,pro_above_threshold_num:378472.0,unlabelled_weak_top1_acc:90.08745359256864,unlabelled_weak_top5_acc:99.5585852228105  \n","[2022-04-17 13:53:52,708][experiments.experiment][INFO] - [EMA] Epoch 84. [Validation] raw_testing_loss: 0.5345, raw test Top1 acc:86.1, raw test Top5 acc: 99.38, ema_testing_loss: 0.3681, ema test Top1 acc:90.98, ema test Top5 acc: 99.76\n","[2022-04-17 13:53:52,709][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 14:04:58,948][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 85: use 666.3451888561249 seconds\n","--- Optimizer learning rate changed from 1.69e-02 to 1.66e-02 ---\n","[2022-04-17 14:04:59,054][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 14:05:00,808][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 14:05:00,809][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 14:05:02,617][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 14:05:02,619][experiments.experiment][INFO] - [EMA] Epoch 85.[Train] time:666.3451888561249 seconds, lr:0.0166, train_loss: 0.3253, unlabeled_losses_real_strong:0.6816,corrrect_unlabeled_num:367483.0,pro_above_threshold_num:379576.0,unlabelled_weak_top1_acc:90.21366560459137,unlabelled_weak_top5_acc:99.55880320444703  \n","[2022-04-17 14:05:02,621][experiments.experiment][INFO] - [EMA] Epoch 85. [Validation] raw_testing_loss: 0.6042, raw test Top1 acc:85.42, raw test Top5 acc: 99.28, ema_testing_loss: 0.3579, ema test Top1 acc:91.2, ema test Top5 acc: 99.68\n","[2022-04-17 14:05:02,622][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 14:16:08,630][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 86: use 666.1040186882019 seconds\n","--- Optimizer learning rate changed from 1.66e-02 to 1.63e-02 ---\n","[2022-04-17 14:16:08,726][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 14:16:10,475][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 14:16:10,475][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 14:16:12,286][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 14:16:12,288][experiments.experiment][INFO] - [EMA] Epoch 86.[Train] time:666.1040186882019 seconds, lr:0.0163, train_loss: 0.3238, unlabeled_losses_real_strong:0.6792,corrrect_unlabeled_num:368006.0,pro_above_threshold_num:379763.0,unlabelled_weak_top1_acc:90.3429292961955,unlabelled_weak_top5_acc:99.57253615185618  \n","[2022-04-17 14:16:12,290][experiments.experiment][INFO] - [EMA] Epoch 86. [Validation] raw_testing_loss: 0.6866, raw test Top1 acc:83.58, raw test Top5 acc: 98.66, ema_testing_loss: 0.3537, ema test Top1 acc:90.96, ema test Top5 acc: 99.7\n","[2022-04-17 14:16:12,290][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 14:27:18,946][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 87: use 666.7623369693756 seconds\n","--- Optimizer learning rate changed from 1.63e-02 to 1.60e-02 ---\n","[2022-04-17 14:27:19,053][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 14:27:20,789][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 14:27:20,790][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 14:27:22,611][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 14:27:22,612][experiments.experiment][INFO] - [EMA] Epoch 87.[Train] time:666.7623369693756 seconds, lr:0.0160, train_loss: 0.3189, unlabeled_losses_real_strong:0.6707,corrrect_unlabeled_num:368786.0,pro_above_threshold_num:380451.0,unlabelled_weak_top1_acc:90.43796974793077,unlabelled_weak_top5_acc:99.59433444961905  \n","[2022-04-17 14:27:22,614][experiments.experiment][INFO] - [EMA] Epoch 87. [Validation] raw_testing_loss: 0.5816, raw test Top1 acc:85.88, raw test Top5 acc: 99.2, ema_testing_loss: 0.3558, ema test Top1 acc:91.32, ema test Top5 acc: 99.68\n","[2022-04-17 14:27:22,616][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 14:38:28,962][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 88: use 666.4553191661835 seconds\n","--- Optimizer learning rate changed from 1.60e-02 to 1.57e-02 ---\n","[2022-04-17 14:38:29,071][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 14:38:30,891][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 14:38:30,891][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 14:38:32,719][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 14:38:32,720][experiments.experiment][INFO] - [EMA] Epoch 88.[Train] time:666.4553191661835 seconds, lr:0.0157, train_loss: 0.3177, unlabeled_losses_real_strong:0.6701,corrrect_unlabeled_num:369488.0,pro_above_threshold_num:381152.0,unlabelled_weak_top1_acc:90.44320126622915,unlabelled_weak_top5_acc:99.58408918976784  \n","[2022-04-17 14:38:32,722][experiments.experiment][INFO] - [EMA] Epoch 88. [Validation] raw_testing_loss: 0.5671, raw test Top1 acc:85.74, raw test Top5 acc: 99.28, ema_testing_loss: 0.3505, ema test Top1 acc:91.28, ema test Top5 acc: 99.72\n","[2022-04-17 14:38:32,723][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 14:49:38,807][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 89: use 666.1849191188812 seconds\n","--- Optimizer learning rate changed from 1.57e-02 to 1.54e-02 ---\n","[2022-04-17 14:49:38,908][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 14:49:40,643][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 14:49:40,643][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 14:49:42,371][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 14:49:42,373][experiments.experiment][INFO] - [EMA] Epoch 89.[Train] time:666.1849191188812 seconds, lr:0.0154, train_loss: 0.3180, unlabeled_losses_real_strong:0.6674,corrrect_unlabeled_num:369691.0,pro_above_threshold_num:381379.0,unlabelled_weak_top1_acc:90.53322824835777,unlabelled_weak_top5_acc:99.58517906814814  \n","[2022-04-17 14:49:42,374][experiments.experiment][INFO] - [EMA] Epoch 89. [Validation] raw_testing_loss: 0.6731, raw test Top1 acc:84.5, raw test Top5 acc: 99.2, ema_testing_loss: 0.3454, ema test Top1 acc:91.54, ema test Top5 acc: 99.62\n","[2022-04-17 14:49:42,376][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 15:00:47,800][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 90: use 665.5248708724976 seconds\n","--- Optimizer learning rate changed from 1.54e-02 to 1.51e-02 ---\n","[2022-04-17 15:00:47,901][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 15:00:49,681][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 15:00:49,681][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 15:00:51,440][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 15:00:51,442][experiments.experiment][INFO] - [EMA] Epoch 90.[Train] time:665.5248708724976 seconds, lr:0.0151, train_loss: 0.3177, unlabeled_losses_real_strong:0.6634,corrrect_unlabeled_num:370243.0,pro_above_threshold_num:381902.0,unlabelled_weak_top1_acc:90.57137512415648,unlabelled_weak_top5_acc:99.58430717512965  \n","[2022-04-17 15:00:51,443][experiments.experiment][INFO] - [EMA] Epoch 90. [Validation] raw_testing_loss: 0.5410, raw test Top1 acc:86.04, raw test Top5 acc: 99.2, ema_testing_loss: 0.3482, ema test Top1 acc:91.48, ema test Top5 acc: 99.74\n","[2022-04-17 15:00:51,445][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 15:11:57,795][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 91: use 666.4576358795166 seconds\n","--- Optimizer learning rate changed from 1.51e-02 to 1.48e-02 ---\n","[2022-04-17 15:11:57,903][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 15:11:59,771][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 15:11:59,771][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 15:12:01,546][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 15:12:01,548][experiments.experiment][INFO] - [EMA] Epoch 91.[Train] time:666.4576358795166 seconds, lr:0.0148, train_loss: 0.3140, unlabeled_losses_real_strong:0.6607,corrrect_unlabeled_num:370815.0,pro_above_threshold_num:382708.0,unlabelled_weak_top1_acc:90.56243786588311,unlabelled_weak_top5_acc:99.59324449300766  \n","[2022-04-17 15:12:01,549][experiments.experiment][INFO] - [EMA] Epoch 91. [Validation] raw_testing_loss: 0.4606, raw test Top1 acc:87.5, raw test Top5 acc: 99.44, ema_testing_loss: 0.3443, ema test Top1 acc:91.26, ema test Top5 acc: 99.7\n","[2022-04-17 15:12:01,551][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 15:23:07,288][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 92: use 665.835601568222 seconds\n","--- Optimizer learning rate changed from 1.48e-02 to 1.45e-02 ---\n","[2022-04-17 15:23:07,387][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 15:23:09,172][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 15:23:09,173][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 15:23:10,919][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 15:23:10,921][experiments.experiment][INFO] - [EMA] Epoch 92.[Train] time:665.835601568222 seconds, lr:0.0145, train_loss: 0.3140, unlabeled_losses_real_strong:0.6557,corrrect_unlabeled_num:372053.0,pro_above_threshold_num:383651.0,unlabelled_weak_top1_acc:90.73420833051205,unlabelled_weak_top5_acc:99.58169132098556  \n","[2022-04-17 15:23:10,923][experiments.experiment][INFO] - [EMA] Epoch 92. [Validation] raw_testing_loss: 0.6231, raw test Top1 acc:86.04, raw test Top5 acc: 99.44, ema_testing_loss: 0.3445, ema test Top1 acc:91.38, ema test Top5 acc: 99.76\n","[2022-04-17 15:23:10,924][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 15:34:17,528][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 93: use 666.701244354248 seconds\n","--- Optimizer learning rate changed from 1.45e-02 to 1.42e-02 ---\n","[2022-04-17 15:34:17,626][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 15:34:19,485][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 15:34:19,485][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 15:34:21,304][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 15:34:21,306][experiments.experiment][INFO] - [EMA] Epoch 93.[Train] time:666.701244354248 seconds, lr:0.0142, train_loss: 0.3133, unlabeled_losses_real_strong:0.6525,corrrect_unlabeled_num:372524.0,pro_above_threshold_num:384114.0,unlabelled_weak_top1_acc:90.76755962148309,unlabelled_weak_top5_acc:99.61220901831985  \n","[2022-04-17 15:34:21,307][experiments.experiment][INFO] - [EMA] Epoch 93. [Validation] raw_testing_loss: 0.4569, raw test Top1 acc:87.52, raw test Top5 acc: 99.54, ema_testing_loss: 0.3463, ema test Top1 acc:91.4, ema test Top5 acc: 99.72\n","[2022-04-17 15:34:21,309][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 15:45:27,682][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 94: use 666.4723036289215 seconds\n","--- Optimizer learning rate changed from 1.42e-02 to 1.39e-02 ---\n","[2022-04-17 15:45:27,782][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 15:45:29,523][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 15:45:29,524][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 15:45:31,289][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 15:45:31,290][experiments.experiment][INFO] - [EMA] Epoch 94.[Train] time:666.4723036289215 seconds, lr:0.0139, train_loss: 0.3119, unlabeled_losses_real_strong:0.6497,corrrect_unlabeled_num:373585.0,pro_above_threshold_num:385316.0,unlabelled_weak_top1_acc:90.84058373048902,unlabelled_weak_top5_acc:99.60981119796634  \n","[2022-04-17 15:45:31,292][experiments.experiment][INFO] - [EMA] Epoch 94. [Validation] raw_testing_loss: 0.5901, raw test Top1 acc:85.66, raw test Top5 acc: 99.12, ema_testing_loss: 0.3456, ema test Top1 acc:91.42, ema test Top5 acc: 99.74\n","[2022-04-17 15:45:31,293][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 15:56:39,234][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 95: use 668.0443780422211 seconds\n","--- Optimizer learning rate changed from 1.39e-02 to 1.36e-02 ---\n","[2022-04-17 15:56:39,337][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 15:56:41,149][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 15:56:41,149][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 15:56:43,032][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 15:56:43,033][experiments.experiment][INFO] - [EMA] Epoch 95.[Train] time:668.0443780422211 seconds, lr:0.0136, train_loss: 0.3097, unlabeled_losses_real_strong:0.6466,corrrect_unlabeled_num:373830.0,pro_above_threshold_num:385383.0,unlabelled_weak_top1_acc:90.93845796957612,unlabelled_weak_top5_acc:99.60915723070502  \n","[2022-04-17 15:56:43,035][experiments.experiment][INFO] - [EMA] Epoch 95. [Validation] raw_testing_loss: 0.4838, raw test Top1 acc:87.72, raw test Top5 acc: 99.58, ema_testing_loss: 0.3446, ema test Top1 acc:91.52, ema test Top5 acc: 99.66\n","[2022-04-17 15:56:43,036][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 16:07:49,984][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 96: use 667.0459394454956 seconds\n","--- Optimizer learning rate changed from 1.36e-02 to 1.33e-02 ---\n","[2022-04-17 16:07:50,082][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 16:07:51,880][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 16:07:51,881][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 16:07:53,676][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 16:07:53,678][experiments.experiment][INFO] - [EMA] Epoch 96.[Train] time:667.0459394454956 seconds, lr:0.0133, train_loss: 0.3067, unlabeled_losses_real_strong:0.6378,corrrect_unlabeled_num:374633.0,pro_above_threshold_num:386042.0,unlabelled_weak_top1_acc:90.98902998864651,unlabelled_weak_top5_acc:99.60174579918385  \n","[2022-04-17 16:07:53,680][experiments.experiment][INFO] - [EMA] Epoch 96. [Validation] raw_testing_loss: 0.4815, raw test Top1 acc:87.04, raw test Top5 acc: 99.16, ema_testing_loss: 0.3399, ema test Top1 acc:91.92, ema test Top5 acc: 99.72\n","[2022-04-17 16:07:53,681][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 16:19:00,226][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 97: use 666.644180059433 seconds\n","--- Optimizer learning rate changed from 1.33e-02 to 1.30e-02 ---\n","[2022-04-17 16:19:00,325][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 16:19:02,161][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 16:19:02,161][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 16:19:03,881][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 16:19:03,882][experiments.experiment][INFO] - [EMA] Epoch 97.[Train] time:666.644180059433 seconds, lr:0.0130, train_loss: 0.3040, unlabeled_losses_real_strong:0.6354,corrrect_unlabeled_num:375320.0,pro_above_threshold_num:386494.0,unlabelled_weak_top1_acc:91.07404318451881,unlabelled_weak_top5_acc:99.61482479050756  \n","[2022-04-17 16:19:03,883][experiments.experiment][INFO] - [EMA] Epoch 97. [Validation] raw_testing_loss: 0.4538, raw test Top1 acc:87.92, raw test Top5 acc: 99.52, ema_testing_loss: 0.3419, ema test Top1 acc:91.76, ema test Top5 acc: 99.7\n","[2022-04-17 16:19:03,885][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 16:30:10,129][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 98: use 666.3409359455109 seconds\n","--- Optimizer learning rate changed from 1.30e-02 to 1.27e-02 ---\n","[2022-04-17 16:30:10,226][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 16:30:12,027][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 16:30:12,028][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 16:30:13,757][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 16:30:13,758][experiments.experiment][INFO] - [EMA] Epoch 98.[Train] time:666.3409359455109 seconds, lr:0.0127, train_loss: 0.3022, unlabeled_losses_real_strong:0.6318,corrrect_unlabeled_num:375668.0,pro_above_threshold_num:387043.0,unlabelled_weak_top1_acc:91.09213585034013,unlabelled_weak_top5_acc:99.6047975756228  \n","[2022-04-17 16:30:13,760][experiments.experiment][INFO] - [EMA] Epoch 98. [Validation] raw_testing_loss: 0.5263, raw test Top1 acc:86.7, raw test Top5 acc: 99.24, ema_testing_loss: 0.3452, ema test Top1 acc:91.64, ema test Top5 acc: 99.7\n","[2022-04-17 16:30:13,761][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 16:41:19,021][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 99: use 665.3587310314178 seconds\n","--- Optimizer learning rate changed from 1.27e-02 to 1.24e-02 ---\n","[2022-04-17 16:41:19,120][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 16:41:20,871][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 16:41:20,871][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 16:41:22,594][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 16:41:22,595][experiments.experiment][INFO] - [EMA] Epoch 99.[Train] time:665.3587310314178 seconds, lr:0.0124, train_loss: 0.3016, unlabeled_losses_real_strong:0.6299,corrrect_unlabeled_num:376768.0,pro_above_threshold_num:388164.0,unlabelled_weak_top1_acc:91.19371579959989,unlabelled_weak_top5_acc:99.6047975756228  \n","[2022-04-17 16:41:22,597][experiments.experiment][INFO] - [EMA] Epoch 99. [Validation] raw_testing_loss: 0.4867, raw test Top1 acc:87.72, raw test Top5 acc: 99.54, ema_testing_loss: 0.3401, ema test Top1 acc:91.42, ema test Top5 acc: 99.72\n","[2022-04-17 16:41:22,598][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 16:52:29,203][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 100: use 666.7119657993317 seconds\n","--- Optimizer learning rate changed from 1.24e-02 to 1.21e-02 ---\n","[2022-04-17 16:52:29,310][experiments.experiment][INFO] - ***** Running validation *****\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-17 16:52:31,152][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 16:52:31,152][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 16:52:32,922][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 16:52:32,924][experiments.experiment][INFO] - [EMA] Epoch 100.[Train] time:666.7119657993317 seconds, lr:0.0121, train_loss: 0.2992, unlabeled_losses_real_strong:0.6236,corrrect_unlabeled_num:377368.0,pro_above_threshold_num:388673.0,unlabelled_weak_top1_acc:91.27240756899118,unlabelled_weak_top5_acc:99.62877567484975  \n","[2022-04-17 16:52:32,926][experiments.experiment][INFO] - [EMA] Epoch 100. [Validation] raw_testing_loss: 0.4185, raw test Top1 acc:88.32, raw test Top5 acc: 99.32, ema_testing_loss: 0.3392, ema test Top1 acc:91.56, ema test Top5 acc: 99.7\n","[2022-04-17 16:52:32,928][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 17:03:41,901][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 101: use 669.0786209106445 seconds\n","--- Optimizer learning rate changed from 1.21e-02 to 1.18e-02 ---\n","[2022-04-17 17:03:42,006][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 17:03:43,806][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 17:03:43,807][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 17:03:45,653][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 17:03:45,654][experiments.experiment][INFO] - [EMA] Epoch 101.[Train] time:669.0786209106445 seconds, lr:0.0118, train_loss: 0.2994, unlabeled_losses_real_strong:0.6195,corrrect_unlabeled_num:378344.0,pro_above_threshold_num:389620.0,unlabelled_weak_top1_acc:91.35916463658214,unlabelled_weak_top5_acc:99.62332610785961  \n","[2022-04-17 17:03:45,655][experiments.experiment][INFO] - [EMA] Epoch 101. [Validation] raw_testing_loss: 0.4204, raw test Top1 acc:88.84, raw test Top5 acc: 99.64, ema_testing_loss: 0.3278, ema test Top1 acc:91.78, ema test Top5 acc: 99.74\n","[2022-04-17 17:03:45,657][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 17:14:49,465][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 102: use 663.9068024158478 seconds\n","--- Optimizer learning rate changed from 1.18e-02 to 1.14e-02 ---\n","[2022-04-17 17:14:49,564][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 17:14:51,306][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 17:14:51,306][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 17:14:53,057][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 17:14:53,059][experiments.experiment][INFO] - [EMA] Epoch 102.[Train] time:663.9068024158478 seconds, lr:0.0114, train_loss: 0.2987, unlabeled_losses_real_strong:0.6160,corrrect_unlabeled_num:379223.0,pro_above_threshold_num:390467.0,unlabelled_weak_top1_acc:91.47295162081718,unlabelled_weak_top5_acc:99.6289936862886  \n","[2022-04-17 17:14:53,060][experiments.experiment][INFO] - [EMA] Epoch 102. [Validation] raw_testing_loss: 0.5035, raw test Top1 acc:87.58, raw test Top5 acc: 99.58, ema_testing_loss: 0.3261, ema test Top1 acc:91.64, ema test Top5 acc: 99.74\n","[2022-04-17 17:14:53,062][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 17:25:55,178][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 103: use 662.218850851059 seconds\n","--- Optimizer learning rate changed from 1.14e-02 to 1.11e-02 ---\n","[2022-04-17 17:25:55,281][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 17:25:57,107][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 17:25:57,107][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 17:25:58,883][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 17:25:58,884][experiments.experiment][INFO] - [EMA] Epoch 103.[Train] time:662.218850851059 seconds, lr:0.0111, train_loss: 0.2974, unlabeled_losses_real_strong:0.6103,corrrect_unlabeled_num:379890.0,pro_above_threshold_num:390993.0,unlabelled_weak_top1_acc:91.53028106689453,unlabelled_weak_top5_acc:99.63880287483335  \n","[2022-04-17 17:25:58,887][experiments.experiment][INFO] - [EMA] Epoch 103. [Validation] raw_testing_loss: 0.4703, raw test Top1 acc:88.0, raw test Top5 acc: 99.48, ema_testing_loss: 0.3271, ema test Top1 acc:91.76, ema test Top5 acc: 99.68\n","[2022-04-17 17:25:58,888][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 17:37:03,745][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 104: use 664.9568564891815 seconds\n","--- Optimizer learning rate changed from 1.11e-02 to 1.08e-02 ---\n","[2022-04-17 17:37:03,845][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 17:37:05,687][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 17:37:05,687][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 17:37:07,498][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 17:37:07,499][experiments.experiment][INFO] - [EMA] Epoch 104.[Train] time:664.9568564891815 seconds, lr:0.0108, train_loss: 0.2935, unlabeled_losses_real_strong:0.6067,corrrect_unlabeled_num:380685.0,pro_above_threshold_num:391820.0,unlabelled_weak_top1_acc:91.57300560548902,unlabelled_weak_top5_acc:99.65297185629606  \n","[2022-04-17 17:37:07,502][experiments.experiment][INFO] - [EMA] Epoch 104. [Validation] raw_testing_loss: 0.3858, raw test Top1 acc:89.66, raw test Top5 acc: 99.64, ema_testing_loss: 0.3257, ema test Top1 acc:91.88, ema test Top5 acc: 99.74\n","[2022-04-17 17:37:07,503][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 17:48:13,038][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 105: use 665.6394064426422 seconds\n","--- Optimizer learning rate changed from 1.08e-02 to 1.05e-02 ---\n","[2022-04-17 17:48:13,143][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 17:48:14,876][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 17:48:14,876][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 17:48:16,625][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 17:48:16,627][experiments.experiment][INFO] - [EMA] Epoch 105.[Train] time:665.6394064426422 seconds, lr:0.0105, train_loss: 0.2924, unlabeled_losses_real_strong:0.6043,corrrect_unlabeled_num:381230.0,pro_above_threshold_num:392217.0,unlabelled_weak_top1_acc:91.70575711131096,unlabelled_weak_top5_acc:99.64948418736458  \n","[2022-04-17 17:48:16,630][experiments.experiment][INFO] - [EMA] Epoch 105. [Validation] raw_testing_loss: 0.4407, raw test Top1 acc:87.7, raw test Top5 acc: 99.28, ema_testing_loss: 0.3214, ema test Top1 acc:92.1, ema test Top5 acc: 99.72\n","[2022-04-17 17:48:16,630][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 17:59:23,022][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 106: use 666.4950878620148 seconds\n","--- Optimizer learning rate changed from 1.05e-02 to 1.02e-02 ---\n","[2022-04-17 17:59:23,126][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 17:59:24,922][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 17:59:24,922][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 17:59:26,753][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 17:59:26,755][experiments.experiment][INFO] - [EMA] Epoch 106.[Train] time:666.4950878620148 seconds, lr:0.0102, train_loss: 0.2895, unlabeled_losses_real_strong:0.5988,corrrect_unlabeled_num:381832.0,pro_above_threshold_num:392919.0,unlabelled_weak_top1_acc:91.70641111209989,unlabelled_weak_top5_acc:99.64534237608314  \n","[2022-04-17 17:59:26,757][experiments.experiment][INFO] - [EMA] Epoch 106. [Validation] raw_testing_loss: 0.4268, raw test Top1 acc:88.72, raw test Top5 acc: 99.38, ema_testing_loss: 0.3227, ema test Top1 acc:92.24, ema test Top5 acc: 99.7\n","[2022-04-17 17:59:26,758][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 18:10:31,065][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 107: use 664.4084286689758 seconds\n","--- Optimizer learning rate changed from 1.02e-02 to 9.83e-03 ---\n","[2022-04-17 18:10:31,166][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 18:10:32,904][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 18:10:32,904][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 18:10:34,646][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 18:10:34,647][experiments.experiment][INFO] - [EMA] Epoch 107.[Train] time:664.4084286689758 seconds, lr:0.0098, train_loss: 0.2882, unlabeled_losses_real_strong:0.5940,corrrect_unlabeled_num:382813.0,pro_above_threshold_num:394019.0,unlabelled_weak_top1_acc:91.77987122163177,unlabelled_weak_top5_acc:99.64817615970969  \n","[2022-04-17 18:10:34,649][experiments.experiment][INFO] - [EMA] Epoch 107. [Validation] raw_testing_loss: 0.5006, raw test Top1 acc:87.32, raw test Top5 acc: 99.42, ema_testing_loss: 0.3169, ema test Top1 acc:92.18, ema test Top5 acc: 99.7\n","[2022-04-17 18:10:34,650][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 18:21:37,765][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 108: use 663.2125279903412 seconds\n","--- Optimizer learning rate changed from 9.83e-03 to 9.50e-03 ---\n","[2022-04-17 18:21:37,862][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 18:21:39,598][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 18:21:39,598][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 18:21:41,340][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 18:21:41,341][experiments.experiment][INFO] - [EMA] Epoch 108.[Train] time:663.2125279903412 seconds, lr:0.0095, train_loss: 0.2867, unlabeled_losses_real_strong:0.5901,corrrect_unlabeled_num:383982.0,pro_above_threshold_num:394892.0,unlabelled_weak_top1_acc:91.91959822177887,unlabelled_weak_top5_acc:99.65667748823762  \n","[2022-04-17 18:21:41,344][experiments.experiment][INFO] - [EMA] Epoch 108. [Validation] raw_testing_loss: 0.4549, raw test Top1 acc:87.42, raw test Top5 acc: 99.6, ema_testing_loss: 0.3098, ema test Top1 acc:92.1, ema test Top5 acc: 99.72\n","[2022-04-17 18:21:41,345][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 18:32:45,749][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 109: use 664.5062479972839 seconds\n","--- Optimizer learning rate changed from 9.50e-03 to 9.18e-03 ---\n","[2022-04-17 18:32:45,851][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 18:32:47,619][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 18:32:47,620][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 18:32:49,397][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 18:32:49,399][experiments.experiment][INFO] - [EMA] Epoch 109.[Train] time:664.5062479972839 seconds, lr:0.0092, train_loss: 0.2857, unlabeled_losses_real_strong:0.5866,corrrect_unlabeled_num:384455.0,pro_above_threshold_num:395461.0,unlabelled_weak_top1_acc:91.92853548377752,unlabelled_weak_top5_acc:99.66125515848398  \n","[2022-04-17 18:32:49,400][experiments.experiment][INFO] - [EMA] Epoch 109. [Validation] raw_testing_loss: 0.4719, raw test Top1 acc:88.38, raw test Top5 acc: 99.5, ema_testing_loss: 0.3081, ema test Top1 acc:92.16, ema test Top5 acc: 99.72\n","[2022-04-17 18:32:49,402][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 18:43:54,139][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 110: use 664.8364684581757 seconds\n","--- Optimizer learning rate changed from 9.18e-03 to 8.85e-03 ---\n","[2022-04-17 18:43:54,238][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 18:43:56,060][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 18:43:56,060][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 18:43:57,861][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 18:43:57,862][experiments.experiment][INFO] - [EMA] Epoch 110.[Train] time:664.8364684581757 seconds, lr:0.0088, train_loss: 0.2834, unlabeled_losses_real_strong:0.5791,corrrect_unlabeled_num:385320.0,pro_above_threshold_num:396212.0,unlabelled_weak_top1_acc:92.02117802202702,unlabelled_weak_top5_acc:99.6573314704001  \n","[2022-04-17 18:43:57,865][experiments.experiment][INFO] - [EMA] Epoch 110. [Validation] raw_testing_loss: 0.4255, raw test Top1 acc:89.06, raw test Top5 acc: 99.36, ema_testing_loss: 0.3053, ema test Top1 acc:92.28, ema test Top5 acc: 99.8\n","[2022-04-17 18:43:57,866][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 18:55:03,417][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 111: use 665.6490125656128 seconds\n","--- Optimizer learning rate changed from 8.85e-03 to 8.52e-03 ---\n","[2022-04-17 18:55:03,515][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 18:55:05,310][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 18:55:05,310][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 18:55:07,054][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 18:55:07,055][experiments.experiment][INFO] - [EMA] Epoch 111.[Train] time:665.6490125656128 seconds, lr:0.0085, train_loss: 0.2808, unlabeled_losses_real_strong:0.5745,corrrect_unlabeled_num:385781.0,pro_above_threshold_num:396574.0,unlabelled_weak_top1_acc:92.08635496720672,unlabelled_weak_top5_acc:99.66539684683084  \n","[2022-04-17 18:55:07,057][experiments.experiment][INFO] - [EMA] Epoch 111. [Validation] raw_testing_loss: 0.4323, raw test Top1 acc:88.78, raw test Top5 acc: 99.48, ema_testing_loss: 0.3025, ema test Top1 acc:92.16, ema test Top5 acc: 99.8\n","[2022-04-17 18:55:07,058][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 19:06:12,201][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 112: use 665.2473459243774 seconds\n","--- Optimizer learning rate changed from 8.52e-03 to 8.19e-03 ---\n","[2022-04-17 19:06:12,305][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 19:06:14,079][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 19:06:14,080][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 19:06:15,887][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 19:06:15,888][experiments.experiment][INFO] - [EMA] Epoch 112.[Train] time:665.2473459243774 seconds, lr:0.0082, train_loss: 0.2780, unlabeled_losses_real_strong:0.5710,corrrect_unlabeled_num:386849.0,pro_above_threshold_num:397640.0,unlabelled_weak_top1_acc:92.13169529289007,unlabelled_weak_top5_acc:99.67694990336895  \n","[2022-04-17 19:06:15,889][experiments.experiment][INFO] - [EMA] Epoch 112. [Validation] raw_testing_loss: 0.4124, raw test Top1 acc:89.4, raw test Top5 acc: 99.68, ema_testing_loss: 0.3080, ema test Top1 acc:92.02, ema test Top5 acc: 99.68\n","[2022-04-17 19:06:15,891][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 19:17:22,134][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 113: use 666.3410484790802 seconds\n","--- Optimizer learning rate changed from 8.19e-03 to 7.86e-03 ---\n","[2022-04-17 19:17:22,232][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 19:17:23,985][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 19:17:23,985][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 19:17:25,760][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 19:17:25,761][experiments.experiment][INFO] - [EMA] Epoch 113.[Train] time:666.3410484790802 seconds, lr:0.0079, train_loss: 0.2752, unlabeled_losses_real_strong:0.5671,corrrect_unlabeled_num:387232.0,pro_above_threshold_num:398093.0,unlabelled_weak_top1_acc:92.25768940523267,unlabelled_weak_top5_acc:99.66648674756289  \n","[2022-04-17 19:17:25,764][experiments.experiment][INFO] - [EMA] Epoch 113. [Validation] raw_testing_loss: 0.4071, raw test Top1 acc:89.68, raw test Top5 acc: 99.64, ema_testing_loss: 0.3073, ema test Top1 acc:92.26, ema test Top5 acc: 99.78\n","[2022-04-17 19:17:25,765][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 19:28:30,757][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 114: use 665.0990626811981 seconds\n","--- Optimizer learning rate changed from 7.86e-03 to 7.53e-03 ---\n","[2022-04-17 19:28:30,864][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 19:28:32,648][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 19:28:32,648][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 19:28:34,410][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 19:28:34,411][experiments.experiment][INFO] - [EMA] Epoch 114.[Train] time:665.0990626811981 seconds, lr:0.0075, train_loss: 0.2707, unlabeled_losses_real_strong:0.5572,corrrect_unlabeled_num:388838.0,pro_above_threshold_num:399708.0,unlabelled_weak_top1_acc:92.31589075177908,unlabelled_weak_top5_acc:99.67150035500526  \n","[2022-04-17 19:28:34,414][experiments.experiment][INFO] - [EMA] Epoch 114. [Validation] raw_testing_loss: 0.4718, raw test Top1 acc:88.36, raw test Top5 acc: 99.44, ema_testing_loss: 0.3037, ema test Top1 acc:92.32, ema test Top5 acc: 99.74\n","[2022-04-17 19:28:34,415][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 19:39:40,083][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 115: use 665.7661552429199 seconds\n","--- Optimizer learning rate changed from 7.53e-03 to 7.19e-03 ---\n","[2022-04-17 19:39:40,181][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 19:39:41,991][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 19:39:41,991][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 19:39:43,722][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 19:39:43,724][experiments.experiment][INFO] - [EMA] Epoch 115.[Train] time:665.7661552429199 seconds, lr:0.0072, train_loss: 0.2704, unlabeled_losses_real_strong:0.5557,corrrect_unlabeled_num:389437.0,pro_above_threshold_num:400337.0,unlabelled_weak_top1_acc:92.39044073596597,unlabelled_weak_top5_acc:99.67041052877903  \n","[2022-04-17 19:39:43,726][experiments.experiment][INFO] - [EMA] Epoch 115. [Validation] raw_testing_loss: 0.3888, raw test Top1 acc:89.46, raw test Top5 acc: 99.68, ema_testing_loss: 0.3038, ema test Top1 acc:92.52, ema test Top5 acc: 99.68\n","[2022-04-17 19:39:43,727][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 19:50:48,609][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 116: use 664.9874727725983 seconds\n","--- Optimizer learning rate changed from 7.19e-03 to 6.86e-03 ---\n","[2022-04-17 19:50:48,715][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 19:50:50,457][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 19:50:50,458][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 19:50:52,182][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 19:50:52,183][experiments.experiment][INFO] - [EMA] Epoch 116.[Train] time:664.9874727725983 seconds, lr:0.0069, train_loss: 0.2685, unlabeled_losses_real_strong:0.5485,corrrect_unlabeled_num:390636.0,pro_above_threshold_num:401440.0,unlabelled_weak_top1_acc:92.48896898329258,unlabelled_weak_top5_acc:99.66953863203526  \n","[2022-04-17 19:50:52,186][experiments.experiment][INFO] - [EMA] Epoch 116. [Validation] raw_testing_loss: 0.4663, raw test Top1 acc:88.5, raw test Top5 acc: 99.46, ema_testing_loss: 0.3005, ema test Top1 acc:92.56, ema test Top5 acc: 99.76\n","[2022-04-17 19:50:52,187][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 20:01:57,983][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 117: use 665.8975009918213 seconds\n","--- Optimizer learning rate changed from 6.86e-03 to 6.53e-03 ---\n","[2022-04-17 20:01:58,085][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 20:01:59,882][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 20:01:59,882][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 20:02:01,669][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 20:02:01,671][experiments.experiment][INFO] - [EMA] Epoch 117.[Train] time:665.8975009918213 seconds, lr:0.0065, train_loss: 0.2652, unlabeled_losses_real_strong:0.5454,corrrect_unlabeled_num:391383.0,pro_above_threshold_num:402334.0,unlabelled_weak_top1_acc:92.53779704868793,unlabelled_weak_top5_acc:99.69635040685534  \n","[2022-04-17 20:02:01,674][experiments.experiment][INFO] - [EMA] Epoch 117. [Validation] raw_testing_loss: 0.4185, raw test Top1 acc:89.28, raw test Top5 acc: 99.66, ema_testing_loss: 0.3064, ema test Top1 acc:92.68, ema test Top5 acc: 99.82\n","[2022-04-17 20:02:01,675][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 20:13:06,884][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 118: use 665.3126127719879 seconds\n","--- Optimizer learning rate changed from 6.53e-03 to 6.19e-03 ---\n","[2022-04-17 20:13:06,987][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 20:13:08,886][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 20:13:08,887][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 20:13:10,691][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 20:13:10,692][experiments.experiment][INFO] - [EMA] Epoch 118.[Train] time:665.3126127719879 seconds, lr:0.0062, train_loss: 0.2628, unlabeled_losses_real_strong:0.5394,corrrect_unlabeled_num:392311.0,pro_above_threshold_num:403120.0,unlabelled_weak_top1_acc:92.62128444761038,unlabelled_weak_top5_acc:99.68654120713472  \n","[2022-04-17 20:13:10,695][experiments.experiment][INFO] - [EMA] Epoch 118. [Validation] raw_testing_loss: 0.4483, raw test Top1 acc:88.8, raw test Top5 acc: 99.32, ema_testing_loss: 0.3041, ema test Top1 acc:92.42, ema test Top5 acc: 99.78\n","[2022-04-17 20:13:10,696][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-17 20:24:17,171][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 119: use 666.5799407958984 seconds\n","--- Optimizer learning rate changed from 6.19e-03 to 5.85e-03 ---\n","[2022-04-17 20:24:17,276][experiments.experiment][INFO] - ***** Running validation *****\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-17 20:24:19,094][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-17 20:24:19,094][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 20:24:20,838][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-17 20:24:20,840][experiments.experiment][INFO] - [EMA] Epoch 119.[Train] time:666.5799407958984 seconds, lr:0.0059, train_loss: 0.2604, unlabeled_losses_real_strong:0.5361,corrrect_unlabeled_num:393273.0,pro_above_threshold_num:404415.0,unlabelled_weak_top1_acc:92.67948587611318,unlabelled_weak_top5_acc:99.6882849894464  \n","[2022-04-17 20:24:20,842][experiments.experiment][INFO] - [EMA] Epoch 119. [Validation] raw_testing_loss: 0.3400, raw test Top1 acc:90.7, raw test Top5 acc: 99.72, ema_testing_loss: 0.3047, ema test Top1 acc:92.48, ema test Top5 acc: 99.8\n","======= Training done =======\n","2022-04-17 20:24:20,861 - INFO - Train -   ======= Training done =======\n","[2022-04-17 20:24:20,861][Train][INFO] - ======= Training done =======\n","[2022-04-17 20:24:20,862][experiments.experiment][INFO] - Loading Testing Loader\n","[2022-04-17 20:24:20,868][experiments.experiment][INFO] - [Testing with EMA] apply shadow\n","[2022-04-17 20:24:20,869][experiments.experiment][INFO] - ***** Running testing *****\n","[2022-04-17 20:24:24,220][experiments.experiment][INFO] - [Testing(EMA)] testing_loss: 0.2980, test Top1 acc:92.23, test Top5 acc: 99.76\n","[2022-04-17 20:24:24,224][experiments.experiment][INFO] - [EMA] restore \n","======= Testing done =======\n","2022-04-17 20:24:24,224 - INFO - Train -   ======= Testing done =======\n","[2022-04-17 20:24:24,224][Train][INFO] - ======= Testing done =======\n"]}],"source":["!python run.py DATASET.label_num=4000 DATASET.strongaugment='RA' EXPERIMENT.epoch_n=120 EXPERIMENT.batch_size=32 MODEL.name='CifarResNeXt' MODEL.cardinality=4 MODEL.depth=28 MODEL.width=4 MODEL.widen_factor=4 EXPERIMENT.out_model='./checkpoints/checkpoints_celiali-resnext-120epochs-32batch/' EXPERIMENT.log_path='./outputs/outputs_celiali-resnext-120epochs-32batch/' EXPERIMENT.decay_type='cosine'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F89RrtkIFn0A","outputId":"4bad933c-6c08-4ce6-da8a-80b25c96fd39"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 2)) (1.0.0)\n","Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 3)) (1.9)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 4)) (0.29.28)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 5)) (1.21.5)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 7)) (4.64.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 8)) (1.4.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 9)) (7.1.2)\n","Requirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 10)) (1.8.0)\n","Requirement already satisfied: torchvision==0.9.0 in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 11)) (0.9.0)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 12)) (0.8.0)\n","Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 13)) (0.9.0)\n","Requirement already satisfied: omegaconf in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 14)) (2.1.2)\n","Requirement already satisfied: hydra in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 15)) (2.5)\n","Requirement already satisfied: hydra-core in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 16)) (1.1.2)\n","Requirement already satisfied: ignite in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 17)) (1.1.0)\n","Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 18)) (0.4.8)\n","Requirement already satisfied: tensorboardX in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 19)) (2.5)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 20)) (1.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 21)) (3.2.2)\n","Requirement already satisfied: abel-pytorch in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 22)) (0.0.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->-r google_requirements.txt (line 10)) (4.1.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->-r google_requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.1.2)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (57.4.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (13.0.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.3.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.1.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.14.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (3.17.3)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.6.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (1.44.0)\n","Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.8.0.dev2021122109)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.5.3)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.24.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->-r google_requirements.txt (line 6)) (0.2.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow->-r google_requirements.txt (line 6)) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->-r google_requirements.txt (line 6)) (1.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.4.6)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.35.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2.23.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.3.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow->-r google_requirements.txt (line 6)) (3.2.0)\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf->-r google_requirements.txt (line 14)) (6.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from omegaconf->-r google_requirements.txt (line 14)) (4.8)\n","Requirement already satisfied: importlib-resources<5.3 in /usr/local/lib/python3.7/dist-packages (from hydra-core->-r google_requirements.txt (line 16)) (5.2.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r google_requirements.txt (line 20)) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->-r google_requirements.txt (line 20)) (1.1.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (3.0.8)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (1.4.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r google_requirements.txt (line 21)) (0.11.0)\n","==> CONFIG is: \n"," DATASET:\n","  project_dir: ./\n","  data_dir: data\n","  loading_data: LOAD_LABEL_UNLABEL\n","  dataset: CIFAR10\n","  strongaugment: RA\n","  label_num: 4000\n","  num_expand_x: 65536\n","  mu: 7\n","  barely: false\n","  add_noisy_label: false\n","  both_strong: false\n","MODEL:\n","  name: WideResNet_Lk\n","  depth: 28\n","  widen_factor: 2\n","  num_classes: 10\n","  dropout: 0.0\n","  cardinality: 4\n","  width: 4\n","  base_width: 4\n","EXPERIMENT:\n","  name: FMExperiment\n","  out_model: ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/\n","  log_path: ./outputs/outputs_celiali-wideresnet-120epochs-64batch-no-ema/\n","  used_gpu: true\n","  use_cosine: true\n","  use_abel: false\n","  abel_decay: 0.1\n","  optim_lr: 0.03\n","  optim_momentum: 0.9\n","  used_nesterov: true\n","  warmup: 0\n","  wdecay: 0.0005\n","  clip: 1\n","  ema_used: false\n","  ema_decay: 0.999\n","  threshold: 0.95\n","  lambda_unlabeled: 1\n","  batch_size: 64\n","  num_workers: 4\n","  n_imgs_per_epoch: 65536\n","  epoch_n: 120\n","  save_every: 2\n","  save_matrix_every: 20\n","  resume: false\n","  resume_checkpoints: ./checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar\n","  save_cfmatrix: false\n","  batch_balanced: false\n","  neg_penalty: false\n","  equal_freq: false\n","  eta_negpenalty: 0.05\n","  eta_dynamic: false\n","  use_nlloss: false\n","  q: 0.0001\n","Logging:\n","  name: FM\n","  seed: 1265\n"," \n","\n","2022-04-17 22:05:05,773 - INFO - Train -   {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/', 'log_path': './outputs/outputs_celiali-wideresnet-120epochs-64batch-no-ema/', 'used_gpu': True, 'use_cosine': True, 'use_abel': False, 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': False, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 1, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': False, 'resume_checkpoints': './checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","[2022-04-17 22:05:05,773][Train][INFO] - {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/', 'log_path': './outputs/outputs_celiali-wideresnet-120epochs-64batch-no-ema/', 'used_gpu': True, 'use_cosine': True, 'use_abel': False, 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': False, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 1, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': False, 'resume_checkpoints': './checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","2022-04-17 22:05:06,219 - INFO - Train -   [Model] Building model WideResNet_Lk\n","[2022-04-17 22:05:06,219][Train][INFO] - [Model] Building model WideResNet_Lk\n","2022-04-17 22:05:08,979 - INFO - Train -   Total params: 1.47M\n","[2022-04-17 22:05:08,979][Train][INFO] - Total params: 1.47M\n","[2022-04-17 22:05:08,980][experiments.experiment][INFO] - I'm using cosine decay!\n","[2022-04-17 22:05:14,818][datasets.datasets1][INFO] - Dataset: CIFAR10\n","[2022-04-17 22:05:14,877][datasets.datasets1][INFO] - Labeled examples: 65536 Unlabeled examples: 458752Validation examples: 5000\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-17 22:05:14,879][experiments.experiment][INFO] - Loading Labelled Loader\n","[2022-04-17 22:05:14,880][experiments.experiment][INFO] - Loading Unlabelled Loader\n","[2022-04-17 22:05:14,880][experiments.experiment][INFO] - Loading Validation Loader\n","[2022-04-17 22:05:14,891][experiments.experiment][INFO] - ***** Running training *****\n","epoch 0: use 592.8845062255859 seconds\n","--- Optimizer learning rate changed from inf to 3.00e-02 ---\n","[2022-04-17 22:15:07,775][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:15:09,573][experiments.experiment][INFO] - [no EMA] Epoch 0. [Train] time:592.8845062255859 seconds, lr:0.0300, train_loss: 1.2566, unlabeled_losses_real_strong:2.0060,corrrect_unlabeled_num:22387.0,pro_above_threshold_num:23635.0,unlabelled_weak_top1_acc:51.07618001755327,unlabelled_weak_top5_acc:92.7871693558991  \n","[2022-04-17 22:15:09,573][experiments.experiment][INFO] - [no EMA] Epoch 0. [Validation] testing_loss: 1.5782, test Top1 acc:44.66, test Top5 acc: 91.78\n","[2022-04-17 22:15:09,649][experiments.experiment][INFO] - [Checkpoints] Epoch 0, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_0.pth.tar\n","[2022-04-17 22:15:09,650][experiments.experiment][INFO] - ***** Running training *****\n","epoch 1: use 596.5460426807404 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-17 22:25:06,197][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:25:07,969][experiments.experiment][INFO] - [no EMA] Epoch 1. [Train] time:596.5460426807404 seconds, lr:0.0300, train_loss: 0.8529, unlabeled_losses_real_strong:1.8218,corrrect_unlabeled_num:107112.0,pro_above_threshold_num:113924.0,unlabelled_weak_top1_acc:64.49672070145607,unlabelled_weak_top5_acc:96.55739815533161  \n","[2022-04-17 22:25:07,971][experiments.experiment][INFO] - [no EMA] Epoch 1. [Validation] testing_loss: 2.6647, test Top1 acc:21.88, test Top5 acc: 79.52\n","[2022-04-17 22:25:08,052][experiments.experiment][INFO] - [Checkpoints] Epoch 1, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_1.pth.tar\n","[2022-04-17 22:25:08,053][experiments.experiment][INFO] - ***** Running training *****\n","epoch 2: use 596.5460329055786 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-17 22:35:04,599][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:35:06,366][experiments.experiment][INFO] - [no EMA] Epoch 2. [Train] time:596.5460329055786 seconds, lr:0.0300, train_loss: 0.7072, unlabeled_losses_real_strong:1.6155,corrrect_unlabeled_num:172789.0,pro_above_threshold_num:186531.0,unlabelled_weak_top1_acc:69.74574396386743,unlabelled_weak_top5_acc:97.35499683022499  \n","[2022-04-17 22:35:06,368][experiments.experiment][INFO] - [no EMA] Epoch 2. [Validation] testing_loss: 2.2651, test Top1 acc:31.38, test Top5 acc: 83.16\n","[2022-04-17 22:35:06,368][experiments.experiment][INFO] - ***** Running training *****\n","epoch 3: use 593.3835461139679 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-17 22:44:59,752][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:45:01,470][experiments.experiment][INFO] - [no EMA] Epoch 3. [Train] time:593.3835461139679 seconds, lr:0.0300, train_loss: 0.6398, unlabeled_losses_real_strong:1.4639,corrrect_unlabeled_num:215251.0,pro_above_threshold_num:233064.0,unlabelled_weak_top1_acc:73.32458380609751,unlabelled_weak_top5_acc:97.87662944197655  \n","[2022-04-17 22:45:01,472][experiments.experiment][INFO] - [no EMA] Epoch 3. [Validation] testing_loss: 4.0058, test Top1 acc:25.98, test Top5 acc: 80.36\n","[2022-04-17 22:45:01,555][experiments.experiment][INFO] - [Checkpoints] Epoch 3, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_3.pth.tar\n","[2022-04-17 22:45:01,556][experiments.experiment][INFO] - ***** Running training *****\n","epoch 4: use 593.3911240100861 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-17 22:54:54,947][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 22:54:56,698][experiments.experiment][INFO] - [no EMA] Epoch 4. [Train] time:593.3911240100861 seconds, lr:0.0300, train_loss: 0.5957, unlabeled_losses_real_strong:1.3495,corrrect_unlabeled_num:242996.0,pro_above_threshold_num:262968.0,unlabelled_weak_top1_acc:75.83596241474152,unlabelled_weak_top5_acc:98.1944483295083  \n","[2022-04-17 22:54:56,700][experiments.experiment][INFO] - [no EMA] Epoch 4. [Validation] testing_loss: 2.1887, test Top1 acc:45.62, test Top5 acc: 89.7\n","[2022-04-17 22:54:56,701][experiments.experiment][INFO] - ***** Running training *****\n","epoch 5: use 583.0758521556854 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 2.99e-02 ---\n","[2022-04-17 23:04:39,777][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:04:41,490][experiments.experiment][INFO] - [no EMA] Epoch 5. [Train] time:583.0758521556854 seconds, lr:0.0299, train_loss: 0.5578, unlabeled_losses_real_strong:1.2567,corrrect_unlabeled_num:261709.0,pro_above_threshold_num:281640.0,unlabelled_weak_top1_acc:77.87148512899876,unlabelled_weak_top5_acc:98.46692653745413  \n","[2022-04-17 23:04:41,492][experiments.experiment][INFO] - [no EMA] Epoch 5. [Validation] testing_loss: 1.8854, test Top1 acc:47.1, test Top5 acc: 92.62\n","[2022-04-17 23:04:41,572][experiments.experiment][INFO] - [Checkpoints] Epoch 5, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_5.pth.tar\n","[2022-04-17 23:04:41,573][experiments.experiment][INFO] - ***** Running training *****\n","epoch 6: use 578.2538895606995 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.99e-02 ---\n","[2022-04-17 23:14:19,827][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:14:21,507][experiments.experiment][INFO] - [no EMA] Epoch 6. [Train] time:578.2538895606995 seconds, lr:0.0299, train_loss: 0.5274, unlabeled_losses_real_strong:1.1907,corrrect_unlabeled_num:275201.0,pro_above_threshold_num:294971.0,unlabelled_weak_top1_acc:79.37796349078417,unlabelled_weak_top5_acc:98.64174846559763  \n","[2022-04-17 23:14:21,509][experiments.experiment][INFO] - [no EMA] Epoch 6. [Validation] testing_loss: 1.1270, test Top1 acc:66.0, test Top5 acc: 97.1\n","[2022-04-17 23:14:21,510][experiments.experiment][INFO] - ***** Running training *****\n","epoch 7: use 571.948248386383 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.99e-02 ---\n","[2022-04-17 23:23:53,458][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:23:55,168][experiments.experiment][INFO] - [no EMA] Epoch 7. [Train] time:571.948248386383 seconds, lr:0.0299, train_loss: 0.5014, unlabeled_losses_real_strong:1.1228,corrrect_unlabeled_num:288156.0,pro_above_threshold_num:307479.0,unlabelled_weak_top1_acc:80.76585941761732,unlabelled_weak_top5_acc:98.78670693933964  \n","[2022-04-17 23:23:55,169][experiments.experiment][INFO] - [no EMA] Epoch 7. [Validation] testing_loss: 1.5115, test Top1 acc:61.16, test Top5 acc: 94.54\n","[2022-04-17 23:23:55,248][experiments.experiment][INFO] - [Checkpoints] Epoch 7, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_7.pth.tar\n","[2022-04-17 23:23:55,249][experiments.experiment][INFO] - ***** Running training *****\n","epoch 8: use 572.9485890865326 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.98e-02 ---\n","[2022-04-17 23:33:28,197][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:33:29,887][experiments.experiment][INFO] - [no EMA] Epoch 8. [Train] time:572.9485890865326 seconds, lr:0.0298, train_loss: 0.4852, unlabeled_losses_real_strong:1.0742,corrrect_unlabeled_num:298465.0,pro_above_threshold_num:317290.0,unlabelled_weak_top1_acc:82.02449153363705,unlabelled_weak_top5_acc:98.89766005426645  \n","[2022-04-17 23:33:29,890][experiments.experiment][INFO] - [no EMA] Epoch 8. [Validation] testing_loss: 1.4199, test Top1 acc:61.86, test Top5 acc: 97.06\n","[2022-04-17 23:33:29,890][experiments.experiment][INFO] - ***** Running training *****\n","epoch 9: use 577.9059782028198 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.98e-02 ---\n","[2022-04-17 23:43:07,796][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:43:09,467][experiments.experiment][INFO] - [no EMA] Epoch 9. [Train] time:577.9059782028198 seconds, lr:0.0298, train_loss: 0.4646, unlabeled_losses_real_strong:1.0249,corrrect_unlabeled_num:305995.0,pro_above_threshold_num:324169.0,unlabelled_weak_top1_acc:82.90928319096565,unlabelled_weak_top5_acc:98.98441714793444  \n","[2022-04-17 23:43:09,470][experiments.experiment][INFO] - [no EMA] Epoch 9. [Validation] testing_loss: 1.1189, test Top1 acc:69.76, test Top5 acc: 97.3\n","[2022-04-17 23:43:09,547][experiments.experiment][INFO] - [Checkpoints] Epoch 9, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_9.pth.tar\n","[2022-04-17 23:43:09,548][experiments.experiment][INFO] - ***** Running training *****\n","epoch 10: use 589.1358823776245 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.98e-02 ---\n","[2022-04-17 23:52:58,684][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-17 23:53:00,387][experiments.experiment][INFO] - [no EMA] Epoch 10. [Train] time:589.1358823776245 seconds, lr:0.0298, train_loss: 0.4494, unlabeled_losses_real_strong:0.9836,corrrect_unlabeled_num:313823.0,pro_above_threshold_num:331419.0,unlabelled_weak_top1_acc:83.77118677645922,unlabelled_weak_top5_acc:99.08774085342884  \n","[2022-04-17 23:53:00,389][experiments.experiment][INFO] - [no EMA] Epoch 10. [Validation] testing_loss: 1.3899, test Top1 acc:68.26, test Top5 acc: 98.2\n","[2022-04-17 23:53:00,390][experiments.experiment][INFO] - ***** Running training *****\n","epoch 11: use 584.6497404575348 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.97e-02 ---\n","[2022-04-18 00:02:45,040][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 00:02:46,749][experiments.experiment][INFO] - [no EMA] Epoch 11. [Train] time:584.6497404575348 seconds, lr:0.0297, train_loss: 0.4335, unlabeled_losses_real_strong:0.9491,corrrect_unlabeled_num:320559.0,pro_above_threshold_num:337704.0,unlabelled_weak_top1_acc:84.56507973372936,unlabelled_weak_top5_acc:99.15662360191345  \n","[2022-04-18 00:02:46,750][experiments.experiment][INFO] - [no EMA] Epoch 11. [Validation] testing_loss: 0.9175, test Top1 acc:72.54, test Top5 acc: 96.9\n","[2022-04-18 00:02:46,827][experiments.experiment][INFO] - [Checkpoints] Epoch 11, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_11.pth.tar\n","[2022-04-18 00:02:46,828][experiments.experiment][INFO] - ***** Running training *****\n","epoch 12: use 586.5460793972015 seconds\n","--- Optimizer learning rate changed from 2.97e-02 to 2.97e-02 ---\n","[2022-04-18 00:12:33,375][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 00:12:35,077][experiments.experiment][INFO] - [no EMA] Epoch 12. [Train] time:586.5460793972015 seconds, lr:0.0297, train_loss: 0.4230, unlabeled_losses_real_strong:0.9212,corrrect_unlabeled_num:325757.0,pro_above_threshold_num:342237.0,unlabelled_weak_top1_acc:85.24671170860529,unlabelled_weak_top5_acc:99.17711395025253  \n","[2022-04-18 00:12:35,077][experiments.experiment][INFO] - [no EMA] Epoch 12. [Validation] testing_loss: 0.7206, test Top1 acc:81.98, test Top5 acc: 98.76\n","[2022-04-18 00:12:35,079][experiments.experiment][INFO] - ***** Running training *****\n"]}],"source":["%pip install -r google_requirements.txt\n","!python run.py DATASET.label_num=4000 DATASET.strongaugment='RA' EXPERIMENT.epoch_n=120 EXPERIMENT.batch_size=64 MODEL.name='WideResNet_Lk' MODEL.depth=28 MODEL.widen_factor=2 MODEL.num_classes=10 EXPERIMENT.out_model='./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/' EXPERIMENT.log_path='./outputs/outputs_celiali-wideresnet-120epochs-64batch-no-ema/' EXPERIMENT.save_cfmatrix=False EXPERIMENT.decay_type='cosine' EXPERIMENT.ema_used=False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Cofyi1JMczN","executionInfo":{"status":"ok","timestamp":1650301865269,"user_tz":300,"elapsed":5333886,"user":{"displayName":"CM Y","userId":"12660552299343911788"}},"outputId":"e9150dee-8d10-404c-b56b-046d7c6afc97"},"outputs":[{"output_type":"stream","name":"stdout","text":["==> CONFIG is: \n"," DATASET:\n","  project_dir: ./\n","  data_dir: data\n","  loading_data: LOAD_LABEL_UNLABEL\n","  dataset: CIFAR10\n","  strongaugment: RA\n","  label_num: 4000\n","  num_expand_x: 65536\n","  mu: 7\n","  barely: false\n","  add_noisy_label: false\n","  both_strong: false\n","MODEL:\n","  name: WideResNet_Lk\n","  depth: 28\n","  widen_factor: 2\n","  num_classes: 10\n","  dropout: 0.0\n","  cardinality: 4\n","  width: 4\n","  base_width: 4\n","EXPERIMENT:\n","  name: FMExperiment\n","  out_model: ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/\n","  log_path: ./outputs/outputs_celiali-wideresnet-120epochs-64batch-no-ema/\n","  used_gpu: true\n","  use_cosine: true\n","  use_abel: false\n","  abel_decay: 0.1\n","  optim_lr: 0.03\n","  optim_momentum: 0.9\n","  used_nesterov: true\n","  warmup: 0\n","  wdecay: 0.0005\n","  clip: 1\n","  ema_used: false\n","  ema_decay: 0.999\n","  threshold: 0.95\n","  lambda_unlabeled: 1\n","  batch_size: 64\n","  num_workers: 4\n","  n_imgs_per_epoch: 65536\n","  epoch_n: 120\n","  save_every: 2\n","  save_matrix_every: 20\n","  resume: true\n","  resume_checkpoints: ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_11.pth.tar\n","  save_cfmatrix: false\n","  batch_balanced: false\n","  neg_penalty: false\n","  equal_freq: false\n","  eta_negpenalty: 0.05\n","  eta_dynamic: false\n","  use_nlloss: false\n","  q: 0.0001\n","Logging:\n","  name: FM\n","  seed: 1265\n"," \n","\n","2022-04-18 03:39:32,573 - INFO - Train -   {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/', 'log_path': './outputs/outputs_celiali-wideresnet-120epochs-64batch-no-ema/', 'used_gpu': True, 'use_cosine': True, 'use_abel': False, 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': False, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 1, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': True, 'resume_checkpoints': './checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_11.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","[2022-04-18 03:39:32,573][Train][INFO] - {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/', 'log_path': './outputs/outputs_celiali-wideresnet-120epochs-64batch-no-ema/', 'used_gpu': True, 'use_cosine': True, 'use_abel': False, 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': False, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 1, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': True, 'resume_checkpoints': './checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_11.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","2022-04-18 03:39:33,319 - INFO - Train -   [Model] Building model WideResNet_Lk\n","[2022-04-18 03:39:33,319][Train][INFO] - [Model] Building model WideResNet_Lk\n","2022-04-18 03:39:35,922 - INFO - Train -   Total params: 1.47M\n","[2022-04-18 03:39:35,922][Train][INFO] - Total params: 1.47M\n","[2022-04-18 03:39:35,923][experiments.experiment][INFO] - I'm using cosine decay!\n","[2022-04-18 03:39:45,516][datasets.datasets1][INFO] - Dataset: CIFAR10\n","[2022-04-18 03:39:45,568][datasets.datasets1][INFO] - Labeled examples: 65536 Unlabeled examples: 458752Validation examples: 5000\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-18 03:39:45,570][experiments.experiment][INFO] - Loading Labelled Loader\n","[2022-04-18 03:39:45,570][experiments.experiment][INFO] - Loading Unlabelled Loader\n","[2022-04-18 03:39:45,571][experiments.experiment][INFO] - Loading Validation Loader\n","=> loading checkpoint './checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_11.pth.tar'\n","[2022-04-18 03:39:46,784][experiments.experiment][INFO] - ==> Resuming from checkpoint..\n","=> loaded checkpoint './checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_11.pth.tar' (epoch 11)\n","[2022-04-18 03:39:48,080][experiments.experiment][INFO] - => loaded checkpoint './checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_11.pth.tar' (epoch 11)\n","[2022-04-18 03:39:48,080][experiments.experiment][INFO] - ***** Running training *****\n","epoch 11: use 440.2310047149658 seconds\n","--- Optimizer learning rate changed from inf to 2.97e-02 ---\n","[2022-04-18 03:47:08,312][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 03:47:13,003][experiments.experiment][INFO] - [no EMA] Epoch 11. [Train] time:440.2310047149658 seconds, lr:0.0297, train_loss: 0.4222, unlabeled_losses_real_strong:0.9173,corrrect_unlabeled_num:326245.0,pro_above_threshold_num:342705.0,unlabelled_weak_top1_acc:85.2375563904643,unlabelled_weak_top5_acc:99.1788576990366  \n","[2022-04-18 03:47:13,004][experiments.experiment][INFO] - [no EMA] Epoch 11. [Validation] testing_loss: 0.6610, test Top1 acc:80.88, test Top5 acc: 98.94\n","[2022-04-18 03:47:13,062][experiments.experiment][INFO] - [Checkpoints] Epoch 11, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_11.pth.tar\n","[2022-04-18 03:47:13,070][experiments.experiment][INFO] - ***** Running training *****\n","epoch 12: use 439.5536961555481 seconds\n","--- Optimizer learning rate changed from 2.97e-02 to 2.96e-02 ---\n","[2022-04-18 03:54:32,624][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 03:54:33,924][experiments.experiment][INFO] - [no EMA] Epoch 12. [Train] time:439.5536961555481 seconds, lr:0.0296, train_loss: 0.4152, unlabeled_losses_real_strong:0.8933,corrrect_unlabeled_num:329961.0,pro_above_threshold_num:346132.0,unlabelled_weak_top1_acc:85.70316757261753,unlabelled_weak_top5_acc:99.23269952088594  \n","[2022-04-18 03:54:33,925][experiments.experiment][INFO] - [no EMA] Epoch 12. [Validation] testing_loss: 0.8085, test Top1 acc:78.66, test Top5 acc: 98.84\n","[2022-04-18 03:54:33,926][experiments.experiment][INFO] - ***** Running training *****\n","epoch 13: use 437.8230359554291 seconds\n","--- Optimizer learning rate changed from 2.96e-02 to 2.96e-02 ---\n","[2022-04-18 04:01:51,749][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:01:53,054][experiments.experiment][INFO] - [no EMA] Epoch 13. [Train] time:437.8230359554291 seconds, lr:0.0296, train_loss: 0.4039, unlabeled_losses_real_strong:0.8674,corrrect_unlabeled_num:334949.0,pro_above_threshold_num:350868.0,unlabelled_weak_top1_acc:86.30152992159128,unlabelled_weak_top5_acc:99.28741323947906  \n","[2022-04-18 04:01:53,056][experiments.experiment][INFO] - [no EMA] Epoch 13. [Validation] testing_loss: 0.7307, test Top1 acc:80.8, test Top5 acc: 98.64\n","[2022-04-18 04:01:53,119][experiments.experiment][INFO] - [Checkpoints] Epoch 13, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_13.pth.tar\n","[2022-04-18 04:01:53,119][experiments.experiment][INFO] - ***** Running training *****\n","epoch 14: use 438.38953161239624 seconds\n","--- Optimizer learning rate changed from 2.96e-02 to 2.95e-02 ---\n","[2022-04-18 04:09:11,509][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:09:12,858][experiments.experiment][INFO] - [no EMA] Epoch 14. [Train] time:438.38953161239624 seconds, lr:0.0295, train_loss: 0.3951, unlabeled_losses_real_strong:0.8457,corrrect_unlabeled_num:339747.0,pro_above_threshold_num:355187.0,unlabelled_weak_top1_acc:86.78414367884398,unlabelled_weak_top5_acc:99.30681379884481  \n","[2022-04-18 04:09:12,860][experiments.experiment][INFO] - [no EMA] Epoch 14. [Validation] testing_loss: 0.7933, test Top1 acc:78.3, test Top5 acc: 98.6\n","[2022-04-18 04:09:12,861][experiments.experiment][INFO] - ***** Running training *****\n","epoch 15: use 439.87200903892517 seconds\n","--- Optimizer learning rate changed from 2.95e-02 to 2.94e-02 ---\n","[2022-04-18 04:16:32,733][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:16:34,038][experiments.experiment][INFO] - [no EMA] Epoch 15. [Train] time:439.87200903892517 seconds, lr:0.0294, train_loss: 0.3891, unlabeled_losses_real_strong:0.8290,corrrect_unlabeled_num:342653.0,pro_above_threshold_num:357929.0,unlabelled_weak_top1_acc:87.12659451365471,unlabelled_weak_top5_acc:99.33471563458443  \n","[2022-04-18 04:16:34,040][experiments.experiment][INFO] - [no EMA] Epoch 15. [Validation] testing_loss: 0.7349, test Top1 acc:82.14, test Top5 acc: 99.02\n","[2022-04-18 04:16:34,097][experiments.experiment][INFO] - [Checkpoints] Epoch 15, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_15.pth.tar\n","[2022-04-18 04:16:34,098][experiments.experiment][INFO] - ***** Running training *****\n","epoch 16: use 440.18115878105164 seconds\n","--- Optimizer learning rate changed from 2.94e-02 to 2.94e-02 ---\n","[2022-04-18 04:23:54,279][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:23:55,614][experiments.experiment][INFO] - [no EMA] Epoch 16. [Train] time:440.18115878105164 seconds, lr:0.0294, train_loss: 0.3817, unlabeled_losses_real_strong:0.8102,corrrect_unlabeled_num:346437.0,pro_above_threshold_num:361172.0,unlabelled_weak_top1_acc:87.54403146356344,unlabelled_weak_top5_acc:99.36632326990366  \n","[2022-04-18 04:23:55,615][experiments.experiment][INFO] - [no EMA] Epoch 16. [Validation] testing_loss: 0.7168, test Top1 acc:81.46, test Top5 acc: 99.0\n","[2022-04-18 04:23:55,616][experiments.experiment][INFO] - ***** Running training *****\n","epoch 17: use 440.92535400390625 seconds\n","--- Optimizer learning rate changed from 2.94e-02 to 2.93e-02 ---\n","[2022-04-18 04:31:16,541][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:31:17,886][experiments.experiment][INFO] - [no EMA] Epoch 17. [Train] time:440.92535400390625 seconds, lr:0.0293, train_loss: 0.3735, unlabeled_losses_real_strong:0.7947,corrrect_unlabeled_num:348482.0,pro_above_threshold_num:362990.0,unlabelled_weak_top1_acc:87.89367567747831,unlabelled_weak_top5_acc:99.39553308486938  \n","[2022-04-18 04:31:17,888][experiments.experiment][INFO] - [no EMA] Epoch 17. [Validation] testing_loss: 0.5839, test Top1 acc:84.4, test Top5 acc: 99.04\n","[2022-04-18 04:31:17,947][experiments.experiment][INFO] - [Checkpoints] Epoch 17, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_17.pth.tar\n","[2022-04-18 04:31:17,948][experiments.experiment][INFO] - ***** Running training *****\n","epoch 18: use 440.24382185935974 seconds\n","--- Optimizer learning rate changed from 2.93e-02 to 2.92e-02 ---\n","[2022-04-18 04:38:38,192][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:38:39,490][experiments.experiment][INFO] - [no EMA] Epoch 18. [Train] time:440.24382185935974 seconds, lr:0.0292, train_loss: 0.3682, unlabeled_losses_real_strong:0.7786,corrrect_unlabeled_num:351135.0,pro_above_threshold_num:365348.0,unlabelled_weak_top1_acc:88.10860662907362,unlabelled_weak_top5_acc:99.41406183689833  \n","[2022-04-18 04:38:39,490][experiments.experiment][INFO] - [no EMA] Epoch 18. [Validation] testing_loss: 0.5618, test Top1 acc:83.98, test Top5 acc: 99.1\n","[2022-04-18 04:38:39,491][experiments.experiment][INFO] - ***** Running training *****\n","epoch 19: use 438.34149622917175 seconds\n","--- Optimizer learning rate changed from 2.92e-02 to 2.91e-02 ---\n","[2022-04-18 04:45:57,833][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:45:59,191][experiments.experiment][INFO] - [no EMA] Epoch 19. [Train] time:438.34149622917175 seconds, lr:0.0291, train_loss: 0.3629, unlabeled_losses_real_strong:0.7642,corrrect_unlabeled_num:353894.0,pro_above_threshold_num:367799.0,unlabelled_weak_top1_acc:88.55394538491964,unlabelled_weak_top5_acc:99.43411621451378  \n","[2022-04-18 04:45:59,193][experiments.experiment][INFO] - [no EMA] Epoch 19. [Validation] testing_loss: 0.6163, test Top1 acc:84.56, test Top5 acc: 99.18\n","[2022-04-18 04:45:59,256][experiments.experiment][INFO] - [Checkpoints] Epoch 19, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_19.pth.tar\n","[2022-04-18 04:45:59,256][experiments.experiment][INFO] - ***** Running training *****\n","epoch 20: use 438.76746439933777 seconds\n","--- Optimizer learning rate changed from 2.91e-02 to 2.91e-02 ---\n","[2022-04-18 04:53:18,024][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 04:53:19,339][experiments.experiment][INFO] - [no EMA] Epoch 20. [Train] time:438.76746439933777 seconds, lr:0.0291, train_loss: 0.3587, unlabeled_losses_real_strong:0.7523,corrrect_unlabeled_num:356408.0,pro_above_threshold_num:370068.0,unlabelled_weak_top1_acc:88.73029329627752,unlabelled_weak_top5_acc:99.43738584965467  \n","[2022-04-18 04:53:19,339][experiments.experiment][INFO] - [no EMA] Epoch 20. [Validation] testing_loss: 0.5754, test Top1 acc:84.74, test Top5 acc: 99.32\n","[2022-04-18 04:53:19,340][experiments.experiment][INFO] - ***** Running training *****\n","epoch 21: use 440.5824694633484 seconds\n","--- Optimizer learning rate changed from 2.91e-02 to 2.90e-02 ---\n","[2022-04-18 05:00:39,922][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:00:41,222][experiments.experiment][INFO] - [no EMA] Epoch 21. [Train] time:440.5824694633484 seconds, lr:0.0290, train_loss: 0.3558, unlabeled_losses_real_strong:0.7426,corrrect_unlabeled_num:358983.0,pro_above_threshold_num:372466.0,unlabelled_weak_top1_acc:89.06031917780638,unlabelled_weak_top5_acc:99.4742249250412  \n","[2022-04-18 05:00:41,223][experiments.experiment][INFO] - [no EMA] Epoch 21. [Validation] testing_loss: 0.6030, test Top1 acc:84.44, test Top5 acc: 99.26\n","[2022-04-18 05:00:41,284][experiments.experiment][INFO] - [Checkpoints] Epoch 21, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_21.pth.tar\n","[2022-04-18 05:00:41,285][experiments.experiment][INFO] - ***** Running training *****\n","epoch 22: use 441.75771284103394 seconds\n","--- Optimizer learning rate changed from 2.90e-02 to 2.89e-02 ---\n","[2022-04-18 05:08:03,043][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:08:04,390][experiments.experiment][INFO] - [no EMA] Epoch 22. [Train] time:441.75771284103394 seconds, lr:0.0289, train_loss: 0.3509, unlabeled_losses_real_strong:0.7284,corrrect_unlabeled_num:360564.0,pro_above_threshold_num:373698.0,unlabelled_weak_top1_acc:89.25737551599741,unlabelled_weak_top5_acc:99.46986540406942  \n","[2022-04-18 05:08:04,391][experiments.experiment][INFO] - [no EMA] Epoch 22. [Validation] testing_loss: 0.5270, test Top1 acc:86.02, test Top5 acc: 99.44\n","[2022-04-18 05:08:04,393][experiments.experiment][INFO] - ***** Running training *****\n","epoch 23: use 441.058634519577 seconds\n","--- Optimizer learning rate changed from 2.89e-02 to 2.88e-02 ---\n","[2022-04-18 05:15:25,452][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:15:26,779][experiments.experiment][INFO] - [no EMA] Epoch 23. [Train] time:441.058634519577 seconds, lr:0.0288, train_loss: 0.3474, unlabeled_losses_real_strong:0.7206,corrrect_unlabeled_num:362155.0,pro_above_threshold_num:374847.0,unlabelled_weak_top1_acc:89.46009924262762,unlabelled_weak_top5_acc:99.48883003741503  \n","[2022-04-18 05:15:26,781][experiments.experiment][INFO] - [no EMA] Epoch 23. [Validation] testing_loss: 0.6256, test Top1 acc:84.04, test Top5 acc: 99.3\n","[2022-04-18 05:15:26,845][experiments.experiment][INFO] - [Checkpoints] Epoch 23, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_23.pth.tar\n","[2022-04-18 05:15:26,846][experiments.experiment][INFO] - ***** Running training *****\n","epoch 24: use 442.57288908958435 seconds\n","--- Optimizer learning rate changed from 2.88e-02 to 2.87e-02 ---\n","[2022-04-18 05:22:49,419][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:22:50,746][experiments.experiment][INFO] - [no EMA] Epoch 24. [Train] time:442.57288908958435 seconds, lr:0.0287, train_loss: 0.3442, unlabeled_losses_real_strong:0.7103,corrrect_unlabeled_num:363448.0,pro_above_threshold_num:376495.0,unlabelled_weak_top1_acc:89.57039862126112,unlabelled_weak_top5_acc:99.49994697421789  \n","[2022-04-18 05:22:50,747][experiments.experiment][INFO] - [no EMA] Epoch 24. [Validation] testing_loss: 0.5868, test Top1 acc:84.46, test Top5 acc: 99.0\n","[2022-04-18 05:22:50,748][experiments.experiment][INFO] - ***** Running training *****\n","epoch 25: use 446.7859263420105 seconds\n","--- Optimizer learning rate changed from 2.87e-02 to 2.86e-02 ---\n","[2022-04-18 05:30:17,534][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:30:18,900][experiments.experiment][INFO] - [no EMA] Epoch 25. [Train] time:446.7859263420105 seconds, lr:0.0286, train_loss: 0.3410, unlabeled_losses_real_strong:0.6982,corrrect_unlabeled_num:366306.0,pro_above_threshold_num:378911.0,unlabelled_weak_top1_acc:89.88669154047966,unlabelled_weak_top5_acc:99.51716785132885  \n","[2022-04-18 05:30:18,901][experiments.experiment][INFO] - [no EMA] Epoch 25. [Validation] testing_loss: 0.5607, test Top1 acc:85.5, test Top5 acc: 99.46\n","[2022-04-18 05:30:18,964][experiments.experiment][INFO] - [Checkpoints] Epoch 25, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_25.pth.tar\n","[2022-04-18 05:30:18,964][experiments.experiment][INFO] - ***** Running training *****\n","epoch 26: use 444.9734754562378 seconds\n","--- Optimizer learning rate changed from 2.86e-02 to 2.85e-02 ---\n","[2022-04-18 05:37:43,938][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:37:45,306][experiments.experiment][INFO] - [no EMA] Epoch 26. [Train] time:444.9734754562378 seconds, lr:0.0285, train_loss: 0.3389, unlabeled_losses_real_strong:0.6955,corrrect_unlabeled_num:365835.0,pro_above_threshold_num:378218.0,unlabelled_weak_top1_acc:89.92527444660664,unlabelled_weak_top5_acc:99.52436146140099  \n","[2022-04-18 05:37:45,307][experiments.experiment][INFO] - [no EMA] Epoch 26. [Validation] testing_loss: 0.5865, test Top1 acc:85.3, test Top5 acc: 99.02\n","[2022-04-18 05:37:45,308][experiments.experiment][INFO] - ***** Running training *****\n","epoch 27: use 445.94363713264465 seconds\n","--- Optimizer learning rate changed from 2.85e-02 to 2.84e-02 ---\n","[2022-04-18 05:45:11,252][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:45:12,566][experiments.experiment][INFO] - [no EMA] Epoch 27. [Train] time:445.94363713264465 seconds, lr:0.0284, train_loss: 0.3356, unlabeled_losses_real_strong:0.6830,corrrect_unlabeled_num:368212.0,pro_above_threshold_num:380433.0,unlabelled_weak_top1_acc:90.12908831983805,unlabelled_weak_top5_acc:99.55357105284929  \n","[2022-04-18 05:45:12,567][experiments.experiment][INFO] - [no EMA] Epoch 27. [Validation] testing_loss: 0.5383, test Top1 acc:85.96, test Top5 acc: 99.26\n","[2022-04-18 05:45:12,630][experiments.experiment][INFO] - [Checkpoints] Epoch 27, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_27.pth.tar\n","[2022-04-18 05:45:12,631][experiments.experiment][INFO] - ***** Running training *****\n","epoch 28: use 441.86370062828064 seconds\n","--- Optimizer learning rate changed from 2.84e-02 to 2.82e-02 ---\n","[2022-04-18 05:52:34,495][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 05:52:35,829][experiments.experiment][INFO] - [no EMA] Epoch 28. [Train] time:441.86370062828064 seconds, lr:0.0282, train_loss: 0.3331, unlabeled_losses_real_strong:0.6753,corrrect_unlabeled_num:369959.0,pro_above_threshold_num:382341.0,unlabelled_weak_top1_acc:90.28342014551163,unlabelled_weak_top5_acc:99.55400721728802  \n","[2022-04-18 05:52:35,831][experiments.experiment][INFO] - [no EMA] Epoch 28. [Validation] testing_loss: 0.5223, test Top1 acc:86.32, test Top5 acc: 99.12\n","[2022-04-18 05:52:35,831][experiments.experiment][INFO] - ***** Running training *****\n","epoch 29: use 446.6192202568054 seconds\n","--- Optimizer learning rate changed from 2.82e-02 to 2.81e-02 ---\n","[2022-04-18 06:00:02,451][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:00:03,847][experiments.experiment][INFO] - [no EMA] Epoch 29. [Train] time:446.6192202568054 seconds, lr:0.0281, train_loss: 0.3292, unlabeled_losses_real_strong:0.6708,corrrect_unlabeled_num:370766.0,pro_above_threshold_num:382761.0,unlabelled_weak_top1_acc:90.39197523146868,unlabelled_weak_top5_acc:99.56686819344759  \n","[2022-04-18 06:00:03,849][experiments.experiment][INFO] - [no EMA] Epoch 29. [Validation] testing_loss: 0.5724, test Top1 acc:85.08, test Top5 acc: 99.06\n","[2022-04-18 06:00:03,910][experiments.experiment][INFO] - [Checkpoints] Epoch 29, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_29.pth.tar\n","[2022-04-18 06:00:03,911][experiments.experiment][INFO] - ***** Running training *****\n","epoch 30: use 444.9224691390991 seconds\n","--- Optimizer learning rate changed from 2.81e-02 to 2.80e-02 ---\n","[2022-04-18 06:07:28,833][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:07:30,258][experiments.experiment][INFO] - [no EMA] Epoch 30. [Train] time:444.9224691390991 seconds, lr:0.0280, train_loss: 0.3276, unlabeled_losses_real_strong:0.6633,corrrect_unlabeled_num:371876.0,pro_above_threshold_num:383789.0,unlabelled_weak_top1_acc:90.504672460258,unlabelled_weak_top5_acc:99.58147314935923  \n","[2022-04-18 06:07:30,260][experiments.experiment][INFO] - [no EMA] Epoch 30. [Validation] testing_loss: 0.4409, test Top1 acc:88.5, test Top5 acc: 99.4\n","[2022-04-18 06:07:30,260][experiments.experiment][INFO] - ***** Running training *****\n","epoch 31: use 443.9156448841095 seconds\n","--- Optimizer learning rate changed from 2.80e-02 to 2.79e-02 ---\n","[2022-04-18 06:14:54,176][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:14:55,567][experiments.experiment][INFO] - [no EMA] Epoch 31. [Train] time:443.9156448841095 seconds, lr:0.0279, train_loss: 0.3272, unlabeled_losses_real_strong:0.6583,corrrect_unlabeled_num:373312.0,pro_above_threshold_num:385212.0,unlabelled_weak_top1_acc:90.6409116089344,unlabelled_weak_top5_acc:99.57863922417164  \n","[2022-04-18 06:14:55,569][experiments.experiment][INFO] - [no EMA] Epoch 31. [Validation] testing_loss: 0.4568, test Top1 acc:87.28, test Top5 acc: 99.48\n","[2022-04-18 06:14:55,629][experiments.experiment][INFO] - [Checkpoints] Epoch 31, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_31.pth.tar\n","[2022-04-18 06:14:55,630][experiments.experiment][INFO] - ***** Running training *****\n","epoch 32: use 444.062518119812 seconds\n","--- Optimizer learning rate changed from 2.79e-02 to 2.78e-02 ---\n","[2022-04-18 06:22:19,693][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:22:21,109][experiments.experiment][INFO] - [no EMA] Epoch 32. [Train] time:444.062518119812 seconds, lr:0.0278, train_loss: 0.3236, unlabeled_losses_real_strong:0.6510,corrrect_unlabeled_num:374393.0,pro_above_threshold_num:386046.0,unlabelled_weak_top1_acc:90.80701443552971,unlabelled_weak_top5_acc:99.60784907639027  \n","[2022-04-18 06:22:21,111][experiments.experiment][INFO] - [no EMA] Epoch 32. [Validation] testing_loss: 0.5877, test Top1 acc:85.06, test Top5 acc: 99.1\n","[2022-04-18 06:22:21,112][experiments.experiment][INFO] - ***** Running training *****\n","epoch 33: use 445.33758020401 seconds\n","--- Optimizer learning rate changed from 2.78e-02 to 2.76e-02 ---\n","[2022-04-18 06:29:46,450][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:29:47,807][experiments.experiment][INFO] - [no EMA] Epoch 33. [Train] time:445.33758020401 seconds, lr:0.0276, train_loss: 0.3203, unlabeled_losses_real_strong:0.6434,corrrect_unlabeled_num:375511.0,pro_above_threshold_num:387090.0,unlabelled_weak_top1_acc:90.9177496433258,unlabelled_weak_top5_acc:99.61329883337021  \n","[2022-04-18 06:29:47,809][experiments.experiment][INFO] - [no EMA] Epoch 33. [Validation] testing_loss: 0.4813, test Top1 acc:87.6, test Top5 acc: 99.34\n","[2022-04-18 06:29:47,870][experiments.experiment][INFO] - [Checkpoints] Epoch 33, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_33.pth.tar\n","[2022-04-18 06:29:47,870][experiments.experiment][INFO] - ***** Running training *****\n","epoch 34: use 443.612512588501 seconds\n","--- Optimizer learning rate changed from 2.76e-02 to 2.75e-02 ---\n","[2022-04-18 06:37:11,483][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:37:12,815][experiments.experiment][INFO] - [no EMA] Epoch 34. [Train] time:443.612512588501 seconds, lr:0.0275, train_loss: 0.3202, unlabeled_losses_real_strong:0.6401,corrrect_unlabeled_num:376511.0,pro_above_threshold_num:388162.0,unlabelled_weak_top1_acc:91.0387300401926,unlabelled_weak_top5_acc:99.61722234636545  \n","[2022-04-18 06:37:12,817][experiments.experiment][INFO] - [no EMA] Epoch 34. [Validation] testing_loss: 0.5356, test Top1 acc:86.46, test Top5 acc: 98.94\n","[2022-04-18 06:37:12,817][experiments.experiment][INFO] - ***** Running training *****\n","epoch 35: use 442.18535351753235 seconds\n","--- Optimizer learning rate changed from 2.75e-02 to 2.73e-02 ---\n","[2022-04-18 06:44:35,003][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:44:36,336][experiments.experiment][INFO] - [no EMA] Epoch 35. [Train] time:442.18535351753235 seconds, lr:0.0273, train_loss: 0.3193, unlabeled_losses_real_strong:0.6336,corrrect_unlabeled_num:377854.0,pro_above_threshold_num:389342.0,unlabelled_weak_top1_acc:91.14772123843431,unlabelled_weak_top5_acc:99.61482461541891  \n","[2022-04-18 06:44:36,337][experiments.experiment][INFO] - [no EMA] Epoch 35. [Validation] testing_loss: 0.4589, test Top1 acc:87.16, test Top5 acc: 99.08\n","[2022-04-18 06:44:36,400][experiments.experiment][INFO] - [Checkpoints] Epoch 35, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_35.pth.tar\n","[2022-04-18 06:44:36,401][experiments.experiment][INFO] - ***** Running training *****\n","epoch 36: use 443.4085259437561 seconds\n","--- Optimizer learning rate changed from 2.73e-02 to 2.72e-02 ---\n","[2022-04-18 06:51:59,809][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:52:01,198][experiments.experiment][INFO] - [no EMA] Epoch 36. [Train] time:443.4085259437561 seconds, lr:0.0272, train_loss: 0.3169, unlabeled_losses_real_strong:0.6292,corrrect_unlabeled_num:378515.0,pro_above_threshold_num:390107.0,unlabelled_weak_top1_acc:91.25540487468243,unlabelled_weak_top5_acc:99.6385847851634  \n","[2022-04-18 06:52:01,200][experiments.experiment][INFO] - [no EMA] Epoch 36. [Validation] testing_loss: 0.4609, test Top1 acc:87.78, test Top5 acc: 99.24\n","[2022-04-18 06:52:01,200][experiments.experiment][INFO] - ***** Running training *****\n","epoch 37: use 450.9190676212311 seconds\n","--- Optimizer learning rate changed from 2.72e-02 to 2.71e-02 ---\n","[2022-04-18 06:59:32,120][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 06:59:33,499][experiments.experiment][INFO] - [no EMA] Epoch 37. [Train] time:450.9190676212311 seconds, lr:0.0271, train_loss: 0.3169, unlabeled_losses_real_strong:0.6249,corrrect_unlabeled_num:379307.0,pro_above_threshold_num:390745.0,unlabelled_weak_top1_acc:91.32733908295631,unlabelled_weak_top5_acc:99.64643222093582  \n","[2022-04-18 06:59:33,501][experiments.experiment][INFO] - [no EMA] Epoch 37. [Validation] testing_loss: 0.5656, test Top1 acc:84.58, test Top5 acc: 99.32\n","[2022-04-18 06:59:33,560][experiments.experiment][INFO] - [Checkpoints] Epoch 37, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_37.pth.tar\n","[2022-04-18 06:59:33,561][experiments.experiment][INFO] - ***** Running training *****\n","epoch 38: use 453.58479952812195 seconds\n","--- Optimizer learning rate changed from 2.71e-02 to 2.69e-02 ---\n","[2022-04-18 07:07:07,146][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:07:08,563][experiments.experiment][INFO] - [no EMA] Epoch 38. [Train] time:453.58479952812195 seconds, lr:0.0269, train_loss: 0.3148, unlabeled_losses_real_strong:0.6203,corrrect_unlabeled_num:380361.0,pro_above_threshold_num:391729.0,unlabelled_weak_top1_acc:91.42935506254435,unlabelled_weak_top5_acc:99.63182719051838  \n","[2022-04-18 07:07:08,564][experiments.experiment][INFO] - [no EMA] Epoch 38. [Validation] testing_loss: 0.4391, test Top1 acc:87.68, test Top5 acc: 99.54\n","[2022-04-18 07:07:08,565][experiments.experiment][INFO] - ***** Running training *****\n","epoch 39: use 452.7594757080078 seconds\n","--- Optimizer learning rate changed from 2.69e-02 to 2.68e-02 ---\n","[2022-04-18 07:14:41,324][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:14:42,664][experiments.experiment][INFO] - [no EMA] Epoch 39. [Train] time:452.7594757080078 seconds, lr:0.0268, train_loss: 0.3100, unlabeled_losses_real_strong:0.6156,corrrect_unlabeled_num:381270.0,pro_above_threshold_num:392614.0,unlabelled_weak_top1_acc:91.53442268073559,unlabelled_weak_top5_acc:99.6403286382556  \n","[2022-04-18 07:14:42,665][experiments.experiment][INFO] - [no EMA] Epoch 39. [Validation] testing_loss: 0.6512, test Top1 acc:84.3, test Top5 acc: 98.68\n","[2022-04-18 07:14:42,727][experiments.experiment][INFO] - [Checkpoints] Epoch 39, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_39.pth.tar\n","[2022-04-18 07:14:42,727][experiments.experiment][INFO] - ***** Running training *****\n","epoch 40: use 453.3881685733795 seconds\n","--- Optimizer learning rate changed from 2.68e-02 to 2.66e-02 ---\n","[2022-04-18 07:22:16,116][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:22:17,478][experiments.experiment][INFO] - [no EMA] Epoch 40. [Train] time:453.3881685733795 seconds, lr:0.0266, train_loss: 0.3108, unlabeled_losses_real_strong:0.6115,corrrect_unlabeled_num:382375.0,pro_above_threshold_num:393461.0,unlabelled_weak_top1_acc:91.66194263845682,unlabelled_weak_top5_acc:99.6536255851388  \n","[2022-04-18 07:22:17,480][experiments.experiment][INFO] - [no EMA] Epoch 40. [Validation] testing_loss: 0.4386, test Top1 acc:88.14, test Top5 acc: 99.42\n","[2022-04-18 07:22:17,480][experiments.experiment][INFO] - ***** Running training *****\n","epoch 41: use 454.9163942337036 seconds\n","--- Optimizer learning rate changed from 2.66e-02 to 2.64e-02 ---\n","[2022-04-18 07:29:52,397][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:29:53,787][experiments.experiment][INFO] - [no EMA] Epoch 41. [Train] time:454.9163942337036 seconds, lr:0.0264, train_loss: 0.3098, unlabeled_losses_real_strong:0.6065,corrrect_unlabeled_num:382903.0,pro_above_threshold_num:394181.0,unlabelled_weak_top1_acc:91.69420402497053,unlabelled_weak_top5_acc:99.64839413762093  \n","[2022-04-18 07:29:53,789][experiments.experiment][INFO] - [no EMA] Epoch 41. [Validation] testing_loss: 0.4348, test Top1 acc:89.12, test Top5 acc: 99.54\n","[2022-04-18 07:29:53,852][experiments.experiment][INFO] - [Checkpoints] Epoch 41, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_41.pth.tar\n","[2022-04-18 07:29:53,855][experiments.experiment][INFO] - ***** Running training *****\n","epoch 42: use 454.4959716796875 seconds\n","--- Optimizer learning rate changed from 2.64e-02 to 2.63e-02 ---\n","[2022-04-18 07:37:28,351][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:37:29,740][experiments.experiment][INFO] - [no EMA] Epoch 42. [Train] time:454.4959716796875 seconds, lr:0.0263, train_loss: 0.3082, unlabeled_losses_real_strong:0.6007,corrrect_unlabeled_num:383535.0,pro_above_threshold_num:394432.0,unlabelled_weak_top1_acc:91.8310971930623,unlabelled_weak_top5_acc:99.66932038962841  \n","[2022-04-18 07:37:29,741][experiments.experiment][INFO] - [no EMA] Epoch 42. [Validation] testing_loss: 0.4536, test Top1 acc:88.12, test Top5 acc: 99.6\n","[2022-04-18 07:37:29,742][experiments.experiment][INFO] - ***** Running training *****\n","epoch 43: use 455.83670711517334 seconds\n","--- Optimizer learning rate changed from 2.63e-02 to 2.61e-02 ---\n","[2022-04-18 07:45:05,579][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:45:06,998][experiments.experiment][INFO] - [no EMA] Epoch 43. [Train] time:455.83670711517334 seconds, lr:0.0261, train_loss: 0.3065, unlabeled_losses_real_strong:0.5985,corrrect_unlabeled_num:383786.0,pro_above_threshold_num:394724.0,unlabelled_weak_top1_acc:91.8572550714016,unlabelled_weak_top5_acc:99.65907523781061  \n","[2022-04-18 07:45:06,999][experiments.experiment][INFO] - [no EMA] Epoch 43. [Validation] testing_loss: 0.3931, test Top1 acc:89.74, test Top5 acc: 99.58\n","[2022-04-18 07:45:07,061][experiments.experiment][INFO] - [Checkpoints] Epoch 43, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_43.pth.tar\n","[2022-04-18 07:45:07,062][experiments.experiment][INFO] - ***** Running training *****\n","epoch 44: use 451.95925879478455 seconds\n","--- Optimizer learning rate changed from 2.61e-02 to 2.59e-02 ---\n","[2022-04-18 07:52:39,021][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 07:52:40,421][experiments.experiment][INFO] - [no EMA] Epoch 44. [Train] time:451.95925879478455 seconds, lr:0.0259, train_loss: 0.3048, unlabeled_losses_real_strong:0.5901,corrrect_unlabeled_num:384918.0,pro_above_threshold_num:395841.0,unlabelled_weak_top1_acc:91.90673716366291,unlabelled_weak_top5_acc:99.66038303077221  \n","[2022-04-18 07:52:40,423][experiments.experiment][INFO] - [no EMA] Epoch 44. [Validation] testing_loss: 0.4191, test Top1 acc:88.82, test Top5 acc: 99.6\n","[2022-04-18 07:52:40,423][experiments.experiment][INFO] - ***** Running training *****\n","epoch 45: use 451.6865301132202 seconds\n","--- Optimizer learning rate changed from 2.59e-02 to 2.58e-02 ---\n","[2022-04-18 08:00:12,110][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:00:13,428][experiments.experiment][INFO] - [no EMA] Epoch 45. [Train] time:451.6865301132202 seconds, lr:0.0258, train_loss: 0.3025, unlabeled_losses_real_strong:0.5879,corrrect_unlabeled_num:385939.0,pro_above_threshold_num:396810.0,unlabelled_weak_top1_acc:92.06564647704363,unlabelled_weak_top5_acc:99.67869365215302  \n","[2022-04-18 08:00:13,430][experiments.experiment][INFO] - [no EMA] Epoch 45. [Validation] testing_loss: 0.4769, test Top1 acc:87.66, test Top5 acc: 99.5\n","[2022-04-18 08:00:13,488][experiments.experiment][INFO] - [Checkpoints] Epoch 45, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_45.pth.tar\n","[2022-04-18 08:00:13,489][experiments.experiment][INFO] - ***** Running training *****\n","epoch 46: use 443.6704831123352 seconds\n","--- Optimizer learning rate changed from 2.58e-02 to 2.56e-02 ---\n","[2022-04-18 08:07:37,160][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:07:38,508][experiments.experiment][INFO] - [no EMA] Epoch 46. [Train] time:443.6704831123352 seconds, lr:0.0256, train_loss: 0.3041, unlabeled_losses_real_strong:0.5861,corrrect_unlabeled_num:385993.0,pro_above_threshold_num:396871.0,unlabelled_weak_top1_acc:92.08330319076777,unlabelled_weak_top5_acc:99.66081909835339  \n","[2022-04-18 08:07:38,511][experiments.experiment][INFO] - [no EMA] Epoch 46. [Validation] testing_loss: 0.4352, test Top1 acc:88.48, test Top5 acc: 99.32\n","[2022-04-18 08:07:38,512][experiments.experiment][INFO] - ***** Running training *****\n","epoch 47: use 443.92822790145874 seconds\n","--- Optimizer learning rate changed from 2.56e-02 to 2.54e-02 ---\n","[2022-04-18 08:15:02,440][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:15:03,826][experiments.experiment][INFO] - [no EMA] Epoch 47. [Train] time:443.92822790145874 seconds, lr:0.0254, train_loss: 0.2998, unlabeled_losses_real_strong:0.5784,corrrect_unlabeled_num:387621.0,pro_above_threshold_num:398195.0,unlabelled_weak_top1_acc:92.27207607030869,unlabelled_weak_top5_acc:99.68000154942274  \n","[2022-04-18 08:15:03,827][experiments.experiment][INFO] - [no EMA] Epoch 47. [Validation] testing_loss: 0.4413, test Top1 acc:88.4, test Top5 acc: 99.52\n","[2022-04-18 08:15:03,891][experiments.experiment][INFO] - [Checkpoints] Epoch 47, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_47.pth.tar\n","[2022-04-18 08:15:03,891][experiments.experiment][INFO] - ***** Running training *****\n","epoch 48: use 440.9593918323517 seconds\n","--- Optimizer learning rate changed from 2.54e-02 to 2.52e-02 ---\n","[2022-04-18 08:22:24,851][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:22:26,199][experiments.experiment][INFO] - [no EMA] Epoch 48. [Train] time:440.9593918323517 seconds, lr:0.0252, train_loss: 0.2985, unlabeled_losses_real_strong:0.5739,corrrect_unlabeled_num:388065.0,pro_above_threshold_num:398613.0,unlabelled_weak_top1_acc:92.32155830413103,unlabelled_weak_top5_acc:99.6647427752614  \n","[2022-04-18 08:22:26,201][experiments.experiment][INFO] - [no EMA] Epoch 48. [Validation] testing_loss: 0.4562, test Top1 acc:86.88, test Top5 acc: 99.42\n","[2022-04-18 08:22:26,201][experiments.experiment][INFO] - ***** Running training *****\n","epoch 49: use 443.9383144378662 seconds\n","--- Optimizer learning rate changed from 2.52e-02 to 2.50e-02 ---\n","[2022-04-18 08:29:50,140][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:29:51,517][experiments.experiment][INFO] - [no EMA] Epoch 49. [Train] time:443.9383144378662 seconds, lr:0.0250, train_loss: 0.2960, unlabeled_losses_real_strong:0.5732,corrrect_unlabeled_num:388194.0,pro_above_threshold_num:399047.0,unlabelled_weak_top1_acc:92.27643582969904,unlabelled_weak_top5_acc:99.67956572026014  \n","[2022-04-18 08:29:51,519][experiments.experiment][INFO] - [no EMA] Epoch 49. [Validation] testing_loss: 0.5192, test Top1 acc:87.26, test Top5 acc: 99.48\n","[2022-04-18 08:29:51,578][experiments.experiment][INFO] - [Checkpoints] Epoch 49, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_49.pth.tar\n","[2022-04-18 08:29:51,579][experiments.experiment][INFO] - ***** Running training *****\n","epoch 50: use 444.44636583328247 seconds\n","--- Optimizer learning rate changed from 2.50e-02 to 2.48e-02 ---\n","[2022-04-18 08:37:16,025][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:37:17,442][experiments.experiment][INFO] - [no EMA] Epoch 50. [Train] time:444.44636583328247 seconds, lr:0.0248, train_loss: 0.2986, unlabeled_losses_real_strong:0.5709,corrrect_unlabeled_num:389070.0,pro_above_threshold_num:399609.0,unlabelled_weak_top1_acc:92.34161270409822,unlabelled_weak_top5_acc:99.70136401057243  \n","[2022-04-18 08:37:17,444][experiments.experiment][INFO] - [no EMA] Epoch 50. [Validation] testing_loss: 0.3687, test Top1 acc:89.92, test Top5 acc: 99.64\n","[2022-04-18 08:37:17,444][experiments.experiment][INFO] - ***** Running training *****\n","epoch 51: use 443.8537721633911 seconds\n","--- Optimizer learning rate changed from 2.48e-02 to 2.46e-02 ---\n","[2022-04-18 08:44:41,298][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:44:42,652][experiments.experiment][INFO] - [no EMA] Epoch 51. [Train] time:443.8537721633911 seconds, lr:0.0246, train_loss: 0.2944, unlabeled_losses_real_strong:0.5643,corrrect_unlabeled_num:390129.0,pro_above_threshold_num:400507.0,unlabelled_weak_top1_acc:92.49485445022583,unlabelled_weak_top5_acc:99.69983804225922  \n","[2022-04-18 08:44:42,654][experiments.experiment][INFO] - [no EMA] Epoch 51. [Validation] testing_loss: 0.3390, test Top1 acc:91.1, test Top5 acc: 99.66\n","[2022-04-18 08:44:42,716][experiments.experiment][INFO] - [Checkpoints] Epoch 51, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_51.pth.tar\n","[2022-04-18 08:44:42,717][experiments.experiment][INFO] - ***** Running training *****\n","epoch 52: use 445.5928204059601 seconds\n","--- Optimizer learning rate changed from 2.46e-02 to 2.44e-02 ---\n","[2022-04-18 08:52:08,310][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:52:09,729][experiments.experiment][INFO] - [no EMA] Epoch 52. [Train] time:445.5928204059601 seconds, lr:0.0244, train_loss: 0.2949, unlabeled_losses_real_strong:0.5625,corrrect_unlabeled_num:390379.0,pro_above_threshold_num:400964.0,unlabelled_weak_top1_acc:92.52951380610466,unlabelled_weak_top5_acc:99.6902468726039  \n","[2022-04-18 08:52:09,731][experiments.experiment][INFO] - [no EMA] Epoch 52. [Validation] testing_loss: 0.3879, test Top1 acc:90.34, test Top5 acc: 99.6\n","[2022-04-18 08:52:09,731][experiments.experiment][INFO] - ***** Running training *****\n","epoch 53: use 446.4110794067383 seconds\n","--- Optimizer learning rate changed from 2.44e-02 to 2.42e-02 ---\n","[2022-04-18 08:59:36,143][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 08:59:37,482][experiments.experiment][INFO] - [no EMA] Epoch 53. [Train] time:446.4110794067383 seconds, lr:0.0242, train_loss: 0.2928, unlabeled_losses_real_strong:0.5571,corrrect_unlabeled_num:390942.0,pro_above_threshold_num:401407.0,unlabelled_weak_top1_acc:92.54215679317713,unlabelled_weak_top5_acc:99.68697706609964  \n","[2022-04-18 08:59:37,484][experiments.experiment][INFO] - [no EMA] Epoch 53. [Validation] testing_loss: 0.3666, test Top1 acc:90.22, test Top5 acc: 99.68\n","[2022-04-18 08:59:37,543][experiments.experiment][INFO] - [Checkpoints] Epoch 53, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_53.pth.tar\n","[2022-04-18 08:59:37,544][experiments.experiment][INFO] - ***** Running training *****\n","epoch 54: use 444.6214928627014 seconds\n","--- Optimizer learning rate changed from 2.42e-02 to 2.40e-02 ---\n","[2022-04-18 09:07:02,165][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:07:03,457][experiments.experiment][INFO] - [no EMA] Epoch 54. [Train] time:444.6214928627014 seconds, lr:0.0240, train_loss: 0.2925, unlabeled_losses_real_strong:0.5563,corrrect_unlabeled_num:391778.0,pro_above_threshold_num:402016.0,unlabelled_weak_top1_acc:92.65572566539049,unlabelled_weak_top5_acc:99.7116092517972  \n","[2022-04-18 09:07:03,458][experiments.experiment][INFO] - [no EMA] Epoch 54. [Validation] testing_loss: 0.3886, test Top1 acc:89.3, test Top5 acc: 99.58\n","[2022-04-18 09:07:03,459][experiments.experiment][INFO] - ***** Running training *****\n","epoch 55: use 442.3627665042877 seconds\n","--- Optimizer learning rate changed from 2.40e-02 to 2.38e-02 ---\n","[2022-04-18 09:14:25,822][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:14:27,180][experiments.experiment][INFO] - [no EMA] Epoch 55. [Train] time:442.3627665042877 seconds, lr:0.0238, train_loss: 0.2878, unlabeled_losses_real_strong:0.5534,corrrect_unlabeled_num:391644.0,pro_above_threshold_num:401914.0,unlabelled_weak_top1_acc:92.63828723877668,unlabelled_weak_top5_acc:99.70071008056402  \n","[2022-04-18 09:14:27,182][experiments.experiment][INFO] - [no EMA] Epoch 55. [Validation] testing_loss: 0.3916, test Top1 acc:89.9, test Top5 acc: 99.54\n","[2022-04-18 09:14:27,240][experiments.experiment][INFO] - [Checkpoints] Epoch 55, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_55.pth.tar\n","[2022-04-18 09:14:27,241][experiments.experiment][INFO] - ***** Running training *****\n","epoch 56: use 442.88417410850525 seconds\n","--- Optimizer learning rate changed from 2.38e-02 to 2.36e-02 ---\n","[2022-04-18 09:21:50,126][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:21:51,513][experiments.experiment][INFO] - [no EMA] Epoch 56. [Train] time:442.88417410850525 seconds, lr:0.0236, train_loss: 0.2890, unlabeled_losses_real_strong:0.5496,corrrect_unlabeled_num:392719.0,pro_above_threshold_num:402937.0,unlabelled_weak_top1_acc:92.7468425706029,unlabelled_weak_top5_acc:99.72403429448605  \n","[2022-04-18 09:21:51,515][experiments.experiment][INFO] - [no EMA] Epoch 56. [Validation] testing_loss: 0.4073, test Top1 acc:89.9, test Top5 acc: 99.78\n","[2022-04-18 09:21:51,515][experiments.experiment][INFO] - ***** Running training *****\n","epoch 57: use 444.8495330810547 seconds\n","--- Optimizer learning rate changed from 2.36e-02 to 2.34e-02 ---\n","[2022-04-18 09:29:16,365][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:29:17,700][experiments.experiment][INFO] - [no EMA] Epoch 57. [Train] time:444.8495330810547 seconds, lr:0.0234, train_loss: 0.2869, unlabeled_losses_real_strong:0.5466,corrrect_unlabeled_num:392625.0,pro_above_threshold_num:402752.0,unlabelled_weak_top1_acc:92.78368157148361,unlabelled_weak_top5_acc:99.71575095504522  \n","[2022-04-18 09:29:17,700][experiments.experiment][INFO] - [no EMA] Epoch 57. [Validation] testing_loss: 0.3465, test Top1 acc:90.26, test Top5 acc: 99.62\n","[2022-04-18 09:29:17,760][experiments.experiment][INFO] - [Checkpoints] Epoch 57, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_57.pth.tar\n","[2022-04-18 09:29:17,761][experiments.experiment][INFO] - ***** Running training *****\n","epoch 58: use 443.358083486557 seconds\n","--- Optimizer learning rate changed from 2.34e-02 to 2.32e-02 ---\n","[2022-04-18 09:36:41,119][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:36:42,481][experiments.experiment][INFO] - [no EMA] Epoch 58. [Train] time:443.358083486557 seconds, lr:0.0232, train_loss: 0.2883, unlabeled_losses_real_strong:0.5444,corrrect_unlabeled_num:393472.0,pro_above_threshold_num:403706.0,unlabelled_weak_top1_acc:92.81659699231386,unlabelled_weak_top5_acc:99.7159688398242  \n","[2022-04-18 09:36:42,483][experiments.experiment][INFO] - [no EMA] Epoch 58. [Validation] testing_loss: 0.3474, test Top1 acc:90.04, test Top5 acc: 99.78\n","[2022-04-18 09:36:42,483][experiments.experiment][INFO] - ***** Running training *****\n","epoch 59: use 444.10091853141785 seconds\n","--- Optimizer learning rate changed from 2.32e-02 to 2.30e-02 ---\n","[2022-04-18 09:44:06,584][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:44:07,974][experiments.experiment][INFO] - [no EMA] Epoch 59. [Train] time:444.10091853141785 seconds, lr:0.0230, train_loss: 0.2865, unlabeled_losses_real_strong:0.5395,corrrect_unlabeled_num:394165.0,pro_above_threshold_num:404234.0,unlabelled_weak_top1_acc:92.95065630972385,unlabelled_weak_top5_acc:99.72207237780094  \n","[2022-04-18 09:44:07,975][experiments.experiment][INFO] - [no EMA] Epoch 59. [Validation] testing_loss: 0.3876, test Top1 acc:89.76, test Top5 acc: 99.74\n","[2022-04-18 09:44:08,047][experiments.experiment][INFO] - [Checkpoints] Epoch 59, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_59.pth.tar\n","[2022-04-18 09:44:08,048][experiments.experiment][INFO] - ***** Running training *****\n","epoch 60: use 442.65003657341003 seconds\n","--- Optimizer learning rate changed from 2.30e-02 to 2.27e-02 ---\n","[2022-04-18 09:51:30,698][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:51:32,113][experiments.experiment][INFO] - [no EMA] Epoch 60. [Train] time:442.65003657341003 seconds, lr:0.0227, train_loss: 0.2832, unlabeled_losses_real_strong:0.5348,corrrect_unlabeled_num:394665.0,pro_above_threshold_num:404683.0,unlabelled_weak_top1_acc:93.0345797687769,unlabelled_weak_top5_acc:99.72098258882761  \n","[2022-04-18 09:51:32,114][experiments.experiment][INFO] - [no EMA] Epoch 60. [Validation] testing_loss: 0.3553, test Top1 acc:90.78, test Top5 acc: 99.7\n","[2022-04-18 09:51:32,115][experiments.experiment][INFO] - ***** Running training *****\n","epoch 61: use 443.32395458221436 seconds\n","--- Optimizer learning rate changed from 2.27e-02 to 2.25e-02 ---\n","[2022-04-18 09:58:55,439][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 09:58:56,777][experiments.experiment][INFO] - [no EMA] Epoch 61. [Train] time:443.32395458221436 seconds, lr:0.0225, train_loss: 0.2818, unlabeled_losses_real_strong:0.5328,corrrect_unlabeled_num:394609.0,pro_above_threshold_num:404575.0,unlabelled_weak_top1_acc:92.99599675834179,unlabelled_weak_top5_acc:99.73645944148302  \n","[2022-04-18 09:58:56,778][experiments.experiment][INFO] - [no EMA] Epoch 61. [Validation] testing_loss: 0.3578, test Top1 acc:90.08, test Top5 acc: 99.66\n","[2022-04-18 09:58:56,838][experiments.experiment][INFO] - [Checkpoints] Epoch 61, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_61.pth.tar\n","[2022-04-18 09:58:56,838][experiments.experiment][INFO] - ***** Running training *****\n","epoch 62: use 445.9511888027191 seconds\n","--- Optimizer learning rate changed from 2.25e-02 to 2.23e-02 ---\n","[2022-04-18 10:06:22,790][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:06:24,135][experiments.experiment][INFO] - [no EMA] Epoch 62. [Train] time:445.9511888027191 seconds, lr:0.0223, train_loss: 0.2828, unlabeled_losses_real_strong:0.5329,corrrect_unlabeled_num:395425.0,pro_above_threshold_num:405451.0,unlabelled_weak_top1_acc:93.04831247776747,unlabelled_weak_top5_acc:99.7320996671915  \n","[2022-04-18 10:06:24,137][experiments.experiment][INFO] - [no EMA] Epoch 62. [Validation] testing_loss: 0.3834, test Top1 acc:89.36, test Top5 acc: 99.48\n","[2022-04-18 10:06:24,138][experiments.experiment][INFO] - ***** Running training *****\n","epoch 63: use 446.0905578136444 seconds\n","--- Optimizer learning rate changed from 2.23e-02 to 2.21e-02 ---\n","[2022-04-18 10:13:50,228][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:13:51,559][experiments.experiment][INFO] - [no EMA] Epoch 63. [Train] time:446.0905578136444 seconds, lr:0.0221, train_loss: 0.2801, unlabeled_losses_real_strong:0.5275,corrrect_unlabeled_num:395641.0,pro_above_threshold_num:405693.0,unlabelled_weak_top1_acc:93.04308100789785,unlabelled_weak_top5_acc:99.7218544408679  \n","[2022-04-18 10:13:51,560][experiments.experiment][INFO] - [no EMA] Epoch 63. [Validation] testing_loss: 0.3912, test Top1 acc:90.12, test Top5 acc: 99.64\n","[2022-04-18 10:13:51,620][experiments.experiment][INFO] - [Checkpoints] Epoch 63, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_63.pth.tar\n","[2022-04-18 10:13:51,621][experiments.experiment][INFO] - ***** Running training *****\n","epoch 64: use 442.3478624820709 seconds\n","--- Optimizer learning rate changed from 2.21e-02 to 2.18e-02 ---\n","[2022-04-18 10:21:13,969][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:21:15,331][experiments.experiment][INFO] - [no EMA] Epoch 64. [Train] time:442.3478624820709 seconds, lr:0.0218, train_loss: 0.2797, unlabeled_losses_real_strong:0.5249,corrrect_unlabeled_num:396406.0,pro_above_threshold_num:406541.0,unlabelled_weak_top1_acc:93.13768549263477,unlabelled_weak_top5_acc:99.74169100821018  \n","[2022-04-18 10:21:15,332][experiments.experiment][INFO] - [no EMA] Epoch 64. [Validation] testing_loss: 0.3478, test Top1 acc:90.52, test Top5 acc: 99.72\n","[2022-04-18 10:21:15,333][experiments.experiment][INFO] - ***** Running training *****\n","epoch 65: use 445.4365589618683 seconds\n","--- Optimizer learning rate changed from 2.18e-02 to 2.16e-02 ---\n","[2022-04-18 10:28:40,770][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:28:42,106][experiments.experiment][INFO] - [no EMA] Epoch 65. [Train] time:445.4365589618683 seconds, lr:0.0216, train_loss: 0.2766, unlabeled_losses_real_strong:0.5210,corrrect_unlabeled_num:396990.0,pro_above_threshold_num:406713.0,unlabelled_weak_top1_acc:93.2091838568449,unlabelled_weak_top5_acc:99.73951116204262  \n","[2022-04-18 10:28:42,108][experiments.experiment][INFO] - [no EMA] Epoch 65. [Validation] testing_loss: 0.3210, test Top1 acc:90.98, test Top5 acc: 99.58\n","[2022-04-18 10:28:42,173][experiments.experiment][INFO] - [Checkpoints] Epoch 65, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_65.pth.tar\n","[2022-04-18 10:28:42,174][experiments.experiment][INFO] - ***** Running training *****\n","epoch 66: use 445.8991014957428 seconds\n","--- Optimizer learning rate changed from 2.16e-02 to 2.14e-02 ---\n","[2022-04-18 10:36:08,073][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:36:09,532][experiments.experiment][INFO] - [no EMA] Epoch 66. [Train] time:445.8991014957428 seconds, lr:0.0214, train_loss: 0.2755, unlabeled_losses_real_strong:0.5193,corrrect_unlabeled_num:397258.0,pro_above_threshold_num:407143.0,unlabelled_weak_top1_acc:93.25430620461702,unlabelled_weak_top5_acc:99.73100972175598  \n","[2022-04-18 10:36:09,533][experiments.experiment][INFO] - [no EMA] Epoch 66. [Validation] testing_loss: 0.3360, test Top1 acc:91.16, test Top5 acc: 99.78\n","[2022-04-18 10:36:09,534][experiments.experiment][INFO] - ***** Running training *****\n","epoch 67: use 444.5640983581543 seconds\n","--- Optimizer learning rate changed from 2.14e-02 to 2.11e-02 ---\n","[2022-04-18 10:43:34,098][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:43:35,502][experiments.experiment][INFO] - [no EMA] Epoch 67. [Train] time:444.5640983581543 seconds, lr:0.0211, train_loss: 0.2760, unlabeled_losses_real_strong:0.5178,corrrect_unlabeled_num:398032.0,pro_above_threshold_num:407927.0,unlabelled_weak_top1_acc:93.29594088345766,unlabelled_weak_top5_acc:99.74888431280851  \n","[2022-04-18 10:43:35,504][experiments.experiment][INFO] - [no EMA] Epoch 67. [Validation] testing_loss: 0.3451, test Top1 acc:91.14, test Top5 acc: 99.56\n","[2022-04-18 10:43:35,564][experiments.experiment][INFO] - [Checkpoints] Epoch 67, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_67.pth.tar\n","[2022-04-18 10:43:35,565][experiments.experiment][INFO] - ***** Running training *****\n","epoch 68: use 442.7090873718262 seconds\n","--- Optimizer learning rate changed from 2.11e-02 to 2.09e-02 ---\n","[2022-04-18 10:50:58,274][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:50:59,614][experiments.experiment][INFO] - [no EMA] Epoch 68. [Train] time:442.7090873718262 seconds, lr:0.0209, train_loss: 0.2755, unlabeled_losses_real_strong:0.5134,corrrect_unlabeled_num:398265.0,pro_above_threshold_num:408206.0,unlabelled_weak_top1_acc:93.32231680303812,unlabelled_weak_top5_acc:99.73820315301418  \n","[2022-04-18 10:50:59,616][experiments.experiment][INFO] - [no EMA] Epoch 68. [Validation] testing_loss: 0.3312, test Top1 acc:90.98, test Top5 acc: 99.64\n","[2022-04-18 10:50:59,617][experiments.experiment][INFO] - ***** Running training *****\n","epoch 69: use 443.78382897377014 seconds\n","--- Optimizer learning rate changed from 2.09e-02 to 2.06e-02 ---\n","[2022-04-18 10:58:23,401][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 10:58:24,831][experiments.experiment][INFO] - [no EMA] Epoch 69. [Train] time:443.78382897377014 seconds, lr:0.0206, train_loss: 0.2763, unlabeled_losses_real_strong:0.5125,corrrect_unlabeled_num:399590.0,pro_above_threshold_num:409236.0,unlabelled_weak_top1_acc:93.43544990569353,unlabelled_weak_top5_acc:99.73035578429699  \n","[2022-04-18 10:58:24,832][experiments.experiment][INFO] - [no EMA] Epoch 69. [Validation] testing_loss: 0.3694, test Top1 acc:90.4, test Top5 acc: 99.6\n","[2022-04-18 10:58:24,891][experiments.experiment][INFO] - [Checkpoints] Epoch 69, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_69.pth.tar\n","[2022-04-18 10:58:24,892][experiments.experiment][INFO] - ***** Running training *****\n","epoch 70: use 444.04102206230164 seconds\n","--- Optimizer learning rate changed from 2.06e-02 to 2.04e-02 ---\n","[2022-04-18 11:05:48,933][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:05:50,263][experiments.experiment][INFO] - [no EMA] Epoch 70. [Train] time:444.04102206230164 seconds, lr:0.0204, train_loss: 0.2746, unlabeled_losses_real_strong:0.5092,corrrect_unlabeled_num:399594.0,pro_above_threshold_num:409339.0,unlabelled_weak_top1_acc:93.52068115770817,unlabelled_weak_top5_acc:99.73689524829388  \n","[2022-04-18 11:05:50,264][experiments.experiment][INFO] - [no EMA] Epoch 70. [Validation] testing_loss: 0.3469, test Top1 acc:90.64, test Top5 acc: 99.78\n","[2022-04-18 11:05:50,265][experiments.experiment][INFO] - ***** Running training *****\n","epoch 71: use 443.1795735359192 seconds\n","--- Optimizer learning rate changed from 2.04e-02 to 2.01e-02 ---\n","[2022-04-18 11:13:13,444][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:13:14,753][experiments.experiment][INFO] - [no EMA] Epoch 71. [Train] time:443.1795735359192 seconds, lr:0.0201, train_loss: 0.2719, unlabeled_losses_real_strong:0.5054,corrrect_unlabeled_num:400201.0,pro_above_threshold_num:409833.0,unlabelled_weak_top1_acc:93.54335130751133,unlabelled_weak_top5_acc:99.75302607566118  \n","[2022-04-18 11:13:14,754][experiments.experiment][INFO] - [no EMA] Epoch 71. [Validation] testing_loss: 0.3497, test Top1 acc:90.14, test Top5 acc: 99.72\n","[2022-04-18 11:13:14,817][experiments.experiment][INFO] - [Checkpoints] Epoch 71, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_71.pth.tar\n","[2022-04-18 11:13:14,818][experiments.experiment][INFO] - ***** Running training *****\n","epoch 72: use 448.1640148162842 seconds\n","--- Optimizer learning rate changed from 2.01e-02 to 1.99e-02 ---\n","[2022-04-18 11:20:42,982][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:20:44,353][experiments.experiment][INFO] - [no EMA] Epoch 72. [Train] time:448.1640148162842 seconds, lr:0.0199, train_loss: 0.2722, unlabeled_losses_real_strong:0.5017,corrrect_unlabeled_num:401003.0,pro_above_threshold_num:410757.0,unlabelled_weak_top1_acc:93.58193427324295,unlabelled_weak_top5_acc:99.75389797985554  \n","[2022-04-18 11:20:44,355][experiments.experiment][INFO] - [no EMA] Epoch 72. [Validation] testing_loss: 0.3094, test Top1 acc:90.82, test Top5 acc: 99.68\n","[2022-04-18 11:20:44,355][experiments.experiment][INFO] - ***** Running training *****\n","epoch 73: use 450.75450897216797 seconds\n","--- Optimizer learning rate changed from 1.99e-02 to 1.96e-02 ---\n","[2022-04-18 11:28:15,110][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:28:16,458][experiments.experiment][INFO] - [no EMA] Epoch 73. [Train] time:450.75450897216797 seconds, lr:0.0196, train_loss: 0.2696, unlabeled_losses_real_strong:0.4977,corrrect_unlabeled_num:401279.0,pro_above_threshold_num:410792.0,unlabelled_weak_top1_acc:93.63751982152462,unlabelled_weak_top5_acc:99.74866637587547  \n","[2022-04-18 11:28:16,459][experiments.experiment][INFO] - [no EMA] Epoch 73. [Validation] testing_loss: 0.3313, test Top1 acc:91.32, test Top5 acc: 99.8\n","[2022-04-18 11:28:16,527][experiments.experiment][INFO] - [Checkpoints] Epoch 73, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_73.pth.tar\n","[2022-04-18 11:28:16,527][experiments.experiment][INFO] - ***** Running training *****\n","epoch 74: use 457.3141314983368 seconds\n","--- Optimizer learning rate changed from 1.96e-02 to 1.93e-02 ---\n","[2022-04-18 11:35:53,842][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:35:55,291][experiments.experiment][INFO] - [no EMA] Epoch 74. [Train] time:457.3141314983368 seconds, lr:0.0193, train_loss: 0.2669, unlabeled_losses_real_strong:0.4940,corrrect_unlabeled_num:401366.0,pro_above_threshold_num:411037.0,unlabelled_weak_top1_acc:93.65779217332602,unlabelled_weak_top5_acc:99.76348914951086  \n","[2022-04-18 11:35:55,292][experiments.experiment][INFO] - [no EMA] Epoch 74. [Validation] testing_loss: 0.3184, test Top1 acc:91.6, test Top5 acc: 99.78\n","[2022-04-18 11:35:55,293][experiments.experiment][INFO] - ***** Running training *****\n","epoch 75: use 457.6044087409973 seconds\n","--- Optimizer learning rate changed from 1.93e-02 to 1.91e-02 ---\n","[2022-04-18 11:43:32,898][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:43:34,259][experiments.experiment][INFO] - [no EMA] Epoch 75. [Train] time:457.6044087409973 seconds, lr:0.0191, train_loss: 0.2670, unlabeled_losses_real_strong:0.4942,corrrect_unlabeled_num:401771.0,pro_above_threshold_num:411112.0,unlabelled_weak_top1_acc:93.75828229635954,unlabelled_weak_top5_acc:99.77351649850607  \n","[2022-04-18 11:43:34,261][experiments.experiment][INFO] - [no EMA] Epoch 75. [Validation] testing_loss: 0.3150, test Top1 acc:91.06, test Top5 acc: 99.82\n","[2022-04-18 11:43:34,319][experiments.experiment][INFO] - [Checkpoints] Epoch 75, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_75.pth.tar\n","[2022-04-18 11:43:34,320][experiments.experiment][INFO] - ***** Running training *****\n","epoch 76: use 447.05551290512085 seconds\n","--- Optimizer learning rate changed from 1.91e-02 to 1.88e-02 ---\n","[2022-04-18 11:51:01,375][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:51:02,750][experiments.experiment][INFO] - [no EMA] Epoch 76. [Train] time:447.05551290512085 seconds, lr:0.0188, train_loss: 0.2663, unlabeled_losses_real_strong:0.4909,corrrect_unlabeled_num:402629.0,pro_above_threshold_num:412152.0,unlabelled_weak_top1_acc:93.78705585002899,unlabelled_weak_top5_acc:99.75694968551397  \n","[2022-04-18 11:51:02,752][experiments.experiment][INFO] - [no EMA] Epoch 76. [Validation] testing_loss: 0.3796, test Top1 acc:89.86, test Top5 acc: 99.54\n","[2022-04-18 11:51:02,752][experiments.experiment][INFO] - ***** Running training *****\n","epoch 77: use 447.7340531349182 seconds\n","--- Optimizer learning rate changed from 1.88e-02 to 1.85e-02 ---\n","[2022-04-18 11:58:30,487][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 11:58:31,854][experiments.experiment][INFO] - [no EMA] Epoch 77. [Train] time:447.7340531349182 seconds, lr:0.0185, train_loss: 0.2667, unlabeled_losses_real_strong:0.4902,corrrect_unlabeled_num:402815.0,pro_above_threshold_num:412318.0,unlabelled_weak_top1_acc:93.76111596822739,unlabelled_weak_top5_acc:99.76479712128639  \n","[2022-04-18 11:58:31,855][experiments.experiment][INFO] - [no EMA] Epoch 77. [Validation] testing_loss: 0.3174, test Top1 acc:90.32, test Top5 acc: 99.74\n","[2022-04-18 11:58:31,915][experiments.experiment][INFO] - [Checkpoints] Epoch 77, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_77.pth.tar\n","[2022-04-18 11:58:31,916][experiments.experiment][INFO] - ***** Running training *****\n","epoch 78: use 453.9444613456726 seconds\n","--- Optimizer learning rate changed from 1.85e-02 to 1.83e-02 ---\n","[2022-04-18 12:06:05,860][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:06:07,282][experiments.experiment][INFO] - [no EMA] Epoch 78. [Train] time:453.9444613456726 seconds, lr:0.0183, train_loss: 0.2624, unlabeled_losses_real_strong:0.4846,corrrect_unlabeled_num:402951.0,pro_above_threshold_num:412381.0,unlabelled_weak_top1_acc:93.79533947259188,unlabelled_weak_top5_acc:99.77199051529169  \n","[2022-04-18 12:06:07,283][experiments.experiment][INFO] - [no EMA] Epoch 78. [Validation] testing_loss: 0.3237, test Top1 acc:90.72, test Top5 acc: 99.76\n","[2022-04-18 12:06:07,284][experiments.experiment][INFO] - ***** Running training *****\n","epoch 79: use 450.69865798950195 seconds\n","--- Optimizer learning rate changed from 1.83e-02 to 1.80e-02 ---\n","[2022-04-18 12:13:37,983][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:13:39,321][experiments.experiment][INFO] - [no EMA] Epoch 79. [Train] time:450.69865798950195 seconds, lr:0.0180, train_loss: 0.2638, unlabeled_losses_real_strong:0.4849,corrrect_unlabeled_num:403898.0,pro_above_threshold_num:413454.0,unlabelled_weak_top1_acc:93.86858146637678,unlabelled_weak_top5_acc:99.76632299274206  \n","[2022-04-18 12:13:39,323][experiments.experiment][INFO] - [no EMA] Epoch 79. [Validation] testing_loss: 0.3114, test Top1 acc:91.64, test Top5 acc: 99.74\n","[2022-04-18 12:13:39,388][experiments.experiment][INFO] - [Checkpoints] Epoch 79, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_79.pth.tar\n","[2022-04-18 12:13:39,388][experiments.experiment][INFO] - ***** Running training *****\n","epoch 80: use 446.99207186698914 seconds\n","--- Optimizer learning rate changed from 1.80e-02 to 1.77e-02 ---\n","[2022-04-18 12:21:06,380][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:21:07,729][experiments.experiment][INFO] - [no EMA] Epoch 80. [Train] time:446.99207186698914 seconds, lr:0.0177, train_loss: 0.2618, unlabeled_losses_real_strong:0.4797,corrrect_unlabeled_num:404056.0,pro_above_threshold_num:413504.0,unlabelled_weak_top1_acc:93.96907157450914,unlabelled_weak_top5_acc:99.77417044341564  \n","[2022-04-18 12:21:07,731][experiments.experiment][INFO] - [no EMA] Epoch 80. [Validation] testing_loss: 0.3796, test Top1 acc:90.8, test Top5 acc: 99.82\n","[2022-04-18 12:21:07,731][experiments.experiment][INFO] - ***** Running training *****\n","epoch 81: use 456.7946615219116 seconds\n","--- Optimizer learning rate changed from 1.77e-02 to 1.74e-02 ---\n","[2022-04-18 12:28:44,526][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:28:45,937][experiments.experiment][INFO] - [no EMA] Epoch 81. [Train] time:456.7946615219116 seconds, lr:0.0174, train_loss: 0.2597, unlabeled_losses_real_strong:0.4759,corrrect_unlabeled_num:404824.0,pro_above_threshold_num:414056.0,unlabelled_weak_top1_acc:94.03076058626175,unlabelled_weak_top5_acc:99.75869362801313  \n","[2022-04-18 12:28:45,939][experiments.experiment][INFO] - [no EMA] Epoch 81. [Validation] testing_loss: 0.3117, test Top1 acc:91.92, test Top5 acc: 99.66\n","[2022-04-18 12:28:46,001][experiments.experiment][INFO] - [Checkpoints] Epoch 81, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_81.pth.tar\n","[2022-04-18 12:28:46,001][experiments.experiment][INFO] - ***** Running training *****\n","epoch 82: use 451.56828784942627 seconds\n","--- Optimizer learning rate changed from 1.74e-02 to 1.72e-02 ---\n","[2022-04-18 12:36:17,570][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:36:18,986][experiments.experiment][INFO] - [no EMA] Epoch 82. [Train] time:451.56828784942627 seconds, lr:0.0172, train_loss: 0.2586, unlabeled_losses_real_strong:0.4769,corrrect_unlabeled_num:404837.0,pro_above_threshold_num:414114.0,unlabelled_weak_top1_acc:94.02661892771721,unlabelled_weak_top5_acc:99.77417042851448  \n","[2022-04-18 12:36:18,988][experiments.experiment][INFO] - [no EMA] Epoch 82. [Validation] testing_loss: 0.3153, test Top1 acc:91.3, test Top5 acc: 99.64\n","[2022-04-18 12:36:18,989][experiments.experiment][INFO] - ***** Running training *****\n","epoch 83: use 447.4215888977051 seconds\n","--- Optimizer learning rate changed from 1.72e-02 to 1.69e-02 ---\n","[2022-04-18 12:43:46,411][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:43:47,803][experiments.experiment][INFO] - [no EMA] Epoch 83. [Train] time:447.4215888977051 seconds, lr:0.0169, train_loss: 0.2562, unlabeled_losses_real_strong:0.4703,corrrect_unlabeled_num:405927.0,pro_above_threshold_num:415229.0,unlabelled_weak_top1_acc:94.0983352214098,unlabelled_weak_top5_acc:99.77809404581785  \n","[2022-04-18 12:43:47,804][experiments.experiment][INFO] - [no EMA] Epoch 83. [Validation] testing_loss: 0.3475, test Top1 acc:90.86, test Top5 acc: 99.72\n","[2022-04-18 12:43:47,864][experiments.experiment][INFO] - [Checkpoints] Epoch 83, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_83.pth.tar\n","[2022-04-18 12:43:47,865][experiments.experiment][INFO] - ***** Running training *****\n","epoch 84: use 451.6718726158142 seconds\n","--- Optimizer learning rate changed from 1.69e-02 to 1.66e-02 ---\n","[2022-04-18 12:51:19,537][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:51:20,939][experiments.experiment][INFO] - [no EMA] Epoch 84. [Train] time:451.6718726158142 seconds, lr:0.0166, train_loss: 0.2566, unlabeled_losses_real_strong:0.4666,corrrect_unlabeled_num:406445.0,pro_above_threshold_num:415736.0,unlabelled_weak_top1_acc:94.14934328198433,unlabelled_weak_top5_acc:99.7763502150774  \n","[2022-04-18 12:51:20,940][experiments.experiment][INFO] - [no EMA] Epoch 84. [Validation] testing_loss: 0.2813, test Top1 acc:92.58, test Top5 acc: 99.76\n","[2022-04-18 12:51:20,941][experiments.experiment][INFO] - ***** Running training *****\n","epoch 85: use 452.7216753959656 seconds\n","--- Optimizer learning rate changed from 1.66e-02 to 1.63e-02 ---\n","[2022-04-18 12:58:53,663][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 12:58:55,075][experiments.experiment][INFO] - [no EMA] Epoch 85. [Train] time:452.7216753959656 seconds, lr:0.0163, train_loss: 0.2545, unlabeled_losses_real_strong:0.4649,corrrect_unlabeled_num:406873.0,pro_above_threshold_num:416028.0,unlabelled_weak_top1_acc:94.18923404067755,unlabelled_weak_top5_acc:99.78877532482147  \n","[2022-04-18 12:58:55,077][experiments.experiment][INFO] - [no EMA] Epoch 85. [Validation] testing_loss: 0.3721, test Top1 acc:90.46, test Top5 acc: 99.68\n","[2022-04-18 12:58:55,138][experiments.experiment][INFO] - [Checkpoints] Epoch 85, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_85.pth.tar\n","[2022-04-18 12:58:55,139][experiments.experiment][INFO] - ***** Running training *****\n","epoch 86: use 447.98197078704834 seconds\n","--- Optimizer learning rate changed from 1.63e-02 to 1.60e-02 ---\n","[2022-04-18 13:06:23,121][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:06:24,504][experiments.experiment][INFO] - [no EMA] Epoch 86. [Train] time:447.98197078704834 seconds, lr:0.0160, train_loss: 0.2546, unlabeled_losses_real_strong:0.4637,corrrect_unlabeled_num:407199.0,pro_above_threshold_num:416522.0,unlabelled_weak_top1_acc:94.18901596218348,unlabelled_weak_top5_acc:99.78114584833384  \n","[2022-04-18 13:06:24,506][experiments.experiment][INFO] - [no EMA] Epoch 86. [Validation] testing_loss: 0.3076, test Top1 acc:91.08, test Top5 acc: 99.8\n","[2022-04-18 13:06:24,507][experiments.experiment][INFO] - ***** Running training *****\n","epoch 87: use 443.55667185783386 seconds\n","--- Optimizer learning rate changed from 1.60e-02 to 1.57e-02 ---\n","[2022-04-18 13:13:48,064][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:13:49,391][experiments.experiment][INFO] - [no EMA] Epoch 87. [Train] time:443.55667185783386 seconds, lr:0.0157, train_loss: 0.2534, unlabeled_losses_real_strong:0.4612,corrrect_unlabeled_num:407521.0,pro_above_threshold_num:416931.0,unlabelled_weak_top1_acc:94.19686353206635,unlabelled_weak_top5_acc:99.78419761359692  \n","[2022-04-18 13:13:49,393][experiments.experiment][INFO] - [no EMA] Epoch 87. [Validation] testing_loss: 0.2756, test Top1 acc:92.32, test Top5 acc: 99.82\n","[2022-04-18 13:13:49,466][experiments.experiment][INFO] - [Checkpoints] Epoch 87, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_87.pth.tar\n","[2022-04-18 13:13:49,467][experiments.experiment][INFO] - ***** Running training *****\n","epoch 88: use 447.5289316177368 seconds\n","--- Optimizer learning rate changed from 1.57e-02 to 1.54e-02 ---\n","[2022-04-18 13:21:16,996][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:21:18,314][experiments.experiment][INFO] - [no EMA] Epoch 88. [Train] time:447.5289316177368 seconds, lr:0.0154, train_loss: 0.2522, unlabeled_losses_real_strong:0.4586,corrrect_unlabeled_num:408040.0,pro_above_threshold_num:417369.0,unlabelled_weak_top1_acc:94.2570267021656,unlabelled_weak_top5_acc:99.78615941852331  \n","[2022-04-18 13:21:18,316][experiments.experiment][INFO] - [no EMA] Epoch 88. [Validation] testing_loss: 0.3438, test Top1 acc:90.92, test Top5 acc: 99.7\n","[2022-04-18 13:21:18,316][experiments.experiment][INFO] - ***** Running training *****\n","epoch 89: use 444.9446008205414 seconds\n","--- Optimizer learning rate changed from 1.54e-02 to 1.51e-02 ---\n","[2022-04-18 13:28:43,261][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:28:44,593][experiments.experiment][INFO] - [no EMA] Epoch 89. [Train] time:444.9446008205414 seconds, lr:0.0151, train_loss: 0.2501, unlabeled_losses_real_strong:0.4553,corrrect_unlabeled_num:408566.0,pro_above_threshold_num:417802.0,unlabelled_weak_top1_acc:94.35533694177866,unlabelled_weak_top5_acc:99.7913911268115  \n","[2022-04-18 13:28:44,594][experiments.experiment][INFO] - [no EMA] Epoch 89. [Validation] testing_loss: 0.3027, test Top1 acc:91.46, test Top5 acc: 99.66\n","[2022-04-18 13:28:44,663][experiments.experiment][INFO] - [Checkpoints] Epoch 89, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_89.pth.tar\n","[2022-04-18 13:28:44,663][experiments.experiment][INFO] - ***** Running training *****\n","epoch 90: use 444.40531516075134 seconds\n","--- Optimizer learning rate changed from 1.51e-02 to 1.48e-02 ---\n","[2022-04-18 13:36:09,069][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:36:10,402][experiments.experiment][INFO] - [no EMA] Epoch 90. [Train] time:444.40531516075134 seconds, lr:0.0148, train_loss: 0.2475, unlabeled_losses_real_strong:0.4504,corrrect_unlabeled_num:409328.0,pro_above_threshold_num:418470.0,unlabelled_weak_top1_acc:94.39413785934448,unlabelled_weak_top5_acc:99.79945640265942  \n","[2022-04-18 13:36:10,403][experiments.experiment][INFO] - [no EMA] Epoch 90. [Validation] testing_loss: 0.3804, test Top1 acc:90.14, test Top5 acc: 99.44\n","[2022-04-18 13:36:10,404][experiments.experiment][INFO] - ***** Running training *****\n","epoch 91: use 444.9385027885437 seconds\n","--- Optimizer learning rate changed from 1.48e-02 to 1.45e-02 ---\n","[2022-04-18 13:43:35,343][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:43:36,670][experiments.experiment][INFO] - [no EMA] Epoch 91. [Train] time:444.9385027885437 seconds, lr:0.0145, train_loss: 0.2484, unlabeled_losses_real_strong:0.4522,corrrect_unlabeled_num:409003.0,pro_above_threshold_num:418392.0,unlabelled_weak_top1_acc:94.35838878899813,unlabelled_weak_top5_acc:99.78572348505259  \n","[2022-04-18 13:43:36,672][experiments.experiment][INFO] - [no EMA] Epoch 91. [Validation] testing_loss: 0.3326, test Top1 acc:90.56, test Top5 acc: 99.8\n","[2022-04-18 13:43:36,731][experiments.experiment][INFO] - [Checkpoints] Epoch 91, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_91.pth.tar\n","[2022-04-18 13:43:36,732][experiments.experiment][INFO] - ***** Running training *****\n","epoch 92: use 442.64933037757874 seconds\n","--- Optimizer learning rate changed from 1.45e-02 to 1.42e-02 ---\n","[2022-04-18 13:50:59,381][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:51:00,690][experiments.experiment][INFO] - [no EMA] Epoch 92. [Train] time:442.64933037757874 seconds, lr:0.0142, train_loss: 0.2465, unlabeled_losses_real_strong:0.4481,corrrect_unlabeled_num:409648.0,pro_above_threshold_num:418773.0,unlabelled_weak_top1_acc:94.47370152920485,unlabelled_weak_top5_acc:99.79575069993734  \n","[2022-04-18 13:51:00,693][experiments.experiment][INFO] - [no EMA] Epoch 92. [Validation] testing_loss: 0.3115, test Top1 acc:91.68, test Top5 acc: 99.9\n","[2022-04-18 13:51:00,693][experiments.experiment][INFO] - ***** Running training *****\n","epoch 93: use 444.40835785865784 seconds\n","--- Optimizer learning rate changed from 1.42e-02 to 1.39e-02 ---\n","[2022-04-18 13:58:25,101][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 13:58:26,434][experiments.experiment][INFO] - [no EMA] Epoch 93. [Train] time:444.40835785865784 seconds, lr:0.0139, train_loss: 0.2422, unlabeled_losses_real_strong:0.4420,corrrect_unlabeled_num:410262.0,pro_above_threshold_num:419432.0,unlabelled_weak_top1_acc:94.50836079567671,unlabelled_weak_top5_acc:99.79051911085844  \n","[2022-04-18 13:58:26,436][experiments.experiment][INFO] - [no EMA] Epoch 93. [Validation] testing_loss: 0.3471, test Top1 acc:90.76, test Top5 acc: 99.78\n","[2022-04-18 13:58:26,495][experiments.experiment][INFO] - [Checkpoints] Epoch 93, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_93.pth.tar\n","[2022-04-18 13:58:26,496][experiments.experiment][INFO] - ***** Running training *****\n","epoch 94: use 443.26680183410645 seconds\n","--- Optimizer learning rate changed from 1.39e-02 to 1.36e-02 ---\n","[2022-04-18 14:05:49,763][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:05:51,115][experiments.experiment][INFO] - [no EMA] Epoch 94. [Train] time:443.26680183410645 seconds, lr:0.0136, train_loss: 0.2433, unlabeled_losses_real_strong:0.4419,corrrect_unlabeled_num:410663.0,pro_above_threshold_num:419801.0,unlabelled_weak_top1_acc:94.48961425572634,unlabelled_weak_top5_acc:99.78942922502756  \n","[2022-04-18 14:05:51,117][experiments.experiment][INFO] - [no EMA] Epoch 94. [Validation] testing_loss: 0.2764, test Top1 acc:92.3, test Top5 acc: 99.84\n","[2022-04-18 14:05:51,117][experiments.experiment][INFO] - ***** Running training *****\n","epoch 95: use 444.01397347450256 seconds\n","--- Optimizer learning rate changed from 1.36e-02 to 1.33e-02 ---\n","[2022-04-18 14:13:15,131][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:13:16,474][experiments.experiment][INFO] - [no EMA] Epoch 95. [Train] time:444.01397347450256 seconds, lr:0.0133, train_loss: 0.2413, unlabeled_losses_real_strong:0.4378,corrrect_unlabeled_num:411479.0,pro_above_threshold_num:420614.0,unlabelled_weak_top1_acc:94.63326481729746,unlabelled_weak_top5_acc:99.80403406918049  \n","[2022-04-18 14:13:16,475][experiments.experiment][INFO] - [no EMA] Epoch 95. [Validation] testing_loss: 0.2944, test Top1 acc:91.74, test Top5 acc: 99.76\n","[2022-04-18 14:13:16,537][experiments.experiment][INFO] - [Checkpoints] Epoch 95, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_95.pth.tar\n","[2022-04-18 14:13:16,538][experiments.experiment][INFO] - ***** Running training *****\n","epoch 96: use 443.7382757663727 seconds\n","--- Optimizer learning rate changed from 1.33e-02 to 1.30e-02 ---\n","[2022-04-18 14:20:40,276][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:20:41,639][experiments.experiment][INFO] - [no EMA] Epoch 96. [Train] time:443.7382757663727 seconds, lr:0.0130, train_loss: 0.2400, unlabeled_losses_real_strong:0.4359,corrrect_unlabeled_num:411536.0,pro_above_threshold_num:420795.0,unlabelled_weak_top1_acc:94.60187536478043,unlabelled_weak_top5_acc:99.79531466215849  \n","[2022-04-18 14:20:41,640][experiments.experiment][INFO] - [no EMA] Epoch 96. [Validation] testing_loss: 0.3131, test Top1 acc:91.68, test Top5 acc: 99.74\n","[2022-04-18 14:20:41,641][experiments.experiment][INFO] - ***** Running training *****\n","epoch 97: use 444.8616120815277 seconds\n","--- Optimizer learning rate changed from 1.30e-02 to 1.27e-02 ---\n","[2022-04-18 14:28:06,502][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:28:07,858][experiments.experiment][INFO] - [no EMA] Epoch 97. [Train] time:444.8616120815277 seconds, lr:0.0127, train_loss: 0.2394, unlabeled_losses_real_strong:0.4330,corrrect_unlabeled_num:411900.0,pro_above_threshold_num:421053.0,unlabelled_weak_top1_acc:94.68013107776642,unlabelled_weak_top5_acc:99.81122751533985  \n","[2022-04-18 14:28:07,860][experiments.experiment][INFO] - [no EMA] Epoch 97. [Validation] testing_loss: 0.2428, test Top1 acc:92.9, test Top5 acc: 99.82\n","[2022-04-18 14:28:07,927][experiments.experiment][INFO] - [Checkpoints] Epoch 97, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_97.pth.tar\n","[2022-04-18 14:28:07,928][experiments.experiment][INFO] - ***** Running training *****\n","epoch 98: use 445.31202697753906 seconds\n","--- Optimizer learning rate changed from 1.27e-02 to 1.24e-02 ---\n","[2022-04-18 14:35:33,240][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:35:34,610][experiments.experiment][INFO] - [no EMA] Epoch 98. [Train] time:445.31202697753906 seconds, lr:0.0124, train_loss: 0.2383, unlabeled_losses_real_strong:0.4298,corrrect_unlabeled_num:412715.0,pro_above_threshold_num:422203.0,unlabelled_weak_top1_acc:94.70171135663986,unlabelled_weak_top5_acc:99.80403405427933  \n","[2022-04-18 14:35:34,612][experiments.experiment][INFO] - [no EMA] Epoch 98. [Validation] testing_loss: 0.2521, test Top1 acc:92.8, test Top5 acc: 99.92\n","[2022-04-18 14:35:34,612][experiments.experiment][INFO] - ***** Running training *****\n","epoch 99: use 445.50507950782776 seconds\n","--- Optimizer learning rate changed from 1.24e-02 to 1.21e-02 ---\n","[2022-04-18 14:43:00,118][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:43:01,491][experiments.experiment][INFO] - [no EMA] Epoch 99. [Train] time:445.50507950782776 seconds, lr:0.0121, train_loss: 0.2354, unlabeled_losses_real_strong:0.4253,corrrect_unlabeled_num:413112.0,pro_above_threshold_num:422403.0,unlabelled_weak_top1_acc:94.74051225930452,unlabelled_weak_top5_acc:99.8166770413518  \n","[2022-04-18 14:43:01,493][experiments.experiment][INFO] - [no EMA] Epoch 99. [Validation] testing_loss: 0.3469, test Top1 acc:91.28, test Top5 acc: 99.8\n","[2022-04-18 14:43:01,552][experiments.experiment][INFO] - [Checkpoints] Epoch 99, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_99.pth.tar\n","[2022-04-18 14:43:01,553][experiments.experiment][INFO] - ***** Running training *****\n","epoch 100: use 441.4303126335144 seconds\n","--- Optimizer learning rate changed from 1.21e-02 to 1.18e-02 ---\n","[2022-04-18 14:50:22,983][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:50:24,310][experiments.experiment][INFO] - [no EMA] Epoch 100. [Train] time:441.4303126335144 seconds, lr:0.0118, train_loss: 0.2344, unlabeled_losses_real_strong:0.4228,corrrect_unlabeled_num:413724.0,pro_above_threshold_num:423055.0,unlabelled_weak_top1_acc:94.78498081862926,unlabelled_weak_top5_acc:99.8164590895176  \n","[2022-04-18 14:50:24,311][experiments.experiment][INFO] - [no EMA] Epoch 100. [Validation] testing_loss: 0.2596, test Top1 acc:92.78, test Top5 acc: 99.8\n","[2022-04-18 14:50:24,312][experiments.experiment][INFO] - ***** Running training *****\n","epoch 101: use 443.42393708229065 seconds\n","--- Optimizer learning rate changed from 1.18e-02 to 1.14e-02 ---\n","[2022-04-18 14:57:47,736][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 14:57:49,104][experiments.experiment][INFO] - [no EMA] Epoch 101. [Train] time:443.42393708229065 seconds, lr:0.0114, train_loss: 0.2317, unlabeled_losses_real_strong:0.4199,corrrect_unlabeled_num:414485.0,pro_above_threshold_num:423891.0,unlabelled_weak_top1_acc:94.80241928994656,unlabelled_weak_top5_acc:99.81907487660646  \n","[2022-04-18 14:57:49,105][experiments.experiment][INFO] - [no EMA] Epoch 101. [Validation] testing_loss: 0.2595, test Top1 acc:93.0, test Top5 acc: 99.92\n","[2022-04-18 14:57:49,167][experiments.experiment][INFO] - [Checkpoints] Epoch 101, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_101.pth.tar\n","[2022-04-18 14:57:49,168][experiments.experiment][INFO] - ***** Running training *****\n","epoch 102: use 440.79722237586975 seconds\n","--- Optimizer learning rate changed from 1.14e-02 to 1.11e-02 ---\n","[2022-04-18 15:05:09,965][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 15:05:11,326][experiments.experiment][INFO] - [no EMA] Epoch 102. [Train] time:440.79722237586975 seconds, lr:0.0111, train_loss: 0.2318, unlabeled_losses_real_strong:0.4197,corrrect_unlabeled_num:414701.0,pro_above_threshold_num:423879.0,unlabelled_weak_top1_acc:94.85844101756811,unlabelled_weak_top5_acc:99.80447001755238  \n","[2022-04-18 15:05:11,328][experiments.experiment][INFO] - [no EMA] Epoch 102. [Validation] testing_loss: 0.2516, test Top1 acc:92.86, test Top5 acc: 99.78\n","[2022-04-18 15:05:11,329][experiments.experiment][INFO] - ***** Running training *****\n","epoch 103: use 439.7741162776947 seconds\n","--- Optimizer learning rate changed from 1.11e-02 to 1.08e-02 ---\n","[2022-04-18 15:12:31,103][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 15:12:32,429][experiments.experiment][INFO] - [no EMA] Epoch 103. [Train] time:439.7741162776947 seconds, lr:0.0108, train_loss: 0.2295, unlabeled_losses_real_strong:0.4158,corrrect_unlabeled_num:415195.0,pro_above_threshold_num:424566.0,unlabelled_weak_top1_acc:94.86214673519135,unlabelled_weak_top5_acc:99.81297136098146  \n","[2022-04-18 15:12:32,431][experiments.experiment][INFO] - [no EMA] Epoch 103. [Validation] testing_loss: 0.2610, test Top1 acc:93.06, test Top5 acc: 99.86\n","[2022-04-18 15:12:32,490][experiments.experiment][INFO] - [Checkpoints] Epoch 103, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_103.pth.tar\n","[2022-04-18 15:12:32,490][experiments.experiment][INFO] - ***** Running training *****\n","epoch 104: use 439.6184067726135 seconds\n","--- Optimizer learning rate changed from 1.08e-02 to 1.05e-02 ---\n","[2022-04-18 15:19:52,109][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 15:19:53,415][experiments.experiment][INFO] - [no EMA] Epoch 104. [Train] time:439.6184067726135 seconds, lr:0.0105, train_loss: 0.2281, unlabeled_losses_real_strong:0.4118,corrrect_unlabeled_num:415682.0,pro_above_threshold_num:425088.0,unlabelled_weak_top1_acc:94.92318177223206,unlabelled_weak_top5_acc:99.80839367955923  \n","[2022-04-18 15:19:53,417][experiments.experiment][INFO] - [no EMA] Epoch 104. [Validation] testing_loss: 0.2218, test Top1 acc:93.5, test Top5 acc: 99.86\n","[2022-04-18 15:19:53,417][experiments.experiment][INFO] - ***** Running training *****\n","epoch 105: use 444.21343302726746 seconds\n","--- Optimizer learning rate changed from 1.05e-02 to 1.02e-02 ---\n","[2022-04-18 15:27:17,631][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 15:27:18,974][experiments.experiment][INFO] - [no EMA] Epoch 105. [Train] time:444.21343302726746 seconds, lr:0.0102, train_loss: 0.2255, unlabeled_losses_real_strong:0.4082,corrrect_unlabeled_num:416143.0,pro_above_threshold_num:425507.0,unlabelled_weak_top1_acc:94.98007517307997,unlabelled_weak_top5_acc:99.81318932771683  \n","[2022-04-18 15:27:18,976][experiments.experiment][INFO] - [no EMA] Epoch 105. [Validation] testing_loss: 0.2648, test Top1 acc:93.04, test Top5 acc: 99.84\n","[2022-04-18 15:27:19,039][experiments.experiment][INFO] - [Checkpoints] Epoch 105, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_105.pth.tar\n","[2022-04-18 15:27:19,040][experiments.experiment][INFO] - ***** Running training *****\n","epoch 106: use 442.61239528656006 seconds\n","--- Optimizer learning rate changed from 1.02e-02 to 9.83e-03 ---\n","[2022-04-18 15:34:41,652][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 15:34:43,006][experiments.experiment][INFO] - [no EMA] Epoch 106. [Train] time:442.61239528656006 seconds, lr:0.0098, train_loss: 0.2243, unlabeled_losses_real_strong:0.4045,corrrect_unlabeled_num:417173.0,pro_above_threshold_num:426657.0,unlabelled_weak_top1_acc:95.0254156589508,unlabelled_weak_top5_acc:99.8186388835311  \n","[2022-04-18 15:34:43,007][experiments.experiment][INFO] - [no EMA] Epoch 106. [Validation] testing_loss: 0.2307, test Top1 acc:93.4, test Top5 acc: 99.8\n","[2022-04-18 15:34:43,008][experiments.experiment][INFO] - ***** Running training *****\n","epoch 107: use 441.4006173610687 seconds\n","--- Optimizer learning rate changed from 9.83e-03 to 9.50e-03 ---\n","[2022-04-18 15:42:04,410][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 15:42:05,719][experiments.experiment][INFO] - [no EMA] Epoch 107. [Train] time:441.4006173610687 seconds, lr:0.0095, train_loss: 0.2221, unlabeled_losses_real_strong:0.4011,corrrect_unlabeled_num:418027.0,pro_above_threshold_num:427585.0,unlabelled_weak_top1_acc:95.06857627630234,unlabelled_weak_top5_acc:99.81013761460781  \n","[2022-04-18 15:42:05,721][experiments.experiment][INFO] - [no EMA] Epoch 107. [Validation] testing_loss: 0.2338, test Top1 acc:93.34, test Top5 acc: 99.8\n","[2022-04-18 15:42:05,780][experiments.experiment][INFO] - [Checkpoints] Epoch 107, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_107.pth.tar\n","[2022-04-18 15:42:05,781][experiments.experiment][INFO] - ***** Running training *****\n","epoch 108: use 438.4860372543335 seconds\n","--- Optimizer learning rate changed from 9.50e-03 to 9.18e-03 ---\n","[2022-04-18 15:49:24,267][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 15:49:25,619][experiments.experiment][INFO] - [no EMA] Epoch 108. [Train] time:438.4860372543335 seconds, lr:0.0092, train_loss: 0.2203, unlabeled_losses_real_strong:0.3979,corrrect_unlabeled_num:417944.0,pro_above_threshold_num:427336.0,unlabelled_weak_top1_acc:95.07729560881853,unlabelled_weak_top5_acc:99.82343455404043  \n","[2022-04-18 15:49:25,621][experiments.experiment][INFO] - [no EMA] Epoch 108. [Validation] testing_loss: 0.2495, test Top1 acc:93.12, test Top5 acc: 99.84\n","[2022-04-18 15:49:25,621][experiments.experiment][INFO] - ***** Running training *****\n","epoch 109: use 439.556090593338 seconds\n","--- Optimizer learning rate changed from 9.18e-03 to 8.85e-03 ---\n","[2022-04-18 15:56:45,177][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 15:56:46,479][experiments.experiment][INFO] - [no EMA] Epoch 109. [Train] time:439.556090593338 seconds, lr:0.0088, train_loss: 0.2194, unlabeled_losses_real_strong:0.3943,corrrect_unlabeled_num:418428.0,pro_above_threshold_num:427759.0,unlabelled_weak_top1_acc:95.130919277668,unlabelled_weak_top5_acc:99.8212546557188  \n","[2022-04-18 15:56:46,481][experiments.experiment][INFO] - [no EMA] Epoch 109. [Validation] testing_loss: 0.2417, test Top1 acc:93.42, test Top5 acc: 99.84\n","[2022-04-18 15:56:46,540][experiments.experiment][INFO] - [Checkpoints] Epoch 109, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_109.pth.tar\n","[2022-04-18 15:56:46,541][experiments.experiment][INFO] - ***** Running training *****\n","epoch 110: use 440.33092856407166 seconds\n","--- Optimizer learning rate changed from 8.85e-03 to 8.52e-03 ---\n","[2022-04-18 16:04:06,872][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 16:04:08,212][experiments.experiment][INFO] - [no EMA] Epoch 110. [Train] time:440.33092856407166 seconds, lr:0.0085, train_loss: 0.2159, unlabeled_losses_real_strong:0.3903,corrrect_unlabeled_num:419078.0,pro_above_threshold_num:428608.0,unlabelled_weak_top1_acc:95.1605649664998,unlabelled_weak_top5_acc:99.82779411971569  \n","[2022-04-18 16:04:08,214][experiments.experiment][INFO] - [no EMA] Epoch 110. [Validation] testing_loss: 0.2798, test Top1 acc:92.4, test Top5 acc: 99.86\n","[2022-04-18 16:04:08,215][experiments.experiment][INFO] - ***** Running training *****\n","epoch 111: use 443.5611660480499 seconds\n","--- Optimizer learning rate changed from 8.52e-03 to 8.19e-03 ---\n","[2022-04-18 16:11:31,776][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 16:11:33,109][experiments.experiment][INFO] - [no EMA] Epoch 111. [Train] time:443.5611660480499 seconds, lr:0.0082, train_loss: 0.2148, unlabeled_losses_real_strong:0.3884,corrrect_unlabeled_num:419791.0,pro_above_threshold_num:429428.0,unlabelled_weak_top1_acc:95.17931143194437,unlabelled_weak_top5_acc:99.81711295992136  \n","[2022-04-18 16:11:33,111][experiments.experiment][INFO] - [no EMA] Epoch 111. [Validation] testing_loss: 0.2586, test Top1 acc:93.02, test Top5 acc: 99.78\n","[2022-04-18 16:11:33,172][experiments.experiment][INFO] - [Checkpoints] Epoch 111, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_111.pth.tar\n","[2022-04-18 16:11:33,172][experiments.experiment][INFO] - ***** Running training *****\n","epoch 112: use 442.8062255382538 seconds\n","--- Optimizer learning rate changed from 8.19e-03 to 7.86e-03 ---\n","[2022-04-18 16:18:55,979][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 16:18:57,348][experiments.experiment][INFO] - [no EMA] Epoch 112. [Train] time:442.8062255382538 seconds, lr:0.0079, train_loss: 0.2137, unlabeled_losses_real_strong:0.3852,corrrect_unlabeled_num:420169.0,pro_above_threshold_num:429898.0,unlabelled_weak_top1_acc:95.22377990186214,unlabelled_weak_top5_acc:99.8147152364254  \n","[2022-04-18 16:18:57,351][experiments.experiment][INFO] - [no EMA] Epoch 112. [Validation] testing_loss: 0.2491, test Top1 acc:93.6, test Top5 acc: 99.8\n","[2022-04-18 16:18:57,351][experiments.experiment][INFO] - ***** Running training *****\n","epoch 113: use 445.92567229270935 seconds\n","--- Optimizer learning rate changed from 7.86e-03 to 7.53e-03 ---\n","[2022-04-18 16:26:23,277][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 16:26:24,605][experiments.experiment][INFO] - [no EMA] Epoch 113. [Train] time:445.92567229270935 seconds, lr:0.0075, train_loss: 0.2091, unlabeled_losses_real_strong:0.3802,corrrect_unlabeled_num:420572.0,pro_above_threshold_num:430309.0,unlabelled_weak_top1_acc:95.28067342936993,unlabelled_weak_top5_acc:99.83019200712442  \n","[2022-04-18 16:26:24,608][experiments.experiment][INFO] - [no EMA] Epoch 113. [Validation] testing_loss: 0.2673, test Top1 acc:93.36, test Top5 acc: 99.72\n","[2022-04-18 16:26:24,666][experiments.experiment][INFO] - [Checkpoints] Epoch 113, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_113.pth.tar\n","[2022-04-18 16:26:24,667][experiments.experiment][INFO] - ***** Running training *****\n","epoch 114: use 443.60835576057434 seconds\n","--- Optimizer learning rate changed from 7.53e-03 to 7.19e-03 ---\n","[2022-04-18 16:33:48,276][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 16:33:49,624][experiments.experiment][INFO] - [no EMA] Epoch 114. [Train] time:443.60835576057434 seconds, lr:0.0072, train_loss: 0.2076, unlabeled_losses_real_strong:0.3747,corrrect_unlabeled_num:421407.0,pro_above_threshold_num:431113.0,unlabelled_weak_top1_acc:95.3299375474453,unlabelled_weak_top5_acc:99.83411564677954  \n","[2022-04-18 16:33:49,625][experiments.experiment][INFO] - [no EMA] Epoch 114. [Validation] testing_loss: 0.2329, test Top1 acc:93.56, test Top5 acc: 99.9\n","[2022-04-18 16:33:49,626][experiments.experiment][INFO] - ***** Running training *****\n","epoch 115: use 442.4971385002136 seconds\n","--- Optimizer learning rate changed from 7.19e-03 to 6.86e-03 ---\n","[2022-04-18 16:41:12,124][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 16:41:13,439][experiments.experiment][INFO] - [no EMA] Epoch 115. [Train] time:442.4971385002136 seconds, lr:0.0069, train_loss: 0.2061, unlabeled_losses_real_strong:0.3728,corrrect_unlabeled_num:422080.0,pro_above_threshold_num:431867.0,unlabelled_weak_top1_acc:95.33647694438696,unlabelled_weak_top5_acc:99.83084590733051  \n","[2022-04-18 16:41:13,440][experiments.experiment][INFO] - [no EMA] Epoch 115. [Validation] testing_loss: 0.2501, test Top1 acc:93.56, test Top5 acc: 99.86\n","[2022-04-18 16:41:13,502][experiments.experiment][INFO] - [Checkpoints] Epoch 115, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_115.pth.tar\n","[2022-04-18 16:41:13,503][experiments.experiment][INFO] - ***** Running training *****\n","epoch 116: use 440.63844108581543 seconds\n","--- Optimizer learning rate changed from 6.86e-03 to 6.53e-03 ---\n","[2022-04-18 16:48:34,141][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 16:48:35,453][experiments.experiment][INFO] - [no EMA] Epoch 116. [Train] time:440.63844108581543 seconds, lr:0.0065, train_loss: 0.2048, unlabeled_losses_real_strong:0.3716,corrrect_unlabeled_num:422467.0,pro_above_threshold_num:432404.0,unlabelled_weak_top1_acc:95.38661312311888,unlabelled_weak_top5_acc:99.82670424878597  \n","[2022-04-18 16:48:35,455][experiments.experiment][INFO] - [no EMA] Epoch 116. [Validation] testing_loss: 0.2354, test Top1 acc:93.78, test Top5 acc: 99.9\n","[2022-04-18 16:48:35,456][experiments.experiment][INFO] - ***** Running training *****\n","epoch 117: use 445.2285490036011 seconds\n","--- Optimizer learning rate changed from 6.53e-03 to 6.19e-03 ---\n","[2022-04-18 16:56:00,684][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 16:56:02,083][experiments.experiment][INFO] - [no EMA] Epoch 117. [Train] time:445.2285490036011 seconds, lr:0.0062, train_loss: 0.2016, unlabeled_losses_real_strong:0.3650,corrrect_unlabeled_num:423224.0,pro_above_threshold_num:433124.0,unlabelled_weak_top1_acc:95.44328857958317,unlabelled_weak_top5_acc:99.83542358875275  \n","[2022-04-18 16:56:02,085][experiments.experiment][INFO] - [no EMA] Epoch 117. [Validation] testing_loss: 0.2066, test Top1 acc:93.98, test Top5 acc: 99.9\n","[2022-04-18 16:56:02,145][experiments.experiment][INFO] - [Checkpoints] Epoch 117, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_117.pth.tar\n","[2022-04-18 16:56:02,146][experiments.experiment][INFO] - ***** Running training *****\n","epoch 118: use 445.56873655319214 seconds\n","--- Optimizer learning rate changed from 6.19e-03 to 5.85e-03 ---\n","[2022-04-18 17:03:27,715][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 17:03:29,031][experiments.experiment][INFO] - [no EMA] Epoch 118. [Train] time:445.56873655319214 seconds, lr:0.0059, train_loss: 0.1982, unlabeled_losses_real_strong:0.3620,corrrect_unlabeled_num:423462.0,pro_above_threshold_num:433305.0,unlabelled_weak_top1_acc:95.4807815477252,unlabelled_weak_top5_acc:99.83738543093204  \n","[2022-04-18 17:03:29,032][experiments.experiment][INFO] - [no EMA] Epoch 118. [Validation] testing_loss: 0.2224, test Top1 acc:94.22, test Top5 acc: 99.94\n","[2022-04-18 17:03:29,033][experiments.experiment][INFO] - ***** Running training *****\n","epoch 119: use 451.0290906429291 seconds\n","--- Optimizer learning rate changed from 5.85e-03 to 5.52e-03 ---\n","[2022-04-18 17:11:00,062][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-18 17:11:01,483][experiments.experiment][INFO] - [no EMA] Epoch 119. [Train] time:451.0290906429291 seconds, lr:0.0055, train_loss: 0.1955, unlabeled_losses_real_strong:0.3576,corrrect_unlabeled_num:424320.0,pro_above_threshold_num:434478.0,unlabelled_weak_top1_acc:95.50759343802929,unlabelled_weak_top5_acc:99.83258979767561  \n","[2022-04-18 17:11:01,485][experiments.experiment][INFO] - [no EMA] Epoch 119. [Validation] testing_loss: 0.1881, test Top1 acc:94.36, test Top5 acc: 99.96\n","[2022-04-18 17:11:01,545][experiments.experiment][INFO] - [Checkpoints] Epoch 119, saving to ./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_119.pth.tar\n","======= Training done =======\n","2022-04-18 17:11:01,556 - INFO - Train -   ======= Training done =======\n","[2022-04-18 17:11:01,556][Train][INFO] - ======= Training done =======\n","[2022-04-18 17:11:01,557][experiments.experiment][INFO] - Loading Testing Loader\n","[2022-04-18 17:11:01,557][experiments.experiment][INFO] - ***** Running testing *****\n","[2022-04-18 17:11:04,054][experiments.experiment][INFO] - [Testing] testing_loss: 0.2055, test Top1 acc:94.19, test Top5 acc: 99.82\n","======= Testing done =======\n","2022-04-18 17:11:04,055 - INFO - Train -   ======= Testing done =======\n","[2022-04-18 17:11:04,055][Train][INFO] - ======= Testing done =======\n"]}],"source":["# Pick up where left out\n","!python run.py DATASET.label_num=4000 DATASET.strongaugment='RA' EXPERIMENT.epoch_n=120 EXPERIMENT.batch_size=64 MODEL.name='WideResNet_Lk' MODEL.depth=28 MODEL.widen_factor=2 MODEL.num_classes=10 EXPERIMENT.out_model='./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/' EXPERIMENT.log_path='./outputs/outputs_celiali-wideresnet-120epochs-64batch-no-ema/' EXPERIMENT.save_cfmatrix=False EXPERIMENT.decay_type='cosine' EXPERIMENT.ema_used=False EXPERIMENT.resume=True EXPERIMENT.resume_checkpoints='./checkpoints/checkpoints_celiali-wideresnet-120epochs-64batch-no-ema/FMExperiment_epoch_11.pth.tar'"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"celiali-resnext-120epochs-32batch.ipynb","provenance":[],"authorship_tag":"ABX9TyNheZtYF1k4JgP7oLl/bbRw"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}