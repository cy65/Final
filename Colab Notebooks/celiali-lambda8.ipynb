{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":133178,"status":"ok","timestamp":1650597223614,"user":{"displayName":"CM Y","userId":"12660552299343911788"},"user_tz":300},"id":"toZZ8nMX7AsV","outputId":"9992caec-0889-43db-df29-8c42c6b4ba43"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/celiali\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 2)) (1.0.0)\n","Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 3)) (1.9)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 4)) (0.29.28)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 5)) (1.21.6)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 7)) (4.64.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 8)) (1.4.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 9)) (7.1.2)\n","Collecting torch==1.8.0\n","  Downloading torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5 MB)\n","\u001b[K     |████████████████████████████████| 735.5 MB 15 kB/s \n","\u001b[?25hCollecting torchvision==0.9.0\n","  Downloading torchvision-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n","\u001b[K     |████████████████████████████████| 17.3 MB 134 kB/s \n","\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 12)) (0.10.0+cu111)\n","Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 13)) (0.11.0)\n","Collecting omegaconf\n","  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\n","\u001b[K     |████████████████████████████████| 74 kB 4.1 MB/s \n","\u001b[?25hCollecting hydra\n","  Downloading Hydra-2.5.tar.gz (82 kB)\n","\u001b[K     |████████████████████████████████| 82 kB 304 kB/s \n","\u001b[?25hCollecting hydra-core\n","  Downloading hydra_core-1.1.2-py3-none-any.whl (147 kB)\n","\u001b[K     |████████████████████████████████| 147 kB 69.8 MB/s \n","\u001b[?25hCollecting ignite\n","  Downloading ignite-1.1.0-py2.py3-none-any.whl (4.5 kB)\n","Collecting pytorch-ignite\n","  Downloading pytorch_ignite-0.4.8-py3-none-any.whl (251 kB)\n","\u001b[K     |████████████████████████████████| 251 kB 51.2 MB/s \n","\u001b[?25hCollecting tensorboardX\n","  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 74.9 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 20)) (1.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r google_requirements.txt (line 21)) (3.2.2)\n","Collecting abel-pytorch\n","  Downloading abel_pytorch-0.0.1-py3-none-any.whl (4.2 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0-\u003e-r google_requirements.txt (line 10)) (4.1.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py-\u003e-r google_requirements.txt (line 2)) (1.15.0)\n","Requirement already satisfied: wrapt\u003e=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003e-r google_requirements.txt (line 6)) (1.14.0)\n","Requirement already satisfied: keras\u003c2.9,\u003e=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003e-r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: grpcio\u003c2.0,\u003e=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003e-r google_requirements.txt (line 6)) (1.44.0)\n","Requirement already satisfied: astunparse\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003e-r google_requirements.txt (line 6)) (1.6.3)\n","Requirement already satisfied: h5py\u003e=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003e-r google_requirements.txt (line 6)) (3.1.0)\n","Requirement already satisfied: keras-preprocessing\u003e=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003e-r google_requirements.txt (line 6)) (1.1.2)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 62.1 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf\u003e=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003e-r google_requirements.txt (line 6)) (3.17.3)\n","Requirement already satisfied: tensorboard\u003c2.9,\u003e=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003e-r google_requirements.txt (line 6)) (2.8.0)\n","Requirement already satisfied: libclang\u003e=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003e-r google_requirements.txt (line 6)) (13.0.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem\u003e=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003e-r google_requirements.txt (line 6)) (0.24.0)\n","Requirement already satisfied: google-pasta\u003e=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003e-r google_requirements.txt (line 6)) (0.2.0)\n","Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003e-r google_requirements.txt (line 6)) (1.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003e-r google_requirements.txt (line 6)) (57.4.0)\n","Requirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003e-r google_requirements.txt (line 6)) (3.3.0)\n","Requirement already satisfied: flatbuffers\u003e=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003e-r google_requirements.txt (line 6)) (2.0)\n","Requirement already satisfied: gast\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-\u003e-r google_requirements.txt (line 6)) (0.5.3)\n","Requirement already satisfied: wheel\u003c1.0,\u003e=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse\u003e=1.6.0-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py\u003e=2.9.0-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (1.5.2)\n","Requirement already satisfied: requests\u003c3,\u003e=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib\u003c0.5,\u003e=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (0.4.6)\n","Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (1.35.0)\n","Requirement already satisfied: werkzeug\u003e=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit\u003e=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (1.8.1)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (3.3.6)\n","Requirement already satisfied: tensorboard-data-server\u003c0.7.0,\u003e=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (0.6.1)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (4.8)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (0.2.8)\n","Requirement already satisfied: cachetools\u003c5.0,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (4.2.4)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (1.3.1)\n","Requirement already satisfied: importlib-metadata\u003e=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown\u003e=2.6.8-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (4.11.3)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata\u003e=4.4-\u003emarkdown\u003e=2.6.8-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (3.8.0)\n","Requirement already satisfied: pyasn1\u003c0.5.0,\u003e=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (0.4.8)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (2021.10.8)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.21.0-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (1.24.3)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c0.5,\u003e=0.4.1-\u003etensorboard\u003c2.9,\u003e=2.8-\u003etensorflow-\u003e-r google_requirements.txt (line 6)) (3.2.0)\n","Collecting torchaudio\n","  Downloading torchaudio-0.11.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 55.3 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 57.1 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 60.2 MB/s \n","\u001b[?25h  Downloading torchaudio-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 58.9 MB/s \n","\u001b[?25h  Downloading torchaudio-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 25.4 MB/s \n","\u001b[?25h  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 61.4 MB/s \n","\u001b[?25h  Downloading torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 57.8 MB/s \n","\u001b[?25h  Downloading torchaudio-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 59.1 MB/s \n","\u001b[?25hCollecting torchtext\n","  Downloading torchtext-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n","\u001b[K     |████████████████████████████████| 10.4 MB 24.9 MB/s \n","\u001b[?25h  Downloading torchtext-0.11.2-cp37-cp37m-manylinux1_x86_64.whl (8.0 MB)\n","\u001b[K     |████████████████████████████████| 8.0 MB 27.2 MB/s \n","\u001b[?25h  Downloading torchtext-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (8.0 MB)\n","\u001b[K     |████████████████████████████████| 8.0 MB 26.9 MB/s \n","\u001b[?25h  Downloading torchtext-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 29.7 MB/s \n","\u001b[?25h  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 49.7 MB/s \n","\u001b[?25h  Downloading torchtext-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 4.5 MB/s \n","\u001b[?25h  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 26.5 MB/s \n","\u001b[?25hCollecting PyYAML\u003e=5.1.0\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 39.3 MB/s \n","\u001b[?25hCollecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 73.5 MB/s \n","\u001b[?25hCollecting importlib-resources\u003c5.3\n","  Downloading importlib_resources-5.2.3-py3-none-any.whl (27 kB)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-\u003e-r google_requirements.txt (line 20)) (3.1.0)\n","Requirement already satisfied: joblib\u003e=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-\u003e-r google_requirements.txt (line 20)) (1.1.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,\u003e=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003e-r google_requirements.txt (line 21)) (3.0.8)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003e-r google_requirements.txt (line 21)) (0.11.0)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003e-r google_requirements.txt (line 21)) (1.4.2)\n","Requirement already satisfied: python-dateutil\u003e=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-\u003e-r google_requirements.txt (line 21)) (2.8.2)\n","Building wheels for collected packages: antlr4-python3-runtime, hydra\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=6fa3c826ebe8931ab34e05ad1ec46c0f97d5c45d20d5ddfd260a95a808c4334c\n","  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n","  Building wheel for hydra (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hydra: filename=Hydra-2.5-cp37-cp37m-linux_x86_64.whl size=220773 sha256=bd50a0a8dbbf06c8ec29ec003f335bd822da2a8ed4d0a450e7dd34b261f23d71\n","  Stored in directory: /root/.cache/pip/wheels/46/28/7d/3b38a41d900da90c4e17576f442bac9344eb1f5a4e78ee9f83\n","Successfully built antlr4-python3-runtime hydra\n","Installing collected packages: PyYAML, antlr4-python3-runtime, torch, tf-estimator-nightly, omegaconf, importlib-resources, torchvision, torchtext, torchaudio, tensorboardX, pytorch-ignite, ignite, hydra-core, hydra, abel-pytorch\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.10.0+cu111\n","    Uninstalling torch-1.10.0+cu111:\n","      Successfully uninstalled torch-1.10.0+cu111\n","  Attempting uninstall: importlib-resources\n","    Found existing installation: importlib-resources 5.7.0\n","    Uninstalling importlib-resources-5.7.0:\n","      Successfully uninstalled importlib-resources-5.7.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.11.1+cu111\n","    Uninstalling torchvision-0.11.1+cu111:\n","      Successfully uninstalled torchvision-0.11.1+cu111\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.11.0\n","    Uninstalling torchtext-0.11.0:\n","      Successfully uninstalled torchtext-0.11.0\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.10.0+cu111\n","    Uninstalling torchaudio-0.10.0+cu111:\n","      Successfully uninstalled torchaudio-0.10.0+cu111\n","Successfully installed PyYAML-6.0 abel-pytorch-0.0.1 antlr4-python3-runtime-4.8 hydra-2.5 hydra-core-1.1.2 ignite-1.1.0 importlib-resources-5.2.3 omegaconf-2.1.2 pytorch-ignite-0.4.8 tensorboardX-2.5 tf-estimator-nightly-2.8.0.dev2021122109 torch-1.8.0 torchaudio-0.8.0 torchtext-0.9.0 torchvision-0.9.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{},"output_type":"display_data"}],"source":["# Mount into drive\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","# Change directory to the package folder\n","%cd '/content/drive/MyDrive/celiali'\n","%pip install -r google_requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"cb7eeaJS7GhZ"},"outputs":[{"name":"stdout","output_type":"stream","text":["==\u003e CONFIG is: \n"," DATASET:\n","  project_dir: ./\n","  data_dir: data\n","  loading_data: LOAD_LABEL_UNLABEL\n","  dataset: CIFAR10\n","  strongaugment: RA\n","  cut_type: cutout\n","  label_num: 4000\n","  num_expand_x: 65536\n","  mu: 7\n","  barely: false\n","  add_noisy_label: false\n","  both_strong: false\n","MODEL:\n","  name: WideResNet_Lk\n","  depth: 28\n","  widen_factor: 2\n","  num_classes: 10\n","  dropout: 0.0\n","  cardinality: 4\n","  width: 4\n","  base_width: 4\n","EXPERIMENT:\n","  name: FMExperiment\n","  out_model: ./checkpoints/checkpoints_celiali-lambda_unlabled_8/\n","  log_path: ./outputs/outputs_lambda_unlabled_8/\n","  used_gpu: true\n","  decay_type: cosine\n","  abel_decay: 0.1\n","  optim_lr: 0.03\n","  optim_momentum: 0.9\n","  used_nesterov: true\n","  warmup: 0\n","  wdecay: 0.0005\n","  clip: 1\n","  ema_used: true\n","  ema_decay: 0.999\n","  threshold: 0.95\n","  lambda_unlabeled: 8\n","  batch_size: 64\n","  num_workers: 4\n","  n_imgs_per_epoch: 65536\n","  epoch_n: 120\n","  save_every: 2\n","  save_matrix_every: 20\n","  resume: false\n","  resume_checkpoints: ./checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar\n","  save_cfmatrix: false\n","  batch_balanced: false\n","  neg_penalty: false\n","  equal_freq: false\n","  eta_negpenalty: 0.05\n","  eta_dynamic: false\n","  use_nlloss: false\n","  q: 0.0001\n","Logging:\n","  name: FM\n","  seed: 1265\n"," \n","\n","2022-04-22 03:14:44,566 - INFO - Train -   {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'cut_type': 'cutout', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-lambda_unlabled_8/', 'log_path': './outputs/outputs_lambda_unlabled_8/', 'used_gpu': True, 'decay_type': 'cosine', 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 8, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': False, 'resume_checkpoints': './checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","[2022-04-22 03:14:44,566][Train][INFO] - {'DATASET': {'project_dir': './', 'data_dir': 'data', 'loading_data': 'LOAD_LABEL_UNLABEL', 'dataset': 'CIFAR10', 'strongaugment': 'RA', 'cut_type': 'cutout', 'label_num': 4000, 'num_expand_x': 65536, 'mu': 7, 'barely': False, 'add_noisy_label': False, 'both_strong': False}, 'MODEL': {'name': 'WideResNet_Lk', 'depth': 28, 'widen_factor': 2, 'num_classes': 10, 'dropout': 0.0, 'cardinality': 4, 'width': 4, 'base_width': 4}, 'EXPERIMENT': {'name': 'FMExperiment', 'out_model': './checkpoints/checkpoints_celiali-lambda_unlabled_8/', 'log_path': './outputs/outputs_lambda_unlabled_8/', 'used_gpu': True, 'decay_type': 'cosine', 'abel_decay': 0.1, 'optim_lr': 0.03, 'optim_momentum': 0.9, 'used_nesterov': True, 'warmup': 0, 'wdecay': 0.0005, 'clip': 1, 'ema_used': True, 'ema_decay': 0.999, 'threshold': 0.95, 'lambda_unlabeled': 8, 'batch_size': 64, 'num_workers': 4, 'n_imgs_per_epoch': 65536, 'epoch_n': 120, 'save_every': 2, 'save_matrix_every': 20, 'resume': False, 'resume_checkpoints': './checkpoints/exp_4000_1/FMExperiment_epoch_179.pth.tar', 'save_cfmatrix': False, 'batch_balanced': False, 'neg_penalty': False, 'equal_freq': False, 'eta_negpenalty': 0.05, 'eta_dynamic': False, 'use_nlloss': False, 'q': 0.0001}, 'Logging': {'name': 'FM', 'seed': 1265}}\n","2022-04-22 03:14:45,269 - INFO - Train -   [Model] Building model WideResNet_Lk\n","[2022-04-22 03:14:45,269][Train][INFO] - [Model] Building model WideResNet_Lk\n","2022-04-22 03:14:47,804 - INFO - Train -   Total params: 1.47M\n","[2022-04-22 03:14:47,804][Train][INFO] - Total params: 1.47M\n","[2022-04-22 03:14:47,805][experiments.experiment][INFO] - I'm using cosine decay!\n","[2022-04-22 03:14:47,809][experiments.experiment][INFO] - [EMA] initial \n","[2022-04-22 03:14:56,981][datasets.datasets1][INFO] - Dataset: CIFAR10\n","[2022-04-22 03:14:57,033][datasets.datasets1][INFO] - Labeled examples: 65536 Unlabeled examples: 458752Validation examples: 5000\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","[2022-04-22 03:14:57,035][experiments.experiment][INFO] - Loading Labelled Loader\n","[2022-04-22 03:14:57,035][experiments.experiment][INFO] - Loading Unlabelled Loader\n","[2022-04-22 03:14:57,036][experiments.experiment][INFO] - Loading Validation Loader\n","[2022-04-22 03:14:57,044][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 03:22:16,748][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 0: use 439.8045597076416 seconds\n","--- Optimizer learning rate changed from inf to 3.00e-02 ---\n","[2022-04-22 03:22:16,848][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 03:22:18,162][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 03:22:18,162][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 03:22:19,505][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 03:22:19,561][experiments.experiment][INFO] - [EMA] Epoch 0.[Train] time:439.8045597076416 seconds, lr:0.0300, train_loss: 1.5660, unlabeled_losses_real_strong:2.2269,corrrect_unlabeled_num:26486.0,pro_above_threshold_num:28374.0,unlabelled_weak_top1_acc:50.148663681931794,unlabelled_weak_top5_acc:92.51294721290469  \n","[2022-04-22 03:22:19,562][experiments.experiment][INFO] - [EMA] Epoch 0. [Validation] raw_testing_loss: 1.7102, raw test Top1 acc:43.9, raw test Top5 acc: 89.92, ema_testing_loss: 1.5905, ema test Top1 acc:44.78, ema test Top5 acc: 91.5\n","[2022-04-22 03:22:19,647][experiments.experiment][INFO] - [Checkpoints] Epoch 0, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 03:22:19,648][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 03:29:41,622][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 1: use 442.07737278938293 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-22 03:29:41,725][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 03:29:43,053][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 03:29:43,054][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 03:29:44,438][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 03:29:44,440][experiments.experiment][INFO] - [EMA] Epoch 1.[Train] time:442.07737278938293 seconds, lr:0.0300, train_loss: 1.9228, unlabeled_losses_real_strong:1.9639,corrrect_unlabeled_num:111556.0,pro_above_threshold_num:118046.0,unlabelled_weak_top1_acc:64.20898357778788,unlabelled_weak_top5_acc:96.46889718621969  \n","[2022-04-22 03:29:44,442][experiments.experiment][INFO] - [EMA] Epoch 1. [Validation] raw_testing_loss: 2.5236, raw test Top1 acc:27.22, raw test Top5 acc: 79.36, ema_testing_loss: 1.1099, ema test Top1 acc:60.54, ema test Top5 acc: 95.76\n","[2022-04-22 03:29:44,536][experiments.experiment][INFO] - [Checkpoints] Epoch 1, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 03:29:44,538][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 03:37:09,961][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 2: use 445.5256495475769 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-22 03:37:10,064][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 03:37:11,373][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 03:37:11,373][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 03:37:12,731][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 03:37:12,732][experiments.experiment][INFO] - [EMA] Epoch 2.[Train] time:445.5256495475769 seconds, lr:0.0300, train_loss: 2.0595, unlabeled_losses_real_strong:1.6290,corrrect_unlabeled_num:162182.0,pro_above_threshold_num:170668.0,unlabelled_weak_top1_acc:70.19827606528997,unlabelled_weak_top5_acc:97.50453297793865  \n","[2022-04-22 03:37:12,733][experiments.experiment][INFO] - [EMA] Epoch 2. [Validation] raw_testing_loss: 4.1345, raw test Top1 acc:18.52, raw test Top5 acc: 81.78, ema_testing_loss: 0.8739, ema test Top1 acc:69.52, ema test Top5 acc: 97.44\n","[2022-04-22 03:37:12,735][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 03:44:39,757][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 3: use 447.1194884777069 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-22 03:44:39,854][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 03:44:41,223][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 03:44:41,223][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 03:44:42,570][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 03:44:42,571][experiments.experiment][INFO] - [EMA] Epoch 3.[Train] time:447.1194884777069 seconds, lr:0.0300, train_loss: 2.2164, unlabeled_losses_real_strong:1.3269,corrrect_unlabeled_num:204453.0,pro_above_threshold_num:214249.0,unlabelled_weak_top1_acc:74.85220669209957,unlabelled_weak_top5_acc:98.21254083514214  \n","[2022-04-22 03:44:42,572][experiments.experiment][INFO] - [EMA] Epoch 3. [Validation] raw_testing_loss: 1.8916, raw test Top1 acc:41.9, raw test Top5 acc: 92.64, ema_testing_loss: 0.7469, ema test Top1 acc:75.1, ema test Top5 acc: 98.22\n","[2022-04-22 03:44:42,671][experiments.experiment][INFO] - [Checkpoints] Epoch 3, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 03:44:42,673][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 03:52:07,453][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 4: use 444.87874007225037 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 3.00e-02 ---\n","[2022-04-22 03:52:07,551][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 03:52:08,891][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 03:52:08,891][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 03:52:10,236][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 03:52:10,238][experiments.experiment][INFO] - [EMA] Epoch 4.[Train] time:444.87874007225037 seconds, lr:0.0300, train_loss: 2.2880, unlabeled_losses_real_strong:1.1819,corrrect_unlabeled_num:234834.0,pro_above_threshold_num:245422.0,unlabelled_weak_top1_acc:78.1389497667551,unlabelled_weak_top5_acc:98.59640825539827  \n","[2022-04-22 03:52:10,239][experiments.experiment][INFO] - [EMA] Epoch 4. [Validation] raw_testing_loss: 2.8512, raw test Top1 acc:32.82, raw test Top5 acc: 87.88, ema_testing_loss: 0.6702, ema test Top1 acc:78.5, ema test Top5 acc: 98.78\n","[2022-04-22 03:52:10,241][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 03:59:37,194][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 5: use 447.0611493587494 seconds\n","--- Optimizer learning rate changed from 3.00e-02 to 2.99e-02 ---\n","[2022-04-22 03:59:37,302][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 03:59:38,648][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 03:59:38,648][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 03:59:40,003][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 03:59:40,004][experiments.experiment][INFO] - [EMA] Epoch 5.[Train] time:447.0611493587494 seconds, lr:0.0299, train_loss: 2.2703, unlabeled_losses_real_strong:1.0834,corrrect_unlabeled_num:257180.0,pro_above_threshold_num:267949.0,unlabelled_weak_top1_acc:80.35365408658981,unlabelled_weak_top5_acc:98.83030339330435  \n","[2022-04-22 03:59:40,006][experiments.experiment][INFO] - [EMA] Epoch 5. [Validation] raw_testing_loss: 1.1968, raw test Top1 acc:59.02, raw test Top5 acc: 95.66, ema_testing_loss: 0.6023, ema test Top1 acc:81.12, ema test Top5 acc: 99.0\n","[2022-04-22 03:59:40,101][experiments.experiment][INFO] - [Checkpoints] Epoch 5, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 03:59:40,111][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 04:07:06,179][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 6: use 446.16796946525574 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.99e-02 ---\n","[2022-04-22 04:07:06,279][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 04:07:07,635][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 04:07:07,635][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 04:07:09,002][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 04:07:09,003][experiments.experiment][INFO] - [EMA] Epoch 6.[Train] time:446.16796946525574 seconds, lr:0.0299, train_loss: 2.2770, unlabeled_losses_real_strong:1.0210,corrrect_unlabeled_num:272766.0,pro_above_threshold_num:283695.0,unlabelled_weak_top1_acc:81.89849739521742,unlabelled_weak_top5_acc:98.97613370418549  \n","[2022-04-22 04:07:09,004][experiments.experiment][INFO] - [EMA] Epoch 6. [Validation] raw_testing_loss: 1.5461, raw test Top1 acc:53.4, raw test Top5 acc: 93.86, ema_testing_loss: 0.5526, ema test Top1 acc:83.04, ema test Top5 acc: 99.18\n","[2022-04-22 04:07:09,005][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 04:14:34,349][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 7: use 445.44579315185547 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.99e-02 ---\n","[2022-04-22 04:14:34,451][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 04:14:35,778][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 04:14:35,778][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 04:14:37,181][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 04:14:37,182][experiments.experiment][INFO] - [EMA] Epoch 7.[Train] time:445.44579315185547 seconds, lr:0.0299, train_loss: 2.2687, unlabeled_losses_real_strong:0.9652,corrrect_unlabeled_num:285612.0,pro_above_threshold_num:296115.0,unlabelled_weak_top1_acc:83.22601214051247,unlabelled_weak_top5_acc:99.0934085175395  \n","[2022-04-22 04:14:37,184][experiments.experiment][INFO] - [EMA] Epoch 7. [Validation] raw_testing_loss: 0.7851, raw test Top1 acc:75.22, raw test Top5 acc: 97.96, ema_testing_loss: 0.5056, ema test Top1 acc:84.78, ema test Top5 acc: 99.32\n","[2022-04-22 04:14:37,280][experiments.experiment][INFO] - [Checkpoints] Epoch 7, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 04:14:37,285][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 04:22:02,254][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 8: use 445.0709340572357 seconds\n","--- Optimizer learning rate changed from 2.99e-02 to 2.98e-02 ---\n","[2022-04-22 04:22:02,356][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 04:22:03,739][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 04:22:03,740][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 04:22:05,084][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 04:22:05,086][experiments.experiment][INFO] - [EMA] Epoch 8.[Train] time:445.0709340572357 seconds, lr:0.0298, train_loss: 2.2736, unlabeled_losses_real_strong:0.9207,corrrect_unlabeled_num:295518.0,pro_above_threshold_num:306145.0,unlabelled_weak_top1_acc:84.15963207930326,unlabelled_weak_top5_acc:99.16708672046661  \n","[2022-04-22 04:22:05,087][experiments.experiment][INFO] - [EMA] Epoch 8. [Validation] raw_testing_loss: 0.8157, raw test Top1 acc:73.24, raw test Top5 acc: 98.24, ema_testing_loss: 0.4729, ema test Top1 acc:85.66, ema test Top5 acc: 99.5\n","[2022-04-22 04:22:05,088][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 04:29:29,387][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 9: use 444.3958594799042 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.98e-02 ---\n","[2022-04-22 04:29:29,484][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 04:29:30,820][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 04:29:30,820][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 04:29:32,164][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 04:29:32,165][experiments.experiment][INFO] - [EMA] Epoch 9.[Train] time:444.3958594799042 seconds, lr:0.0298, train_loss: 2.2739, unlabeled_losses_real_strong:0.8851,corrrect_unlabeled_num:304852.0,pro_above_threshold_num:315387.0,unlabelled_weak_top1_acc:85.02567733824253,unlabelled_weak_top5_acc:99.2021819576621  \n","[2022-04-22 04:29:32,167][experiments.experiment][INFO] - [EMA] Epoch 9. [Validation] raw_testing_loss: 0.5924, raw test Top1 acc:79.3, raw test Top5 acc: 98.7, ema_testing_loss: 0.4430, ema test Top1 acc:86.5, ema test Top5 acc: 99.56\n","[2022-04-22 04:29:32,262][experiments.experiment][INFO] - [Checkpoints] Epoch 9, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 04:29:32,264][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 04:36:56,645][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 10: use 444.47934460639954 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.98e-02 ---\n","[2022-04-22 04:36:56,743][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 04:36:58,154][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 04:36:58,155][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 04:36:59,500][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 04:36:59,502][experiments.experiment][INFO] - [EMA] Epoch 10.[Train] time:444.47934460639954 seconds, lr:0.0298, train_loss: 2.2743, unlabeled_losses_real_strong:0.8541,corrrect_unlabeled_num:311860.0,pro_above_threshold_num:322341.0,unlabelled_weak_top1_acc:85.66458454728127,unlabelled_weak_top5_acc:99.2823997437954  \n","[2022-04-22 04:36:59,504][experiments.experiment][INFO] - [EMA] Epoch 10. [Validation] raw_testing_loss: 0.5819, raw test Top1 acc:82.06, raw test Top5 acc: 98.86, ema_testing_loss: 0.4237, ema test Top1 acc:87.38, ema test Top5 acc: 99.58\n","[2022-04-22 04:36:59,505][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 04:44:29,001][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 11: use 449.59780073165894 seconds\n","--- Optimizer learning rate changed from 2.98e-02 to 2.97e-02 ---\n","[2022-04-22 04:44:29,103][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 04:44:30,444][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 04:44:30,444][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 04:44:31,823][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 04:44:31,824][experiments.experiment][INFO] - [EMA] Epoch 11.[Train] time:449.59780073165894 seconds, lr:0.0297, train_loss: 2.2563, unlabeled_losses_real_strong:0.8319,corrrect_unlabeled_num:317836.0,pro_above_threshold_num:328303.0,unlabelled_weak_top1_acc:86.33902309089899,unlabelled_weak_top5_acc:99.32316245138645  \n","[2022-04-22 04:44:31,826][experiments.experiment][INFO] - [EMA] Epoch 11. [Validation] raw_testing_loss: 0.5916, raw test Top1 acc:81.14, raw test Top5 acc: 99.1, ema_testing_loss: 0.4023, ema test Top1 acc:88.12, ema test Top5 acc: 99.62\n","[2022-04-22 04:44:31,922][experiments.experiment][INFO] - [Checkpoints] Epoch 11, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 04:44:31,931][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 04:52:01,132][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 12: use 449.2974145412445 seconds\n","--- Optimizer learning rate changed from 2.97e-02 to 2.97e-02 ---\n","[2022-04-22 04:52:01,228][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 04:52:02,596][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 04:52:02,597][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 04:52:03,962][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 04:52:03,964][experiments.experiment][INFO] - [EMA] Epoch 12.[Train] time:449.2974145412445 seconds, lr:0.0297, train_loss: 2.2393, unlabeled_losses_real_strong:0.8096,corrrect_unlabeled_num:322063.0,pro_above_threshold_num:332239.0,unlabelled_weak_top1_acc:86.82207278907299,unlabelled_weak_top5_acc:99.36109150201082  \n","[2022-04-22 04:52:03,966][experiments.experiment][INFO] - [EMA] Epoch 12. [Validation] raw_testing_loss: 0.7266, raw test Top1 acc:79.0, raw test Top5 acc: 98.44, ema_testing_loss: 0.3868, ema test Top1 acc:88.46, ema test Top5 acc: 99.62\n","[2022-04-22 04:52:03,966][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 04:59:31,221][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 13: use 447.3523907661438 seconds\n","--- Optimizer learning rate changed from 2.97e-02 to 2.96e-02 ---\n","[2022-04-22 04:59:31,319][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 04:59:32,708][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 04:59:32,709][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 04:59:34,102][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 04:59:34,104][experiments.experiment][INFO] - [EMA] Epoch 13.[Train] time:447.3523907661438 seconds, lr:0.0296, train_loss: 2.2368, unlabeled_losses_real_strong:0.7875,corrrect_unlabeled_num:328023.0,pro_above_threshold_num:338277.0,unlabelled_weak_top1_acc:87.30010873824358,unlabelled_weak_top5_acc:99.36763123422861  \n","[2022-04-22 04:59:34,106][experiments.experiment][INFO] - [EMA] Epoch 13. [Validation] raw_testing_loss: 0.4933, raw test Top1 acc:84.06, raw test Top5 acc: 99.04, ema_testing_loss: 0.3756, ema test Top1 acc:88.72, ema test Top5 acc: 99.7\n","[2022-04-22 04:59:34,204][experiments.experiment][INFO] - [Checkpoints] Epoch 13, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 04:59:34,214][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 05:06:58,086][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 14: use 443.9683916568756 seconds\n","--- Optimizer learning rate changed from 2.96e-02 to 2.96e-02 ---\n","[2022-04-22 05:06:58,183][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 05:06:59,511][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 05:06:59,511][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 05:07:00,825][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 05:07:00,827][experiments.experiment][INFO] - [EMA] Epoch 14.[Train] time:443.9683916568756 seconds, lr:0.0296, train_loss: 2.2168, unlabeled_losses_real_strong:0.7705,corrrect_unlabeled_num:332112.0,pro_above_threshold_num:342231.0,unlabelled_weak_top1_acc:87.74653720110655,unlabelled_weak_top5_acc:99.4269225820899  \n","[2022-04-22 05:07:00,829][experiments.experiment][INFO] - [EMA] Epoch 14. [Validation] raw_testing_loss: 0.5482, raw test Top1 acc:82.98, raw test Top5 acc: 98.84, ema_testing_loss: 0.3591, ema test Top1 acc:89.36, ema test Top5 acc: 99.72\n","[2022-04-22 05:07:00,830][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 05:14:25,869][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 15: use 445.13581442832947 seconds\n","--- Optimizer learning rate changed from 2.96e-02 to 2.95e-02 ---\n","[2022-04-22 05:14:25,965][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 05:14:27,335][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 05:14:27,336][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 05:14:28,660][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 05:14:28,661][experiments.experiment][INFO] - [EMA] Epoch 15.[Train] time:445.13581442832947 seconds, lr:0.0295, train_loss: 2.2121, unlabeled_losses_real_strong:0.7548,corrrect_unlabeled_num:335699.0,pro_above_threshold_num:345605.0,unlabelled_weak_top1_acc:88.04081401228905,unlabelled_weak_top5_acc:99.42801266163588  \n","[2022-04-22 05:14:28,663][experiments.experiment][INFO] - [EMA] Epoch 15. [Validation] raw_testing_loss: 0.9637, raw test Top1 acc:74.9, raw test Top5 acc: 98.6, ema_testing_loss: 0.3475, ema test Top1 acc:89.66, ema test Top5 acc: 99.66\n","[2022-04-22 05:14:28,757][experiments.experiment][INFO] - [Checkpoints] Epoch 15, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 05:14:28,765][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 05:21:56,137][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 16: use 447.4715621471405 seconds\n","--- Optimizer learning rate changed from 2.95e-02 to 2.94e-02 ---\n","[2022-04-22 05:21:56,237][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 05:21:57,590][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 05:21:57,590][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 05:21:58,933][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 05:21:58,934][experiments.experiment][INFO] - [EMA] Epoch 16.[Train] time:447.4715621471405 seconds, lr:0.0294, train_loss: 2.2134, unlabeled_losses_real_strong:0.7435,corrrect_unlabeled_num:339801.0,pro_above_threshold_num:349897.0,unlabelled_weak_top1_acc:88.43972229212523,unlabelled_weak_top5_acc:99.44348935037851  \n","[2022-04-22 05:21:58,937][experiments.experiment][INFO] - [EMA] Epoch 16. [Validation] raw_testing_loss: 0.5546, raw test Top1 acc:83.76, raw test Top5 acc: 98.94, ema_testing_loss: 0.3386, ema test Top1 acc:89.88, ema test Top5 acc: 99.68\n","[2022-04-22 05:21:58,937][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 05:29:22,829][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 17: use 443.9902386665344 seconds\n","--- Optimizer learning rate changed from 2.94e-02 to 2.94e-02 ---\n","[2022-04-22 05:29:22,928][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 05:29:24,313][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 05:29:24,313][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 05:29:25,707][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 05:29:25,709][experiments.experiment][INFO] - [EMA] Epoch 17.[Train] time:443.9902386665344 seconds, lr:0.0294, train_loss: 2.1978, unlabeled_losses_real_strong:0.7321,corrrect_unlabeled_num:341653.0,pro_above_threshold_num:351335.0,unlabelled_weak_top1_acc:88.64963971823454,unlabelled_weak_top5_acc:99.48468832671642  \n","[2022-04-22 05:29:25,710][experiments.experiment][INFO] - [EMA] Epoch 17. [Validation] raw_testing_loss: 0.4798, raw test Top1 acc:84.96, raw test Top5 acc: 99.48, ema_testing_loss: 0.3294, ema test Top1 acc:90.42, ema test Top5 acc: 99.7\n","[2022-04-22 05:29:25,808][experiments.experiment][INFO] - [Checkpoints] Epoch 17, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 05:29:25,809][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 05:36:50,368][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 18: use 444.66096663475037 seconds\n","--- Optimizer learning rate changed from 2.94e-02 to 2.93e-02 ---\n","[2022-04-22 05:36:50,470][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 05:36:51,781][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 05:36:51,782][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 05:36:53,118][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 05:36:53,120][experiments.experiment][INFO] - [EMA] Epoch 18.[Train] time:444.66096663475037 seconds, lr:0.0293, train_loss: 2.1961, unlabeled_losses_real_strong:0.7210,corrrect_unlabeled_num:344706.0,pro_above_threshold_num:354615.0,unlabelled_weak_top1_acc:88.94587814807892,unlabelled_weak_top5_acc:99.48468827456236  \n","[2022-04-22 05:36:53,122][experiments.experiment][INFO] - [EMA] Epoch 18. [Validation] raw_testing_loss: 0.5707, raw test Top1 acc:83.82, raw test Top5 acc: 98.4, ema_testing_loss: 0.3258, ema test Top1 acc:90.38, ema test Top5 acc: 99.72\n","[2022-04-22 05:36:53,123][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 05:44:16,720][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 19: use 443.6979184150696 seconds\n","--- Optimizer learning rate changed from 2.93e-02 to 2.92e-02 ---\n","[2022-04-22 05:44:16,821][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 05:44:18,215][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 05:44:18,216][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 05:44:19,541][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 05:44:19,543][experiments.experiment][INFO] - [EMA] Epoch 19.[Train] time:443.6979184150696 seconds, lr:0.0292, train_loss: 2.1804, unlabeled_losses_real_strong:0.7083,corrrect_unlabeled_num:346163.0,pro_above_threshold_num:355959.0,unlabelled_weak_top1_acc:89.17911964654922,unlabelled_weak_top5_acc:99.5060508325696  \n","[2022-04-22 05:44:19,544][experiments.experiment][INFO] - [EMA] Epoch 19. [Validation] raw_testing_loss: 0.6883, raw test Top1 acc:80.98, raw test Top5 acc: 99.12, ema_testing_loss: 0.3154, ema test Top1 acc:90.62, ema test Top5 acc: 99.76\n","[2022-04-22 05:44:19,639][experiments.experiment][INFO] - [Checkpoints] Epoch 19, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 05:44:19,639][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 05:51:43,073][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 20: use 443.53057885169983 seconds\n","--- Optimizer learning rate changed from 2.92e-02 to 2.91e-02 ---\n","[2022-04-22 05:51:43,170][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 05:51:44,467][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 05:51:44,467][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 05:51:45,774][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 05:51:45,775][experiments.experiment][INFO] - [EMA] Epoch 20.[Train] time:443.53057885169983 seconds, lr:0.0291, train_loss: 2.1590, unlabeled_losses_real_strong:0.6996,corrrect_unlabeled_num:348122.0,pro_above_threshold_num:357661.0,unlabelled_weak_top1_acc:89.36331507563591,unlabelled_weak_top5_acc:99.51324417442083  \n","[2022-04-22 05:51:45,776][experiments.experiment][INFO] - [EMA] Epoch 20. [Validation] raw_testing_loss: 0.5540, raw test Top1 acc:84.0, raw test Top5 acc: 98.64, ema_testing_loss: 0.3101, ema test Top1 acc:90.48, ema test Top5 acc: 99.72\n","[2022-04-22 05:51:45,778][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 05:59:09,394][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 21: use 443.711962223053 seconds\n","--- Optimizer learning rate changed from 2.91e-02 to 2.91e-02 ---\n","[2022-04-22 05:59:09,490][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 05:59:10,791][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 05:59:10,791][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 05:59:12,115][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 05:59:12,117][experiments.experiment][INFO] - [EMA] Epoch 21.[Train] time:443.711962223053 seconds, lr:0.0291, train_loss: 2.1685, unlabeled_losses_real_strong:0.6882,corrrect_unlabeled_num:351269.0,pro_above_threshold_num:360809.0,unlabelled_weak_top1_acc:89.57061664760113,unlabelled_weak_top5_acc:99.52479735761881  \n","[2022-04-22 05:59:12,119][experiments.experiment][INFO] - [EMA] Epoch 21. [Validation] raw_testing_loss: 0.4978, raw test Top1 acc:85.7, raw test Top5 acc: 99.56, ema_testing_loss: 0.3057, ema test Top1 acc:90.88, ema test Top5 acc: 99.84\n","[2022-04-22 05:59:12,211][experiments.experiment][INFO] - [Checkpoints] Epoch 21, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 05:59:12,221][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 06:06:32,298][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 22: use 440.1769344806671 seconds\n","--- Optimizer learning rate changed from 2.91e-02 to 2.90e-02 ---\n","[2022-04-22 06:06:32,398][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 06:06:33,750][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 06:06:33,751][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 06:06:35,077][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 06:06:35,079][experiments.experiment][INFO] - [EMA] Epoch 22.[Train] time:440.1769344806671 seconds, lr:0.0290, train_loss: 2.1600, unlabeled_losses_real_strong:0.6810,corrrect_unlabeled_num:352914.0,pro_above_threshold_num:362496.0,unlabelled_weak_top1_acc:89.78467571735382,unlabelled_weak_top5_acc:99.56141856312752  \n","[2022-04-22 06:06:35,081][experiments.experiment][INFO] - [EMA] Epoch 22. [Validation] raw_testing_loss: 0.4286, raw test Top1 acc:86.48, raw test Top5 acc: 99.42, ema_testing_loss: 0.2971, ema test Top1 acc:91.38, ema test Top5 acc: 99.78\n","[2022-04-22 06:06:35,082][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 06:13:57,720][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 23: use 442.7456660270691 seconds\n","--- Optimizer learning rate changed from 2.90e-02 to 2.89e-02 ---\n","[2022-04-22 06:13:57,828][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 06:13:59,158][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 06:13:59,159][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 06:14:00,462][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 06:14:00,464][experiments.experiment][INFO] - [EMA] Epoch 23.[Train] time:442.7456660270691 seconds, lr:0.0289, train_loss: 2.1474, unlabeled_losses_real_strong:0.6747,corrrect_unlabeled_num:354699.0,pro_above_threshold_num:364017.0,unlabelled_weak_top1_acc:89.91110546141863,unlabelled_weak_top5_acc:99.57449761778116  \n","[2022-04-22 06:14:00,466][experiments.experiment][INFO] - [EMA] Epoch 23. [Validation] raw_testing_loss: 0.4959, raw test Top1 acc:84.36, raw test Top5 acc: 99.52, ema_testing_loss: 0.2919, ema test Top1 acc:91.5, ema test Top5 acc: 99.76\n","[2022-04-22 06:14:00,558][experiments.experiment][INFO] - [Checkpoints] Epoch 23, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 06:14:00,560][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 06:21:23,715][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 24: use 443.25017070770264 seconds\n","--- Optimizer learning rate changed from 2.89e-02 to 2.88e-02 ---\n","[2022-04-22 06:21:23,810][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 06:21:25,140][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 06:21:25,140][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 06:21:26,429][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 06:21:26,430][experiments.experiment][INFO] - [EMA] Epoch 24.[Train] time:443.25017070770264 seconds, lr:0.0288, train_loss: 2.1315, unlabeled_losses_real_strong:0.6677,corrrect_unlabeled_num:356010.0,pro_above_threshold_num:365382.0,unlabelled_weak_top1_acc:90.13955138623714,unlabelled_weak_top5_acc:99.5786393135786  \n","[2022-04-22 06:21:26,433][experiments.experiment][INFO] - [EMA] Epoch 24. [Validation] raw_testing_loss: 0.5038, raw test Top1 acc:85.92, raw test Top5 acc: 99.48, ema_testing_loss: 0.2922, ema test Top1 acc:91.44, ema test Top5 acc: 99.78\n","[2022-04-22 06:21:26,433][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 06:28:52,692][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 25: use 446.35695815086365 seconds\n","--- Optimizer learning rate changed from 2.88e-02 to 2.87e-02 ---\n","[2022-04-22 06:28:52,791][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 06:28:54,124][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 06:28:54,125][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 06:28:55,452][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 06:28:55,453][experiments.experiment][INFO] - [EMA] Epoch 25.[Train] time:446.35695815086365 seconds, lr:0.0287, train_loss: 2.1325, unlabeled_losses_real_strong:0.6575,corrrect_unlabeled_num:358039.0,pro_above_threshold_num:367262.0,unlabelled_weak_top1_acc:90.28777963668108,unlabelled_weak_top5_acc:99.56512419879436  \n","[2022-04-22 06:28:55,455][experiments.experiment][INFO] - [EMA] Epoch 25. [Validation] raw_testing_loss: 0.4473, raw test Top1 acc:86.92, raw test Top5 acc: 99.44, ema_testing_loss: 0.2895, ema test Top1 acc:91.56, ema test Top5 acc: 99.78\n","[2022-04-22 06:28:55,570][experiments.experiment][INFO] - [Checkpoints] Epoch 25, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 06:28:55,580][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 06:36:15,980][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 26: use 440.49835085868835 seconds\n","--- Optimizer learning rate changed from 2.87e-02 to 2.86e-02 ---\n","[2022-04-22 06:36:16,079][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 06:36:17,404][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 06:36:17,404][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 06:36:18,745][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 06:36:18,747][experiments.experiment][INFO] - [EMA] Epoch 26.[Train] time:440.49835085868835 seconds, lr:0.0286, train_loss: 2.1456, unlabeled_losses_real_strong:0.6526,corrrect_unlabeled_num:359521.0,pro_above_threshold_num:368825.0,unlabelled_weak_top1_acc:90.42946847528219,unlabelled_weak_top5_acc:99.59564197063446  \n","[2022-04-22 06:36:18,748][experiments.experiment][INFO] - [EMA] Epoch 26. [Validation] raw_testing_loss: 0.4236, raw test Top1 acc:87.82, raw test Top5 acc: 99.42, ema_testing_loss: 0.2822, ema test Top1 acc:91.54, ema test Top5 acc: 99.82\n","[2022-04-22 06:36:18,749][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 06:43:42,783][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 27: use 444.1376893520355 seconds\n","--- Optimizer learning rate changed from 2.86e-02 to 2.85e-02 ---\n","[2022-04-22 06:43:42,886][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 06:43:44,196][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 06:43:44,197][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 06:43:45,495][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 06:43:45,496][experiments.experiment][INFO] - [EMA] Epoch 27.[Train] time:444.1376893520355 seconds, lr:0.0285, train_loss: 2.1291, unlabeled_losses_real_strong:0.6471,corrrect_unlabeled_num:360565.0,pro_above_threshold_num:369820.0,unlabelled_weak_top1_acc:90.50009479373693,unlabelled_weak_top5_acc:99.59847578406334  \n","[2022-04-22 06:43:45,498][experiments.experiment][INFO] - [EMA] Epoch 27. [Validation] raw_testing_loss: 0.5834, raw test Top1 acc:84.5, raw test Top5 acc: 99.0, ema_testing_loss: 0.2778, ema test Top1 acc:91.88, ema test Top5 acc: 99.76\n","[2022-04-22 06:43:45,591][experiments.experiment][INFO] - [Checkpoints] Epoch 27, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 06:43:45,594][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 06:51:10,117][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 28: use 444.6189777851105 seconds\n","--- Optimizer learning rate changed from 2.85e-02 to 2.84e-02 ---\n","[2022-04-22 06:51:10,213][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 06:51:11,535][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 06:51:11,535][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 06:51:12,886][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 06:51:12,887][experiments.experiment][INFO] - [EMA] Epoch 28.[Train] time:444.6189777851105 seconds, lr:0.0284, train_loss: 2.1155, unlabeled_losses_real_strong:0.6405,corrrect_unlabeled_num:362189.0,pro_above_threshold_num:371230.0,unlabelled_weak_top1_acc:90.69061180204153,unlabelled_weak_top5_acc:99.60523335635662  \n","[2022-04-22 06:51:12,889][experiments.experiment][INFO] - [EMA] Epoch 28. [Validation] raw_testing_loss: 0.5180, raw test Top1 acc:85.82, raw test Top5 acc: 99.36, ema_testing_loss: 0.2738, ema test Top1 acc:91.9, ema test Top5 acc: 99.78\n","[2022-04-22 06:51:12,890][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 06:58:37,323][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 29: use 444.5300073623657 seconds\n","--- Optimizer learning rate changed from 2.84e-02 to 2.82e-02 ---\n","[2022-04-22 06:58:37,420][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 06:58:38,778][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 06:58:38,779][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 06:58:40,155][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 06:58:40,156][experiments.experiment][INFO] - [EMA] Epoch 29.[Train] time:444.5300073623657 seconds, lr:0.0282, train_loss: 2.1140, unlabeled_losses_real_strong:0.6379,corrrect_unlabeled_num:362752.0,pro_above_threshold_num:371873.0,unlabelled_weak_top1_acc:90.75164677202702,unlabelled_weak_top5_acc:99.61068280041218  \n","[2022-04-22 06:58:40,158][experiments.experiment][INFO] - [EMA] Epoch 29. [Validation] raw_testing_loss: 0.4842, raw test Top1 acc:87.34, raw test Top5 acc: 99.18, ema_testing_loss: 0.2730, ema test Top1 acc:91.92, ema test Top5 acc: 99.76\n","[2022-04-22 06:58:40,253][experiments.experiment][INFO] - [Checkpoints] Epoch 29, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 06:58:40,263][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 07:06:05,030][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 30: use 444.86858320236206 seconds\n","--- Optimizer learning rate changed from 2.82e-02 to 2.81e-02 ---\n","[2022-04-22 07:06:05,132][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 07:06:06,475][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 07:06:06,475][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 07:06:07,791][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 07:06:07,792][experiments.experiment][INFO] - [EMA] Epoch 30.[Train] time:444.86858320236206 seconds, lr:0.0281, train_loss: 2.0939, unlabeled_losses_real_strong:0.6314,corrrect_unlabeled_num:363355.0,pro_above_threshold_num:372479.0,unlabelled_weak_top1_acc:90.79524338245392,unlabelled_weak_top5_acc:99.6174403578043  \n","[2022-04-22 07:06:07,794][experiments.experiment][INFO] - [EMA] Epoch 30. [Validation] raw_testing_loss: 0.4044, raw test Top1 acc:88.28, raw test Top5 acc: 99.18, ema_testing_loss: 0.2731, ema test Top1 acc:92.0, ema test Top5 acc: 99.76\n","[2022-04-22 07:06:07,795][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 07:13:35,269][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 31: use 447.57319712638855 seconds\n","--- Optimizer learning rate changed from 2.81e-02 to 2.80e-02 ---\n","[2022-04-22 07:13:35,368][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 07:13:36,771][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 07:13:36,771][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 07:13:38,134][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 07:13:38,136][experiments.experiment][INFO] - [EMA] Epoch 31.[Train] time:447.57319712638855 seconds, lr:0.0280, train_loss: 2.1099, unlabeled_losses_real_strong:0.6276,corrrect_unlabeled_num:364828.0,pro_above_threshold_num:373927.0,unlabelled_weak_top1_acc:90.93126465380192,unlabelled_weak_top5_acc:99.61308065056801  \n","[2022-04-22 07:13:38,137][experiments.experiment][INFO] - [EMA] Epoch 31. [Validation] raw_testing_loss: 0.4985, raw test Top1 acc:86.62, raw test Top5 acc: 99.22, ema_testing_loss: 0.2691, ema test Top1 acc:91.94, ema test Top5 acc: 99.78\n","[2022-04-22 07:13:38,233][experiments.experiment][INFO] - [Checkpoints] Epoch 31, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 07:13:38,237][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 07:21:01,997][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 32: use 443.8585362434387 seconds\n","--- Optimizer learning rate changed from 2.80e-02 to 2.79e-02 ---\n","[2022-04-22 07:21:02,096][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 07:21:03,432][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 07:21:03,433][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 07:21:04,806][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 07:21:04,807][experiments.experiment][INFO] - [EMA] Epoch 32.[Train] time:443.8585362434387 seconds, lr:0.0279, train_loss: 2.0783, unlabeled_losses_real_strong:0.6194,corrrect_unlabeled_num:365799.0,pro_above_threshold_num:374643.0,unlabelled_weak_top1_acc:91.04941119998693,unlabelled_weak_top5_acc:99.62223599851131  \n","[2022-04-22 07:21:04,810][experiments.experiment][INFO] - [EMA] Epoch 32. [Validation] raw_testing_loss: 0.4069, raw test Top1 acc:88.0, raw test Top5 acc: 99.52, ema_testing_loss: 0.2663, ema test Top1 acc:92.24, ema test Top5 acc: 99.78\n","[2022-04-22 07:21:04,810][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 07:28:27,643][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 33: use 442.9369821548462 seconds\n","--- Optimizer learning rate changed from 2.79e-02 to 2.78e-02 ---\n","[2022-04-22 07:28:27,747][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 07:28:29,066][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 07:28:29,066][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 07:28:30,411][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 07:28:30,413][experiments.experiment][INFO] - [EMA] Epoch 33.[Train] time:442.9369821548462 seconds, lr:0.0278, train_loss: 2.0802, unlabeled_losses_real_strong:0.6173,corrrect_unlabeled_num:366705.0,pro_above_threshold_num:375591.0,unlabelled_weak_top1_acc:91.13071874529123,unlabelled_weak_top5_acc:99.64577823877335  \n","[2022-04-22 07:28:30,415][experiments.experiment][INFO] - [EMA] Epoch 33. [Validation] raw_testing_loss: 0.3695, raw test Top1 acc:88.8, raw test Top5 acc: 99.42, ema_testing_loss: 0.2661, ema test Top1 acc:92.34, ema test Top5 acc: 99.76\n","[2022-04-22 07:28:30,511][experiments.experiment][INFO] - [Checkpoints] Epoch 33, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 07:28:30,512][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 07:35:52,001][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 34: use 441.5876100063324 seconds\n","--- Optimizer learning rate changed from 2.78e-02 to 2.76e-02 ---\n","[2022-04-22 07:35:52,100][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 07:35:53,449][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 07:35:53,449][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 07:35:54,782][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 07:35:54,783][experiments.experiment][INFO] - [EMA] Epoch 34.[Train] time:441.5876100063324 seconds, lr:0.0276, train_loss: 2.0778, unlabeled_losses_real_strong:0.6119,corrrect_unlabeled_num:368421.0,pro_above_threshold_num:377313.0,unlabelled_weak_top1_acc:91.24494176357985,unlabelled_weak_top5_acc:99.62899354845285  \n","[2022-04-22 07:35:54,785][experiments.experiment][INFO] - [EMA] Epoch 34. [Validation] raw_testing_loss: 0.5158, raw test Top1 acc:85.68, raw test Top5 acc: 98.82, ema_testing_loss: 0.2613, ema test Top1 acc:92.54, ema test Top5 acc: 99.76\n","[2022-04-22 07:35:54,786][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 07:43:17,171][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 35: use 442.4820375442505 seconds\n","--- Optimizer learning rate changed from 2.76e-02 to 2.75e-02 ---\n","[2022-04-22 07:43:17,268][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 07:43:18,579][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 07:43:18,580][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 07:43:19,879][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 07:43:19,880][experiments.experiment][INFO] - [EMA] Epoch 35.[Train] time:442.4820375442505 seconds, lr:0.0275, train_loss: 2.0726, unlabeled_losses_real_strong:0.6110,corrrect_unlabeled_num:368852.0,pro_above_threshold_num:377774.0,unlabelled_weak_top1_acc:91.31818388402462,unlabelled_weak_top5_acc:99.6477402150631  \n","[2022-04-22 07:43:19,882][experiments.experiment][INFO] - [EMA] Epoch 35. [Validation] raw_testing_loss: 0.4799, raw test Top1 acc:86.7, raw test Top5 acc: 99.34, ema_testing_loss: 0.2616, ema test Top1 acc:92.56, ema test Top5 acc: 99.78\n","[2022-04-22 07:43:19,979][experiments.experiment][INFO] - [Checkpoints] Epoch 35, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 07:43:19,980][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 07:50:41,318][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 36: use 441.43333864212036 seconds\n","--- Optimizer learning rate changed from 2.75e-02 to 2.73e-02 ---\n","[2022-04-22 07:50:41,413][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 07:50:42,736][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 07:50:42,736][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 07:50:44,101][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 07:50:44,103][experiments.experiment][INFO] - [EMA] Epoch 36.[Train] time:441.43333864212036 seconds, lr:0.0273, train_loss: 2.0628, unlabeled_losses_real_strong:0.6012,corrrect_unlabeled_num:370169.0,pro_above_threshold_num:379060.0,unlabelled_weak_top1_acc:91.41758409887552,unlabelled_weak_top5_acc:99.66496078670025  \n","[2022-04-22 07:50:44,105][experiments.experiment][INFO] - [EMA] Epoch 36. [Validation] raw_testing_loss: 0.4122, raw test Top1 acc:87.82, raw test Top5 acc: 99.64, ema_testing_loss: 0.2615, ema test Top1 acc:92.58, ema test Top5 acc: 99.76\n","[2022-04-22 07:50:44,105][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 07:58:07,101][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 37: use 443.0964903831482 seconds\n","--- Optimizer learning rate changed from 2.73e-02 to 2.72e-02 ---\n","[2022-04-22 07:58:07,202][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 07:58:08,512][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 07:58:08,512][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 07:58:09,819][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 07:58:09,821][experiments.experiment][INFO] - [EMA] Epoch 37.[Train] time:443.0964903831482 seconds, lr:0.0272, train_loss: 2.0611, unlabeled_losses_real_strong:0.6003,corrrect_unlabeled_num:370457.0,pro_above_threshold_num:379279.0,unlabelled_weak_top1_acc:91.46706619858742,unlabelled_weak_top5_acc:99.66714052855968  \n","[2022-04-22 07:58:09,822][experiments.experiment][INFO] - [EMA] Epoch 37. [Validation] raw_testing_loss: 0.4944, raw test Top1 acc:86.64, raw test Top5 acc: 99.36, ema_testing_loss: 0.2568, ema test Top1 acc:92.84, ema test Top5 acc: 99.82\n","[2022-04-22 07:58:09,920][experiments.experiment][INFO] - [Checkpoints] Epoch 37, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 07:58:09,922][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 08:05:30,904][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 38: use 441.08003401756287 seconds\n","--- Optimizer learning rate changed from 2.72e-02 to 2.71e-02 ---\n","[2022-04-22 08:05:31,002][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 08:05:32,323][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 08:05:32,324][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 08:05:33,670][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 08:05:33,672][experiments.experiment][INFO] - [EMA] Epoch 38.[Train] time:441.08003401756287 seconds, lr:0.0271, train_loss: 2.0599, unlabeled_losses_real_strong:0.5975,corrrect_unlabeled_num:371103.0,pro_above_threshold_num:379928.0,unlabelled_weak_top1_acc:91.50870084762573,unlabelled_weak_top5_acc:99.67280820012093  \n","[2022-04-22 08:05:33,675][experiments.experiment][INFO] - [EMA] Epoch 38. [Validation] raw_testing_loss: 0.4315, raw test Top1 acc:87.66, raw test Top5 acc: 99.22, ema_testing_loss: 0.2572, ema test Top1 acc:92.74, ema test Top5 acc: 99.82\n","[2022-04-22 08:05:33,675][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 08:12:55,911][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 39: use 442.3292338848114 seconds\n","--- Optimizer learning rate changed from 2.71e-02 to 2.69e-02 ---\n","[2022-04-22 08:12:56,004][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 08:12:57,318][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 08:12:57,319][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 08:12:58,628][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 08:12:58,630][experiments.experiment][INFO] - [EMA] Epoch 39.[Train] time:442.3292338848114 seconds, lr:0.0269, train_loss: 2.0527, unlabeled_losses_real_strong:0.5916,corrrect_unlabeled_num:371855.0,pro_above_threshold_num:380558.0,unlabelled_weak_top1_acc:91.58325085043907,unlabelled_weak_top5_acc:99.67585987597704  \n","[2022-04-22 08:12:58,632][experiments.experiment][INFO] - [EMA] Epoch 39. [Validation] raw_testing_loss: 0.3828, raw test Top1 acc:88.48, raw test Top5 acc: 99.6, ema_testing_loss: 0.2555, ema test Top1 acc:93.08, ema test Top5 acc: 99.8\n","[2022-04-22 08:12:58,724][experiments.experiment][INFO] - [Checkpoints] Epoch 39, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 08:12:58,725][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 08:20:20,148][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 40: use 441.52192759513855 seconds\n","--- Optimizer learning rate changed from 2.69e-02 to 2.68e-02 ---\n","[2022-04-22 08:20:20,247][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 08:20:21,565][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 08:20:21,566][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 08:20:22,933][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 08:20:22,935][experiments.experiment][INFO] - [EMA] Epoch 40.[Train] time:441.52192759513855 seconds, lr:0.0268, train_loss: 2.0435, unlabeled_losses_real_strong:0.5855,corrrect_unlabeled_num:373657.0,pro_above_threshold_num:382330.0,unlabelled_weak_top1_acc:91.73562088608742,unlabelled_weak_top5_acc:99.67019230872393  \n","[2022-04-22 08:20:22,937][experiments.experiment][INFO] - [EMA] Epoch 40. [Validation] raw_testing_loss: 0.3820, raw test Top1 acc:89.18, raw test Top5 acc: 99.48, ema_testing_loss: 0.2524, ema test Top1 acc:93.02, ema test Top5 acc: 99.8\n","[2022-04-22 08:20:22,938][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 08:27:45,204][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 41: use 442.37108850479126 seconds\n","--- Optimizer learning rate changed from 2.68e-02 to 2.66e-02 ---\n","[2022-04-22 08:27:45,309][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 08:27:46,639][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 08:27:46,639][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 08:27:47,986][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 08:27:47,987][experiments.experiment][INFO] - [EMA] Epoch 41.[Train] time:442.37108850479126 seconds, lr:0.0266, train_loss: 2.0602, unlabeled_losses_real_strong:0.5824,corrrect_unlabeled_num:375154.0,pro_above_threshold_num:383827.0,unlabelled_weak_top1_acc:91.85856291651726,unlabelled_weak_top5_acc:99.6882850304246  \n","[2022-04-22 08:27:47,989][experiments.experiment][INFO] - [EMA] Epoch 41. [Validation] raw_testing_loss: 0.3727, raw test Top1 acc:89.46, raw test Top5 acc: 99.48, ema_testing_loss: 0.2495, ema test Top1 acc:93.32, ema test Top5 acc: 99.82\n","[2022-04-22 08:27:48,083][experiments.experiment][INFO] - [Checkpoints] Epoch 41, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 08:27:48,086][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 08:35:09,530][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 42: use 441.5443968772888 seconds\n","--- Optimizer learning rate changed from 2.66e-02 to 2.64e-02 ---\n","[2022-04-22 08:35:09,630][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 08:35:10,964][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 08:35:10,965][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 08:35:12,317][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 08:35:12,319][experiments.experiment][INFO] - [EMA] Epoch 42.[Train] time:441.5443968772888 seconds, lr:0.0264, train_loss: 2.0361, unlabeled_losses_real_strong:0.5756,corrrect_unlabeled_num:374859.0,pro_above_threshold_num:383474.0,unlabelled_weak_top1_acc:91.90303159505129,unlabelled_weak_top5_acc:99.68196345865726  \n","[2022-04-22 08:35:12,320][experiments.experiment][INFO] - [EMA] Epoch 42. [Validation] raw_testing_loss: 0.4472, raw test Top1 acc:87.64, raw test Top5 acc: 99.5, ema_testing_loss: 0.2480, ema test Top1 acc:93.06, ema test Top5 acc: 99.82\n","[2022-04-22 08:35:12,322][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 08:42:35,402][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 43: use 443.1768100261688 seconds\n","--- Optimizer learning rate changed from 2.64e-02 to 2.63e-02 ---\n","[2022-04-22 08:42:35,499][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 08:42:36,885][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 08:42:36,885][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 08:42:38,239][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 08:42:38,241][experiments.experiment][INFO] - [EMA] Epoch 43.[Train] time:443.1768100261688 seconds, lr:0.0263, train_loss: 2.0368, unlabeled_losses_real_strong:0.5787,corrrect_unlabeled_num:375121.0,pro_above_threshold_num:383571.0,unlabelled_weak_top1_acc:91.86575636267662,unlabelled_weak_top5_acc:99.69373454898596  \n","[2022-04-22 08:42:38,243][experiments.experiment][INFO] - [EMA] Epoch 43. [Validation] raw_testing_loss: 0.4119, raw test Top1 acc:88.5, raw test Top5 acc: 99.52, ema_testing_loss: 0.2437, ema test Top1 acc:93.1, ema test Top5 acc: 99.8\n","[2022-04-22 08:42:38,333][experiments.experiment][INFO] - [Checkpoints] Epoch 43, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 08:42:38,335][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 08:49:58,938][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 44: use 440.6965796947479 seconds\n","--- Optimizer learning rate changed from 2.63e-02 to 2.61e-02 ---\n","[2022-04-22 08:49:59,031][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 08:50:00,371][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 08:50:00,372][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 08:50:01,692][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 08:50:01,694][experiments.experiment][INFO] - [EMA] Epoch 44.[Train] time:440.6965796947479 seconds, lr:0.0261, train_loss: 2.0349, unlabeled_losses_real_strong:0.5734,corrrect_unlabeled_num:376547.0,pro_above_threshold_num:385145.0,unlabelled_weak_top1_acc:92.04733606427908,unlabelled_weak_top5_acc:99.70485174655914  \n","[2022-04-22 08:50:01,696][experiments.experiment][INFO] - [EMA] Epoch 44. [Validation] raw_testing_loss: 0.3790, raw test Top1 acc:88.44, raw test Top5 acc: 99.66, ema_testing_loss: 0.2433, ema test Top1 acc:93.36, ema test Top5 acc: 99.82\n","[2022-04-22 08:50:01,697][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 08:57:24,137][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 45: use 442.5352523326874 seconds\n","--- Optimizer learning rate changed from 2.61e-02 to 2.59e-02 ---\n","[2022-04-22 08:57:24,232][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 08:57:25,577][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 08:57:25,577][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 08:57:26,901][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 08:57:26,902][experiments.experiment][INFO] - [EMA] Epoch 45.[Train] time:442.5352523326874 seconds, lr:0.0259, train_loss: 2.0270, unlabeled_losses_real_strong:0.5696,corrrect_unlabeled_num:377149.0,pro_above_threshold_num:385865.0,unlabelled_weak_top1_acc:92.01681838929653,unlabelled_weak_top5_acc:99.7037617713213  \n","[2022-04-22 08:57:26,904][experiments.experiment][INFO] - [EMA] Epoch 45. [Validation] raw_testing_loss: 0.3909, raw test Top1 acc:88.66, raw test Top5 acc: 99.76, ema_testing_loss: 0.2476, ema test Top1 acc:93.16, ema test Top5 acc: 99.82\n","[2022-04-22 08:57:26,999][experiments.experiment][INFO] - [Checkpoints] Epoch 45, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 08:57:27,000][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 09:04:46,137][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 46: use 439.2327370643616 seconds\n","--- Optimizer learning rate changed from 2.59e-02 to 2.58e-02 ---\n","[2022-04-22 09:04:46,232][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 09:04:47,533][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 09:04:47,533][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 09:04:48,900][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 09:04:48,902][experiments.experiment][INFO] - [EMA] Epoch 46.[Train] time:439.2327370643616 seconds, lr:0.0258, train_loss: 2.0410, unlabeled_losses_real_strong:0.5669,corrrect_unlabeled_num:378056.0,pro_above_threshold_num:386509.0,unlabelled_weak_top1_acc:92.16221281886101,unlabelled_weak_top5_acc:99.69068286567926  \n","[2022-04-22 09:04:48,904][experiments.experiment][INFO] - [EMA] Epoch 46. [Validation] raw_testing_loss: 0.3662, raw test Top1 acc:89.52, raw test Top5 acc: 99.6, ema_testing_loss: 0.2409, ema test Top1 acc:93.42, ema test Top5 acc: 99.86\n","[2022-04-22 09:04:48,905][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 09:12:09,094][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 47: use 440.28928542137146 seconds\n","--- Optimizer learning rate changed from 2.58e-02 to 2.56e-02 ---\n","[2022-04-22 09:12:09,194][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 09:12:10,521][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 09:12:10,521][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 09:12:11,865][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 09:12:11,867][experiments.experiment][INFO] - [EMA] Epoch 47.[Train] time:440.28928542137146 seconds, lr:0.0256, train_loss: 2.0255, unlabeled_losses_real_strong:0.5627,corrrect_unlabeled_num:378453.0,pro_above_threshold_num:386867.0,unlabelled_weak_top1_acc:92.2164906039834,unlabelled_weak_top5_acc:99.71008336544037  \n","[2022-04-22 09:12:11,868][experiments.experiment][INFO] - [EMA] Epoch 47. [Validation] raw_testing_loss: 0.3886, raw test Top1 acc:88.32, raw test Top5 acc: 99.5, ema_testing_loss: 0.2393, ema test Top1 acc:93.26, ema test Top5 acc: 99.86\n","[2022-04-22 09:12:11,971][experiments.experiment][INFO] - [Checkpoints] Epoch 47, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 09:12:11,973][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 09:19:34,371][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 48: use 442.4953327178955 seconds\n","--- Optimizer learning rate changed from 2.56e-02 to 2.54e-02 ---\n","[2022-04-22 09:19:34,469][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 09:19:35,763][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 09:19:35,763][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 09:19:37,060][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 09:19:37,061][experiments.experiment][INFO] - [EMA] Epoch 48.[Train] time:442.4953327178955 seconds, lr:0.0254, train_loss: 2.0231, unlabeled_losses_real_strong:0.5606,corrrect_unlabeled_num:379587.0,pro_above_threshold_num:388021.0,unlabelled_weak_top1_acc:92.32155820727348,unlabelled_weak_top5_acc:99.69853027164936  \n","[2022-04-22 09:19:37,064][experiments.experiment][INFO] - [EMA] Epoch 48. [Validation] raw_testing_loss: 0.5566, raw test Top1 acc:84.86, raw test Top5 acc: 98.84, ema_testing_loss: 0.2351, ema test Top1 acc:93.46, ema test Top5 acc: 99.8\n","[2022-04-22 09:19:37,064][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 09:27:01,685][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 49: use 444.71651554107666 seconds\n","--- Optimizer learning rate changed from 2.54e-02 to 2.52e-02 ---\n","[2022-04-22 09:27:01,781][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 09:27:03,085][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 09:27:03,085][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 09:27:04,421][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 09:27:04,423][experiments.experiment][INFO] - [EMA] Epoch 49.[Train] time:444.71651554107666 seconds, lr:0.0252, train_loss: 2.0263, unlabeled_losses_real_strong:0.5568,corrrect_unlabeled_num:380051.0,pro_above_threshold_num:388528.0,unlabelled_weak_top1_acc:92.32896967232227,unlabelled_weak_top5_acc:99.71182721853256  \n","[2022-04-22 09:27:04,424][experiments.experiment][INFO] - [EMA] Epoch 49. [Validation] raw_testing_loss: 0.3666, raw test Top1 acc:89.0, raw test Top5 acc: 99.56, ema_testing_loss: 0.2341, ema test Top1 acc:93.62, ema test Top5 acc: 99.8\n","[2022-04-22 09:27:04,524][experiments.experiment][INFO] - [Checkpoints] Epoch 49, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 09:27:04,526][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 09:34:27,394][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 50: use 442.96887254714966 seconds\n","--- Optimizer learning rate changed from 2.52e-02 to 2.50e-02 ---\n","[2022-04-22 09:34:27,495][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 09:34:28,819][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 09:34:28,819][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 09:34:30,191][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 09:34:30,193][experiments.experiment][INFO] - [EMA] Epoch 50.[Train] time:442.96887254714966 seconds, lr:0.0250, train_loss: 2.0047, unlabeled_losses_real_strong:0.5526,corrrect_unlabeled_num:380885.0,pro_above_threshold_num:389385.0,unlabelled_weak_top1_acc:92.41638062149286,unlabelled_weak_top5_acc:99.70637760311365  \n","[2022-04-22 09:34:30,196][experiments.experiment][INFO] - [EMA] Epoch 50. [Validation] raw_testing_loss: 0.4466, raw test Top1 acc:88.22, raw test Top5 acc: 99.66, ema_testing_loss: 0.2309, ema test Top1 acc:93.58, ema test Top5 acc: 99.8\n","[2022-04-22 09:34:30,196][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 09:41:54,415][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 51: use 444.3147714138031 seconds\n","--- Optimizer learning rate changed from 2.50e-02 to 2.48e-02 ---\n","[2022-04-22 09:41:54,511][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 09:41:55,859][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 09:41:55,860][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 09:41:57,218][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 09:41:57,220][experiments.experiment][INFO] - [EMA] Epoch 51.[Train] time:444.3147714138031 seconds, lr:0.0248, train_loss: 2.0044, unlabeled_losses_real_strong:0.5533,corrrect_unlabeled_num:380688.0,pro_above_threshold_num:389303.0,unlabelled_weak_top1_acc:92.43185755610466,unlabelled_weak_top5_acc:99.7085574194789  \n","[2022-04-22 09:41:57,221][experiments.experiment][INFO] - [EMA] Epoch 51. [Validation] raw_testing_loss: 0.4516, raw test Top1 acc:87.36, raw test Top5 acc: 99.24, ema_testing_loss: 0.2314, ema test Top1 acc:93.48, ema test Top5 acc: 99.84\n","[2022-04-22 09:41:57,320][experiments.experiment][INFO] - [Checkpoints] Epoch 51, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 09:41:57,322][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 09:49:22,865][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 52: use 445.6394567489624 seconds\n","--- Optimizer learning rate changed from 2.48e-02 to 2.46e-02 ---\n","[2022-04-22 09:49:22,962][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 09:49:24,261][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 09:49:24,261][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 09:49:25,621][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 09:49:25,622][experiments.experiment][INFO] - [EMA] Epoch 52.[Train] time:445.6394567489624 seconds, lr:0.0246, train_loss: 1.9997, unlabeled_losses_real_strong:0.5456,corrrect_unlabeled_num:382464.0,pro_above_threshold_num:390844.0,unlabelled_weak_top1_acc:92.51948673278093,unlabelled_weak_top5_acc:99.73057372868061  \n","[2022-04-22 09:49:25,624][experiments.experiment][INFO] - [EMA] Epoch 52. [Validation] raw_testing_loss: 0.4328, raw test Top1 acc:87.62, raw test Top5 acc: 99.48, ema_testing_loss: 0.2321, ema test Top1 acc:93.44, ema test Top5 acc: 99.86\n","[2022-04-22 09:49:25,625][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 09:56:49,149][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 53: use 443.62217712402344 seconds\n","--- Optimizer learning rate changed from 2.46e-02 to 2.44e-02 ---\n","[2022-04-22 09:56:49,247][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 09:56:50,554][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 09:56:50,555][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 09:56:51,850][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 09:56:51,852][experiments.experiment][INFO] - [EMA] Epoch 53.[Train] time:443.62217712402344 seconds, lr:0.0244, train_loss: 1.9914, unlabeled_losses_real_strong:0.5417,corrrect_unlabeled_num:382421.0,pro_above_threshold_num:390709.0,unlabelled_weak_top1_acc:92.61910480260849,unlabelled_weak_top5_acc:99.71858460456133  \n","[2022-04-22 09:56:51,855][experiments.experiment][INFO] - [EMA] Epoch 53. [Validation] raw_testing_loss: 0.3599, raw test Top1 acc:89.24, raw test Top5 acc: 99.78, ema_testing_loss: 0.2297, ema test Top1 acc:93.58, ema test Top5 acc: 99.86\n","[2022-04-22 09:56:51,946][experiments.experiment][INFO] - [Checkpoints] Epoch 53, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 09:56:51,950][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 10:04:16,081][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 54: use 444.23240542411804 seconds\n","--- Optimizer learning rate changed from 2.44e-02 to 2.42e-02 ---\n","[2022-04-22 10:04:16,182][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 10:04:17,489][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 10:04:17,490][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 10:04:18,784][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 10:04:18,786][experiments.experiment][INFO] - [EMA] Epoch 54.[Train] time:444.23240542411804 seconds, lr:0.0242, train_loss: 1.9978, unlabeled_losses_real_strong:0.5441,corrrect_unlabeled_num:383143.0,pro_above_threshold_num:391522.0,unlabelled_weak_top1_acc:92.62368232011795,unlabelled_weak_top5_acc:99.72817600518465  \n","[2022-04-22 10:04:18,787][experiments.experiment][INFO] - [EMA] Epoch 54. [Validation] raw_testing_loss: 0.3397, raw test Top1 acc:89.84, raw test Top5 acc: 99.78, ema_testing_loss: 0.2252, ema test Top1 acc:93.74, ema test Top5 acc: 99.86\n","[2022-04-22 10:04:18,789][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 10:11:43,990][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 55: use 445.3093674182892 seconds\n","--- Optimizer learning rate changed from 2.42e-02 to 2.40e-02 ---\n","[2022-04-22 10:11:44,098][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 10:11:45,393][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 10:11:45,393][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 10:11:46,716][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 10:11:46,718][experiments.experiment][INFO] - [EMA] Epoch 55.[Train] time:445.3093674182892 seconds, lr:0.0240, train_loss: 2.0000, unlabeled_losses_real_strong:0.5380,corrrect_unlabeled_num:384456.0,pro_above_threshold_num:392676.0,unlabelled_weak_top1_acc:92.74771448224783,unlabelled_weak_top5_acc:99.72447025030851  \n","[2022-04-22 10:11:46,721][experiments.experiment][INFO] - [EMA] Epoch 55. [Validation] raw_testing_loss: 0.3805, raw test Top1 acc:88.1, raw test Top5 acc: 99.6, ema_testing_loss: 0.2210, ema test Top1 acc:93.96, ema test Top5 acc: 99.84\n","[2022-04-22 10:11:46,820][experiments.experiment][INFO] - [Checkpoints] Epoch 55, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 10:11:46,822][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 10:19:11,731][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 56: use 445.00642490386963 seconds\n","--- Optimizer learning rate changed from 2.40e-02 to 2.38e-02 ---\n","[2022-04-22 10:19:11,829][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 10:19:13,130][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 10:19:13,131][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 10:19:14,524][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 10:19:14,526][experiments.experiment][INFO] - [EMA] Epoch 56.[Train] time:445.00642490386963 seconds, lr:0.0238, train_loss: 1.9890, unlabeled_losses_real_strong:0.5365,corrrect_unlabeled_num:384732.0,pro_above_threshold_num:393142.0,unlabelled_weak_top1_acc:92.8000303953886,unlabelled_weak_top5_acc:99.7209825515747  \n","[2022-04-22 10:19:14,529][experiments.experiment][INFO] - [EMA] Epoch 56. [Validation] raw_testing_loss: 0.3738, raw test Top1 acc:90.0, raw test Top5 acc: 99.54, ema_testing_loss: 0.2212, ema test Top1 acc:93.88, ema test Top5 acc: 99.86\n","[2022-04-22 10:19:14,529][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 10:26:39,756][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 57: use 445.3240349292755 seconds\n","--- Optimizer learning rate changed from 2.38e-02 to 2.36e-02 ---\n","[2022-04-22 10:26:39,853][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 10:26:41,178][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 10:26:41,178][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 10:26:42,557][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 10:26:42,559][experiments.experiment][INFO] - [EMA] Epoch 57.[Train] time:445.3240349292755 seconds, lr:0.0236, train_loss: 1.9801, unlabeled_losses_real_strong:0.5315,corrrect_unlabeled_num:384713.0,pro_above_threshold_num:392956.0,unlabelled_weak_top1_acc:92.78368145227432,unlabelled_weak_top5_acc:99.70659551024437  \n","[2022-04-22 10:26:42,561][experiments.experiment][INFO] - [EMA] Epoch 57. [Validation] raw_testing_loss: 0.3558, raw test Top1 acc:90.08, raw test Top5 acc: 99.54, ema_testing_loss: 0.2188, ema test Top1 acc:93.98, ema test Top5 acc: 99.84\n","[2022-04-22 10:26:42,656][experiments.experiment][INFO] - [Checkpoints] Epoch 57, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 10:26:42,659][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 10:34:06,956][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 58: use 444.39136362075806 seconds\n","--- Optimizer learning rate changed from 2.36e-02 to 2.34e-02 ---\n","[2022-04-22 10:34:07,050][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 10:34:08,435][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 10:34:08,435][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 10:34:09,749][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 10:34:09,750][experiments.experiment][INFO] - [EMA] Epoch 58.[Train] time:444.39136362075806 seconds, lr:0.0234, train_loss: 1.9759, unlabeled_losses_real_strong:0.5333,corrrect_unlabeled_num:385407.0,pro_above_threshold_num:393769.0,unlabelled_weak_top1_acc:92.8227005675435,unlabelled_weak_top5_acc:99.73297157883644  \n","[2022-04-22 10:34:09,752][experiments.experiment][INFO] - [EMA] Epoch 58. [Validation] raw_testing_loss: 0.4361, raw test Top1 acc:88.52, raw test Top5 acc: 99.72, ema_testing_loss: 0.2183, ema test Top1 acc:93.94, ema test Top5 acc: 99.84\n","[2022-04-22 10:34:09,753][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 10:41:32,932][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 59: use 443.2723410129547 seconds\n","--- Optimizer learning rate changed from 2.34e-02 to 2.32e-02 ---\n","[2022-04-22 10:41:33,026][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 10:41:34,356][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 10:41:34,357][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 10:41:35,652][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 10:41:35,653][experiments.experiment][INFO] - [EMA] Epoch 59.[Train] time:443.2723410129547 seconds, lr:0.0232, train_loss: 1.9568, unlabeled_losses_real_strong:0.5286,corrrect_unlabeled_num:386060.0,pro_above_threshold_num:394363.0,unlabelled_weak_top1_acc:92.91708688437939,unlabelled_weak_top5_acc:99.73144572973251  \n","[2022-04-22 10:41:35,655][experiments.experiment][INFO] - [EMA] Epoch 59. [Validation] raw_testing_loss: 0.3642, raw test Top1 acc:90.02, raw test Top5 acc: 99.64, ema_testing_loss: 0.2233, ema test Top1 acc:93.8, ema test Top5 acc: 99.88\n","[2022-04-22 10:41:35,749][experiments.experiment][INFO] - [Checkpoints] Epoch 59, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 10:41:35,759][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 10:48:59,103][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 60: use 443.4433259963989 seconds\n","--- Optimizer learning rate changed from 2.32e-02 to 2.30e-02 ---\n","[2022-04-22 10:48:59,202][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 10:49:00,499][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 10:49:00,499][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 10:49:01,850][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 10:49:01,851][experiments.experiment][INFO] - [EMA] Epoch 60.[Train] time:443.4433259963989 seconds, lr:0.0230, train_loss: 1.9742, unlabeled_losses_real_strong:0.5270,corrrect_unlabeled_num:386435.0,pro_above_threshold_num:394618.0,unlabelled_weak_top1_acc:92.95131036639214,unlabelled_weak_top5_acc:99.7401649877429  \n","[2022-04-22 10:49:01,853][experiments.experiment][INFO] - [EMA] Epoch 60. [Validation] raw_testing_loss: 0.3543, raw test Top1 acc:90.16, raw test Top5 acc: 99.78, ema_testing_loss: 0.2217, ema test Top1 acc:93.9, ema test Top5 acc: 99.84\n","[2022-04-22 10:49:01,855][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 10:56:25,585][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 61: use 443.8271255493164 seconds\n","--- Optimizer learning rate changed from 2.30e-02 to 2.27e-02 ---\n","[2022-04-22 10:56:25,682][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 10:56:27,017][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 10:56:27,017][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 10:56:28,361][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 10:56:28,362][experiments.experiment][INFO] - [EMA] Epoch 61.[Train] time:443.8271255493164 seconds, lr:0.0227, train_loss: 1.9516, unlabeled_losses_real_strong:0.5243,corrrect_unlabeled_num:386659.0,pro_above_threshold_num:394874.0,unlabelled_weak_top1_acc:92.9783402979374,unlabelled_weak_top5_acc:99.73580531030893  \n","[2022-04-22 10:56:28,365][experiments.experiment][INFO] - [EMA] Epoch 61. [Validation] raw_testing_loss: 0.3301, raw test Top1 acc:90.5, raw test Top5 acc: 99.68, ema_testing_loss: 0.2206, ema test Top1 acc:93.88, ema test Top5 acc: 99.86\n","[2022-04-22 10:56:28,457][experiments.experiment][INFO] - [Checkpoints] Epoch 61, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 10:56:28,460][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 11:03:54,393][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 62: use 446.0321843624115 seconds\n","--- Optimizer learning rate changed from 2.27e-02 to 2.25e-02 ---\n","[2022-04-22 11:03:54,492][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 11:03:55,832][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 11:03:55,832][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 11:03:57,120][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 11:03:57,122][experiments.experiment][INFO] - [EMA] Epoch 62.[Train] time:446.0321843624115 seconds, lr:0.0225, train_loss: 1.9497, unlabeled_losses_real_strong:0.5211,corrrect_unlabeled_num:388202.0,pro_above_threshold_num:396447.0,unlabelled_weak_top1_acc:93.07948403060436,unlabelled_weak_top5_acc:99.747358456254  \n","[2022-04-22 11:03:57,123][experiments.experiment][INFO] - [EMA] Epoch 62. [Validation] raw_testing_loss: 0.2910, raw test Top1 acc:91.26, raw test Top5 acc: 99.78, ema_testing_loss: 0.2185, ema test Top1 acc:93.88, ema test Top5 acc: 99.84\n","[2022-04-22 11:03:57,125][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 11:11:22,096][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 63: use 445.0733470916748 seconds\n","--- Optimizer learning rate changed from 2.25e-02 to 2.23e-02 ---\n","[2022-04-22 11:11:22,198][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 11:11:23,533][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 11:11:23,533][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 11:11:24,823][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 11:11:24,825][experiments.experiment][INFO] - [EMA] Epoch 63.[Train] time:445.0733470916748 seconds, lr:0.0223, train_loss: 1.9450, unlabeled_losses_real_strong:0.5169,corrrect_unlabeled_num:388353.0,pro_above_threshold_num:396422.0,unlabelled_weak_top1_acc:93.13594171404839,unlabelled_weak_top5_acc:99.74714041501284  \n","[2022-04-22 11:11:24,827][experiments.experiment][INFO] - [EMA] Epoch 63. [Validation] raw_testing_loss: 0.4031, raw test Top1 acc:89.58, raw test Top5 acc: 99.64, ema_testing_loss: 0.2187, ema test Top1 acc:94.08, ema test Top5 acc: 99.82\n","[2022-04-22 11:11:24,919][experiments.experiment][INFO] - [Checkpoints] Epoch 63, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 11:11:24,927][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 11:18:49,557][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 64: use 444.73373770713806 seconds\n","--- Optimizer learning rate changed from 2.23e-02 to 2.21e-02 ---\n","[2022-04-22 11:18:49,661][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 11:18:50,970][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 11:18:50,971][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 11:18:52,290][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 11:18:52,292][experiments.experiment][INFO] - [EMA] Epoch 64.[Train] time:444.73373770713806 seconds, lr:0.0221, train_loss: 1.9563, unlabeled_losses_real_strong:0.5149,corrrect_unlabeled_num:388841.0,pro_above_threshold_num:397027.0,unlabelled_weak_top1_acc:93.20417023450136,unlabelled_weak_top5_acc:99.75869360566139  \n","[2022-04-22 11:18:52,293][experiments.experiment][INFO] - [EMA] Epoch 64. [Validation] raw_testing_loss: 0.3058, raw test Top1 acc:90.84, raw test Top5 acc: 99.74, ema_testing_loss: 0.2167, ema test Top1 acc:94.0, ema test Top5 acc: 99.84\n","[2022-04-22 11:18:52,294][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 11:26:16,069][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 65: use 443.880250453949 seconds\n","--- Optimizer learning rate changed from 2.21e-02 to 2.18e-02 ---\n","[2022-04-22 11:26:16,174][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 11:26:17,466][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 11:26:17,467][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 11:26:18,796][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 11:26:18,797][experiments.experiment][INFO] - [EMA] Epoch 65.[Train] time:443.880250453949 seconds, lr:0.0218, train_loss: 1.9440, unlabeled_losses_real_strong:0.5112,corrrect_unlabeled_num:389365.0,pro_above_threshold_num:397397.0,unlabelled_weak_top1_acc:93.21049174666405,unlabelled_weak_top5_acc:99.75302602350712  \n","[2022-04-22 11:26:18,799][experiments.experiment][INFO] - [EMA] Epoch 65. [Validation] raw_testing_loss: 0.3628, raw test Top1 acc:89.66, raw test Top5 acc: 99.54, ema_testing_loss: 0.2153, ema test Top1 acc:94.08, ema test Top5 acc: 99.84\n","[2022-04-22 11:26:18,897][experiments.experiment][INFO] - [Checkpoints] Epoch 65, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 11:26:18,899][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 11:33:43,392][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 66: use 444.58986258506775 seconds\n","--- Optimizer learning rate changed from 2.18e-02 to 2.16e-02 ---\n","[2022-04-22 11:33:43,489][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 11:33:44,873][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 11:33:44,873][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 11:33:46,186][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 11:33:46,188][experiments.experiment][INFO] - [EMA] Epoch 66.[Train] time:444.58986258506775 seconds, lr:0.0216, train_loss: 1.9295, unlabeled_losses_real_strong:0.5092,corrrect_unlabeled_num:389653.0,pro_above_threshold_num:397592.0,unlabelled_weak_top1_acc:93.28656767308712,unlabelled_weak_top5_acc:99.75956549495459  \n","[2022-04-22 11:33:46,190][experiments.experiment][INFO] - [EMA] Epoch 66. [Validation] raw_testing_loss: 0.2987, raw test Top1 acc:91.28, raw test Top5 acc: 99.78, ema_testing_loss: 0.2128, ema test Top1 acc:94.32, ema test Top5 acc: 99.86\n","[2022-04-22 11:33:46,191][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 11:41:08,741][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 67: use 442.646226644516 seconds\n","--- Optimizer learning rate changed from 2.16e-02 to 2.14e-02 ---\n","[2022-04-22 11:41:08,837][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 11:41:10,262][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 11:41:10,262][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 11:41:11,571][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 11:41:11,573][experiments.experiment][INFO] - [EMA] Epoch 67.[Train] time:442.646226644516 seconds, lr:0.0214, train_loss: 1.9214, unlabeled_losses_real_strong:0.5069,corrrect_unlabeled_num:390189.0,pro_above_threshold_num:398228.0,unlabelled_weak_top1_acc:93.274578563869,unlabelled_weak_top5_acc:99.76283524930477  \n","[2022-04-22 11:41:11,574][experiments.experiment][INFO] - [EMA] Epoch 67. [Validation] raw_testing_loss: 0.3224, raw test Top1 acc:90.72, raw test Top5 acc: 99.6, ema_testing_loss: 0.2101, ema test Top1 acc:94.34, ema test Top5 acc: 99.86\n","[2022-04-22 11:41:11,680][experiments.experiment][INFO] - [Checkpoints] Epoch 67, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 11:41:11,684][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 11:48:35,255][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 68: use 443.6662743091583 seconds\n","--- Optimizer learning rate changed from 2.14e-02 to 2.11e-02 ---\n","[2022-04-22 11:48:35,350][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 11:48:36,665][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 11:48:36,666][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 11:48:37,981][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 11:48:37,983][experiments.experiment][INFO] - [EMA] Epoch 68.[Train] time:443.6662743091583 seconds, lr:0.0211, train_loss: 1.9228, unlabeled_losses_real_strong:0.5074,corrrect_unlabeled_num:390466.0,pro_above_threshold_num:398555.0,unlabelled_weak_top1_acc:93.25822986662388,unlabelled_weak_top5_acc:99.74648655205965  \n","[2022-04-22 11:48:37,985][experiments.experiment][INFO] - [EMA] Epoch 68. [Validation] raw_testing_loss: 0.3402, raw test Top1 acc:90.62, raw test Top5 acc: 99.78, ema_testing_loss: 0.2095, ema test Top1 acc:94.42, ema test Top5 acc: 99.84\n","[2022-04-22 11:48:37,986][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 11:56:01,346][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 69: use 443.4669222831726 seconds\n","--- Optimizer learning rate changed from 2.11e-02 to 2.09e-02 ---\n","[2022-04-22 11:56:01,453][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 11:56:02,790][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 11:56:02,790][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 11:56:04,099][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 11:56:04,100][experiments.experiment][INFO] - [EMA] Epoch 69.[Train] time:443.4669222831726 seconds, lr:0.0209, train_loss: 1.9119, unlabeled_losses_real_strong:0.5036,corrrect_unlabeled_num:391160.0,pro_above_threshold_num:399232.0,unlabelled_weak_top1_acc:93.34106346219778,unlabelled_weak_top5_acc:99.7562957033515  \n","[2022-04-22 11:56:04,103][experiments.experiment][INFO] - [EMA] Epoch 69. [Validation] raw_testing_loss: 0.2922, raw test Top1 acc:91.58, raw test Top5 acc: 99.54, ema_testing_loss: 0.2078, ema test Top1 acc:94.56, ema test Top5 acc: 99.86\n","[2022-04-22 11:56:04,201][experiments.experiment][INFO] - [Checkpoints] Epoch 69, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 11:56:04,210][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 12:03:27,083][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 70: use 442.97204184532166 seconds\n","--- Optimizer learning rate changed from 2.09e-02 to 2.06e-02 ---\n","[2022-04-22 12:03:27,182][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 12:03:28,483][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 12:03:28,484][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 12:03:29,794][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 12:03:29,796][experiments.experiment][INFO] - [EMA] Epoch 70.[Train] time:442.97204184532166 seconds, lr:0.0206, train_loss: 1.9040, unlabeled_losses_real_strong:0.4998,corrrect_unlabeled_num:391030.0,pro_above_threshold_num:398940.0,unlabelled_weak_top1_acc:93.4038424640894,unlabelled_weak_top5_acc:99.75498791784048  \n","[2022-04-22 12:03:29,798][experiments.experiment][INFO] - [EMA] Epoch 70. [Validation] raw_testing_loss: 0.3311, raw test Top1 acc:90.22, raw test Top5 acc: 99.74, ema_testing_loss: 0.2080, ema test Top1 acc:94.46, ema test Top5 acc: 99.84\n","[2022-04-22 12:03:29,799][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 12:10:54,603][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 71: use 444.8992443084717 seconds\n","--- Optimizer learning rate changed from 2.06e-02 to 2.04e-02 ---\n","[2022-04-22 12:10:54,698][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 12:10:56,048][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 12:10:56,048][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 12:10:57,330][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 12:10:57,331][experiments.experiment][INFO] - [EMA] Epoch 71.[Train] time:444.8992443084717 seconds, lr:0.0204, train_loss: 1.8989, unlabeled_losses_real_strong:0.4994,corrrect_unlabeled_num:392116.0,pro_above_threshold_num:400209.0,unlabelled_weak_top1_acc:93.45942790806293,unlabelled_weak_top5_acc:99.75738570094109  \n","[2022-04-22 12:10:57,332][experiments.experiment][INFO] - [EMA] Epoch 71. [Validation] raw_testing_loss: 0.3407, raw test Top1 acc:90.68, raw test Top5 acc: 99.8, ema_testing_loss: 0.2070, ema test Top1 acc:94.52, ema test Top5 acc: 99.84\n","[2022-04-22 12:10:57,426][experiments.experiment][INFO] - [Checkpoints] Epoch 71, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 12:10:57,429][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 12:18:22,398][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 72: use 445.0667383670807 seconds\n","--- Optimizer learning rate changed from 2.04e-02 to 2.01e-02 ---\n","[2022-04-22 12:18:22,496][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 12:18:23,872][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 12:18:23,873][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 12:18:25,241][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 12:18:25,243][experiments.experiment][INFO] - [EMA] Epoch 72.[Train] time:445.0667383670807 seconds, lr:0.0201, train_loss: 1.9010, unlabeled_losses_real_strong:0.4942,corrrect_unlabeled_num:391986.0,pro_above_threshold_num:399915.0,unlabelled_weak_top1_acc:93.52002714574337,unlabelled_weak_top5_acc:99.76501512527466  \n","[2022-04-22 12:18:25,245][experiments.experiment][INFO] - [EMA] Epoch 72. [Validation] raw_testing_loss: 0.3561, raw test Top1 acc:90.26, raw test Top5 acc: 99.5, ema_testing_loss: 0.2097, ema test Top1 acc:94.4, ema test Top5 acc: 99.86\n","[2022-04-22 12:18:25,245][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 12:25:50,309][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 73: use 445.16832518577576 seconds\n","--- Optimizer learning rate changed from 2.01e-02 to 1.99e-02 ---\n","[2022-04-22 12:25:50,414][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 12:25:51,721][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 12:25:51,722][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 12:25:53,013][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 12:25:53,014][experiments.experiment][INFO] - [EMA] Epoch 73.[Train] time:445.16832518577576 seconds, lr:0.0199, train_loss: 1.9067, unlabeled_losses_real_strong:0.4937,corrrect_unlabeled_num:393000.0,pro_above_threshold_num:400682.0,unlabelled_weak_top1_acc:93.61441364139318,unlabelled_weak_top5_acc:99.76981072872877  \n","[2022-04-22 12:25:53,017][experiments.experiment][INFO] - [EMA] Epoch 73. [Validation] raw_testing_loss: 0.3420, raw test Top1 acc:90.82, raw test Top5 acc: 99.7, ema_testing_loss: 0.2056, ema test Top1 acc:94.4, ema test Top5 acc: 99.88\n","[2022-04-22 12:25:53,116][experiments.experiment][INFO] - [Checkpoints] Epoch 73, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 12:25:53,123][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 12:33:16,301][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 74: use 443.2746591567993 seconds\n","--- Optimizer learning rate changed from 1.99e-02 to 1.96e-02 ---\n","[2022-04-22 12:33:16,397][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 12:33:17,677][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 12:33:17,678][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 12:33:18,993][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 12:33:18,994][experiments.experiment][INFO] - [EMA] Epoch 74.[Train] time:443.2746591567993 seconds, lr:0.0196, train_loss: 1.8876, unlabeled_losses_real_strong:0.4915,corrrect_unlabeled_num:393010.0,pro_above_threshold_num:400870.0,unlabelled_weak_top1_acc:93.57125309854746,unlabelled_weak_top5_acc:99.7552058249712  \n","[2022-04-22 12:33:18,996][experiments.experiment][INFO] - [EMA] Epoch 74. [Validation] raw_testing_loss: 0.3072, raw test Top1 acc:91.2, raw test Top5 acc: 99.76, ema_testing_loss: 0.2086, ema test Top1 acc:94.56, ema test Top5 acc: 99.84\n","[2022-04-22 12:33:18,998][experiments.experiment][INFO] - ***** Running training *****\n","[2022-04-22 12:40:43,240][experiments.experiment][INFO] - [EMA] update buffer()\n","epoch 75: use 444.33688020706177 seconds\n","--- Optimizer learning rate changed from 1.96e-02 to 1.93e-02 ---\n","[2022-04-22 12:40:43,335][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 12:40:44,801][experiments.experiment][INFO] - [EMA] apply shadow\n","[2022-04-22 12:40:44,801][experiments.experiment][INFO] - ***** Running validation *****\n","[2022-04-22 12:40:46,139][experiments.experiment][INFO] - [EMA] restore \n","[2022-04-22 12:40:46,141][experiments.experiment][INFO] - [EMA] Epoch 75.[Train] time:444.33688020706177 seconds, lr:0.0193, train_loss: 1.8866, unlabeled_losses_real_strong:0.4885,corrrect_unlabeled_num:393662.0,pro_above_threshold_num:401633.0,unlabelled_weak_top1_acc:93.59588521718979,unlabelled_weak_top5_acc:99.77526034414768  \n","[2022-04-22 12:40:46,144][experiments.experiment][INFO] - [EMA] Epoch 75. [Validation] raw_testing_loss: 0.3088, raw test Top1 acc:91.16, raw test Top5 acc: 99.76, ema_testing_loss: 0.2087, ema test Top1 acc:94.22, ema test Top5 acc: 99.82\n","[2022-04-22 12:40:46,241][experiments.experiment][INFO] - [Checkpoints] Epoch 75, saving to ./checkpoints/checkpoints_celiali-lambda_unlabled_8/FMExperiment.pth.tar\n","[2022-04-22 12:40:46,250][experiments.experiment][INFO] - ***** Running training *****\n"]}],"source":["!python run.py DATASET.label_num=4000 DATASET.strongaugment='RA' EXPERIMENT.epoch_n=120 EXPERIMENT.batch_size=64 MODEL.name='WideResNet_Lk' MODEL.depth=28 MODEL.widen_factor=2 MODEL.num_classes=10 EXPERIMENT.out_model='./checkpoints/checkpoints_celiali-lambda_unlabled_8/' EXPERIMENT.log_path='./outputs/outputs_lambda_unlabled_8/' EXPERIMENT.save_cfmatrix=False EXPERIMENT.decay_type='cosine' DATASET.cut_type='cutout' EXPERIMENT.lambda_unlabeled=8"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPxo/mOKW0bnw4uCEbst75J","collapsed_sections":[],"name":"celiali-lambda8.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}